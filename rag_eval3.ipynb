{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install deepeval\n",
    "# %pip install python-dotenv\n",
    "# %pip install rouge-score\n",
    "# %pip install nltk\n",
    "# %pip install \"ragas==0.2.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise RuntimeError(\"OPENAI_API_KEY not set in environment variables.\")\n",
    "\n",
    "# Importing metrics from deepeval\n",
    "from deepeval.metrics.ragas import (\n",
    "    RAGASContextualPrecisionMetric,\n",
    "    RAGASFaithfulnessMetric,\n",
    "    RAGASContextualRecallMetric,\n",
    "    RAGASAnswerRelevancyMetric\n",
    ")\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.evaluate import evaluate\n",
    "\n",
    "# Download necessary NLTK data files\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Import NLTK translation metrics\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "# Import ROUGE scorer\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics Overview\n",
    "\n",
    "This evaluation framework assesses our RAG system using both quantitative and qualitative metrics. The quantitative metrics provide objective, automated scores that reflect the similarity, consistency, and factuality of the generated answers. The qualitative metrics capture aspects such as context relevance, diversity, and clarity, which are essential for understanding the overall performance in real-world applications.\n",
    "\n",
    "---\n",
    "\n",
    "### Quantitative Metrics\n",
    "\n",
    "- **BLEUMetric**  \n",
    "  **What it measures:** Similarity between the generated answer and the expected output based on n-gram overlap.  \n",
    "  **Explanation:** Uses NLTK's `sentence_bleu` to compute a BLEU score. A higher score indicates a better overlap with the reference answer.\n",
    "  **Threshold:** >= 0.40.\n",
    "\n",
    "- **ROUGEMetric**  \n",
    "  **What it measures:** Recall-oriented overlap between the generated answer and the expected output.  \n",
    "  **Explanation:** Computes ROUGE-1, ROUGE-2, and ROUGE-L F-measures and averages them. This reflects the degree to which key phrases and overall content are captured.\n",
    "  **Threshold:** >= 0.50.\n",
    "\n",
    "- **METEORMetric**  \n",
    "  **What it measures:** Similarity between the generated answer and the expected output, addressing certain limitations of BLEU.  \n",
    "  **Explanation:** Uses NLTK’s `meteor_score` to compute the METEOR score, providing an alternative perspective on answer quality.\n",
    "  **Threshold:** >= 0.35.\n",
    "\n",
    "- **FactualConsistencyMetric**  \n",
    "  **What it measures:** The factual consistency between the generated answer and the retrieved context.  \n",
    "  **Explanation:** Computes the cosine similarity between the TF-IDF vector representations of the generated answer and the combined retrieval context. A higher score indicates better alignment of the answer with the supporting context.\n",
    "  **Threshold:** >= 0.75.\n",
    "\n",
    "---\n",
    "\n",
    "### Qualitative Metrics\n",
    "\n",
    "- **RAGASContextualPrecisionMetric**  \n",
    "  **What it measures:** Relevance of the retrieved context to the query.  \n",
    "  **Threshold:** >0.7.\n",
    "\n",
    "- **RAGASFaithfulnessMetric**  \n",
    "  **What it measures:** Factual consistency between the generated answer and the retrieved context.  \n",
    "  **Threshold:** >0.7.\n",
    "\n",
    "- **RAGASContextualRecallMetric**  \n",
    "  **What it measures:** Completeness of the retrieved context with respect to the query.  \n",
    "  **Threshold:** >0.7.\n",
    "\n",
    "- **RAGASAnswerRelevancyMetric**  \n",
    "  **What it measures:** Relevance of the generated answer to the query.  \n",
    "  **Threshold:** >0.7.\n",
    "\n",
    "- **ContextualRelevancyMetric (Custom)**  \n",
    "  **What it measures:** Combined relevance of the context and the generated answer to the query, computed via cosine similarity using TF-IDF vectors.  \n",
    "  **Threshold:** >0.65.\n",
    "\n",
    "- **ContextualDiversityMetric (Custom)**  \n",
    "  **What it measures:** Diversity of the retrieved context.  \n",
    "  **Threshold:** >0.5.\n",
    "\n",
    "- **ContextualConsistencyMetric (Custom)**  \n",
    "  **What it measures:** Consistency of the generated answer across multiple queries or context sources.  \n",
    "  **Threshold:** >0.7.\n",
    "\n",
    "- **TechnicalTermClarityMetric (Custom)**  \n",
    "  **What it measures:** Clarity of technical term explanations in the generated answer.  \n",
    "  **Threshold:** At least 1 explanation per technical term.\n",
    "\n",
    "- **QuerySpecificityMetric (Custom)**  \n",
    "  **What it measures:** Specificity of the generated answer relative to the query.  \n",
    "  **Threshold:** >0.7.\n",
    "\n",
    "- **CrossDocumentConsistencyMetric (Custom)**  \n",
    "  **What it measures:** Consistency of the generated answer across multiple documents or context sources.  \n",
    "  **Threshold:** >0.8.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_cases = [\\n    LLMTestCase(\\n        input=\"What is the role of attention mechanisms in Transformers?\",\\n        actual_output=\"Attention mechanisms (components that weigh the importance of different input tokens) enable Transformers to process sequential data efficiently.\",\\n        expected_output=\"Attention mechanisms allow Transformers to focus on relevant parts of the input.\",\\n        context=[\\n            \"\"\"The matching engine processes these orders\\nthrough three sequential phases:\\nFirst, incoming limit orders that do not immediately cross the market are added to\\nthe order book, maintaining strict price-time priority. Second, market orders are processed\\nthrough a two-stage matching algorithm: (a) market-to-market matching, where market\\norders are netted against each other at the current market price, and (b) market-to-book\\nmatching, where remaining market orders are executed against standing limit orders. Finally,\\nany crossing limit orders are matched against the order book.\"\"\"\\n        ],\\n        retrieval_context=[\\n            \"oAttentin mechanisms in Transformers...\",\\n            \"The 2017 paper introduced self-attention...\"\\n        ]\\n    ),\\n    # Add more test cases\\n]\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''test_cases = [\n",
    "    LLMTestCase(\n",
    "        input=\"What is the role of attention mechanisms in Transformers?\",\n",
    "        actual_output=\"Attention mechanisms (components that weigh the importance of different input tokens) enable Transformers to process sequential data efficiently.\",\n",
    "        expected_output=\"Attention mechanisms allow Transformers to focus on relevant parts of the input.\",\n",
    "        context=[\n",
    "            \"\"\"The matching engine processes these orders\n",
    "through three sequential phases:\n",
    "First, incoming limit orders that do not immediately cross the market are added to\n",
    "the order book, maintaining strict price-time priority. Second, market orders are processed\n",
    "through a two-stage matching algorithm: (a) market-to-market matching, where market\n",
    "orders are netted against each other at the current market price, and (b) market-to-book\n",
    "matching, where remaining market orders are executed against standing limit orders. Finally,\n",
    "any crossing limit orders are matched against the order book.\"\"\"\n",
    "        ],\n",
    "        retrieval_context=[\n",
    "            \"oAttentin mechanisms in Transformers...\",\n",
    "            \"The 2017 paper introduced self-attention...\"\n",
    "        ]\n",
    "    ),\n",
    "    # Add more test cases\n",
    "]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BLEUMetric:\n",
    "    \"\"\"\n",
    "    BLEU Metric calculates the BLEU score between the generated answer (actual_output)\n",
    "    and the expected output as a measure of similarity.\n",
    "    \"\"\"\n",
    "    def __init__(self, threshold: float):\n",
    "        # required by DeepEval’s formatter\n",
    "        self.evaluation_model = \"gpt-3.5-turbo\"\n",
    "        self.strict_mode = False\n",
    "        # the pass/fail threshold\n",
    "        self.threshold = threshold\n",
    "\n",
    "        # your own state\n",
    "        self.score = 0.0\n",
    "\n",
    "    def measure(self, test_case: LLMTestCase) -> float:\n",
    "        reference = [test_case.expected_output.split()]\n",
    "        hypothesis = test_case.actual_output.split()\n",
    "        smoothing = SmoothingFunction().method1\n",
    "        self.score = sentence_bleu(reference, hypothesis, smoothing_function=smoothing)\n",
    "        return self.score\n",
    "\n",
    "\n",
    "class ROUGEMetric:\n",
    "    \"\"\"\n",
    "    ROUGE Metric calculates ROUGE scores (e.g., ROUGE-1, ROUGE-2, ROUGE-L) between the\n",
    "    generated answer (actual_output) and the expected output.\n",
    "    \"\"\"\n",
    "    def __init__(self, threshold: float):\n",
    "        # required by DeepEval’s formatter\n",
    "        self.evaluation_model = \"gpt-3.5-turbo\"\n",
    "        self.strict_mode = False\n",
    "        # the pass/fail threshold\n",
    "        self.threshold = threshold\n",
    "\n",
    "        # your own state\n",
    "        self.score = 0.0\n",
    "        self.details = {}\n",
    "\n",
    "    def measure(self, test_case: LLMTestCase) -> float:\n",
    "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "        scores = scorer.score(test_case.expected_output, test_case.actual_output)\n",
    "        self.details = scores\n",
    "        # average the F-measure of each ROUGE variant\n",
    "        self.score = np.mean([s.fmeasure for s in scores.values()])\n",
    "        return self.score\n",
    "\n",
    "\n",
    "class METEORMetric:\n",
    "    \"\"\"\n",
    "    METEOR Metric calculates the METEOR score between the generated answer (actual_output)\n",
    "    and the expected output.\n",
    "    \"\"\"\n",
    "    def __init__(self, threshold: float):\n",
    "        # required by DeepEval’s formatter\n",
    "        self.evaluation_model = \"gpt-3.5-turbo\"\n",
    "        self.strict_mode = False\n",
    "        # the pass/fail threshold\n",
    "        self.threshold = threshold\n",
    "\n",
    "        # your own state\n",
    "        self.score = 0.0\n",
    "\n",
    "    def measure(self, test_case: LLMTestCase) -> float:\n",
    "        self.score = meteor_score([test_case.expected_output], test_case.actual_output)\n",
    "        return self.score\n",
    "\n",
    "\n",
    "class FactualConsistencyMetric:\n",
    "    \"\"\"\n",
    "    FactualConsistencyMetric measures factual consistency between the generated answer \n",
    "    and the retrieval context via TF-IDF cosine similarity.\n",
    "    \"\"\"\n",
    "    def __init__(self, threshold: float):\n",
    "        # required by DeepEval’s formatter\n",
    "        self.evaluation_model = \"gpt-3.5-turbo\"\n",
    "        self.strict_mode = False\n",
    "        # the pass/fail threshold\n",
    "        self.threshold = threshold\n",
    "\n",
    "        # your own state\n",
    "        self.score = 0.0\n",
    "\n",
    "    def measure(self, test_case: LLMTestCase) -> float:\n",
    "        answer = test_case.actual_output\n",
    "        context = \" \".join(test_case.retrieval_context)\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vectors = vectorizer.fit_transform([answer, context])\n",
    "        self.score = cosine_similarity(vectors[0:1], vectors[1:2])[0][0]\n",
    "        return self.score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextualRelevancyMetric:\n",
    "    def __init__(self):\n",
    "        # required by DeepEval’s formatter\n",
    "        self.evaluation_model = \"gpt-3.5-turbo\"\n",
    "        self.strict_mode = False\n",
    "\n",
    "        # your own state\n",
    "        self.score = 0.0\n",
    "\n",
    "    def measure(self, test_case: LLMTestCase) -> float:\n",
    "        query = test_case.input\n",
    "        answer = test_case.actual_output\n",
    "        context = \" \".join(test_case.retrieval_context)\n",
    "        \n",
    "        # Compute similarity between query, answer, and context\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vectors = vectorizer.fit_transform([query, answer, context])\n",
    "        query_answer_sim = cosine_similarity(vectors[0:1], vectors[1:2])[0][0]\n",
    "        query_context_sim = cosine_similarity(vectors[0:1], vectors[2:3])[0][0]\n",
    "        \n",
    "        self.score = (query_answer_sim + query_context_sim) / 2\n",
    "        return self.score\n",
    "    \n",
    "\n",
    "\n",
    "class ContextualDiversityMetric:\n",
    "    def __init__(self):\n",
    "        # required by DeepEval’s formatter\n",
    "        self.evaluation_model = \"gpt-3.5-turbo\"\n",
    "        self.strict_mode = False\n",
    "\n",
    "        # your own state\n",
    "        self.score = 0.0\n",
    "\n",
    "    def measure(self, test_case: LLMTestCase) -> float:\n",
    "        contexts = test_case.retrieval_context\n",
    "        \n",
    "        # Compute pairwise similarity between contexts\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vectors = vectorizer.fit_transform(contexts)\n",
    "        similarity_matrix = cosine_similarity(vectors)\n",
    "        \n",
    "        # Average similarity (lower = more diverse)\n",
    "        avg_similarity = np.mean(similarity_matrix[np.triu_indices(len(contexts), 1)])\n",
    "        self.score = 1 - avg_similarity\n",
    "        return self.score\n",
    "\n",
    "    \n",
    "\n",
    "class ContextualConsistencyMetric:\n",
    "    def __init__(self):\n",
    "        # required by DeepEval’s formatter\n",
    "        self.evaluation_model = \"gpt-3.5-turbo\"\n",
    "        self.strict_mode = False\n",
    "\n",
    "        # your own state\n",
    "        self.score = 0.0\n",
    "\n",
    "    def measure(self, test_case: LLMTestCase) -> float:\n",
    "        contexts = test_case.retrieval_context\n",
    "        answer = test_case.actual_output\n",
    "        \n",
    "        # Check if answer appears in all contexts\n",
    "        consistent = all(answer in ctx for ctx in contexts)\n",
    "        self.score = 1.0 if consistent else 0.0\n",
    "        return self.score\n",
    "\n",
    "    \n",
    "\n",
    "class TechnicalTermClarityMetric:\n",
    "    def __init__(self):\n",
    "        # required by DeepEval’s formatter\n",
    "        self.evaluation_model = \"gpt-3.5-turbo\"\n",
    "        self.strict_mode = False\n",
    "\n",
    "        # your own state\n",
    "        self.score = 0.0\n",
    "        self.explanations = []\n",
    "\n",
    "    def measure(self, test_case: LLMTestCase) -> float:\n",
    "        answer = test_case.actual_output\n",
    "        # Regex to detect terms with explanations in parentheses\n",
    "        pattern = r\"([A-Z][a-zA-Z\\s]+) \\((.+?)\\)\"\n",
    "        matches = re.findall(pattern, answer)\n",
    "        \n",
    "        self.explanations = [term[0] for term in matches]\n",
    "        detected = self._detect_technical_terms(answer)\n",
    "        self.score = len(matches) / len(detected) if detected else 0.0\n",
    "        return self.score\n",
    "\n",
    "    def _detect_technical_terms(self, text: str) -> List[str]:\n",
    "        # Replace with your domain-specific term list\n",
    "        technical_terms = [\"attention mechanisms\", \"Transformers\", \"self-attention\"]\n",
    "        return [term for term in technical_terms if term in text]\n",
    "\n",
    "    \n",
    "\n",
    "class QuerySpecificityMetric:\n",
    "    def __init__(self):\n",
    "        # required by DeepEval’s formatter\n",
    "        self.evaluation_model = \"gpt-3.5-turbo\"\n",
    "        self.strict_mode = False\n",
    "\n",
    "        # your own state\n",
    "        self.score = 0.0\n",
    "\n",
    "    def measure(self, test_case: LLMTestCase) -> float:\n",
    "        query = test_case.input\n",
    "        answer = test_case.actual_output\n",
    "        \n",
    "        # Simple heuristic: Longer answers for specific queries\n",
    "        query_words = len(query.split())\n",
    "        answer_words = len(answer.split())\n",
    "        self.score = min(answer_words / (query_words * 3), 1.0)\n",
    "        return self.score\n",
    "\n",
    "\n",
    "class CrossDocumentConsistencyMetric:\n",
    "    def __init__(self):\n",
    "        # required by DeepEval’s formatter\n",
    "        self.evaluation_model = \"gpt-3.5-turbo\"\n",
    "        self.strict_mode = False\n",
    "\n",
    "        # your own state\n",
    "        self.score = 0.0\n",
    "\n",
    "    def measure(self, test_case: LLMTestCase) -> float:\n",
    "        contexts = test_case.retrieval_context\n",
    "        answer = test_case.actual_output\n",
    "        \n",
    "        # Check if answer appears in all contexts\n",
    "        consistent = all(answer in ctx for ctx in contexts)\n",
    "        self.score = 1.0 if consistent else 0.0\n",
    "        return self.score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rag_system(test_cases):\n",
    "    metrics = [\n",
    "        RAGASContextualPrecisionMetric(threshold=0.7),\n",
    "        RAGASFaithfulnessMetric(threshold=0.7),\n",
    "        RAGASContextualRecallMetric(threshold=0.6),\n",
    "        RAGASAnswerRelevancyMetric(threshold=0.7),\n",
    "        ContextualRelevancyMetric(),\n",
    "        ContextualDiversityMetric(),\n",
    "        ContextualConsistencyMetric(),\n",
    "        TechnicalTermClarityMetric(),\n",
    "        QuerySpecificityMetric(),\n",
    "        CrossDocumentConsistencyMetric(),\n",
    "        BLEUMetric(threshold=0.4),\n",
    "        ROUGEMetric(threshold=0.5),\n",
    "        METEORMetric(threshold=0.35),\n",
    "        FactualConsistencyMetric(threshold=0.75)\n",
    "    ]\n",
    "    \n",
    "    # ←—— HERE’S THE PATCH — assign a __name__ so DeepEval’s logger can pick it up:\n",
    "    for m in metrics:\n",
    "        if not hasattr(m, \"__name__\"):\n",
    "            m.__name__ = m.__class__.__name__\n",
    "    \n",
    "    return evaluate(test_cases, metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2256: SyntaxWarning: invalid escape sequence '\\%'\n",
      "<>:3443: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:3597: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:2256: SyntaxWarning: invalid escape sequence '\\%'\n",
      "<>:3443: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:3597: SyntaxWarning: invalid escape sequence '\\{'\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6124\\1646259826.py:2256: SyntaxWarning: invalid escape sequence '\\%'\n",
      "  \"\"\"Main Cash Account: $988500.00\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6124\\1646259826.py:3443: SyntaxWarning: invalid escape sequence '\\{'\n",
      "  \"\"\"there that the revised index accurately captures the jumps and diffusions in the markets previously unaccounted\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_6124\\1646259826.py:3597: SyntaxWarning: invalid escape sequence '\\{'\n",
      "  \"\"\"Given that performance ratios should satisfy the first two mandatory properties and the two conditional\n"
     ]
    }
   ],
   "source": [
    "test_cases = [\n",
    "    LLMTestCase(\n",
    "        input=\"Could you walk me through the three‑stage matching algorithm the authors implement in their continuous double‑auction market?\",\n",
    "        actual_output = \"\"\"The matching engine in the continuous double-auction market uses a three-stage algorithm:\n",
    "Stage 1: Order Book Population: Incoming limit orders (orders to buy or sell at a specific price or better) that don't immediately find a match are added to the order book. The order book is organized using price-time priority, meaning the best prices are matched first, and if multiple orders exist at the same price, the oldest order is prioritized.\n",
    "Stage 2: Market Order Processing: Market orders (orders to buy or sell at the best available price) are processed in two steps:\n",
    "(a) Market-to-Market Matching: Market buy orders are matched with market sell orders at the current market price. These orders are essentially netted against each other.\n",
    "(b) Market-to-Book Matching: Any remaining market orders are then matched against existing limit orders in the order book.\n",
    "Stage 3: Crossing Limit Order Matching: Any limit orders that cross the market (a buy order with a price higher than the best ask price or a sell order with a price lower than the best bid price) are matched against existing orders in the order book. This ensures that trades occur whenever possible.\"\"\",\n",
    "\n",
    "        expected_output=\"\"\"Orders are handled in three sequential phases: (1) non‑crossing limit orders join the book; (2a) market‑to‑market netting; (2b) market‑to‑book execution; (3) any still‑crossing limit orders are matched.\"\"\",\n",
    "        context=[\n",
    "            \"\"\"The matching engine processes these orders\n",
    "through three sequential phases:\n",
    "First, incoming limit orders that do not immediately cross the market are added to\n",
    "the order book, maintaining strict price-time priority. Second, market orders are processed\n",
    "through a two-stage matching algorithm: (a) market-to-market matching, where market\n",
    "orders are netted against each other at the current market price, and (b) market-to-book\n",
    "matching, where remaining market orders are executed against standing limit orders. Finally,\n",
    "any crossing limit orders are matched against the order book.\"\"\"\n",
    "            \n",
    "        ],\n",
    "        retrieval_context=[\n",
    "    \"\"\"value considerations.\n",
    "In a double auction, buyers and sellers actively submit orders, with trades occurring when\n",
    "compatible buy and sell orders match the price. The matching engine processes these orders\n",
    "through three sequential phases:\n",
    "First, incoming limit orders that do not immediately cross the market are added to\n",
    "the order book, maintaining strict price-time priority. Second, market orders are processed\n",
    "through a two-stage matching algorithm: (a) market-to-market matching, where market\n",
    "orders are netted against each other at the current market price, and (b) market-to-book\n",
    "matching, where remaining market orders are executed against standing limit orders. Finally,\n",
    "any crossing limit orders are matched against the order book.\n",
    "10\n",
    "2.1.2 Implementation Details\n",
    "The matching engine ( MatchingEngine class) implements three primary components that\n",
    "work together to facilitate efficient market operation. The order processing component han-\n",
    "dles the core matching functionality, where market orders are executed immediately against\n",
    "the best available prices in the order book during each trading round. When immediate\n",
    "execution is impossible, limit orders are stored in the order book according to price-time\n",
    "priority. The system supports partial executions, maintaining careful tracking of remaining\n",
    "quantities to ensure complete order fulfillment across multiple trades when necessary.\n",
    "Position management forms the second critical component, providing comprehensive\n",
    "tracking of agent positions and cash balances throughout the trading session. Before any\n",
    "trade execution, the system performs rigorous pre-trade validation to ensure agents have suffi-\n",
    "cient resources to fulfill their orders. This check includes validating buyer cash commitments\n",
    "and shares availability for sellers, with the system maintaining accurate records of commit-\n",
    "ted and available resources for each agent. The position management system updates in\n",
    "real-time as trades are executed, ensuring market integrity and preventing over-commitment\n",
    "of resources.\n",
    "The price formation mechanism constitutes the third component, implementing a sys-\n",
    "tematic price discovery and market monitoring approach. As trades are executed within each\n",
    "round, the system dynamically updates prices based on executed trades while continuously\n",
    "tracking market depth and bid-ask spreads. This data collection provides detailed insights\n",
    "into market liquidity and efficiency. Each trade is logged with comprehensive information,\n",
    "including price, quantity, and participating agents, creating a complete audit trail of mar-\n",
    "ket activity. This comprehensive price formation system ensures transparent price discovery\n",
    "while generating rich data for market quality analysis.\n",
    "11\n",
    "2.1.3 Extensibility Features\n",
    "The framework employs a modular architecture to support diverse experimental configura-\n",
    "tions and research objectives. At its foundation, the system implements configurable market\n",
    "rules and trading constraints that can be adjusted to study different market conditions.\n",
    "The asset model supports fundamental features like dividend payments and interest accrual,\n",
    "enabling research across different market scenarios. Through its modular service-based ar-\n",
    "chitecture, the trading mechanism layer allows for adaptation to other market structures\n",
    "beyond the base double-auction system, such as call auctions or dark pools. Furthermore,\n",
    "the framework provides flexible integration points for different LLM agent types and strate-\n",
    "gies, allowing researchers to experiment with diverse behavioral models and decision-making\n",
    "approaches.\n",
    "This extensible design creates numerous research opportunities for market microstructure\n",
    "studies. Researchers can systematically investigate how different market structures influence\n",
    "price formation and efficiency, evaluate the impact of various trading rules on market qual-\n",
    "ity, and analyze the complex interactions between different agent types and strategies. The\"\"\",\n",
    "    \"\"\"the second agents’ design, and the third the analysis module.\n",
    "8\n",
    "2.1 Market Design\n",
    "Our methodological framework integrates three components that create a controlled envi-\n",
    "ronment for LLM-based trading agents. The framework implements a flexible continuous\n",
    "double-auction market mechanism that couples standard market microstructure principles\n",
    "with market clearing and matching algorithms to accommodate asynchronous LLM decisions.\n",
    "The market clearing process employs a dual-stage matching algorithm. In the first stage,\n",
    "limit orders are posted. In the second stage, market orders are netted using a market-\n",
    "to-market matching engine that processes buy and sell orders, reconciling orders based on\n",
    "available agent cash and share commitments. In the third stage, any remaining market\n",
    "orders are matched against the existing order book, with unfilled quantities converted to\n",
    "aggressive limit orders. This three-tiered approach optimizes immediate execution and price\n",
    "discovery while maintaining market liquidity.\n",
    "The system’s OrderMatchingService orchestrates this process by coordinating trade ex-\n",
    "ecutions through the TradeExecutionService and managing order state transitions via the\n",
    "OrderStateManager. Each trade is logged in detail, with the overall market state—including\n",
    "order books, market depth, and price evolution—recalculated at the end of each trading\n",
    "round.\n",
    "This modular design in the matching and clearing engine provides several advantages.\n",
    "First, it enables rigorous trade validation where each market order is validated against agent\n",
    "cash commitments and position constraints before matching, with the system dynamically\n",
    "adjusting order quantities based on available cash when an agent’s commitment is insuf-\n",
    "ficient, thus minimizing execution errors. Second, it offers flexible liquidity handling by\n",
    "supporting market-to-market and market-to-book matching, ensuring orders have multiple\n",
    "execution pathways, with unexecuted market orders converted to aggressive limit orders to\n",
    "capture remaining liquidity. Third, it maintains detailed trade audit capabilities by recording\n",
    "comprehensive traceability data including timestamps, trade volumes, executed prices, and\n",
    "agent identifiers, thereby enabling post-trade analysis and performance benchmarking that\n",
    "9\n",
    "serves as the foundation for subsequent market efficiency and agent performance validations.\n",
    "2.1.1 Market Mechanism Design\n",
    "Our framework implements a continuous double-auction market mechanism that processes\n",
    "orders in discrete trading rounds. We use discrete trading rounds because LLMs have latency\n",
    "constraints, making it infeasible to process orders in real time. Within each round, the order\n",
    "of agent submissions is randomized to avoid giving systematic priority to specific agents,\n",
    "thus simulating concurrent order arrival while maintaining fairness. Once randomized, or-\n",
    "ders are then processed according to standard price-time priority rules. The system supports\n",
    "finite and infinite horizon markets, with differences in terminal conditions and wealth cal-\n",
    "culation. In finite-horizon markets, agents are informed of the total number of rounds, and\n",
    "their terminal wealth is calculated by redeeming all shares at the fundamental value of the\n",
    "final round. In infinite-horizon markets, no terminal information is provided to agents, and\n",
    "final wealth is determined using the last market price for share valuation. This design choice\n",
    "enables researchers to study how time horizons influence trading strategies and price for-\n",
    "mation, particularly how agents balance short-term trading opportunities against long-term\n",
    "value considerations.\n",
    "In a double auction, buyers and sellers actively submit orders, with trades occurring when\n",
    "compatible buy and sell orders match the price. The matching engine processes these orders\n",
    "through three sequential phases:\n",
    "First, incoming limit orders that do not immediately cross the market are added to\n",
    "the order book, maintaining strict price-time priority. Second, market orders are processed\"\"\",\n",
    "    \"\"\"2024). Another examines LLMs’ strategic capabilities through task-based simulations and\n",
    "collaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\n",
    "Within the computer science literature, early works apply LLMs to financial markets but\n",
    "abstract away many fundamental stock market characteristics. Often, they employ single-\n",
    "price clearing mechanisms without a persistent order book, ignore partial fills and bid-ask\n",
    "spreads, and omit dividends. Consequently, these simplified environments can primarily\n",
    "address exogenous macro shocks (e.g., changes in interest rates or inflation; Gao et al. 2024),\n",
    "exogenous policy changes (Zhang et al. 2024), or rely on advanced methods such as repetitive\n",
    "next-token predictions to generate better answers (Koa et al. 2024). This work extends\n",
    "these efforts by incorporating these crucial market features, enabling the study of complex\n",
    "endogenous events such as flash crashes, liquidity shocks, and large-trader impacts.\n",
    "This work also connects to emerging research on algorithmic and AI-powered trading\n",
    "systems. Dou, Goldstein, and Ji (2024) demonstrate how reinforcement learning-based AI\n",
    "speculators can autonomously learn to sustain collusive behavior without explicit coordi-\n",
    "nation, achieving supra-competitive profits through either price-trigger strategies or self-\n",
    "confirming bias in learning. This finding is particularly informative for this framework as\n",
    "it highlights potential emergent behaviors that may arise when intelligent agents interact in\n",
    "7\n",
    "markets—behaviors that could manifest differently with LLM agents due to their natural\n",
    "language reasoning capabilities. Similarly, Colliard, Foucault, and Lovo (2022) examine al-\n",
    "gorithmic market makers using Q-learning and find they charge markups that increase when\n",
    "adverse selection costs decrease—contrary to Nash equilibrium predictions. Their work pro-\n",
    "vides methodological insights on how to test strategic pricing behaviors against theoretical\n",
    "benchmarks incorporated into this LLM-based framework.\n",
    "Finally, this approach is informed by complexity economics, which views markets as dy-\n",
    "namic, non-equilibrium systems where agents adaptively learn and evolve strategies (Arthur\n",
    "2013; Wolfram 2017). According to this view, markets exhibit emergent phenomena and\n",
    "self-organization, especially when trading agents (human or artificial) update their behav-\n",
    "ior in response to outcomes. This paradigm is particularly relevant in an era of increasing\n",
    "automation and algorithmic trading (Balland et al. 2022; Ping 2019). Like adaptive agents\n",
    "in complexity economics, these LLM traders incorporate new information and adjust their\n",
    "strategies, generating emergent market patterns—a key motivation behind this framework.\n",
    "Unlike previous frameworks that abstract away crucial market features or focus on narrow\n",
    "strategies, this system incorporates realistic market microstructure while accommodating\n",
    "heterogeneous agents interacting simultaneously. While earlier work demonstrates LLMs’\n",
    "promise for macroeconomic modeling and simple trading simulations, this work introduces a\n",
    "complex, open-source financial market platform that supports multiple agent architectures,\n",
    "thorough market microstructure (limit orders, partial fills, dividends), and rigorous testing\n",
    "protocols—fulfilling a critical need in complexity economics research and market microstruc-\n",
    "ture analysis.\n",
    "2 Methodology\n",
    "The methodology section contains three parts. The first part describes the market design,\n",
    "the second agents’ design, and the third the analysis module.\n",
    "8\n",
    "2.1 Market Design\n",
    "Our methodological framework integrates three components that create a controlled envi-\n",
    "ronment for LLM-based trading agents. The framework implements a flexible continuous\n",
    "double-auction market mechanism that couples standard market microstructure principles\n",
    "with market clearing and matching algorithms to accommodate asynchronous LLM decisions.\"\"\",\n",
    "    \"\"\"by detailed Trade Data, which records individual transaction details such as prices, quan-\n",
    "tities, buyer and seller identifiers, timestamps, round information, and specific execution\n",
    "details.\n",
    "Agent Data provides insights into participant behavior by monitoring cash and share\n",
    "25\n",
    "Figure 5: Order Type Analysis under Systematic Variation. Displays the proportion of\n",
    "Market vs. Limit orders used by different agent types across varying Price/Fundamental\n",
    "ratios.\n",
    "26\n",
    "positions, portfolio values, wealth evolution, and agent type and strategy identifiers. Or-\n",
    "der Data captures the complete lifecycle of trading decisions, including order specifications\n",
    "(type, size, price), agent reasoning and justification, decision context and timing, and order\n",
    "lifecycle events. Finally, Market State data maintains a comprehensive view of overall mar-\n",
    "ket conditions through order book snapshots, market depth information, aggregate statistics,\n",
    "and various market microstructure metrics.\n",
    "2.3.3 Data Validation and Storage\n",
    "The system implements a comprehensive set of data quality measures to ensure reliability and\n",
    "consistency. The validation framework performs continuous checks for data completeness,\n",
    "verifies consistency across related data streams, enforces format and type validation, and\n",
    "maintains proper temporal sequencing of all recorded events. These validation mechanisms\n",
    "work together to maintain data integrity throughout the experimental process.\n",
    "The storage architecture employs multiple formats optimized for different data types and\n",
    "use cases. Structured CSV files store tabular data for efficient analysis, while JSON formats\n",
    "accommodate complex nested structures that preserve the rich relationships between market\n",
    "elements. The system maintains detailed timestamped logs for debugging purposes and\n",
    "generates summary statistics to facilitate quick analysis of experimental outcomes.\n",
    "This comprehensive data collection architecture enables researchers to conduct detailed\n",
    "analysis of market dynamics, validate agent behavior patterns, ensure experiment repro-\n",
    "ducibility, and perform meaningful cross-experiment comparisons. The integrated approach\n",
    "to data management provides the foundation for rigorous empirical investigation of market\n",
    "behavior and agent interactions.\n",
    "The framework implements specialized visualization techniques to analyze agent behavior\n",
    "and market dynamics. Decision heatmaps plot agent actions across trading rounds, reveal-\n",
    "ing strategic patterns and consistency. Trading flow visualizations track cumulative position\n",
    "changes, identifying net buyers and sellers throughout market evolution. Reasoning word-\n",
    "27\n",
    "clouds extract key terms from agent explanations, providing insight into decision drivers\n",
    "across different agent types.\n",
    "The system also generates specialized market quality visualizations including bid-ask\n",
    "spread evolution, price target accuracy, and agent valuation tracking. These visualizations\n",
    "work in concert with the numerical metrics to provide both quantitative and qualitative\n",
    "insights into agent behavior and market dynamics.\n",
    "2.3.4 Validation Metrics and Performance Monitoring\n",
    "The framework implements a comprehensive set of performance metrics and visualization\n",
    "tools that monitor agent behavior and market dynamics. Market evolution visualizations\n",
    "track price movements relative to fundamental values, including time series of transaction\n",
    "prices, midpoint prices, and bid-ask spreads. These visualizations enable researchers to assess\n",
    "market efficiency and price discovery processes throughout the simulation.\n",
    "Agent performance metrics include absolute position tracking (shares, cash, and total\n",
    "wealth), wealth composition analysis, position change metrics, and return calculations. The\n",
    "system computes both absolute and percentage returns on various portfolio components\n",
    "and compares performance across agent types to identify relative advantages of different\"\"\",\n",
    "    \"\"\"value, the system:\n",
    "1. Sets market price P = ρV where ρ is the target ratio\n",
    "2. Generates a consistent order book structure around this price\n",
    "3. Executes multiple decision trials with the same agent type\n",
    "4. Records decision outcomes (buy/sell/hold), order types, quantities, and reasoning\n",
    "This process maps how LLM agents respond to different price environments, as illustrated\n",
    "in Figures 2, 3, 4, and 5. The analysis reveals clear patterns in decision boundaries, with\n",
    "distinct transitions between buying, selling, and holding regions that vary by agent type. For\n",
    "example, value investors show strong buying tendencies when prices are below fundamental\n",
    "value (ρ <1) and selling preferences when prices exceed fundamentals ( ρ >1). In contrast,\n",
    "momentum traders show less sensitivity to the fundamental ratio and more responsiveness\n",
    "to recent price trends.\n",
    "The systematic variation approach also reveals patterns in order sizing and limit price\n",
    "selection, with agents typically placing larger orders when prices deviate significantly from\n",
    "their valuation models (Figure 4). This methodology provides unprecedented transparency\n",
    "into LLM decision processes and enables quantitative comparison of different agent types\n",
    "and LLM architectures.\n",
    "22\n",
    "Figure 2: Price Analysis under Systematic Variation. Shows how agent valuation estimates\n",
    "and price targets respond to varying Price/Fundamental ratios.\n",
    "The decision analysis can be customized for different experimental designs. For example,\n",
    "researchers can use the framework to study the impact of various market conditions on agent\n",
    "behavior by varying other market parameters or the effect of different agent types on market\n",
    "dynamics by changing the agent population.\n",
    "2.3 Data Collection and Analysis\n",
    "Evaluating LLM trading agents requires robust methodologies for capturing, processing,\n",
    "and analyzing their behavior in market environments. The framework implements a com-\n",
    "prehensive analytics module that tracks all market activity, agent decisions, and performance\n",
    "metrics throughout experimental runs. This multi-layered approach not only records what\n",
    "happens in each simulation but also provides insights into why agents make specific deci-\n",
    "sions, enabling researchers to validate agent behavior against their defined strategies and\n",
    "assess overall market dynamics. The following sections detail the key components of this\n",
    "analytics infrastructure.\n",
    "23\n",
    "Figure 3: Trading Decision Distribution under Systematic Variation. Illustrates the proba-\n",
    "bility of Buy, Sell, or Hold decisions across different agent types as the Price/Fundamental\n",
    "ratio changes.\n",
    "24\n",
    "Figure 4: Order Size Distribution under Systematic Variation. Shows the average quan-\n",
    "tity traded (as a percentage of initial shares) for Buy and Sell orders across different\n",
    "Price/Fundamental ratios.\n",
    "2.3.1 Data Collection Architecture\n",
    "The framework implements a comprehensive data collection system that captures multiple\n",
    "dimensions of market behavior and agent decision-making. This structured approach ensures\n",
    "reproducibility and enables detailed analysis of market dynamics.\n",
    "2.3.2 Core Data Streams\n",
    "The system captures five primary data streams that work together to provide a complete\n",
    "picture of market activity. Market Data forms the foundation, tracking essential metrics\n",
    "including price evolution, fundamental values, trading volumes, order book depth, market\n",
    "liquidity, best bid/ask prices, spreads, and price-fundamental ratios. This is complemented\n",
    "by detailed Trade Data, which records individual transaction details such as prices, quan-\n",
    "tities, buyer and seller identifiers, timestamps, round information, and specific execution\n",
    "details.\n",
    "Agent Data provides insights into participant behavior by monitoring cash and share\n",
    "25\n",
    "Figure 5: Order Type Analysis under Systematic Variation. Displays the proportion of\n",
    "Market vs. Limit orders used by different agent types across varying Price/Fundamental\n",
    "ratios.\n",
    "26\"\"\",\n",
    "    \"\"\"The theory of intermediation developed in Chapter 14 focuses on the risk-pooling and\n",
    "risk-sharing products created by ﬁnancial-services institutions. Products examined\n",
    "range from standardized instruments such as a group of mutual funds with charac-\n",
    "teristics described in Theorem 15.5 to custom products tailored to meet the speciﬁc\n",
    "requirements of each investor. Contingent-claims analysis (CCA) is the tool used\n",
    "to derive the production technologies and costs for intermediaries to create these\n",
    "custom derivative securities. As discussed, such ﬁnancial products and the associ-\n",
    "ated activities of their producers are redundant in a frictionless environment with no\n",
    "information-gathering or transactions costs. Thus, to provide a nontrivial role for\n",
    "intermediaries in our equilibrium analysis here, we assume that some investors and\n",
    "business ﬁrms face transactions costs for trading and issuing securities directly in\n",
    "the capital markets. However, to preserve the CCA production theory for intermedi-\n",
    "aries, we follow the model in Chapter 14 and posit that ﬁnancial intermediaries, as\n",
    "the lowest-cost transactors, can trade continuously in the capital market at no cost.\n",
    "2In this chapter, the returns on he growth-optimum portfolio are perfectly correlated with a combination of\n",
    "themtraded securities used to hedge against state-variable changes. Hence, them m+ 2spanning funds of\n",
    "Theorem 15.5 reduce to in m+ 1funds.\n",
    "16.2 Financial Intermediation with Dynamically-Complete Markets 417\n",
    "In applying this model to derive equilibrium prices and allocations, we shall further\n",
    "assume that the ﬁnancial-services industry is competitive so that ﬁnancial-product\n",
    "prices equal their marginal production costs.\n",
    "In the production theory of Chapter 14, a manufacturing technology is developed\n",
    "to create Arrow-Debreu securities that are contingent on traded asset prices. In this\n",
    "section, we generalize that analysis to derive the production technology and cost\n",
    "for intermediaries to create a complete set of Arrow-Debreu securities with payoffs\n",
    "contingent on the state of the economy S(t)at each time t.\n",
    "From (16.2), we can express ρijdt≡dqidqj,i,j= 1,. .. , n as functions of ρkiand\n",
    "δij,k, i= 1,. . ., m andj=m+ 1,. .. , n . Deﬁne hjby\n",
    "hj≡\n",
    "fj−r−gjαj−r\n",
    "σjj= 1,. . ., m\n",
    "fj−r−gjm∑\n",
    "i=1δijαi−r\n",
    "σij=m+ 1,. .. , n(16.6)\n",
    "LetΠ(S, t;S,τ)denote the solution to the linear partial differential equation\n",
    "0 =1\n",
    "2n∑\n",
    "i=1n∑\n",
    "j=1gigjρijSiSjΠij+n∑\n",
    "j=1(r+hj)SjΠj+ Πt−rΠ (16.7)\n",
    "subject to the boundary conditions that Π(S, t;S,τ)≥0and∫∞\n",
    "0···∫∞\n",
    "0Π(S, t;S,τ)dS1···dSn\n",
    "exists for all Sandt < τ < ∞;Π(S, t;S,τ) =δ(S1−S1)δ(S2−S2)···δ(Sn−Sn)\n",
    "where δ(·)is the Dirac delta function and S≡[S1,. . .,Sn]is a vector of speciﬁed pos-\n",
    "itive numbers. Subscripts on Πdenote partial derivatives with respect to S1,. .. , S n,\n",
    "andt.{hj,gj,r,ρij}are functions of Sandt, and under mild regularity conditions on\n",
    "these functions, a solution to (16.7) exists and is unique.\n",
    "Consider the continuous-trading portfolio strategy that allocates fraction\n",
    "xj(t) =ΠjgjSj+∑n\n",
    "k=m+1ΠkgkSkδjk\n",
    "σjV(t)(16.8)\n",
    "to traded asset j,j= 1,. .. , m and fraction 1−∑m\n",
    "1xj(t)to the riskless security at\n",
    "timet, where V(t)denotes the current value of the portfolio. It follows from (16.3),\n",
    "(16.6), and (16.8) that the dynamics of the portfolio value can be written as\n",
    "dV=V\n",
    "m∑\n",
    "j=1xj(αj−r) +r\n",
    "dt+m∑\n",
    "j=1xjσjdzj\n",
    "=\n",
    "rV+n∑\n",
    "j=1ΠjSj(fj−hj−r)\n",
    "dt+m∑\n",
    "j=1(\n",
    "ΠjgjSj+n∑\n",
    "k=m+1ΠkgkSkδjk)\n",
    "dzj\n",
    "=\n",
    "rV+n∑\n",
    "j=1ΠjSj(fj−hj−r)\n",
    "dt+n∑\n",
    "j=1ΠjgjSjdqj\n",
    "(16.9)\n",
    "because, from (16.2), dqk=∑m\n",
    "1δjkdqj,k=m+1,. . ., n , and, from (16.4), dzj=dqj,\n",
    "j= 1,. .. , m .\n",
    "418 A Complete-Markets General Equilibrium Theory of Finance in Continuous Time\n",
    "Πis a solution to (16.7) and is therefore twice-continuously differentiable. Thus,\n",
    "Itˆo’s lemma can be used to describe the stochastic process for Y(t)≡Π[S(t),t;S,τ]\n",
    "as\n",
    "dY=\n",
    "1\n",
    "2n∑\n",
    "i=1n∑\n",
    "j=1gigjρijSiSjΠij+n∑\n",
    "j=1ΠjfjSj+ Πt\n",
    "dt+n∑\n",
    "j=1ΠjgjSjdqj(16.10)\n",
    "where Πand its derivatives are evaluated at S=S(t)at each time t. Because Π\"\"\",\n",
    "    \"\"\"allocations are brieﬂy addressed in Chapter 15 and analyzed more fully in Chapter 16. If a set of existing\n",
    "securities and markets leads to an equilibrium that is an unconstrained Pareto optimum, then any additional\n",
    "securities or markets will be redundant.\n",
    "50The term “transactions costs” can, of course, mean more than just the bid-ask spread or commissions\n",
    "paid for buying and selling assets. For example, if an investor literally traded his portfolio continuously, he\n",
    "would have no time to do anything else! Because investment management and ﬁnancial intermediation involve\n",
    "primarily information processing and security trading, there arc signiﬁcant economies of scale. One would thus\n",
    "expect substantially lower costs for the individual investor to use intermediaries instead of transacting directly\n",
    "in the asset markets.\n",
    "368 Financial Intermediation in the Continuous-Time Model\n",
    "It would seem therefore that the same dichotomy derived in the frictionless-market\n",
    "case applies also to our model with transactions costs. In a formal computational\n",
    "sense it does. We can still solve for the equilibrium asset-price dynamics in the model\n",
    "of Chapter 15 and then compute the prices of derivative securities, mutual funds, and\n",
    "corporate liabilities using CCA. There is one signiﬁcant difference, however: the\n",
    "ﬁrst-part calculation of equilibrium real-sector allocations is valid if and only if there\n",
    "exists a sufﬁciently rich set of securities and intermediaries in the ﬁnancial sector to\n",
    "make these allocations feasible for agents who cannot trade without cost. Because\n",
    "of this conditioning. perhaps a more appropriate term for this separation is “quasi-\n",
    "dichotomy.”\n",
    "With the assumption that not all agents can trade continuously without cost, a\n",
    "signiﬁcant economic role is established for derivative-security markets and ﬁnancial\n",
    "intermediaries in the model. Somewhat paradoxically, we ﬁnd that, if intermediation\n",
    "is efﬁcient, then derivative securities and the ﬁnancial products of the intermediaries\n",
    "will be priced as if they are redundant.51Under these conditions, quasi-dichotomy\n",
    "obtains, and we can derive equilibrium real-sector allocations and asset prices from\n",
    "the frictionless-market version of the model.\n",
    "14.6 Afterword: Policy and Strategy in Financial Intermediation\n",
    "In this chapter, as throughout the book, the focus has been on theory. Allusions to\n",
    "practice were concentrated on the micro quantitative applications of the continuous-\n",
    "time model to product technologies and risk management. Still, I cannot wholly\n",
    "resist the temptation to call attention to the model’s potential for addressing broader\n",
    "issues in the practice of intermediation. And so this afterword shall ever so brieﬂy\n",
    "touch upon implications of the model for intermediation policy and strategy in the\n",
    "hope that it will lead others, better qualiﬁed, to explore this matter elsewhere.\n",
    "Derivative securities have long been an integral part of the ﬁnancial markets,52\n",
    "but most would mark the creation of the Chicago Board Options Exchange in April\n",
    "1973 as the start of the current wave of ﬁnancial innovations involving derivative\n",
    "securities. The succeeding years have witnessed an unprecedented proliferation of\n",
    "organized trading markets in both equity and ﬁxed-income derivative instruments.\n",
    "In turn, these markets made possible the creation of a wide range of ﬁnancial prod-\n",
    "51Thus, our model provides a resolution to Hakansson’s (1979, p. 722) “The Catch 22 of Option Pricing.”\n",
    "Although the equilibrium prices of options and other derivative securities satisfy the redundancy condition of\n",
    "CCA, they are nevertheless needed to support the equilibrium allocations, and hence their elimination would\n",
    "reduce social welfare.\n",
    "52Bernstein (1992) reports that Aristotle’s anecdote about Thales in Book I of Politics is the ﬁrst recorded\n",
    "mention of a ﬁnancial option. Schaede (1988) makes the case that the Dojima rice market in Osaka was a\"\"\",\n",
    "    \"\"\"market efficiency and price discovery processes throughout the simulation.\n",
    "Agent performance metrics include absolute position tracking (shares, cash, and total\n",
    "wealth), wealth composition analysis, position change metrics, and return calculations. The\n",
    "system computes both absolute and percentage returns on various portfolio components\n",
    "and compares performance across agent types to identify relative advantages of different\n",
    "strategies. Trading flow analysis visualizes the volume of shares moving between different\n",
    "agent types and cumulative net trading flows, revealing which agents act as net buyers or\n",
    "sellers in different market conditions.\n",
    "Decision pattern analysis employs heatmaps to visualize the consistency of agent decision-\n",
    "making over time, allowing researchers to identify shifts in strategic behavior. This is com-\n",
    "plemented by decision quantities visualization that plots order sizes to highlight variations\n",
    "in trade aggressiveness across agent types. When agent reasoning data is available, the\n",
    "system generates wordclouds to extract key terms from agent explanations, providing qual-\n",
    "itative insights into decision drivers for different agent strategies. Additional visualizations\n",
    "track price target accuracy and compare agent-specific valuations to realized market prices,\n",
    "28\n",
    "offering insights into the forecasting abilities of different agents.\n",
    "A key advantage of simulation-based analysis is complete observability of all market\n",
    "processes and agent states. Unlike real-world markets where data availability is often limited,\n",
    "the framework captures every interaction, decision, and state change with perfect fidelity.\n",
    "This comprehensive data collection allows researchers to compute additional metrics beyond\n",
    "standard market measures, enabling novel analyses such as counterfactual testing (e.g., how\n",
    "would markets evolve with different agent compositions), causal inference of specific agent\n",
    "behaviors on market outcomes, and the development of custom efficiency or stability metrics\n",
    "tailored to particular research questions. The system’s modular design facilitates rapid\n",
    "implementation of new metrics and visualizations as research questions evolve.\n",
    "3 Experimental Design and Results\n",
    "Our experimental framework implements a dividend-paying asset market with heterogeneous\n",
    "agents. The baseline simulation runs for 15 to 20 rounds with 8 participating agents, although\n",
    "these parameters are fully configurable. Each agent begins with an initial endowment of\n",
    "1,000,000 monetary units and 10,000 shares of the asset. The fundamental value of the asset\n",
    "is set at $28.00, with a final redemption value matching this fundamental price in finite\n",
    "horizon scenarios. Transaction costs are set to zero to isolate the effects of agent behavior\n",
    "and market structure.\n",
    "The dividend structure follows a stochastic process with a base payment of $1.40 and a\n",
    "variation of ±$1.00, paid with 50% probability each round. This design creates uncertainty\n",
    "in the asset’s income stream while maintaining a known expected value. Cash holdings earn\n",
    "a risk-free interest rate of 5% per round, providing an opportunity cost for asset investment.\n",
    "Agent composition is controlled through a flexible distribution system that allows for\n",
    "various experimental configurations. In our baseline setup, we employ a mixed population\n",
    "of value investors, momentum traders, and market makers. Each agent type implements\n",
    "29\n",
    "distinct trading strategies through Large Language Model (LLM) prompts, with GPT-4o as\n",
    "the decision-making engine.\n",
    "The data collection system captures comprehensive market activity across multiple di-\n",
    "mensions. At the market level, it tracks the evolution of prices, fundamental values, and\n",
    "realized dividends, providing insights into overall market dynamics. Individual agent data\n",
    "includes detailed wealth trajectories and portfolio compositions, enabling analysis of strategy\n",
    "effectiveness and wealth distribution patterns. The system maintains complete transaction\"\"\",\n",
    "]\n",
    "\n",
    "    ),\n",
    "    LLMTestCase(\n",
    "        input=\"Why do the authors choose discrete trading rounds instead of real‑time order processing for the LLM agents?\",\n",
    "        actual_output = \"\"\"LLMs (Large Language Models, AI models that can understand and generate human-like text) have latency constraints (delays in processing information). This makes real-time order processing infeasible, so the authors use discrete trading rounds instead.\"\"\",\n",
    "\n",
    "        expected_output=\"\"\"LLMs have latency; discrete rounds let agents think while still approximating concurrency via randomised order of submission.\"\"\",\n",
    "        context=[\n",
    "            \"\"\"When the market starts significantly above\n",
    "the fundamental value (left panels), the price fails to converge downwards towards the $28.00\n",
    "benchmark within the 15 rounds, remaining substantially elevated. Agent valuations mirror\n",
    "this persistence, with many agents maintaining estimates well above the fundamental value.\n",
    "However, when the market begins significantly below the fundamental value\"\"\"\n",
    "            \n",
    "        ],\n",
    "        retrieval_context=[\n",
    "    \"\"\"the second agents’ design, and the third the analysis module.\n",
    "8\n",
    "2.1 Market Design\n",
    "Our methodological framework integrates three components that create a controlled envi-\n",
    "ronment for LLM-based trading agents. The framework implements a flexible continuous\n",
    "double-auction market mechanism that couples standard market microstructure principles\n",
    "with market clearing and matching algorithms to accommodate asynchronous LLM decisions.\n",
    "The market clearing process employs a dual-stage matching algorithm. In the first stage,\n",
    "limit orders are posted. In the second stage, market orders are netted using a market-\n",
    "to-market matching engine that processes buy and sell orders, reconciling orders based on\n",
    "available agent cash and share commitments. In the third stage, any remaining market\n",
    "orders are matched against the existing order book, with unfilled quantities converted to\n",
    "aggressive limit orders. This three-tiered approach optimizes immediate execution and price\n",
    "discovery while maintaining market liquidity.\n",
    "The system’s OrderMatchingService orchestrates this process by coordinating trade ex-\n",
    "ecutions through the TradeExecutionService and managing order state transitions via the\n",
    "OrderStateManager. Each trade is logged in detail, with the overall market state—including\n",
    "order books, market depth, and price evolution—recalculated at the end of each trading\n",
    "round.\n",
    "This modular design in the matching and clearing engine provides several advantages.\n",
    "First, it enables rigorous trade validation where each market order is validated against agent\n",
    "cash commitments and position constraints before matching, with the system dynamically\n",
    "adjusting order quantities based on available cash when an agent’s commitment is insuf-\n",
    "ficient, thus minimizing execution errors. Second, it offers flexible liquidity handling by\n",
    "supporting market-to-market and market-to-book matching, ensuring orders have multiple\n",
    "execution pathways, with unexecuted market orders converted to aggressive limit orders to\n",
    "capture remaining liquidity. Third, it maintains detailed trade audit capabilities by recording\n",
    "comprehensive traceability data including timestamps, trade volumes, executed prices, and\n",
    "agent identifiers, thereby enabling post-trade analysis and performance benchmarking that\n",
    "9\n",
    "serves as the foundation for subsequent market efficiency and agent performance validations.\n",
    "2.1.1 Market Mechanism Design\n",
    "Our framework implements a continuous double-auction market mechanism that processes\n",
    "orders in discrete trading rounds. We use discrete trading rounds because LLMs have latency\n",
    "constraints, making it infeasible to process orders in real time. Within each round, the order\n",
    "of agent submissions is randomized to avoid giving systematic priority to specific agents,\n",
    "thus simulating concurrent order arrival while maintaining fairness. Once randomized, or-\n",
    "ders are then processed according to standard price-time priority rules. The system supports\n",
    "finite and infinite horizon markets, with differences in terminal conditions and wealth cal-\n",
    "culation. In finite-horizon markets, agents are informed of the total number of rounds, and\n",
    "their terminal wealth is calculated by redeeming all shares at the fundamental value of the\n",
    "final round. In infinite-horizon markets, no terminal information is provided to agents, and\n",
    "final wealth is determined using the last market price for share valuation. This design choice\n",
    "enables researchers to study how time horizons influence trading strategies and price for-\n",
    "mation, particularly how agents balance short-term trading opportunities against long-term\n",
    "value considerations.\n",
    "In a double auction, buyers and sellers actively submit orders, with trades occurring when\n",
    "compatible buy and sell orders match the price. The matching engine processes these orders\n",
    "through three sequential phases:\n",
    "First, incoming limit orders that do not immediately cross the market are added to\n",
    "the order book, maintaining strict price-time priority. Second, market orders are processed\"\"\",\n",
    "    \"\"\"2024). Another examines LLMs’ strategic capabilities through task-based simulations and\n",
    "collaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\n",
    "Within the computer science literature, early works apply LLMs to financial markets but\n",
    "abstract away many fundamental stock market characteristics. Often, they employ single-\n",
    "price clearing mechanisms without a persistent order book, ignore partial fills and bid-ask\n",
    "spreads, and omit dividends. Consequently, these simplified environments can primarily\n",
    "address exogenous macro shocks (e.g., changes in interest rates or inflation; Gao et al. 2024),\n",
    "exogenous policy changes (Zhang et al. 2024), or rely on advanced methods such as repetitive\n",
    "next-token predictions to generate better answers (Koa et al. 2024). This work extends\n",
    "these efforts by incorporating these crucial market features, enabling the study of complex\n",
    "endogenous events such as flash crashes, liquidity shocks, and large-trader impacts.\n",
    "This work also connects to emerging research on algorithmic and AI-powered trading\n",
    "systems. Dou, Goldstein, and Ji (2024) demonstrate how reinforcement learning-based AI\n",
    "speculators can autonomously learn to sustain collusive behavior without explicit coordi-\n",
    "nation, achieving supra-competitive profits through either price-trigger strategies or self-\n",
    "confirming bias in learning. This finding is particularly informative for this framework as\n",
    "it highlights potential emergent behaviors that may arise when intelligent agents interact in\n",
    "7\n",
    "markets—behaviors that could manifest differently with LLM agents due to their natural\n",
    "language reasoning capabilities. Similarly, Colliard, Foucault, and Lovo (2022) examine al-\n",
    "gorithmic market makers using Q-learning and find they charge markups that increase when\n",
    "adverse selection costs decrease—contrary to Nash equilibrium predictions. Their work pro-\n",
    "vides methodological insights on how to test strategic pricing behaviors against theoretical\n",
    "benchmarks incorporated into this LLM-based framework.\n",
    "Finally, this approach is informed by complexity economics, which views markets as dy-\n",
    "namic, non-equilibrium systems where agents adaptively learn and evolve strategies (Arthur\n",
    "2013; Wolfram 2017). According to this view, markets exhibit emergent phenomena and\n",
    "self-organization, especially when trading agents (human or artificial) update their behav-\n",
    "ior in response to outcomes. This paradigm is particularly relevant in an era of increasing\n",
    "automation and algorithmic trading (Balland et al. 2022; Ping 2019). Like adaptive agents\n",
    "in complexity economics, these LLM traders incorporate new information and adjust their\n",
    "strategies, generating emergent market patterns—a key motivation behind this framework.\n",
    "Unlike previous frameworks that abstract away crucial market features or focus on narrow\n",
    "strategies, this system incorporates realistic market microstructure while accommodating\n",
    "heterogeneous agents interacting simultaneously. While earlier work demonstrates LLMs’\n",
    "promise for macroeconomic modeling and simple trading simulations, this work introduces a\n",
    "complex, open-source financial market platform that supports multiple agent architectures,\n",
    "thorough market microstructure (limit orders, partial fills, dividends), and rigorous testing\n",
    "protocols—fulfilling a critical need in complexity economics research and market microstruc-\n",
    "ture analysis.\n",
    "2 Methodology\n",
    "The methodology section contains three parts. The first part describes the market design,\n",
    "the second agents’ design, and the third the analysis module.\n",
    "8\n",
    "2.1 Market Design\n",
    "Our methodological framework integrates three components that create a controlled envi-\n",
    "ronment for LLM-based trading agents. The framework implements a flexible continuous\n",
    "double-auction market mechanism that couples standard market microstructure principles\n",
    "with market clearing and matching algorithms to accommodate asynchronous LLM decisions.\"\"\",\n",
    "    \"\"\"(2023)). This work, however, focuses on financial markets and how LLM agents can operate\n",
    "as full-fledged trading participants.\n",
    "Recent research examines specific applications of LLMs for trading. FinMem and Trad-\n",
    "ingGPT introduce frameworks with layered memory systems and customizable agent traits\n",
    "5\n",
    "to improve financial decision-making (Yu, Li, et al. 2024; Li, Zhang, and Sun 2023). Hierar-\n",
    "chical multi-agent architectures have been explored in FinCon, which uses a manager-analyst\n",
    "setup for collaborative portfolio decisions (Yu, Yao, et al. 2024). QuantAgent implements\n",
    "a self-improving signal-mining approach (Wang et al. 2024), while other work underscores\n",
    "the importance of long-term memory in LLM agents via vector databases (Hatalis et al.\n",
    "2024). This line of research builds on successful reinforcement learning applications such as\n",
    "AlphaPortfolio (Cong et al. 2021) and AlphaManager (Campello, Cong, and Zhou 2023),\n",
    "which leverage deep RL and robust control for portfolio management.\n",
    "Analyzing LLM agent behavior by changing only some parameters draws on methods\n",
    "from the interpretable machine learning literature. In particular, the systematic variation\n",
    "of market parameters to reveal decision patterns mirrors partial dependence plots and in-\n",
    "dividual conditional expectation curves used to interpret complex machine learning models\n",
    "(Molnar 2022). These techniques help reveal how LLM agents respond to changes in specific\n",
    "variables while holding others constant, providing insight into their internal decision-making\n",
    "processes that would otherwise remain opaque.\n",
    "Beyond finance, studies of LLM capabilities in interactive or multi-agent settings offer\n",
    "valuable insights. Benchmarks like AgentBench evaluate LLMs’ performance in interac-\n",
    "tive tasks (Liu et al. 2023), while InvestorBench focuses on financial decision-making tasks\n",
    "specifically (H. Li et al. 2024). NegotiationArena demonstrates LLMs’ capacity for strategic\n",
    "interaction in bargaining contexts (Bianchi et al. 2024). Similarly, Guo et al. (2024) provide\n",
    "an economics ”arena” where LLMs compete in strategic games, revealing that advanced\n",
    "models like GPT-4 can exhibit rational, adaptive behavior—albeit not always reaching Nash\n",
    "Equilibrium. Existing frameworks typically assess individual agents or hierarchical collab-\n",
    "orations, whereas this work studies emergent market behaviors that arise from multiple\n",
    "independent LLM traders interacting in a marketplace.\n",
    "The approach also connects to the tradition of experimental asset markets. For instance,\n",
    "Weitzel et al. (2020) show that even finance professionals are susceptible to speculative\n",
    "6\n",
    "bubbles, especially amid high capital inflows. Kop´ anyi-Peuker and Weber (2021) find that\n",
    "trading experience alone does not eliminate bubbles, challenging assumptions about rational\n",
    "market learning. Kirchler, Huber, and St¨ ockl (2012) identify confusion about fundamental\n",
    "values as a key driver of bubble formation. This framework offers a new way to study these\n",
    "phenomena with LLM traders, which can be rigorously parameterized for sophistication,\n",
    "strategy, and information processing. Hence, this paper provides a method to investigate\n",
    "how automated or ”artificial” agents might affect market stability or volatility.\n",
    "Other recent work highlights the versatility of LLM agents in complex, interactive sce-\n",
    "narios beyond finance. One stream focuses on simulating social behaviors—such as opinion\n",
    "dynamics (Chuang et al. 2023), trust (Xie et al. 2024), and resource-sharing (Piatti et al.\n",
    "2024). Another examines LLMs’ strategic capabilities through task-based simulations and\n",
    "collaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\n",
    "Within the computer science literature, early works apply LLMs to financial markets but\n",
    "abstract away many fundamental stock market characteristics. Often, they employ single-\n",
    "price clearing mechanisms without a persistent order book, ignore partial fills and bid-ask\"\"\",\n",
    "    \"\"\"Can Large Language Models Trade? Testing Financial\n",
    "Theories with LLM Agents in Market Simulations\n",
    "Alejandro Lopez-Lira∗\n",
    "First Version: November 29, 2024; Current Version: April 16, 2025\n",
    "Abstract\n",
    "This paper presents a realistic simulated stock market where large language models\n",
    "(LLMs) act as heterogeneous competing trading agents. The open-source framework\n",
    "incorporates a persistent order book with market and limit orders, partial fills, div-\n",
    "idends, and equilibrium clearing alongside agents with varied strategies, information\n",
    "sets, and endowments. Agents submit standardized decisions using structured outputs\n",
    "and function calls while expressing their reasoning in natural language. Three findings\n",
    "emerge: First, LLMs demonstrate consistent strategy adherence and can function as\n",
    "value investors, momentum traders, or market makers per their instructions. Second,\n",
    "market dynamics exhibit features of real financial markets, including price discovery,\n",
    "bubbles, underreaction, and strategic liquidity provision. Third, the framework enables\n",
    "analysis of LLMs’ responses to varying market conditions, similar to partial dependence\n",
    "plots in machine-learning interpretability. The framework allows simulating financial\n",
    "theories without closed-form solutions, creating experimental designs that would be\n",
    "costly with human participants, and establishing how prompts can generate correlated\n",
    "behaviors affecting market stability.\n",
    "Keywords: LLM Agents; Agent-Based Markets; Experimental Finance; AI Trading;\n",
    "Multi-Agent Systems\n",
    "∗University of Florida. Email: alejandro.lopez-lira@warrington.ufl.edu. I am grateful to seminar par-\n",
    "ticipants at the London Business School, Oxford University, Stockholm School of Economics, University of\n",
    "Virginia, and the City University of Hong Kong for helpful suggestions and feedback.\n",
    "1\n",
    "arXiv:2504.10789v1  [q-fin.CP]  15 Apr 2025\n",
    "1 Introduction\n",
    "Large language models (LLMs) can increasingly function as autonomous agents—systems\n",
    "that observe, reason, and act independently. LLMs have shown promising results in finan-\n",
    "cial forecasting, but their potential as trading agents introduces a fundamental shift from\n",
    "algorithms with explicit objectives to systems guided by natural language instructions. This\n",
    "change raises critical questions: Can LLMs execute trading strategies? Do LLMs optimize\n",
    "for profit maximization? What are the implications for market stability and efficiency?\n",
    "If LLMs trade similarly to humans, they could enable experimental market simulations\n",
    "without human participants. Conversely, if their trading behavior differs, understanding\n",
    "these differences becomes critical for systemic risk management. These questions extend be-\n",
    "yond theory; LLM-based strategies are already being deployed.1 To address these questions,\n",
    "I develop an open-source simulation that tests LLM trading agents in a realistic market envi-\n",
    "ronment with a persistent order book, supporting various order types, stochastic dividends,\n",
    "and heterogeneous information.\n",
    "The framework allows heterogeneous LLMs—defined in natural language, using different\n",
    "system prompts—to act as diverse types of traders, such as value investors, momentum\n",
    "traders, market makers, and contrarians. Agents submit standardized trading decisions in a\n",
    "human-readable format while expressing their reasoning transparently. Figure 1 illustrates\n",
    "this approach, showing how a speculator agent combines explicit valuation reasoning with\n",
    "structured trading parameters, enabling systematic analysis and insight into the agent’s\n",
    "decision-making process.\n",
    "The analysis reveals three key findings about LLMs’ capabilities as trading agents. First,\n",
    "LLMs can effectively execute trading strategies. They consistently understand market me-\n",
    "chanics, process market information, form price expectations, and execute trades according\n",
    "to specific instructions. Their trading behavior is highly sensitive to the prompts they\n",
    "receive—they faithfully follow directions regardless of profit implications. This observance\"\"\",\n",
    "    \"\"\"decision-making process.\n",
    "The analysis reveals three key findings about LLMs’ capabilities as trading agents. First,\n",
    "LLMs can effectively execute trading strategies. They consistently understand market me-\n",
    "chanics, process market information, form price expectations, and execute trades according\n",
    "to specific instructions. Their trading behavior is highly sensitive to the prompts they\n",
    "receive—they faithfully follow directions regardless of profit implications. This observance\n",
    "1. For example, Autopilot has a ChatGPT-based portfolio https://x.com/thegptinvestor.\n",
    "2\n",
    "{\"valuation_reasoning\":\n",
    "\"The fundamental value is based on the expected dividend,\n",
    "and the interest rate.\n",
    "The expected dividend is $1.40, and the interest rate is 5%.\n",
    "Using a perpetuity formula, the value is $1.40 / 0.05 = $28.\",\n",
    "\"valuation\":28.0,\n",
    "\"price_target_reasoning\":\"The current price is $29.00, which is\n",
    "slightly above the fundamental value of $28.00. I expect the price\n",
    "to remain around $29.00 in the next round due to market stability.\",\n",
    "\"price_target\":29.0,\n",
    "\"orders\":[{\"decision\":\"Sell\",\"quantity\":1000,\"order_type\":\"limit\",\n",
    "\"price_limit\":29.50}],\n",
    "\"replace_decision\":\"Add\",\n",
    "\"reasoning\":\"The current price is slightly above the fundamental value.\n",
    "I will place a limit sell order at $29.50 to capitalize on potential price\n",
    "increases.\"}\n",
    "Figure 1: Example of a structured trading decision from a Speculator agent defined by its\n",
    "system prompt: “You are a speculator who tries to profit from market inefficiencies.”. The\n",
    "LLM provides explicit reasoning for its valuation, price target, and trading decision in a\n",
    "machine-readable JSON format that can be directly processed by the trading system.\n",
    "highlights a fundamental difference from human traders: LLMs do not inherently optimize\n",
    "for profit maximization but rather for following instructions accurately.\n",
    "Second, LLMs react meaningfully to market dynamics. They consider current and his-\n",
    "torical prices, dividends, and other market information when making decisions. However,\n",
    "they maintain their strategic direction even when market conditions change, following their\n",
    "instructions even if doing so results in financial losses. This combination of responsiveness\n",
    "to market conditions while maintaining strategic consistency creates a unique trading profile\n",
    "distinct from rule-based algorithms and human traders.\n",
    "Third, market dynamics with LLM agents can resemble actual markets and mirror classic\n",
    "results from the theoretical finance literature. When these agents interact, they produce\n",
    "realistic price discovery and liquidity provision with emergent behaviors, including price\n",
    "convergence toward fundamental values. Depending on the distribution of agent types,\n",
    "the system can generate various market phenomena, such as bubbles or underreactions to\n",
    "information. This complex behavior suggests potential applications for studying market\n",
    "3\n",
    "dynamics using LLM agents instead of experiments with human participants.\n",
    "Hence, these findings raise important questions about algorithmic consistency in LLM-\n",
    "based systems. Since trading agents are implemented through prompts, their behavior in-\n",
    "herits characteristics of the underlying language models. The standardization of LLM ar-\n",
    "chitectures across implementations could create unexpected behavioral patterns—if many\n",
    "agents are based on similar foundation models, they might exhibit correlated responses to\n",
    "specific market conditions, potentially amplifying market instabilities.\n",
    "To enable this analysis and accelerate development in this emerging field, we provide\n",
    "an open-source framework with three key components: (1) a structured protocol for im-\n",
    "plementing and validating LLM trading agents, supporting both LLM-based and traditional\n",
    "rule-based agents; (2) a controlled market environment with realistic microstructure for test-\n",
    "ing agent interactions; and (3) a comprehensive data collection system for analyzing trading\n",
    "behavior. This framework serves multiple stakeholders in preparation for the evolution of\"\"\",\n",
    "    \"\"\"2407.18957. arXiv: 2407.18957 [q-fin]. http://arxiv.org/abs/2407.18957.\n",
    "41\n",
    "A Technical Implementation Details\n",
    "A.1 Agent Type Specifications\n",
    "This section details the base system prompts for each agent type in our simulation. These\n",
    "prompts define the core behavioral characteristics and trading strategies for each agent. Each\n",
    "prompt consists of:\n",
    "• A role definition that establishes the agent’s trading philosophy\n",
    "• A structured trading strategy that guides decision-making\n",
    "• Specific instructions for when to use market orders vs limit orders\n",
    "At runtime, these base prompts are combined with:\n",
    "• Current market state (price, volume, order book depth)\n",
    "• Position information (current holdings and available cash)\n",
    "• Trading options and required response format\n",
    "The standard runtime template includes:\n",
    "Position Information Template\n",
    "Your Position:\n",
    "- Available Shares: {shares} shares (Short selling is not allowed)\n",
    "- Main Cash Account: ${cash:.2f}\n",
    "- Dividend Cash Account (not available for trading): ${dividend_cash:.2f}\n",
    "- Total Available Cash: ${total_available_cash:.2f} (Borrowing is not allowed)\n",
    "- Shares in Orders: {committed_shares} shares\n",
    "- Cash in Orders: ${committed_cash:.2f}\n",
    "42\n",
    "Trading Options Template\n",
    "Your analysis should include:\n",
    "- valuation_reasoning: Your numerical analysis of the asset’s fundamental value\n",
    "- valuation: Your estimate of the asset’s current fundamental value\n",
    "- price_target_reasoning: Your numerical analysis of the asset’s price target\n",
    "- price_target: Your predicted price for the next round\n",
    "- reasoning: Your explanation for the trading decision\n",
    "Trading Options:\n",
    "1. New Orders (replace_decision=’Add’):\n",
    "- Single or multiple orders allowed\n",
    "- For each order:\n",
    "- Market order: Set order_type=’market’\n",
    "- Limit order: Set order_type=’limit’ and specify price_limit\n",
    "- IMPORTANT: Sell orders require sufficient available shares\n",
    "- Short selling is NOT allowed\n",
    "2. Cancel Orders (replace_decision=’Cancel’):\n",
    "- Return an empty orders list: orders=[]\n",
    "Your decision must include:\n",
    "- orders: list of orders (empty list for Hold/Cancel)\n",
    "- For Buy/Sell orders, each must contain:\n",
    "- decision: \"Buy\" or \"Sell\"\n",
    "- quantity: number of shares\n",
    "- order_type: \"market\" or \"limit\"\n",
    "- price_limit: required for limit orders\n",
    "- reasoning: brief explanation\n",
    "- replace_decision: \"Add\", \"Cancel\", or \"Replace\"\n",
    "43\n",
    "Base System Prompts The following are the base system prompts for each LLM-based\n",
    "agent type:\n",
    "A.1.1 Value-Based Agents\n",
    "Value Investor\n",
    "You are a value investor who focuses on fundamental analysis.\n",
    "You believe in mean reversion and try to buy undervalued assets and sell overvalued ones.\n",
    "A.1.2 Trend-Following Agents\n",
    "Momentum Trader\n",
    "You are a momentum trader who focuses on price trends and volume.\n",
    "You believe that ’the trend is your friend’ and try to identify and follow market momentum.\n",
    "A.1.3 Liquidity Providers Agents\n",
    "Market Maker\n",
    "You are a professional market maker who provides liquidity to the market.\n",
    "Your profit comes from capturing the spread between bid and ask prices, not from directional price movement.\n",
    "IMPORTANT: There is NO SHORT SELLING allowed. You can only sell shares you already own.\n",
    "Trading Guidelines:\n",
    "- Place LIMIT buy orders slightly below the current market price (1-3% lower)\n",
    "- Place LIMIT sell orders slightly above the current market price (1-3% higher)\n",
    "- Your spread should be proportional to volatility but typically 2-6% of price\n",
    "- NEVER place sell orders more than 10% above your buy orders\n",
    "- Adjust your spread width based on recent price volatility\n",
    "44\n",
    "Inventory Management (No Short Selling):\n",
    "- Monitor your current inventory in the market data\n",
    "- Only place sell orders for quantities you actually own\n",
    "- If you have no inventory, focus on buy orders first\n",
    "- As you acquire inventory, gradually place sell orders\n",
    "- If inventory grows too large, reduce or pause buy orders\n",
    "- Adjust your buy/sell ratio based on current inventory level\n",
    "Example: If price = $100, you might place buy orders at $97-99 and sell orders at $101-103,\"\"\",\n",
    "    \"\"\"• Market Makers: Provide liquidity through symmetric bid-ask spreads\n",
    "• Contrarian Traders: Trade against market extremes and overreactions\n",
    "• Speculators: Seek to profit from market inefficiencies\n",
    "• Sentiment-Based Agents: Include optimistic and pessimistic variants with biased\n",
    "expectations\n",
    "• Retail Traders: Simulate typical individual investor behavior\n",
    "The software also includes a set of deterministic rule-based agents that serve as bench-\n",
    "marks and control conditions:\n",
    "• Directional Traders: Always-buy, always-sell, and always-hold agents\n",
    "• Technical Agents: Gap traders, mean reversion traders, and momentum traders\n",
    "• Algorithmic Market Makers: Implement fixed spread-posting strategies\n",
    "14\n",
    "Each agent type is defined by its system prompt (for LLM agents) or algorithmic rules (for\n",
    "deterministic agents), with standardized interfaces enabling direct comparison across diverse\n",
    "strategies. The agent composition system supports flexible specifications—including uni-\n",
    "form distributions, type-specific concentrations (e.g., ”value heavy”), and precise numerical\n",
    "allocations—enabling systematic exploration of how market dynamics emerge from different\n",
    "agent populations.\n",
    "The framework’s extensible design makes it remarkably simple to add new agent types—\n",
    "LLM-based agents require only defining a new system prompt that specifies the trading\n",
    "strategy. In contrast, deterministic agents can be implemented through the standard agent\n",
    "interface. This flexibility allows researchers to rapidly prototype and deploy novel trading\n",
    "strategies without modifying the underlying system architecture.\n",
    "The complete list of agent types included in the framework and their detailed specifi-\n",
    "cations is provided in the Appendix. The framework’s flexible prompt-based architecture\n",
    "allows researchers to rapidly prototype and deploy new agent types by developing appropri-\n",
    "ate strategic and tactical prompts without modifying the underlying system architecture.\n",
    "2.2.4 User Prompt\n",
    "The user prompt provides the immediate market context necessary for tactical decision-\n",
    "making. This dynamic component delivers current market state information, including\n",
    "prices, volumes, and emerging trends, alongside the agent’s current position information\n",
    "and available trading options. Additionally, the user prompt specifies immediate decision\n",
    "requirements and operational constraints, ensuring that agent responses remain within fea-\n",
    "sible bounds while aligning with their strategic objectives. This separation of strategic and\n",
    "tactical prompting enables precise control over agent behavior while maintaining flexibility\n",
    "for market interactions. All the information in the user prompt is optional at the agent level\n",
    "and can be customized for different experimental designs.\n",
    "15\n",
    "2.2.5 Decision Structure\n",
    "Each agent decision follows a standardized output format comprising several key components.\n",
    "The decision field specifies the basic action as either Buy, Sell, or Hold. For active trades,\n",
    "the quantity field determines the number of shares to trade, while the order type indicates\n",
    "whether it is a Market or Limit order. When placing limit orders, the price limit field\n",
    "specifies the maximum (for buys) or minimum (for sells) acceptable execution price. Finally,\n",
    "each decision includes a reasoning field that provides an explicit rationale for the trading\n",
    "decision, ensuring transparency and facilitating analysis of agent behavior.\n",
    "2.2.6 Structured Outputs and Function Calling\n",
    "Our framework implements a structured output approach using function calling to ensure\n",
    "standardized, human-readable, machine-readable agent decisions. This technique allows\n",
    "LLMs to generate outputs in a specific format that can be directly validated and processed\n",
    "by the trading system, bridging the gap between natural language reasoning and executable\n",
    "trading actions.\n",
    "The system uses Pydantic for validation and parsing of agent outputs, with a schema-\n",
    "based approach that defines the required structure:\n",
    "class TradeDecisionSchema(BaseModel):\"\"\",\n",
    "    \"\"\"ceedings of the 62nd Annual Meeting of the Association for Computational Linguistics\n",
    "(Volume 1: Long Papers),edited by Lun-Wei Ku, Andre Martins, and Vivek Srikumar,\n",
    "15523–15536. ACL 2024. Bangkok, Thailand: Association for Computational Linguis-\n",
    "tics, August.\n",
    "39\n",
    "Li, Yuan, Yixuan Zhang, and Lichao Sun. 2023. “MetaAgents: Simulating Interactions of\n",
    "Human Behaviors for LLM-based T Ask-Oriented Coordination via Collaborative Gen-\n",
    "erative Agents.” arXiv.org.\n",
    "Liu, Xiao, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, et al. 2023.\n",
    "“AgentBench: Evaluating LLMs as Agents.”International Conference on Learning Rep-\n",
    "resentations.\n",
    "Lopez-Lira, Alejandro, and Yuehua Tang. 2023. “Can ChatGPT Forecast Stock Price Move-\n",
    "ments? Return Predictability and Large Language Models.” SSRN Electronic Journal\n",
    "(April 6, 2023).\n",
    "Manning, Benjamin S., Kehang Zhu, and John J. Horton. 2024. “Automated Social Science:\n",
    "Language Models as Scientist and Subjects.” (Cambridge, MA) (April 29, 2024).\n",
    "Molnar, Christoph. 2022. Interpretable Machine Learning.\n",
    "Pelster, Matthias, and Joel Val. 2023. “Can Chatgpt Assist in Picking Stocks?”Social Science\n",
    "Research Network.\n",
    "Piatti, Giorgio, Zhijing Jin, Max Kleiman-Weiner, Bernhard Sch¨ olkopf, Mrinmaya Sachan,\n",
    "and Rada Mihalcea. 2024. “Cooperate or Collapse: Emergence of Sustainable Coopera-\n",
    "tion in a Socie Ty of LLM Agents.” arXiv.org.\n",
    "Ping, Chen. 2019. “From Complexity Science to Complexity Economics.” In Alternative\n",
    "Approaches to Economic Theory,19–55. Routledge, June 11, 2019.\n",
    "Wang, Saizhuo, Hang Yuan, Lionel M. Ni, and Jian Guo. 2024. “QuantAgent: Seeking Holy\n",
    "Grail in Trading by Self-Improving Large Lang Uage Model.” arXiv.org.\n",
    "Weitzel, Utz, Christoph Huber, J¨ urgen Huber, Michael Kirchler, Florian Lindner, and Julia\n",
    "Rose. 2020. “Bubbles and Financial Professionals.” The Review of Financial Studies33,\n",
    "no. 6 (June 1, 2020): 2659–2696.\n",
    "40\n",
    "Wolfram, Elsner. 2017. “Complexity Economics as Heterodoxy: Theory and Policy.”Journal\n",
    "of Economic Issues51, no. 4 (October 2, 2017): 939–978.\n",
    "Woodhouse, Drew, and Alex Charlesworth. 2023. “Can ChatGPT Predict Future Interest\n",
    "Rate Decisions?” Social Science Research Network.\n",
    "Xie, Chengxing, Canyu Chen, Feiran Jia, Ziyu Ye, Shiyang Lai, Kai Shu, Jindong Gu, et al.\n",
    "2024. “Can Large Language Model Agents Simulate Human Trust Behavior?”arXiv.org.\n",
    "Yang, Stephen. 2023. “Predictive Patentomics: Forecasting Innovation Success and Valuation\n",
    "w Ith ChatGPT.” Social Science Research Network.\n",
    "Yu, Yangyang, Haohang Li, Zhi Chen, Yuechen Jiang, Yang Li, Denghui Zhang, Rong\n",
    "Liu, Jordan W. Suchow, and Khaldoun Khashanah. 2024. “FinMem: A Performance-\n",
    "Enhanced LLM Trading Agent with Layered Memory a Nd Character Design.”Proceed-\n",
    "ings of the AAAI Symposium Series3, no. 1 (May 20, 2024): 595–597.\n",
    "Yu, Yangyang, Zhiyuan Yao, Haohang Li, Zhiyang Deng, Yupeng Cao, Zhi Chen, Jordan W.\n",
    "Suchow, et al. 2024. “FinCon: A Synthesized LLM Multi-Agent System with Conceptual\n",
    "Verbal Reinforcement for Enhanced Financial Decision Making.” Pre-published, Novem-\n",
    "ber 7, 2024. Accessed January 8, 2025. https://doi.org/10.48550/arXiv.2407.06567.\n",
    "arXiv: 2407.06567 [cs]. http://arxiv.org/abs/2407.06567.\n",
    "Zhang, Chong, Xinyi Liu, Zhongmou Zhang, Mingyu Jin, Lingyao Li, Zhenting Wang,\n",
    "Wenyue Hua, et al. 2024. “When AI Meets Finance (StockAgent): Large Language\n",
    "Model-based Stock Trading in Simulated Real-world Environments.” Pre-published,\n",
    "September 21, 2024. Accessed January 26, 2025. https://doi.org /10.48550/arXiv .\n",
    "2407.18957. arXiv: 2407.18957 [q-fin]. http://arxiv.org/abs/2407.18957.\n",
    "41\n",
    "A Technical Implementation Details\n",
    "A.1 Agent Type Specifications\n",
    "This section details the base system prompts for each agent type in our simulation. These\n",
    "prompts define the core behavioral characteristics and trading strategies for each agent. Each\n",
    "prompt consists of:\n",
    "• A role definition that establishes the agent’s trading philosophy\n",
    "• A structured trading strategy that guides decision-making\"\"\",\n",
    "]\n",
    "\n",
    "    ),\n",
    "    LLMTestCase(\n",
    "        input=\"What is the main experimental finding when the simulated market starts 25 % above the fundamental value?\",\n",
    "        actual_output=\"\"\"In the infinite horizon scenario where the simulated market began 25% above the fundamental value (overvalued at $56.00 compared to the true value of $28.00), the price failed to converge downwards towards the fundamental value within the 15 trading rounds. The LLM (Large Language Model)-driven agents' valuations also remained significantly elevated above the fundamental value, mirroring the overall market's persistent overvaluation. This suggests that, under these specific conditions, the AI agents were less effective at correcting overvaluation compared to undervaluation within the given timeframe.\"\"\",\n",
    "        expected_output=\"\"\"With an initial price 25 % above fundamentals, prices failed to converge downward within 15 rounds and agents kept over‑valuing the asset.\"\"\",\n",
    "        context=[\n",
    "            \"\"\"When the market starts significantly above the fundamental value … the price fails to converge downwards … remaining substantially elevated. Agent valuations mirror this persistence, with many agents maintaining estimates well above the fundamental value.\"\"\"\n",
    "        ],\n",
    "        retrieval_context=[\n",
    "    \"\"\"bids/asks), and two Speculator agents (opportunistic traders seeking inefficiencies). Market\n",
    "31\n",
    "makers are given enhanced liquidity with 20x the baseline cash and shares to ensure suffi-\n",
    "cient liquidity provision and facilitate price discovery. The scenario tests whether prices can\n",
    "correct downward through trading activity when starting from an overvalued state.\n",
    "3.2.2 Price Discovery (Below Fundamental)\n",
    "This complementary scenario tests upward price convergence by starting with an initial price\n",
    "25% below the fundamental value ( $21.00). It employs the identical agent composition and\n",
    "parameters as the above-fundamental scenario, allowing for direct comparison of market\n",
    "behavior under opposite initial mispricing conditions. This design enables researchers to\n",
    "assess potential asymmetries in price discovery processes.\n",
    "3.2.3 Infinite Horizon Price Discovery\n",
    "We extend both price discovery scenarios to infinite horizon settings, where shares are not\n",
    "redeemed at a terminal date. The initial prices are set at double ($56.00) and half ($14.00) the\n",
    "fundamental value for the above and below fundamental scenarios respectively, creating more\n",
    "extreme mispricing conditions. These scenarios run for 15 trading rounds and test whether\n",
    "agents correctly value assets based on expected dividend streams rather than redemption\n",
    "values. Each infinite horizon scenario involves two Default investors, two Optimistic traders,\n",
    "two Market makers, and two Speculator agents.\n",
    "The results from these infinite horizon scenarios reveal interesting asymmetries in price\n",
    "discovery, as illustrated in Figure 6 and Figure 7. When the market starts significantly above\n",
    "the fundamental value (left panels), the price fails to converge downwards towards the$28.00\n",
    "benchmark within the 15 rounds, remaining substantially elevated. Agent valuations mirror\n",
    "this persistence, with many agents maintaining estimates well above the fundamental value.\n",
    "However, when the market begins significantly below the fundamental value (right panels),\n",
    "the price exhibits a clear convergence towards the fundamental benchmark. Agent valuations\n",
    "in this scenario also tend to adjust upwards, aligning more closely with the calculated fun-\n",
    "32\n",
    "damental value over time. This suggests that under these conditions, LLM agents are more\n",
    "effective at correcting undervaluation than overvaluation within the simulated timeframe.\n",
    "Figure 6: Price Evolution: Infinite Horizon Scenarios. Left: Initial price $56.00 (Above\n",
    "Fundamental). Right: Initial price $14.00 (Below Fundamental). The dashed line indicates\n",
    "the fundamental value ($28.00).\n",
    "Figure 7: Agent Valuations: Infinite Horizon Scenarios. Left: Initial price $56.00 (Above\n",
    "Fundamental). Right: Initial price $14.00 (Below Fundamental). Shows individual agent\n",
    "estimates of fundamental value over time.\n",
    "3.2.4 Divergent Beliefs\n",
    "This scenario explores the impact of heterogeneous beliefs about fundamental value by com-\n",
    "bining agents with systematically different valuation models. The agent composition is\n",
    "designed to create heterogeneity: two Optimistic traders (believing the fundamental value is\n",
    "significantly higher), two Pessimistic traders (believing it is significantly lower), two neutral\n",
    "Market makers, two Momentum traders (following price trends rather than fundamentals),\n",
    "and two Default investors (baseline agents). We test both above-fundamental (initial price\n",
    "$56.00, 2x fundamental) and below-fundamental (initial price$14.00, 0.5x fundamental) vari-\n",
    "33\n",
    "ants, allowing researchers to study how different belief structures influence price formation\n",
    "and trading patterns under different initial mispricings. In these scenarios, the fundamental\n",
    "price is hidden from agents, forcing them to rely on their own valuation models.\n",
    "3.2.5 Market Stress\n",
    "This scenario tests market resilience under challenging conditions by creating a more volatile\n",
    "environment. The scenario includes two consistently bullish Optimistic traders, two consis-\"\"\",\n",
    "    \"\"\"the decision-making engine.\n",
    "The data collection system captures comprehensive market activity across multiple di-\n",
    "mensions. At the market level, it tracks the evolution of prices, fundamental values, and\n",
    "realized dividends, providing insights into overall market dynamics. Individual agent data\n",
    "includes detailed wealth trajectories and portfolio compositions, enabling analysis of strategy\n",
    "effectiveness and wealth distribution patterns. The system maintains complete transaction\n",
    "records with prices, quantities, and counterparty information, facilitating the study of trad-\n",
    "ing patterns and market microstructure. Additionally, it captures agent decision rationales\n",
    "and strategy adherence metrics, allowing researchers to evaluate the consistency and effec-\n",
    "tiveness of different trading approaches.\n",
    "All experimental parameters, market outcomes, and agent interactions are systemati-\n",
    "cally logged and stored in structured formats (CSV and JSON) for subsequent analysis. The\n",
    "framework generates standardized visualizations of price evolution, wealth distribution, and\n",
    "dividend payments to facilitate comparative analysis across different experimental configu-\n",
    "rations.\n",
    "3.1 Fundamental Value Calibration\n",
    "The framework implements a consistent approach to fundamental value calculation that pro-\n",
    "vides a reliable benchmark for price discovery. For infinite horizon markets, the fundamental\n",
    "value follows the standard dividend discount model:\n",
    "Vt = E[D]\n",
    "r = Expected Dividend\n",
    "Interest Rate (1)\n",
    "For the default parameters where the expected dividend is $1.40 and the interest rate is\n",
    "5%, this yields a fundamental value of $28.00.\n",
    "In finite horizon markets with T periods remaining, the fundamental value incorporates\n",
    "30\n",
    "both future dividends and terminal redemption value K:\n",
    "FVt =\n",
    "TX\n",
    "τ=t\n",
    "E[D]\n",
    "(1 + r)τ−t+1 + K\n",
    "(1 + r)T−t+1 (2)\n",
    "To ensure consistency between finite and infinite horizon markets, the redemption value\n",
    "K is set equal to E[D]\n",
    "r , which makes the fundamental value constant atE[D]\n",
    "r across all periods,\n",
    "regardless of the time horizon. This calibration approach ensures a clean experimental design\n",
    "by providing a stable benchmark for price discovery.\n",
    "3.2 Experimental Scenarios\n",
    "To evaluate market dynamics with LLM-based agents, we implemented several experimental\n",
    "scenarios that systematically explore different initial conditions and agent compositions.\n",
    "Each scenario maintains the fundamental value of $28.00 while varying starting prices, time\n",
    "horizons, and agent populations. These scenarios address our core research questions (Section\n",
    "1) by testing LLM capabilities under varying market conditions, focusing on price discovery\n",
    "dynamics, the impact of heterogeneous beliefs, and market stability under stress; GPT-4o\n",
    "was used consistently as the decision-making engine for all LLM agents across these scenarios.\n",
    "We present the setup for several key scenarios below, followed by a discussion of the observed\n",
    "results for the 2 experiments involving an infinite horizon market with a starting price either\n",
    "above or below the fundamental value.\n",
    "3.2.1 Price Discovery (Above Fundamental)\n",
    "This scenario tests downward price convergence by starting with an initial price 25% above\n",
    "the fundamental value ( $35.00). It runs for 20 trading rounds and features a diverse\n",
    "agent population, including two Default investors (baseline agents), two Optimistic traders\n",
    "(who believe prices should be higher), two Market makers (providing liquidity by posting\n",
    "bids/asks), and two Speculator agents (opportunistic traders seeking inefficiencies). Market\n",
    "31\n",
    "makers are given enhanced liquidity with 20x the baseline cash and shares to ensure suffi-\n",
    "cient liquidity provision and facilitate price discovery. The scenario tests whether prices can\n",
    "correct downward through trading activity when starting from an overvalued state.\n",
    "3.2.2 Price Discovery (Below Fundamental)\n",
    "This complementary scenario tests upward price convergence by starting with an initial price\"\"\",\n",
    "    \"\"\"33\n",
    "ants, allowing researchers to study how different belief structures influence price formation\n",
    "and trading patterns under different initial mispricings. In these scenarios, the fundamental\n",
    "price is hidden from agents, forcing them to rely on their own valuation models.\n",
    "3.2.5 Market Stress\n",
    "This scenario tests market resilience under challenging conditions by creating a more volatile\n",
    "environment. The scenario includes two consistently bullish Optimistic traders, two consis-\n",
    "tently bearish Pessimistic traders, two Market makers (liquidity providers), and two Value\n",
    "investors (rational benchmark traders). The scenario runs for 100 rounds to study long-term\n",
    "market behavior and includes unequal initial endowments, with optimistic traders having\n",
    "more cash (1.5x baseline) but fewer shares (0.5x baseline) and pessimistic traders having less\n",
    "cash (0.5x baseline) but more shares (1.5x baseline). This resource imbalance tests whether\n",
    "particular agent types can dominate market outcomes through resource advantages.\n",
    "The scenarios presented here demonstrate the framework’s capabilities for exploring di-\n",
    "verse market conditions. Its modular structure facilitates the straightforward definition and\n",
    "implementation of alternative experimental designs, enabling researchers to tailor simulations\n",
    "to specific research questions.\n",
    "In all scenarios, we maintain consistent baseline parameters with a fundamental value\n",
    "of $28.00, calculated from the expected dividend of $1.40 and interest rate of 5%. Agent\n",
    "endowments start at 1,000,000 monetary units and 10,000 shares unless specifically modified.\n",
    "Transaction costs are set to zero to isolate the effects of agent behavior and market structure\n",
    "on price formation.\n",
    "4 Conclusion\n",
    "This paper demonstrates that Large Language Models can effectively function as diverse\n",
    "trading agents—from value investors to market makers—maintaining strategic consistency\n",
    "34\n",
    "while adapting to market conditions. Our experimental framework reveals that their in-\n",
    "teractions generate realistic market dynamics, including phenomena like price bubbles and\n",
    "corrections, highlighting both the capabilities and potential risks of deploying LLM agents\n",
    "in financial markets.\n",
    "These findings carry significant implications for market structure and regulation. While\n",
    "LLM agents can enhance price discovery and liquidity, their adherence to programmed strate-\n",
    "gies, even potentially flawed ones derived from prompts, could amplify market volatility or\n",
    "introduce novel systemic risks, as observed in our simulated bubble scenarios. A key concern\n",
    "is the potential for widespread correlated behavior: similar underlying LLM architectures\n",
    "responding uniformly to comparable prompts or market signals could inadvertently create\n",
    "destabilizing trading patterns without explicit coordination. This underscores the critical\n",
    "need for rigorous testing and validation of LLM-based trading systems prior to live deploy-\n",
    "ment.\n",
    "A central contribution of this work is the open-source simulation framework itself, de-\n",
    "signed to catalyze research into LLM trading agents. We invite the research community to\n",
    "utilize and extend this platform to investigate pressing questions in this rapidly evolving\n",
    "area. The framework enables systematic exploration of complex scenarios—such as hybrid\n",
    "human-LLM markets, stress tests, varying market structures, regulatory impacts, and the\n",
    "nuances of LLM prompting—often difficult or costly to study otherwise. Specific avenues\n",
    "ripe for investigation using this tool include the emergence of novel trading strategies, the\n",
    "precise effects of agent heterogeneity on market stability, and the development of robust\n",
    "validation protocols for AI traders. As artificial intelligence becomes more integrated into\n",
    "finance, collaborative research leveraging adaptable simulation environments like this one\n",
    "will be crucial for understanding and responsibly shaping the future of trading.\n",
    "35\n",
    "References\"\"\",\n",
    "    \"\"\"market efficiency and price discovery processes throughout the simulation.\n",
    "Agent performance metrics include absolute position tracking (shares, cash, and total\n",
    "wealth), wealth composition analysis, position change metrics, and return calculations. The\n",
    "system computes both absolute and percentage returns on various portfolio components\n",
    "and compares performance across agent types to identify relative advantages of different\n",
    "strategies. Trading flow analysis visualizes the volume of shares moving between different\n",
    "agent types and cumulative net trading flows, revealing which agents act as net buyers or\n",
    "sellers in different market conditions.\n",
    "Decision pattern analysis employs heatmaps to visualize the consistency of agent decision-\n",
    "making over time, allowing researchers to identify shifts in strategic behavior. This is com-\n",
    "plemented by decision quantities visualization that plots order sizes to highlight variations\n",
    "in trade aggressiveness across agent types. When agent reasoning data is available, the\n",
    "system generates wordclouds to extract key terms from agent explanations, providing qual-\n",
    "itative insights into decision drivers for different agent strategies. Additional visualizations\n",
    "track price target accuracy and compare agent-specific valuations to realized market prices,\n",
    "28\n",
    "offering insights into the forecasting abilities of different agents.\n",
    "A key advantage of simulation-based analysis is complete observability of all market\n",
    "processes and agent states. Unlike real-world markets where data availability is often limited,\n",
    "the framework captures every interaction, decision, and state change with perfect fidelity.\n",
    "This comprehensive data collection allows researchers to compute additional metrics beyond\n",
    "standard market measures, enabling novel analyses such as counterfactual testing (e.g., how\n",
    "would markets evolve with different agent compositions), causal inference of specific agent\n",
    "behaviors on market outcomes, and the development of custom efficiency or stability metrics\n",
    "tailored to particular research questions. The system’s modular design facilitates rapid\n",
    "implementation of new metrics and visualizations as research questions evolve.\n",
    "3 Experimental Design and Results\n",
    "Our experimental framework implements a dividend-paying asset market with heterogeneous\n",
    "agents. The baseline simulation runs for 15 to 20 rounds with 8 participating agents, although\n",
    "these parameters are fully configurable. Each agent begins with an initial endowment of\n",
    "1,000,000 monetary units and 10,000 shares of the asset. The fundamental value of the asset\n",
    "is set at $28.00, with a final redemption value matching this fundamental price in finite\n",
    "horizon scenarios. Transaction costs are set to zero to isolate the effects of agent behavior\n",
    "and market structure.\n",
    "The dividend structure follows a stochastic process with a base payment of $1.40 and a\n",
    "variation of ±$1.00, paid with 50% probability each round. This design creates uncertainty\n",
    "in the asset’s income stream while maintaining a known expected value. Cash holdings earn\n",
    "a risk-free interest rate of 5% per round, providing an opportunity cost for asset investment.\n",
    "Agent composition is controlled through a flexible distribution system that allows for\n",
    "various experimental configurations. In our baseline setup, we employ a mixed population\n",
    "of value investors, momentum traders, and market makers. Each agent type implements\n",
    "29\n",
    "distinct trading strategies through Large Language Model (LLM) prompts, with GPT-4o as\n",
    "the decision-making engine.\n",
    "The data collection system captures comprehensive market activity across multiple di-\n",
    "mensions. At the market level, it tracks the evolution of prices, fundamental values, and\n",
    "realized dividends, providing insights into overall market dynamics. Individual agent data\n",
    "includes detailed wealth trajectories and portfolio compositions, enabling analysis of strategy\n",
    "effectiveness and wealth distribution patterns. The system maintains complete transaction\"\"\",\n",
    "    \"\"\"value, the system:\n",
    "1. Sets market price P = ρV where ρ is the target ratio\n",
    "2. Generates a consistent order book structure around this price\n",
    "3. Executes multiple decision trials with the same agent type\n",
    "4. Records decision outcomes (buy/sell/hold), order types, quantities, and reasoning\n",
    "This process maps how LLM agents respond to different price environments, as illustrated\n",
    "in Figures 2, 3, 4, and 5. The analysis reveals clear patterns in decision boundaries, with\n",
    "distinct transitions between buying, selling, and holding regions that vary by agent type. For\n",
    "example, value investors show strong buying tendencies when prices are below fundamental\n",
    "value (ρ <1) and selling preferences when prices exceed fundamentals ( ρ >1). In contrast,\n",
    "momentum traders show less sensitivity to the fundamental ratio and more responsiveness\n",
    "to recent price trends.\n",
    "The systematic variation approach also reveals patterns in order sizing and limit price\n",
    "selection, with agents typically placing larger orders when prices deviate significantly from\n",
    "their valuation models (Figure 4). This methodology provides unprecedented transparency\n",
    "into LLM decision processes and enables quantitative comparison of different agent types\n",
    "and LLM architectures.\n",
    "22\n",
    "Figure 2: Price Analysis under Systematic Variation. Shows how agent valuation estimates\n",
    "and price targets respond to varying Price/Fundamental ratios.\n",
    "The decision analysis can be customized for different experimental designs. For example,\n",
    "researchers can use the framework to study the impact of various market conditions on agent\n",
    "behavior by varying other market parameters or the effect of different agent types on market\n",
    "dynamics by changing the agent population.\n",
    "2.3 Data Collection and Analysis\n",
    "Evaluating LLM trading agents requires robust methodologies for capturing, processing,\n",
    "and analyzing their behavior in market environments. The framework implements a com-\n",
    "prehensive analytics module that tracks all market activity, agent decisions, and performance\n",
    "metrics throughout experimental runs. This multi-layered approach not only records what\n",
    "happens in each simulation but also provides insights into why agents make specific deci-\n",
    "sions, enabling researchers to validate agent behavior against their defined strategies and\n",
    "assess overall market dynamics. The following sections detail the key components of this\n",
    "analytics infrastructure.\n",
    "23\n",
    "Figure 3: Trading Decision Distribution under Systematic Variation. Illustrates the proba-\n",
    "bility of Buy, Sell, or Hold decisions across different agent types as the Price/Fundamental\n",
    "ratio changes.\n",
    "24\n",
    "Figure 4: Order Size Distribution under Systematic Variation. Shows the average quan-\n",
    "tity traded (as a percentage of initial shares) for Buy and Sell orders across different\n",
    "Price/Fundamental ratios.\n",
    "2.3.1 Data Collection Architecture\n",
    "The framework implements a comprehensive data collection system that captures multiple\n",
    "dimensions of market behavior and agent decision-making. This structured approach ensures\n",
    "reproducibility and enables detailed analysis of market dynamics.\n",
    "2.3.2 Core Data Streams\n",
    "The system captures five primary data streams that work together to provide a complete\n",
    "picture of market activity. Market Data forms the foundation, tracking essential metrics\n",
    "including price evolution, fundamental values, trading volumes, order book depth, market\n",
    "liquidity, best bid/ask prices, spreads, and price-fundamental ratios. This is complemented\n",
    "by detailed Trade Data, which records individual transaction details such as prices, quan-\n",
    "tities, buyer and seller identifiers, timestamps, round information, and specific execution\n",
    "details.\n",
    "Agent Data provides insights into participant behavior by monitoring cash and share\n",
    "25\n",
    "Figure 5: Order Type Analysis under Systematic Variation. Displays the proportion of\n",
    "Market vs. Limit orders used by different agent types across varying Price/Fundamental\n",
    "ratios.\n",
    "26\"\"\",\n",
    "    \"\"\"tory equilibrium theory of allocations and prices in the presence of transactions costs\n",
    "promises still more complexity, because it requires a simultaneous endogenous de-\n",
    "termination of prices, allocations, and the least-cost form of market structure and\n",
    "ﬁnancial intermediation.\n",
    "To circumvent all this complexity and also preserve a role for intermediation, I in-\n",
    "troduce a continuous-time model in which many investors cannot trade costlessly, but\n",
    "the lowest-cost transactors (by deﬁnition, ﬁnancial intermediaries) can. In this model,\n",
    "standard CCA can be used to determine the production costs for ﬁnancial products is-\n",
    "sued by intermediaries. However, unlike in the standard zero-cost model, these prod-\n",
    "ucts can signiﬁcantly improve economic efﬁciency. If, moreover, the traded-security\n",
    "markets and ﬁnancial-services industry are competitive, then equilibrium prices of\n",
    "ﬁnancial products will equal the production costs of the lowest-cost transactors. In\n",
    "Section 14.5, we analyze this model and show that, through intermediation, all in-\n",
    "vestors can achieve optimal consumption-bequest allocations as if they could trade\n",
    "continuously without cost. Hence, in this model with transactions costs, both the\n",
    "contingent-claims analyzes of Chapters 11-13 and the equilibrium analyzes of Chap-\n",
    "ter 15 can be used to determine equilibrium allocations and prices.4Thus, this model\n",
    "provides a resolution of the Hakansson paradox by showing that mutual funds and\n",
    "derivative-security markets can provide important economic beneﬁts to investors and\n",
    "corporate issuers, even though these securities are priced in equilibrium as if they\n",
    "were redundant.\n",
    "3With diffusion processes and proportional transactions costs, investors cannot trade continuously, and\n",
    "therefore cannot perfectly hedge derivative-security positions. The reason is that, with continuous trading,\n",
    "transactions costs at each trade will be proportional to |dz|, where dzis a Brownian motion. However, for any\n",
    "noninﬁnitesimal time interval T,∫T\n",
    "0|dz|=∞almost certainly, and hence with continuous trading the total\n",
    "transactions cost is unbounded with probability one.\n",
    "4More generally, standard CCA will provide a close approximation if the “mark-up” per unit required\n",
    "to cover the intermediary’s transactions costs and proﬁt is sufﬁciently small that, from the perspective of its\n",
    "customers’ behavior, the additional cost is negligible. Of course, a tiny margin applied to large volume can\n",
    "produce substantial total proﬁts for the ﬁnancial intermediation industry.\n",
    "14.2 Derivative-Security Pricing with Transactions Costs 341\n",
    "14.2 Derivative-Security Pricing with Transactions Costs\n",
    "In this section, we examine the effects of transactions costs on derivative security\n",
    "pricing by using the two-period version of the Cox-Ross-Rubinstein binomial option\n",
    "pricing model as analyzed in Section 10.2. In that model, the initial stock price S(0)\n",
    "is given by S0. At time 1, the stock price will equal either S11orS12. IfS(1) = S11,\n",
    "then at time 2, S(2)will equal either S21orS22. IfS(1) = S12, then at time 2, S(2)\n",
    "will equal either S23orS24.Rdenotes the return per dollar invested in the riskless\n",
    "security and is constant over both periods. To capture the effect of transactions costs,\n",
    "we assume that a commission must be paid on each purchase or sale of the stock\n",
    "and that the commission rate is a ﬁxed proportion τof the dollar amount of the\n",
    "transaction. Equivalently, we could assume a bid-ask spread, in which investors pay\n",
    "theask price for the stock, Sa(t)≡(1 +τ)S(t), when they buy and receive the bid\n",
    "price ,Sb(t)≡(1−τ)S(t)when they sell. There are no costs for transacting in the\n",
    "riskless security.\n",
    "As shown in (10.3), the array of possible stock prices must satisfy certain condi-\n",
    "tions to rule out the possibility of arbitrage or dominance opportunities between the\n",
    "stock and the riskless security. The corresponding set of restrictions, in the presence\n",
    "of transactions costs can be written as\n",
    "S11< S0R <(1−τ)S12\n",
    "1 +τ(14.1a)\n",
    "S21< S11R <(1−τ)S22\"\"\",\n",
    "    \"\"\"investors’ optimal demand functions will depend upon how frequently they can revise\n",
    "their portfolios. Therefore, it should be pointed out that nowhere in the analysis\n",
    "presented here is it assumed that the distribution of X(T)−X(0)is invariant to h.\n",
    "Deﬁne the conditional expectation operator Etto be the expectation operator con-\n",
    "ditional on knowing all relevant information revealed as of time tor before. Deﬁne\n",
    "the random variables ǫ(k)by\n",
    "ǫ(k)≡X(k)−X(k−1)−Ek−1{\n",
    "X(k)−X(k−1)}\n",
    "k= 1,. .. , n (3.2)\n",
    "where “time k” is used as shorthand for “time kh.” By construction, Ek−1{ǫ(k)}= 0,\n",
    "andǫ(k)is the unanticipated price change in the security between k−1andk, condi-\n",
    "5See Merton (1975b).\n",
    "3.1 Introduction 49\n",
    "tional on being at time k−1. Moreover, by the properties of conditional expectation,\n",
    "it follows that Ek−j{ǫ(k)}= 0forj= 1,. . ., k . Hence the partial sums Sn≡∑n\n",
    "1ǫ(k)\n",
    "form a martingale .6As will be seen, the mathematical analysis to follow depends\n",
    "heavily on the properties of martingales. The theory of martingales is usually associ-\n",
    "ated in the ﬁnancial economics literature with the “Efﬁcient-Market Hypothesis” of\n",
    "Fama and Samuelson.7Therefore, the reader may be tempted to connect the martin-\n",
    "gale property of the unanticipated returns derived here with an implicit assumption\n",
    "that “securities are priced correctly.” However, the martingale property of the unan-\n",
    "ticipated returns here is purely a result of construction, and therefore imposes no such\n",
    "economics assumption. However, two economics assumptions that will be imposed\n",
    "are as follows.\n",
    "Assumption 5.\n",
    "For each ﬁnite time interval [0,T]there exists a number A1>0, independent of the\n",
    "number of trading intervals n, such that Var(Sn)≥A1where Var(Sn)≡E0{[∑n\n",
    "1ǫ(k)]2}\n",
    ".\n",
    "Assumption 6.\n",
    "For each ﬁnite time interval [0,T], there exists a number A2<∞, independent of n,\n",
    "such that Var(Sn)≤A2.\n",
    "Assumption 1 ensures that the uncertainty associated with the unanticipated price\n",
    "changes is not “washed out” or eliminated even in the limit of continuous trading.\n",
    "That is, even as h→dt, the “end-of-period” price at time kwill be uncertain relative\n",
    "to time k−1. This assumption is essential for the continuous-trading model to capture\n",
    "this fundamental property of stock-price behavior.\n",
    "Assumption 2 ensures that the uncertainty associated with the unanticipated price\n",
    "changes over a ﬁnite period of time is not so great that the variance becomes un-\n",
    "bounded. It rules out the possibility that the very act of allowing more frequent trad-\n",
    "ing will induce sufﬁcient price instability to cause the limiting variance of X(T)−\n",
    "X(0)to become unbounded, and it also rules out the Pareto-Levy stable distributions\n",
    "with inﬁnite variances.\n",
    "Deﬁne V(k)≡E0{ǫ2(k)},k= 1,2,. . ., n , to be the variance of the dollar return on\n",
    "the security between time k−1andkbased upon information available as of time\n",
    "zero, and deﬁne V≡maxkV(k).\n",
    "Assumption 7.\n",
    "There exists a number A3,1≥A3>0, independent of n, such that for k= 1,. .. , n ,\n",
    "V(k)/V≥A3.\n",
    "6For a formal deﬁnition of the martingale and discussions of its properties, see Feller (1966, pp. 210-15\n",
    "and 234-8). Important mathematical analyzes of martingales in continuous-time processes are by Dellacherie\n",
    "and Meyer (1982) and Kunita and Watanabe (1967).\n",
    "7See Fama (1965a, 1970a, 1991), Samuelson (1965b, 1973), and also Cootner (1964). The theory of\n",
    "martingales provides a powerful technique for the analysis of equilibrium security prices in continuous-time\n",
    "models. See Harrison and Kreps (1979), Kreps (1981), Harrison and Pliska (1981, 1983), Dufﬁe and Huang\n",
    "(1985, 1986), Dufﬁe (1986, 1988), Huang (1985a, b, 1987), Pliska (1986), and Cox and Huang (1989a, b.\n",
    "1991).\n",
    "50 On the Mathematics and Economics Assumptions of Continuous-Time Models\n",
    "Assumption 3 is closely related to Assumption 1 and in effect rules out the possi-\n",
    "bility that all the uncertainty in the unanticipated price changes over [0,T]is concen-\n",
    "trated in a few of the many trading periods. In other words, there is signiﬁcant price\"\"\",\n",
    "    \"\"\"allocations are brieﬂy addressed in Chapter 15 and analyzed more fully in Chapter 16. If a set of existing\n",
    "securities and markets leads to an equilibrium that is an unconstrained Pareto optimum, then any additional\n",
    "securities or markets will be redundant.\n",
    "50The term “transactions costs” can, of course, mean more than just the bid-ask spread or commissions\n",
    "paid for buying and selling assets. For example, if an investor literally traded his portfolio continuously, he\n",
    "would have no time to do anything else! Because investment management and ﬁnancial intermediation involve\n",
    "primarily information processing and security trading, there arc signiﬁcant economies of scale. One would thus\n",
    "expect substantially lower costs for the individual investor to use intermediaries instead of transacting directly\n",
    "in the asset markets.\n",
    "368 Financial Intermediation in the Continuous-Time Model\n",
    "It would seem therefore that the same dichotomy derived in the frictionless-market\n",
    "case applies also to our model with transactions costs. In a formal computational\n",
    "sense it does. We can still solve for the equilibrium asset-price dynamics in the model\n",
    "of Chapter 15 and then compute the prices of derivative securities, mutual funds, and\n",
    "corporate liabilities using CCA. There is one signiﬁcant difference, however: the\n",
    "ﬁrst-part calculation of equilibrium real-sector allocations is valid if and only if there\n",
    "exists a sufﬁciently rich set of securities and intermediaries in the ﬁnancial sector to\n",
    "make these allocations feasible for agents who cannot trade without cost. Because\n",
    "of this conditioning. perhaps a more appropriate term for this separation is “quasi-\n",
    "dichotomy.”\n",
    "With the assumption that not all agents can trade continuously without cost, a\n",
    "signiﬁcant economic role is established for derivative-security markets and ﬁnancial\n",
    "intermediaries in the model. Somewhat paradoxically, we ﬁnd that, if intermediation\n",
    "is efﬁcient, then derivative securities and the ﬁnancial products of the intermediaries\n",
    "will be priced as if they are redundant.51Under these conditions, quasi-dichotomy\n",
    "obtains, and we can derive equilibrium real-sector allocations and asset prices from\n",
    "the frictionless-market version of the model.\n",
    "14.6 Afterword: Policy and Strategy in Financial Intermediation\n",
    "In this chapter, as throughout the book, the focus has been on theory. Allusions to\n",
    "practice were concentrated on the micro quantitative applications of the continuous-\n",
    "time model to product technologies and risk management. Still, I cannot wholly\n",
    "resist the temptation to call attention to the model’s potential for addressing broader\n",
    "issues in the practice of intermediation. And so this afterword shall ever so brieﬂy\n",
    "touch upon implications of the model for intermediation policy and strategy in the\n",
    "hope that it will lead others, better qualiﬁed, to explore this matter elsewhere.\n",
    "Derivative securities have long been an integral part of the ﬁnancial markets,52\n",
    "but most would mark the creation of the Chicago Board Options Exchange in April\n",
    "1973 as the start of the current wave of ﬁnancial innovations involving derivative\n",
    "securities. The succeeding years have witnessed an unprecedented proliferation of\n",
    "organized trading markets in both equity and ﬁxed-income derivative instruments.\n",
    "In turn, these markets made possible the creation of a wide range of ﬁnancial prod-\n",
    "51Thus, our model provides a resolution to Hakansson’s (1979, p. 722) “The Catch 22 of Option Pricing.”\n",
    "Although the equilibrium prices of options and other derivative securities satisfy the redundancy condition of\n",
    "CCA, they are nevertheless needed to support the equilibrium allocations, and hence their elimination would\n",
    "reduce social welfare.\n",
    "52Bernstein (1992) reports that Aristotle’s anecdote about Thales in Book I of Politics is the ﬁrst recorded\n",
    "mention of a ﬁnancial option. Schaede (1988) makes the case that the Dojima rice market in Osaka was a\"\"\",\n",
    "]\n",
    "\n",
    "    ),\n",
    "    \n",
    "    LLMTestCase(\n",
    "        input=\"In simple terms, what does Figure 7 (agent valuations over time) tell us about over‑ vs under‑valuation corrections?\",\n",
    "        actual_output=\"\"\"Figure 7 shows that the AI agents were better at correcting under-valuations than over-valuations. When the simulated market started low, the agents' valuations gradually increased over time, moving closer to the true fundamental value. However, when the market started high, the agents' valuations remained high and didn't adjust downwards towards the true value within the timeframe of the simulation.\n",
    "\"\"\",\n",
    "        expected_output=\"\"\"With an initial price 25 % above fundamentals, prices failed to converge downward within 15 rounds and agents kept over‑valuing the asset.\"\"\",\n",
    "        context=[\n",
    "            \"\"\"When the market starts significantly above the fundamental value … the price fails to converge downwards … remaining substantially elevated. Agent valuations mirror this persistence, with many agents maintaining estimates well above the fundamental value.\"\"\"\n",
    "        ],\n",
    "        retrieval_context=[\n",
    "    \"\"\"bids/asks), and two Speculator agents (opportunistic traders seeking inefficiencies). Market\n",
    "31\n",
    "makers are given enhanced liquidity with 20x the baseline cash and shares to ensure suffi-\n",
    "cient liquidity provision and facilitate price discovery. The scenario tests whether prices can\n",
    "correct downward through trading activity when starting from an overvalued state.\n",
    "3.2.2 Price Discovery (Below Fundamental)\n",
    "This complementary scenario tests upward price convergence by starting with an initial price\n",
    "25% below the fundamental value ( $21.00). It employs the identical agent composition and\n",
    "parameters as the above-fundamental scenario, allowing for direct comparison of market\n",
    "behavior under opposite initial mispricing conditions. This design enables researchers to\n",
    "assess potential asymmetries in price discovery processes.\n",
    "3.2.3 Infinite Horizon Price Discovery\n",
    "We extend both price discovery scenarios to infinite horizon settings, where shares are not\n",
    "redeemed at a terminal date. The initial prices are set at double ($56.00) and half ($14.00) the\n",
    "fundamental value for the above and below fundamental scenarios respectively, creating more\n",
    "extreme mispricing conditions. These scenarios run for 15 trading rounds and test whether\n",
    "agents correctly value assets based on expected dividend streams rather than redemption\n",
    "values. Each infinite horizon scenario involves two Default investors, two Optimistic traders,\n",
    "two Market makers, and two Speculator agents.\n",
    "The results from these infinite horizon scenarios reveal interesting asymmetries in price\n",
    "discovery, as illustrated in Figure 6 and Figure 7. When the market starts significantly above\n",
    "the fundamental value (left panels), the price fails to converge downwards towards the$28.00\n",
    "benchmark within the 15 rounds, remaining substantially elevated. Agent valuations mirror\n",
    "this persistence, with many agents maintaining estimates well above the fundamental value.\n",
    "However, when the market begins significantly below the fundamental value (right panels),\n",
    "the price exhibits a clear convergence towards the fundamental benchmark. Agent valuations\n",
    "in this scenario also tend to adjust upwards, aligning more closely with the calculated fun-\n",
    "32\n",
    "damental value over time. This suggests that under these conditions, LLM agents are more\n",
    "effective at correcting undervaluation than overvaluation within the simulated timeframe.\n",
    "Figure 6: Price Evolution: Infinite Horizon Scenarios. Left: Initial price $56.00 (Above\n",
    "Fundamental). Right: Initial price $14.00 (Below Fundamental). The dashed line indicates\n",
    "the fundamental value ($28.00).\n",
    "Figure 7: Agent Valuations: Infinite Horizon Scenarios. Left: Initial price $56.00 (Above\n",
    "Fundamental). Right: Initial price $14.00 (Below Fundamental). Shows individual agent\n",
    "estimates of fundamental value over time.\n",
    "3.2.4 Divergent Beliefs\n",
    "This scenario explores the impact of heterogeneous beliefs about fundamental value by com-\n",
    "bining agents with systematically different valuation models. The agent composition is\n",
    "designed to create heterogeneity: two Optimistic traders (believing the fundamental value is\n",
    "significantly higher), two Pessimistic traders (believing it is significantly lower), two neutral\n",
    "Market makers, two Momentum traders (following price trends rather than fundamentals),\n",
    "and two Default investors (baseline agents). We test both above-fundamental (initial price\n",
    "$56.00, 2x fundamental) and below-fundamental (initial price$14.00, 0.5x fundamental) vari-\n",
    "33\n",
    "ants, allowing researchers to study how different belief structures influence price formation\n",
    "and trading patterns under different initial mispricings. In these scenarios, the fundamental\n",
    "price is hidden from agents, forcing them to rely on their own valuation models.\n",
    "3.2.5 Market Stress\n",
    "This scenario tests market resilience under challenging conditions by creating a more volatile\n",
    "environment. The scenario includes two consistently bullish Optimistic traders, two consis-\"\"\",\n",
    "    \"\"\"value, the system:\n",
    "1. Sets market price P = ρV where ρ is the target ratio\n",
    "2. Generates a consistent order book structure around this price\n",
    "3. Executes multiple decision trials with the same agent type\n",
    "4. Records decision outcomes (buy/sell/hold), order types, quantities, and reasoning\n",
    "This process maps how LLM agents respond to different price environments, as illustrated\n",
    "in Figures 2, 3, 4, and 5. The analysis reveals clear patterns in decision boundaries, with\n",
    "distinct transitions between buying, selling, and holding regions that vary by agent type. For\n",
    "example, value investors show strong buying tendencies when prices are below fundamental\n",
    "value (ρ <1) and selling preferences when prices exceed fundamentals ( ρ >1). In contrast,\n",
    "momentum traders show less sensitivity to the fundamental ratio and more responsiveness\n",
    "to recent price trends.\n",
    "The systematic variation approach also reveals patterns in order sizing and limit price\n",
    "selection, with agents typically placing larger orders when prices deviate significantly from\n",
    "their valuation models (Figure 4). This methodology provides unprecedented transparency\n",
    "into LLM decision processes and enables quantitative comparison of different agent types\n",
    "and LLM architectures.\n",
    "22\n",
    "Figure 2: Price Analysis under Systematic Variation. Shows how agent valuation estimates\n",
    "and price targets respond to varying Price/Fundamental ratios.\n",
    "The decision analysis can be customized for different experimental designs. For example,\n",
    "researchers can use the framework to study the impact of various market conditions on agent\n",
    "behavior by varying other market parameters or the effect of different agent types on market\n",
    "dynamics by changing the agent population.\n",
    "2.3 Data Collection and Analysis\n",
    "Evaluating LLM trading agents requires robust methodologies for capturing, processing,\n",
    "and analyzing their behavior in market environments. The framework implements a com-\n",
    "prehensive analytics module that tracks all market activity, agent decisions, and performance\n",
    "metrics throughout experimental runs. This multi-layered approach not only records what\n",
    "happens in each simulation but also provides insights into why agents make specific deci-\n",
    "sions, enabling researchers to validate agent behavior against their defined strategies and\n",
    "assess overall market dynamics. The following sections detail the key components of this\n",
    "analytics infrastructure.\n",
    "23\n",
    "Figure 3: Trading Decision Distribution under Systematic Variation. Illustrates the proba-\n",
    "bility of Buy, Sell, or Hold decisions across different agent types as the Price/Fundamental\n",
    "ratio changes.\n",
    "24\n",
    "Figure 4: Order Size Distribution under Systematic Variation. Shows the average quan-\n",
    "tity traded (as a percentage of initial shares) for Buy and Sell orders across different\n",
    "Price/Fundamental ratios.\n",
    "2.3.1 Data Collection Architecture\n",
    "The framework implements a comprehensive data collection system that captures multiple\n",
    "dimensions of market behavior and agent decision-making. This structured approach ensures\n",
    "reproducibility and enables detailed analysis of market dynamics.\n",
    "2.3.2 Core Data Streams\n",
    "The system captures five primary data streams that work together to provide a complete\n",
    "picture of market activity. Market Data forms the foundation, tracking essential metrics\n",
    "including price evolution, fundamental values, trading volumes, order book depth, market\n",
    "liquidity, best bid/ask prices, spreads, and price-fundamental ratios. This is complemented\n",
    "by detailed Trade Data, which records individual transaction details such as prices, quan-\n",
    "tities, buyer and seller identifiers, timestamps, round information, and specific execution\n",
    "details.\n",
    "Agent Data provides insights into participant behavior by monitoring cash and share\n",
    "25\n",
    "Figure 5: Order Type Analysis under Systematic Variation. Displays the proportion of\n",
    "Market vs. Limit orders used by different agent types across varying Price/Fundamental\n",
    "ratios.\n",
    "26\"\"\",\n",
    "    \"\"\"the decision-making engine.\n",
    "The data collection system captures comprehensive market activity across multiple di-\n",
    "mensions. At the market level, it tracks the evolution of prices, fundamental values, and\n",
    "realized dividends, providing insights into overall market dynamics. Individual agent data\n",
    "includes detailed wealth trajectories and portfolio compositions, enabling analysis of strategy\n",
    "effectiveness and wealth distribution patterns. The system maintains complete transaction\n",
    "records with prices, quantities, and counterparty information, facilitating the study of trad-\n",
    "ing patterns and market microstructure. Additionally, it captures agent decision rationales\n",
    "and strategy adherence metrics, allowing researchers to evaluate the consistency and effec-\n",
    "tiveness of different trading approaches.\n",
    "All experimental parameters, market outcomes, and agent interactions are systemati-\n",
    "cally logged and stored in structured formats (CSV and JSON) for subsequent analysis. The\n",
    "framework generates standardized visualizations of price evolution, wealth distribution, and\n",
    "dividend payments to facilitate comparative analysis across different experimental configu-\n",
    "rations.\n",
    "3.1 Fundamental Value Calibration\n",
    "The framework implements a consistent approach to fundamental value calculation that pro-\n",
    "vides a reliable benchmark for price discovery. For infinite horizon markets, the fundamental\n",
    "value follows the standard dividend discount model:\n",
    "Vt = E[D]\n",
    "r = Expected Dividend\n",
    "Interest Rate (1)\n",
    "For the default parameters where the expected dividend is $1.40 and the interest rate is\n",
    "5%, this yields a fundamental value of $28.00.\n",
    "In finite horizon markets with T periods remaining, the fundamental value incorporates\n",
    "30\n",
    "both future dividends and terminal redemption value K:\n",
    "FVt =\n",
    "TX\n",
    "τ=t\n",
    "E[D]\n",
    "(1 + r)τ−t+1 + K\n",
    "(1 + r)T−t+1 (2)\n",
    "To ensure consistency between finite and infinite horizon markets, the redemption value\n",
    "K is set equal to E[D]\n",
    "r , which makes the fundamental value constant atE[D]\n",
    "r across all periods,\n",
    "regardless of the time horizon. This calibration approach ensures a clean experimental design\n",
    "by providing a stable benchmark for price discovery.\n",
    "3.2 Experimental Scenarios\n",
    "To evaluate market dynamics with LLM-based agents, we implemented several experimental\n",
    "scenarios that systematically explore different initial conditions and agent compositions.\n",
    "Each scenario maintains the fundamental value of $28.00 while varying starting prices, time\n",
    "horizons, and agent populations. These scenarios address our core research questions (Section\n",
    "1) by testing LLM capabilities under varying market conditions, focusing on price discovery\n",
    "dynamics, the impact of heterogeneous beliefs, and market stability under stress; GPT-4o\n",
    "was used consistently as the decision-making engine for all LLM agents across these scenarios.\n",
    "We present the setup for several key scenarios below, followed by a discussion of the observed\n",
    "results for the 2 experiments involving an infinite horizon market with a starting price either\n",
    "above or below the fundamental value.\n",
    "3.2.1 Price Discovery (Above Fundamental)\n",
    "This scenario tests downward price convergence by starting with an initial price 25% above\n",
    "the fundamental value ( $35.00). It runs for 20 trading rounds and features a diverse\n",
    "agent population, including two Default investors (baseline agents), two Optimistic traders\n",
    "(who believe prices should be higher), two Market makers (providing liquidity by posting\n",
    "bids/asks), and two Speculator agents (opportunistic traders seeking inefficiencies). Market\n",
    "31\n",
    "makers are given enhanced liquidity with 20x the baseline cash and shares to ensure suffi-\n",
    "cient liquidity provision and facilitate price discovery. The scenario tests whether prices can\n",
    "correct downward through trading activity when starting from an overvalued state.\n",
    "3.2.2 Price Discovery (Below Fundamental)\n",
    "This complementary scenario tests upward price convergence by starting with an initial price\"\"\",\n",
    "    \"\"\"market efficiency and price discovery processes throughout the simulation.\n",
    "Agent performance metrics include absolute position tracking (shares, cash, and total\n",
    "wealth), wealth composition analysis, position change metrics, and return calculations. The\n",
    "system computes both absolute and percentage returns on various portfolio components\n",
    "and compares performance across agent types to identify relative advantages of different\n",
    "strategies. Trading flow analysis visualizes the volume of shares moving between different\n",
    "agent types and cumulative net trading flows, revealing which agents act as net buyers or\n",
    "sellers in different market conditions.\n",
    "Decision pattern analysis employs heatmaps to visualize the consistency of agent decision-\n",
    "making over time, allowing researchers to identify shifts in strategic behavior. This is com-\n",
    "plemented by decision quantities visualization that plots order sizes to highlight variations\n",
    "in trade aggressiveness across agent types. When agent reasoning data is available, the\n",
    "system generates wordclouds to extract key terms from agent explanations, providing qual-\n",
    "itative insights into decision drivers for different agent strategies. Additional visualizations\n",
    "track price target accuracy and compare agent-specific valuations to realized market prices,\n",
    "28\n",
    "offering insights into the forecasting abilities of different agents.\n",
    "A key advantage of simulation-based analysis is complete observability of all market\n",
    "processes and agent states. Unlike real-world markets where data availability is often limited,\n",
    "the framework captures every interaction, decision, and state change with perfect fidelity.\n",
    "This comprehensive data collection allows researchers to compute additional metrics beyond\n",
    "standard market measures, enabling novel analyses such as counterfactual testing (e.g., how\n",
    "would markets evolve with different agent compositions), causal inference of specific agent\n",
    "behaviors on market outcomes, and the development of custom efficiency or stability metrics\n",
    "tailored to particular research questions. The system’s modular design facilitates rapid\n",
    "implementation of new metrics and visualizations as research questions evolve.\n",
    "3 Experimental Design and Results\n",
    "Our experimental framework implements a dividend-paying asset market with heterogeneous\n",
    "agents. The baseline simulation runs for 15 to 20 rounds with 8 participating agents, although\n",
    "these parameters are fully configurable. Each agent begins with an initial endowment of\n",
    "1,000,000 monetary units and 10,000 shares of the asset. The fundamental value of the asset\n",
    "is set at $28.00, with a final redemption value matching this fundamental price in finite\n",
    "horizon scenarios. Transaction costs are set to zero to isolate the effects of agent behavior\n",
    "and market structure.\n",
    "The dividend structure follows a stochastic process with a base payment of $1.40 and a\n",
    "variation of ±$1.00, paid with 50% probability each round. This design creates uncertainty\n",
    "in the asset’s income stream while maintaining a known expected value. Cash holdings earn\n",
    "a risk-free interest rate of 5% per round, providing an opportunity cost for asset investment.\n",
    "Agent composition is controlled through a flexible distribution system that allows for\n",
    "various experimental configurations. In our baseline setup, we employ a mixed population\n",
    "of value investors, momentum traders, and market makers. Each agent type implements\n",
    "29\n",
    "distinct trading strategies through Large Language Model (LLM) prompts, with GPT-4o as\n",
    "the decision-making engine.\n",
    "The data collection system captures comprehensive market activity across multiple di-\n",
    "mensions. At the market level, it tracks the evolution of prices, fundamental values, and\n",
    "realized dividends, providing insights into overall market dynamics. Individual agent data\n",
    "includes detailed wealth trajectories and portfolio compositions, enabling analysis of strategy\n",
    "effectiveness and wealth distribution patterns. The system maintains complete transaction\"\"\",\n",
    "    \"\"\"by detailed Trade Data, which records individual transaction details such as prices, quan-\n",
    "tities, buyer and seller identifiers, timestamps, round information, and specific execution\n",
    "details.\n",
    "Agent Data provides insights into participant behavior by monitoring cash and share\n",
    "25\n",
    "Figure 5: Order Type Analysis under Systematic Variation. Displays the proportion of\n",
    "Market vs. Limit orders used by different agent types across varying Price/Fundamental\n",
    "ratios.\n",
    "26\n",
    "positions, portfolio values, wealth evolution, and agent type and strategy identifiers. Or-\n",
    "der Data captures the complete lifecycle of trading decisions, including order specifications\n",
    "(type, size, price), agent reasoning and justification, decision context and timing, and order\n",
    "lifecycle events. Finally, Market State data maintains a comprehensive view of overall mar-\n",
    "ket conditions through order book snapshots, market depth information, aggregate statistics,\n",
    "and various market microstructure metrics.\n",
    "2.3.3 Data Validation and Storage\n",
    "The system implements a comprehensive set of data quality measures to ensure reliability and\n",
    "consistency. The validation framework performs continuous checks for data completeness,\n",
    "verifies consistency across related data streams, enforces format and type validation, and\n",
    "maintains proper temporal sequencing of all recorded events. These validation mechanisms\n",
    "work together to maintain data integrity throughout the experimental process.\n",
    "The storage architecture employs multiple formats optimized for different data types and\n",
    "use cases. Structured CSV files store tabular data for efficient analysis, while JSON formats\n",
    "accommodate complex nested structures that preserve the rich relationships between market\n",
    "elements. The system maintains detailed timestamped logs for debugging purposes and\n",
    "generates summary statistics to facilitate quick analysis of experimental outcomes.\n",
    "This comprehensive data collection architecture enables researchers to conduct detailed\n",
    "analysis of market dynamics, validate agent behavior patterns, ensure experiment repro-\n",
    "ducibility, and perform meaningful cross-experiment comparisons. The integrated approach\n",
    "to data management provides the foundation for rigorous empirical investigation of market\n",
    "behavior and agent interactions.\n",
    "The framework implements specialized visualization techniques to analyze agent behavior\n",
    "and market dynamics. Decision heatmaps plot agent actions across trading rounds, reveal-\n",
    "ing strategic patterns and consistency. Trading flow visualizations track cumulative position\n",
    "changes, identifying net buyers and sellers throughout market evolution. Reasoning word-\n",
    "27\n",
    "clouds extract key terms from agent explanations, providing insight into decision drivers\n",
    "across different agent types.\n",
    "The system also generates specialized market quality visualizations including bid-ask\n",
    "spread evolution, price target accuracy, and agent valuation tracking. These visualizations\n",
    "work in concert with the numerical metrics to provide both quantitative and qualitative\n",
    "insights into agent behavior and market dynamics.\n",
    "2.3.4 Validation Metrics and Performance Monitoring\n",
    "The framework implements a comprehensive set of performance metrics and visualization\n",
    "tools that monitor agent behavior and market dynamics. Market evolution visualizations\n",
    "track price movements relative to fundamental values, including time series of transaction\n",
    "prices, midpoint prices, and bid-ask spreads. These visualizations enable researchers to assess\n",
    "market efficiency and price discovery processes throughout the simulation.\n",
    "Agent performance metrics include absolute position tracking (shares, cash, and total\n",
    "wealth), wealth composition analysis, position change metrics, and return calculations. The\n",
    "system computes both absolute and percentage returns on various portfolio components\n",
    "and compares performance across agent types to identify relative advantages of different\"\"\",\n",
    "    \"\"\"the second agents’ design, and the third the analysis module.\n",
    "8\n",
    "2.1 Market Design\n",
    "Our methodological framework integrates three components that create a controlled envi-\n",
    "ronment for LLM-based trading agents. The framework implements a flexible continuous\n",
    "double-auction market mechanism that couples standard market microstructure principles\n",
    "with market clearing and matching algorithms to accommodate asynchronous LLM decisions.\n",
    "The market clearing process employs a dual-stage matching algorithm. In the first stage,\n",
    "limit orders are posted. In the second stage, market orders are netted using a market-\n",
    "to-market matching engine that processes buy and sell orders, reconciling orders based on\n",
    "available agent cash and share commitments. In the third stage, any remaining market\n",
    "orders are matched against the existing order book, with unfilled quantities converted to\n",
    "aggressive limit orders. This three-tiered approach optimizes immediate execution and price\n",
    "discovery while maintaining market liquidity.\n",
    "The system’s OrderMatchingService orchestrates this process by coordinating trade ex-\n",
    "ecutions through the TradeExecutionService and managing order state transitions via the\n",
    "OrderStateManager. Each trade is logged in detail, with the overall market state—including\n",
    "order books, market depth, and price evolution—recalculated at the end of each trading\n",
    "round.\n",
    "This modular design in the matching and clearing engine provides several advantages.\n",
    "First, it enables rigorous trade validation where each market order is validated against agent\n",
    "cash commitments and position constraints before matching, with the system dynamically\n",
    "adjusting order quantities based on available cash when an agent’s commitment is insuf-\n",
    "ficient, thus minimizing execution errors. Second, it offers flexible liquidity handling by\n",
    "supporting market-to-market and market-to-book matching, ensuring orders have multiple\n",
    "execution pathways, with unexecuted market orders converted to aggressive limit orders to\n",
    "capture remaining liquidity. Third, it maintains detailed trade audit capabilities by recording\n",
    "comprehensive traceability data including timestamps, trade volumes, executed prices, and\n",
    "agent identifiers, thereby enabling post-trade analysis and performance benchmarking that\n",
    "9\n",
    "serves as the foundation for subsequent market efficiency and agent performance validations.\n",
    "2.1.1 Market Mechanism Design\n",
    "Our framework implements a continuous double-auction market mechanism that processes\n",
    "orders in discrete trading rounds. We use discrete trading rounds because LLMs have latency\n",
    "constraints, making it infeasible to process orders in real time. Within each round, the order\n",
    "of agent submissions is randomized to avoid giving systematic priority to specific agents,\n",
    "thus simulating concurrent order arrival while maintaining fairness. Once randomized, or-\n",
    "ders are then processed according to standard price-time priority rules. The system supports\n",
    "finite and infinite horizon markets, with differences in terminal conditions and wealth cal-\n",
    "culation. In finite-horizon markets, agents are informed of the total number of rounds, and\n",
    "their terminal wealth is calculated by redeeming all shares at the fundamental value of the\n",
    "final round. In infinite-horizon markets, no terminal information is provided to agents, and\n",
    "final wealth is determined using the last market price for share valuation. This design choice\n",
    "enables researchers to study how time horizons influence trading strategies and price for-\n",
    "mation, particularly how agents balance short-term trading opportunities against long-term\n",
    "value considerations.\n",
    "In a double auction, buyers and sellers actively submit orders, with trades occurring when\n",
    "compatible buy and sell orders match the price. The matching engine processes these orders\n",
    "through three sequential phases:\n",
    "First, incoming limit orders that do not immediately cross the market are added to\n",
    "the order book, maintaining strict price-time priority. Second, market orders are processed\"\"\",\n",
    "    \"\"\"33\n",
    "ants, allowing researchers to study how different belief structures influence price formation\n",
    "and trading patterns under different initial mispricings. In these scenarios, the fundamental\n",
    "price is hidden from agents, forcing them to rely on their own valuation models.\n",
    "3.2.5 Market Stress\n",
    "This scenario tests market resilience under challenging conditions by creating a more volatile\n",
    "environment. The scenario includes two consistently bullish Optimistic traders, two consis-\n",
    "tently bearish Pessimistic traders, two Market makers (liquidity providers), and two Value\n",
    "investors (rational benchmark traders). The scenario runs for 100 rounds to study long-term\n",
    "market behavior and includes unequal initial endowments, with optimistic traders having\n",
    "more cash (1.5x baseline) but fewer shares (0.5x baseline) and pessimistic traders having less\n",
    "cash (0.5x baseline) but more shares (1.5x baseline). This resource imbalance tests whether\n",
    "particular agent types can dominate market outcomes through resource advantages.\n",
    "The scenarios presented here demonstrate the framework’s capabilities for exploring di-\n",
    "verse market conditions. Its modular structure facilitates the straightforward definition and\n",
    "implementation of alternative experimental designs, enabling researchers to tailor simulations\n",
    "to specific research questions.\n",
    "In all scenarios, we maintain consistent baseline parameters with a fundamental value\n",
    "of $28.00, calculated from the expected dividend of $1.40 and interest rate of 5%. Agent\n",
    "endowments start at 1,000,000 monetary units and 10,000 shares unless specifically modified.\n",
    "Transaction costs are set to zero to isolate the effects of agent behavior and market structure\n",
    "on price formation.\n",
    "4 Conclusion\n",
    "This paper demonstrates that Large Language Models can effectively function as diverse\n",
    "trading agents—from value investors to market makers—maintaining strategic consistency\n",
    "34\n",
    "while adapting to market conditions. Our experimental framework reveals that their in-\n",
    "teractions generate realistic market dynamics, including phenomena like price bubbles and\n",
    "corrections, highlighting both the capabilities and potential risks of deploying LLM agents\n",
    "in financial markets.\n",
    "These findings carry significant implications for market structure and regulation. While\n",
    "LLM agents can enhance price discovery and liquidity, their adherence to programmed strate-\n",
    "gies, even potentially flawed ones derived from prompts, could amplify market volatility or\n",
    "introduce novel systemic risks, as observed in our simulated bubble scenarios. A key concern\n",
    "is the potential for widespread correlated behavior: similar underlying LLM architectures\n",
    "responding uniformly to comparable prompts or market signals could inadvertently create\n",
    "destabilizing trading patterns without explicit coordination. This underscores the critical\n",
    "need for rigorous testing and validation of LLM-based trading systems prior to live deploy-\n",
    "ment.\n",
    "A central contribution of this work is the open-source simulation framework itself, de-\n",
    "signed to catalyze research into LLM trading agents. We invite the research community to\n",
    "utilize and extend this platform to investigate pressing questions in this rapidly evolving\n",
    "area. The framework enables systematic exploration of complex scenarios—such as hybrid\n",
    "human-LLM markets, stress tests, varying market structures, regulatory impacts, and the\n",
    "nuances of LLM prompting—often difficult or costly to study otherwise. Specific avenues\n",
    "ripe for investigation using this tool include the emergence of novel trading strategies, the\n",
    "precise effects of agent heterogeneity on market stability, and the development of robust\n",
    "validation protocols for AI traders. As artificial intelligence becomes more integrated into\n",
    "finance, collaborative research leveraging adaptable simulation environments like this one\n",
    "will be crucial for understanding and responsibly shaping the future of trading.\n",
    "35\n",
    "References\"\"\",\n",
    "    \"\"\"(2023)). This work, however, focuses on financial markets and how LLM agents can operate\n",
    "as full-fledged trading participants.\n",
    "Recent research examines specific applications of LLMs for trading. FinMem and Trad-\n",
    "ingGPT introduce frameworks with layered memory systems and customizable agent traits\n",
    "5\n",
    "to improve financial decision-making (Yu, Li, et al. 2024; Li, Zhang, and Sun 2023). Hierar-\n",
    "chical multi-agent architectures have been explored in FinCon, which uses a manager-analyst\n",
    "setup for collaborative portfolio decisions (Yu, Yao, et al. 2024). QuantAgent implements\n",
    "a self-improving signal-mining approach (Wang et al. 2024), while other work underscores\n",
    "the importance of long-term memory in LLM agents via vector databases (Hatalis et al.\n",
    "2024). This line of research builds on successful reinforcement learning applications such as\n",
    "AlphaPortfolio (Cong et al. 2021) and AlphaManager (Campello, Cong, and Zhou 2023),\n",
    "which leverage deep RL and robust control for portfolio management.\n",
    "Analyzing LLM agent behavior by changing only some parameters draws on methods\n",
    "from the interpretable machine learning literature. In particular, the systematic variation\n",
    "of market parameters to reveal decision patterns mirrors partial dependence plots and in-\n",
    "dividual conditional expectation curves used to interpret complex machine learning models\n",
    "(Molnar 2022). These techniques help reveal how LLM agents respond to changes in specific\n",
    "variables while holding others constant, providing insight into their internal decision-making\n",
    "processes that would otherwise remain opaque.\n",
    "Beyond finance, studies of LLM capabilities in interactive or multi-agent settings offer\n",
    "valuable insights. Benchmarks like AgentBench evaluate LLMs’ performance in interac-\n",
    "tive tasks (Liu et al. 2023), while InvestorBench focuses on financial decision-making tasks\n",
    "specifically (H. Li et al. 2024). NegotiationArena demonstrates LLMs’ capacity for strategic\n",
    "interaction in bargaining contexts (Bianchi et al. 2024). Similarly, Guo et al. (2024) provide\n",
    "an economics ”arena” where LLMs compete in strategic games, revealing that advanced\n",
    "models like GPT-4 can exhibit rational, adaptive behavior—albeit not always reaching Nash\n",
    "Equilibrium. Existing frameworks typically assess individual agents or hierarchical collab-\n",
    "orations, whereas this work studies emergent market behaviors that arise from multiple\n",
    "independent LLM traders interacting in a marketplace.\n",
    "The approach also connects to the tradition of experimental asset markets. For instance,\n",
    "Weitzel et al. (2020) show that even finance professionals are susceptible to speculative\n",
    "6\n",
    "bubbles, especially amid high capital inflows. Kop´ anyi-Peuker and Weber (2021) find that\n",
    "trading experience alone does not eliminate bubbles, challenging assumptions about rational\n",
    "market learning. Kirchler, Huber, and St¨ ockl (2012) identify confusion about fundamental\n",
    "values as a key driver of bubble formation. This framework offers a new way to study these\n",
    "phenomena with LLM traders, which can be rigorously parameterized for sophistication,\n",
    "strategy, and information processing. Hence, this paper provides a method to investigate\n",
    "how automated or ”artificial” agents might affect market stability or volatility.\n",
    "Other recent work highlights the versatility of LLM agents in complex, interactive sce-\n",
    "narios beyond finance. One stream focuses on simulating social behaviors—such as opinion\n",
    "dynamics (Chuang et al. 2023), trust (Xie et al. 2024), and resource-sharing (Piatti et al.\n",
    "2024). Another examines LLMs’ strategic capabilities through task-based simulations and\n",
    "collaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\n",
    "Within the computer science literature, early works apply LLMs to financial markets but\n",
    "abstract away many fundamental stock market characteristics. Often, they employ single-\n",
    "price clearing mechanisms without a persistent order book, ignore partial fills and bid-ask\"\"\",\n",
    "]\n",
    "\n",
    "    ),\n",
    "    LLMTestCase(\n",
    "        input=\"Why is short selling prohibited for these agents, and how might allowing it change the results?\",\n",
    "        actual_output=\"\"\"Short selling is prohibited to simplify the simulation and avoid potentially destabilizing effects that short selling can introduce, especially given the experimental nature of using LLMs (Large Language Models) as trading agents. The authors wanted to focus on the core dynamics of price discovery without the added complexity of short selling.\n",
    "\n",
    "Allowing short selling could significantly change the results in several ways:\n",
    "\n",
    "Increased Downward Pressure on Prices: If agents could short sell, they could put more downward pressure on prices when they believe the asset is overvalued. This might lead to faster and more efficient corrections of overvaluations, potentially mitigating the persistent overvaluation observed in the simulations.\n",
    "Increased Market Volatility: Short selling can amplify both upward and downward price movements, making the market more volatile. This is because short sellers can create additional selling pressure, driving prices down further and faster than would be possible with only long positions (owning the asset). Conversely, covering short positions (buying back borrowed shares to close a short position) can lead to rapid price increases.\n",
    "More Complex Agent Strategies: Allowing short selling would open up a wider range of possible trading strategies for the agents. They could implement strategies like short and distort (betting against overvalued assets), pairs trading (simultaneously buying an undervalued asset and shorting an overvalued one), or other more sophisticated approaches. This increased complexity could make it more difficult to interpret the agents' behavior and understand the underlying market dynamics.\n",
    "Potential for Market Manipulation: While not explicitly mentioned, the possibility of market manipulation through short selling could become a factor, especially given the experimental nature of the agents. This could take the form of aggressively shorting an asset to drive down its price, potentially creating artificial price crashes or exacerbating existing downturns.\n",
    "\"\"\",\n",
    "        expected_output=\"\"\"It shows asymmetry: over‑valuation persists, but under‑valuation is corrected—the right panel converges to $28 while the left stays high.\"\"\",\n",
    "        context=[\n",
    "            \"\"\"When the market starts significantly above the fundamental value … the price fails to converge downwards … remaining substantially elevated. Agent valuations mirror this persistence, with many agents maintaining estimates well above the fundamental value.\"\"\"\n",
    "        ],\n",
    "        retrieval_context=[\n",
    "    \"\"\"2407.18957. arXiv: 2407.18957 [q-fin]. http://arxiv.org/abs/2407.18957.\n",
    "41\n",
    "A Technical Implementation Details\n",
    "A.1 Agent Type Specifications\n",
    "This section details the base system prompts for each agent type in our simulation. These\n",
    "prompts define the core behavioral characteristics and trading strategies for each agent. Each\n",
    "prompt consists of:\n",
    "• A role definition that establishes the agent’s trading philosophy\n",
    "• A structured trading strategy that guides decision-making\n",
    "• Specific instructions for when to use market orders vs limit orders\n",
    "At runtime, these base prompts are combined with:\n",
    "• Current market state (price, volume, order book depth)\n",
    "• Position information (current holdings and available cash)\n",
    "• Trading options and required response format\n",
    "The standard runtime template includes:\n",
    "Position Information Template\n",
    "Your Position:\n",
    "- Available Shares: {shares} shares (Short selling is not allowed)\n",
    "- Main Cash Account: ${cash:.2f}\n",
    "- Dividend Cash Account (not available for trading): ${dividend_cash:.2f}\n",
    "- Total Available Cash: ${total_available_cash:.2f} (Borrowing is not allowed)\n",
    "- Shares in Orders: {committed_shares} shares\n",
    "- Cash in Orders: ${committed_cash:.2f}\n",
    "42\n",
    "Trading Options Template\n",
    "Your analysis should include:\n",
    "- valuation_reasoning: Your numerical analysis of the asset’s fundamental value\n",
    "- valuation: Your estimate of the asset’s current fundamental value\n",
    "- price_target_reasoning: Your numerical analysis of the asset’s price target\n",
    "- price_target: Your predicted price for the next round\n",
    "- reasoning: Your explanation for the trading decision\n",
    "Trading Options:\n",
    "1. New Orders (replace_decision=’Add’):\n",
    "- Single or multiple orders allowed\n",
    "- For each order:\n",
    "- Market order: Set order_type=’market’\n",
    "- Limit order: Set order_type=’limit’ and specify price_limit\n",
    "- IMPORTANT: Sell orders require sufficient available shares\n",
    "- Short selling is NOT allowed\n",
    "2. Cancel Orders (replace_decision=’Cancel’):\n",
    "- Return an empty orders list: orders=[]\n",
    "Your decision must include:\n",
    "- orders: list of orders (empty list for Hold/Cancel)\n",
    "- For Buy/Sell orders, each must contain:\n",
    "- decision: \"Buy\" or \"Sell\"\n",
    "- quantity: number of shares\n",
    "- order_type: \"market\" or \"limit\"\n",
    "- price_limit: required for limit orders\n",
    "- reasoning: brief explanation\n",
    "- replace_decision: \"Add\", \"Cancel\", or \"Replace\"\n",
    "43\n",
    "Base System Prompts The following are the base system prompts for each LLM-based\n",
    "agent type:\n",
    "A.1.1 Value-Based Agents\n",
    "Value Investor\n",
    "You are a value investor who focuses on fundamental analysis.\n",
    "You believe in mean reversion and try to buy undervalued assets and sell overvalued ones.\n",
    "A.1.2 Trend-Following Agents\n",
    "Momentum Trader\n",
    "You are a momentum trader who focuses on price trends and volume.\n",
    "You believe that ’the trend is your friend’ and try to identify and follow market momentum.\n",
    "A.1.3 Liquidity Providers Agents\n",
    "Market Maker\n",
    "You are a professional market maker who provides liquidity to the market.\n",
    "Your profit comes from capturing the spread between bid and ask prices, not from directional price movement.\n",
    "IMPORTANT: There is NO SHORT SELLING allowed. You can only sell shares you already own.\n",
    "Trading Guidelines:\n",
    "- Place LIMIT buy orders slightly below the current market price (1-3% lower)\n",
    "- Place LIMIT sell orders slightly above the current market price (1-3% higher)\n",
    "- Your spread should be proportional to volatility but typically 2-6% of price\n",
    "- NEVER place sell orders more than 10% above your buy orders\n",
    "- Adjust your spread width based on recent price volatility\n",
    "44\n",
    "Inventory Management (No Short Selling):\n",
    "- Monitor your current inventory in the market data\n",
    "- Only place sell orders for quantities you actually own\n",
    "- If you have no inventory, focus on buy orders first\n",
    "- As you acquire inventory, gradually place sell orders\n",
    "- If inventory grows too large, reduce or pause buy orders\n",
    "- Adjust your buy/sell ratio based on current inventory level\n",
    "Example: If price = $100, you might place buy orders at $97-99 and sell orders at $101-103,\"\"\",\n",
    "    \"\"\"33\n",
    "ants, allowing researchers to study how different belief structures influence price formation\n",
    "and trading patterns under different initial mispricings. In these scenarios, the fundamental\n",
    "price is hidden from agents, forcing them to rely on their own valuation models.\n",
    "3.2.5 Market Stress\n",
    "This scenario tests market resilience under challenging conditions by creating a more volatile\n",
    "environment. The scenario includes two consistently bullish Optimistic traders, two consis-\n",
    "tently bearish Pessimistic traders, two Market makers (liquidity providers), and two Value\n",
    "investors (rational benchmark traders). The scenario runs for 100 rounds to study long-term\n",
    "market behavior and includes unequal initial endowments, with optimistic traders having\n",
    "more cash (1.5x baseline) but fewer shares (0.5x baseline) and pessimistic traders having less\n",
    "cash (0.5x baseline) but more shares (1.5x baseline). This resource imbalance tests whether\n",
    "particular agent types can dominate market outcomes through resource advantages.\n",
    "The scenarios presented here demonstrate the framework’s capabilities for exploring di-\n",
    "verse market conditions. Its modular structure facilitates the straightforward definition and\n",
    "implementation of alternative experimental designs, enabling researchers to tailor simulations\n",
    "to specific research questions.\n",
    "In all scenarios, we maintain consistent baseline parameters with a fundamental value\n",
    "of $28.00, calculated from the expected dividend of $1.40 and interest rate of 5%. Agent\n",
    "endowments start at 1,000,000 monetary units and 10,000 shares unless specifically modified.\n",
    "Transaction costs are set to zero to isolate the effects of agent behavior and market structure\n",
    "on price formation.\n",
    "4 Conclusion\n",
    "This paper demonstrates that Large Language Models can effectively function as diverse\n",
    "trading agents—from value investors to market makers—maintaining strategic consistency\n",
    "34\n",
    "while adapting to market conditions. Our experimental framework reveals that their in-\n",
    "teractions generate realistic market dynamics, including phenomena like price bubbles and\n",
    "corrections, highlighting both the capabilities and potential risks of deploying LLM agents\n",
    "in financial markets.\n",
    "These findings carry significant implications for market structure and regulation. While\n",
    "LLM agents can enhance price discovery and liquidity, their adherence to programmed strate-\n",
    "gies, even potentially flawed ones derived from prompts, could amplify market volatility or\n",
    "introduce novel systemic risks, as observed in our simulated bubble scenarios. A key concern\n",
    "is the potential for widespread correlated behavior: similar underlying LLM architectures\n",
    "responding uniformly to comparable prompts or market signals could inadvertently create\n",
    "destabilizing trading patterns without explicit coordination. This underscores the critical\n",
    "need for rigorous testing and validation of LLM-based trading systems prior to live deploy-\n",
    "ment.\n",
    "A central contribution of this work is the open-source simulation framework itself, de-\n",
    "signed to catalyze research into LLM trading agents. We invite the research community to\n",
    "utilize and extend this platform to investigate pressing questions in this rapidly evolving\n",
    "area. The framework enables systematic exploration of complex scenarios—such as hybrid\n",
    "human-LLM markets, stress tests, varying market structures, regulatory impacts, and the\n",
    "nuances of LLM prompting—often difficult or costly to study otherwise. Specific avenues\n",
    "ripe for investigation using this tool include the emergence of novel trading strategies, the\n",
    "precise effects of agent heterogeneity on market stability, and the development of robust\n",
    "validation protocols for AI traders. As artificial intelligence becomes more integrated into\n",
    "finance, collaborative research leveraging adaptable simulation environments like this one\n",
    "will be crucial for understanding and responsibly shaping the future of trading.\n",
    "35\n",
    "References\"\"\",\n",
    "    \"\"\"44\n",
    "Inventory Management (No Short Selling):\n",
    "- Monitor your current inventory in the market data\n",
    "- Only place sell orders for quantities you actually own\n",
    "- If you have no inventory, focus on buy orders first\n",
    "- As you acquire inventory, gradually place sell orders\n",
    "- If inventory grows too large, reduce or pause buy orders\n",
    "- Adjust your buy/sell ratio based on current inventory level\n",
    "Example: If price = $100, you might place buy orders at $97-99 and sell orders at $101-103,\n",
    "but limit your sell quantity to what you currently own.\n",
    "Remember that extreme spreads (e.g., buying at $3 and selling at $30) will not execute and will lead to losses.\n",
    "A.1.4 Contrarian Agents\n",
    "Contrarian Trader\n",
    "You are a contrarian trader who looks for excessive market moves to trade against.\n",
    "You believe markets often overreact and try to profit from reversals.\n",
    "A.1.5 Sentiment-Based Agents\n",
    "Optimistic\n",
    "You are an optimistic trader who firmly believes assets are significantly undervalued.\n",
    "Your Core Beliefs:\n",
    "- The probability of maximum dividends is much higher than stated (80-90% chance)\n",
    "Pessimistic\n",
    "You are a pessimistic trader who firmly believes assets are significantly overvalued.\n",
    "45\n",
    "Your Core Beliefs:\n",
    "- The probability of minimum dividends is much higher than stated (80-90% chance)\n",
    "A.1.6 Miscellaneous Agents\n",
    "Speculator\n",
    "You are a speculator who tries to profit from market inefficiencies.\n",
    "Retail Trader\n",
    "You are a retail trader.\n",
    "LLM Hold Trader\n",
    "You are a holding agent that never trades.\n",
    "A.1.7 Deterministic Agents\n",
    "The framework also includes several deterministic rule-based agents that serve as benchmarks\n",
    "and controls. These agents follow fixed algorithmic rules rather than LLM-based decision-\n",
    "making. They include directional traders (always buy, always sell), technical traders (mean\n",
    "reversion, momentum), and algorithmic market makers with pre-defined spread-posting\n",
    "strategies.\n",
    "46\"\"\",\n",
    "    \"\"\"standardized, human-readable, machine-readable agent decisions. This technique allows\n",
    "LLMs to generate outputs in a specific format that can be directly validated and processed\n",
    "by the trading system, bridging the gap between natural language reasoning and executable\n",
    "trading actions.\n",
    "The system uses Pydantic for validation and parsing of agent outputs, with a schema-\n",
    "based approach that defines the required structure:\n",
    "class TradeDecisionSchema(BaseModel):\n",
    "Schema for trade decisions\n",
    "valuation_reasoning: str = Field(...,\n",
    "description=\"Brief explanation of valuation analysis\")\n",
    "valuation: float = Field(...,\n",
    "description=\"Agent’s estimated fundamental value\")\n",
    "price_target: float = Field(...,\n",
    "description=\"Agent’s predicted price in near future\")\n",
    "orders: List[OrderSchema] = Field(...,\n",
    "description=\"List of orders to execute\")\n",
    "16\n",
    "replace_decision: str = Field(...,\n",
    "description=\"Add, Cancel, or Replace\")\n",
    "reasoning: str = Field(...,\n",
    "description=\"Explanation for the trading decisions\")\n",
    "Each order within the decision follows a nested schema:\n",
    "class OrderSchema(BaseModel):\n",
    "Schema for individual orders\n",
    "decision: Literal[\"Buy\", \"Sell\"] = Field(...,\n",
    "description=\"Buy, Sell\")\n",
    "quantity: int = Field(...,\n",
    "description=\"Number of shares\")\n",
    "order_type: str = Field(...,\n",
    "description=\"market or limit\")\n",
    "price_limit: Optional[float] = Field(None,\n",
    "description=\"Required for limit orders\")\n",
    "This structured approach enables several critical features: (1) automatic validation of all\n",
    "decision components, (2) consistent parsing of agent outputs, (3) clear documentation of the\n",
    "expected response format, and (4) standardized error handling for malformed responses. The\n",
    "function calling methodology ensures that LLMs can focus on trading strategy. At the same\n",
    "time, the system handles the technical validation of their decisions, significantly improving\n",
    "reliability compared to free-form text parsing.\n",
    "2.2.7 Complete Example\n",
    "The following example illustrates the complete prompt for a speculator agent, with annota-\n",
    "tions explaining the purpose of each information component.\n",
    "You are a speculator who tries to profit from market inefficiencies.\n",
    "17\n",
    "The system prompt establishes the agent’s core identity and strategic objective concisely,\n",
    "creating a consistent behavioral foundation. Then, the user prompt provides the immediate\n",
    "market context necessary for tactical decision-making.\n",
    "2.2.8 Market State Information\n",
    "Market State:\n",
    "Last Price: $29.00\n",
    "Round Number: 4/Infinite\n",
    "Best Public Estimate of Risk-Neutral Fundamental Value: Unavailable\n",
    "Last Trading Volume: 500.00\n",
    "Price/Fundamental Ratio: Unavailable\n",
    "This subsection provides essential market pricing data to establish current conditions. The\n",
    "speculator intentionally receives no fundamental value estimate to simulate information\n",
    "asymmetry and encourage independent analysis.\n",
    "2.2.9 Market Depth\n",
    "Market Depth:\n",
    "Best Bid: $28.00\n",
    "Best Ask: $29.00\n",
    "Sell Orders:\n",
    "2000 shares @ $57.00\n",
    "3800 shares @ $50.40\n",
    "2000 shares @ $30.00\n",
    "1000 shares @ $29.50\n",
    "4400 shares @ $29.00\n",
    "Buy Orders:\n",
    "1900 shares @ $28.00\n",
    "18\n",
    "1500 shares @ $27.50\n",
    "2500 shares @ $27.00\n",
    "Order book information lets the agent assess market liquidity, identify potential trading\n",
    "opportunities, and determine optimal order placement strategies. The visible imbalance\n",
    "between the bid and ask sides provides critical information about supply and demand dy-\n",
    "namics.\n",
    "2.2.10 Agent Position\n",
    "Your Outstanding Orders:\n",
    "Buy Orders:\n",
    "400 shares @ $28.00\n",
    "Your Position:\n",
    "Available Shares: 10000 shares (Short selling is not allowed)\n",
    "Main Cash Account: $988500.00\n",
    "Dividend Cash Account (not available for trading): $296920.65\n",
    "Total Available Cash: $988500.00 (Borrowing is not allowed)\n",
    "Shares in Orders: 0 shares\n",
    "Cash in Orders: $11500.00\n",
    "Position information establishes resource constraints and current market exposure, enabling\n",
    "the agent to make contextually appropriate decisions while maintaining awareness of out-\n",
    "standing commitments.\n",
    "2.2.11 Historical Context\n",
    "Price History (last 5 rounds):\"\"\",\n",
    "    \"\"\"(2023)). This work, however, focuses on financial markets and how LLM agents can operate\n",
    "as full-fledged trading participants.\n",
    "Recent research examines specific applications of LLMs for trading. FinMem and Trad-\n",
    "ingGPT introduce frameworks with layered memory systems and customizable agent traits\n",
    "5\n",
    "to improve financial decision-making (Yu, Li, et al. 2024; Li, Zhang, and Sun 2023). Hierar-\n",
    "chical multi-agent architectures have been explored in FinCon, which uses a manager-analyst\n",
    "setup for collaborative portfolio decisions (Yu, Yao, et al. 2024). QuantAgent implements\n",
    "a self-improving signal-mining approach (Wang et al. 2024), while other work underscores\n",
    "the importance of long-term memory in LLM agents via vector databases (Hatalis et al.\n",
    "2024). This line of research builds on successful reinforcement learning applications such as\n",
    "AlphaPortfolio (Cong et al. 2021) and AlphaManager (Campello, Cong, and Zhou 2023),\n",
    "which leverage deep RL and robust control for portfolio management.\n",
    "Analyzing LLM agent behavior by changing only some parameters draws on methods\n",
    "from the interpretable machine learning literature. In particular, the systematic variation\n",
    "of market parameters to reveal decision patterns mirrors partial dependence plots and in-\n",
    "dividual conditional expectation curves used to interpret complex machine learning models\n",
    "(Molnar 2022). These techniques help reveal how LLM agents respond to changes in specific\n",
    "variables while holding others constant, providing insight into their internal decision-making\n",
    "processes that would otherwise remain opaque.\n",
    "Beyond finance, studies of LLM capabilities in interactive or multi-agent settings offer\n",
    "valuable insights. Benchmarks like AgentBench evaluate LLMs’ performance in interac-\n",
    "tive tasks (Liu et al. 2023), while InvestorBench focuses on financial decision-making tasks\n",
    "specifically (H. Li et al. 2024). NegotiationArena demonstrates LLMs’ capacity for strategic\n",
    "interaction in bargaining contexts (Bianchi et al. 2024). Similarly, Guo et al. (2024) provide\n",
    "an economics ”arena” where LLMs compete in strategic games, revealing that advanced\n",
    "models like GPT-4 can exhibit rational, adaptive behavior—albeit not always reaching Nash\n",
    "Equilibrium. Existing frameworks typically assess individual agents or hierarchical collab-\n",
    "orations, whereas this work studies emergent market behaviors that arise from multiple\n",
    "independent LLM traders interacting in a marketplace.\n",
    "The approach also connects to the tradition of experimental asset markets. For instance,\n",
    "Weitzel et al. (2020) show that even finance professionals are susceptible to speculative\n",
    "6\n",
    "bubbles, especially amid high capital inflows. Kop´ anyi-Peuker and Weber (2021) find that\n",
    "trading experience alone does not eliminate bubbles, challenging assumptions about rational\n",
    "market learning. Kirchler, Huber, and St¨ ockl (2012) identify confusion about fundamental\n",
    "values as a key driver of bubble formation. This framework offers a new way to study these\n",
    "phenomena with LLM traders, which can be rigorously parameterized for sophistication,\n",
    "strategy, and information processing. Hence, this paper provides a method to investigate\n",
    "how automated or ”artificial” agents might affect market stability or volatility.\n",
    "Other recent work highlights the versatility of LLM agents in complex, interactive sce-\n",
    "narios beyond finance. One stream focuses on simulating social behaviors—such as opinion\n",
    "dynamics (Chuang et al. 2023), trust (Xie et al. 2024), and resource-sharing (Piatti et al.\n",
    "2024). Another examines LLMs’ strategic capabilities through task-based simulations and\n",
    "collaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\n",
    "Within the computer science literature, early works apply LLMs to financial markets but\n",
    "abstract away many fundamental stock market characteristics. Often, they employ single-\n",
    "price clearing mechanisms without a persistent order book, ignore partial fills and bid-ask\"\"\",\n",
    "    \"\"\"bids/asks), and two Speculator agents (opportunistic traders seeking inefficiencies). Market\n",
    "31\n",
    "makers are given enhanced liquidity with 20x the baseline cash and shares to ensure suffi-\n",
    "cient liquidity provision and facilitate price discovery. The scenario tests whether prices can\n",
    "correct downward through trading activity when starting from an overvalued state.\n",
    "3.2.2 Price Discovery (Below Fundamental)\n",
    "This complementary scenario tests upward price convergence by starting with an initial price\n",
    "25% below the fundamental value ( $21.00). It employs the identical agent composition and\n",
    "parameters as the above-fundamental scenario, allowing for direct comparison of market\n",
    "behavior under opposite initial mispricing conditions. This design enables researchers to\n",
    "assess potential asymmetries in price discovery processes.\n",
    "3.2.3 Infinite Horizon Price Discovery\n",
    "We extend both price discovery scenarios to infinite horizon settings, where shares are not\n",
    "redeemed at a terminal date. The initial prices are set at double ($56.00) and half ($14.00) the\n",
    "fundamental value for the above and below fundamental scenarios respectively, creating more\n",
    "extreme mispricing conditions. These scenarios run for 15 trading rounds and test whether\n",
    "agents correctly value assets based on expected dividend streams rather than redemption\n",
    "values. Each infinite horizon scenario involves two Default investors, two Optimistic traders,\n",
    "two Market makers, and two Speculator agents.\n",
    "The results from these infinite horizon scenarios reveal interesting asymmetries in price\n",
    "discovery, as illustrated in Figure 6 and Figure 7. When the market starts significantly above\n",
    "the fundamental value (left panels), the price fails to converge downwards towards the$28.00\n",
    "benchmark within the 15 rounds, remaining substantially elevated. Agent valuations mirror\n",
    "this persistence, with many agents maintaining estimates well above the fundamental value.\n",
    "However, when the market begins significantly below the fundamental value (right panels),\n",
    "the price exhibits a clear convergence towards the fundamental benchmark. Agent valuations\n",
    "in this scenario also tend to adjust upwards, aligning more closely with the calculated fun-\n",
    "32\n",
    "damental value over time. This suggests that under these conditions, LLM agents are more\n",
    "effective at correcting undervaluation than overvaluation within the simulated timeframe.\n",
    "Figure 6: Price Evolution: Infinite Horizon Scenarios. Left: Initial price $56.00 (Above\n",
    "Fundamental). Right: Initial price $14.00 (Below Fundamental). The dashed line indicates\n",
    "the fundamental value ($28.00).\n",
    "Figure 7: Agent Valuations: Infinite Horizon Scenarios. Left: Initial price $56.00 (Above\n",
    "Fundamental). Right: Initial price $14.00 (Below Fundamental). Shows individual agent\n",
    "estimates of fundamental value over time.\n",
    "3.2.4 Divergent Beliefs\n",
    "This scenario explores the impact of heterogeneous beliefs about fundamental value by com-\n",
    "bining agents with systematically different valuation models. The agent composition is\n",
    "designed to create heterogeneity: two Optimistic traders (believing the fundamental value is\n",
    "significantly higher), two Pessimistic traders (believing it is significantly lower), two neutral\n",
    "Market makers, two Momentum traders (following price trends rather than fundamentals),\n",
    "and two Default investors (baseline agents). We test both above-fundamental (initial price\n",
    "$56.00, 2x fundamental) and below-fundamental (initial price$14.00, 0.5x fundamental) vari-\n",
    "33\n",
    "ants, allowing researchers to study how different belief structures influence price formation\n",
    "and trading patterns under different initial mispricings. In these scenarios, the fundamental\n",
    "price is hidden from agents, forcing them to rely on their own valuation models.\n",
    "3.2.5 Market Stress\n",
    "This scenario tests market resilience under challenging conditions by creating a more volatile\n",
    "environment. The scenario includes two consistently bullish Optimistic traders, two consis-\"\"\",\n",
    "    \"\"\"market efficiency and price discovery processes throughout the simulation.\n",
    "Agent performance metrics include absolute position tracking (shares, cash, and total\n",
    "wealth), wealth composition analysis, position change metrics, and return calculations. The\n",
    "system computes both absolute and percentage returns on various portfolio components\n",
    "and compares performance across agent types to identify relative advantages of different\n",
    "strategies. Trading flow analysis visualizes the volume of shares moving between different\n",
    "agent types and cumulative net trading flows, revealing which agents act as net buyers or\n",
    "sellers in different market conditions.\n",
    "Decision pattern analysis employs heatmaps to visualize the consistency of agent decision-\n",
    "making over time, allowing researchers to identify shifts in strategic behavior. This is com-\n",
    "plemented by decision quantities visualization that plots order sizes to highlight variations\n",
    "in trade aggressiveness across agent types. When agent reasoning data is available, the\n",
    "system generates wordclouds to extract key terms from agent explanations, providing qual-\n",
    "itative insights into decision drivers for different agent strategies. Additional visualizations\n",
    "track price target accuracy and compare agent-specific valuations to realized market prices,\n",
    "28\n",
    "offering insights into the forecasting abilities of different agents.\n",
    "A key advantage of simulation-based analysis is complete observability of all market\n",
    "processes and agent states. Unlike real-world markets where data availability is often limited,\n",
    "the framework captures every interaction, decision, and state change with perfect fidelity.\n",
    "This comprehensive data collection allows researchers to compute additional metrics beyond\n",
    "standard market measures, enabling novel analyses such as counterfactual testing (e.g., how\n",
    "would markets evolve with different agent compositions), causal inference of specific agent\n",
    "behaviors on market outcomes, and the development of custom efficiency or stability metrics\n",
    "tailored to particular research questions. The system’s modular design facilitates rapid\n",
    "implementation of new metrics and visualizations as research questions evolve.\n",
    "3 Experimental Design and Results\n",
    "Our experimental framework implements a dividend-paying asset market with heterogeneous\n",
    "agents. The baseline simulation runs for 15 to 20 rounds with 8 participating agents, although\n",
    "these parameters are fully configurable. Each agent begins with an initial endowment of\n",
    "1,000,000 monetary units and 10,000 shares of the asset. The fundamental value of the asset\n",
    "is set at $28.00, with a final redemption value matching this fundamental price in finite\n",
    "horizon scenarios. Transaction costs are set to zero to isolate the effects of agent behavior\n",
    "and market structure.\n",
    "The dividend structure follows a stochastic process with a base payment of $1.40 and a\n",
    "variation of ±$1.00, paid with 50% probability each round. This design creates uncertainty\n",
    "in the asset’s income stream while maintaining a known expected value. Cash holdings earn\n",
    "a risk-free interest rate of 5% per round, providing an opportunity cost for asset investment.\n",
    "Agent composition is controlled through a flexible distribution system that allows for\n",
    "various experimental configurations. In our baseline setup, we employ a mixed population\n",
    "of value investors, momentum traders, and market makers. Each agent type implements\n",
    "29\n",
    "distinct trading strategies through Large Language Model (LLM) prompts, with GPT-4o as\n",
    "the decision-making engine.\n",
    "The data collection system captures comprehensive market activity across multiple di-\n",
    "mensions. At the market level, it tracks the evolution of prices, fundamental values, and\n",
    "realized dividends, providing insights into overall market dynamics. Individual agent data\n",
    "includes detailed wealth trajectories and portfolio compositions, enabling analysis of strategy\n",
    "effectiveness and wealth distribution patterns. The system maintains complete transaction\"\"\",\n",
    "    \"\"\"Main Cash Account: $988500.00\n",
    "Dividend Cash Account (not available for trading): $296920.65\n",
    "Total Available Cash: $988500.00 (Borrowing is not allowed)\n",
    "Shares in Orders: 0 shares\n",
    "Cash in Orders: $11500.00\n",
    "Position information establishes resource constraints and current market exposure, enabling\n",
    "the agent to make contextually appropriate decisions while maintaining awareness of out-\n",
    "standing commitments.\n",
    "2.2.11 Historical Context\n",
    "Price History (last 5 rounds):\n",
    "Round 3: $29.00 (Volume: 100)\n",
    "Round 2: $29.00 (Volume: 100)\n",
    "19\n",
    "Round 1: $28.00 (Volume: 100)\n",
    "Round 0: $56.00 (Volume: 0)\n",
    "Historical price and volume data enables pattern recognition and trend analysis, which is\n",
    "especially important for agents identifying market inefficiencies and developing trends.\n",
    "2.2.12 Asset Fundamentals\n",
    "Dividend Information:\n",
    "Last Paid Dividend: $2.40\n",
    "Expected Dividend: $1.40\n",
    "Base Dividend: $1.40\n",
    "Variation Amount: $1.00\n",
    "Maximum Scenario: $2.40 with 50% probability\n",
    "Minimum Scenario: $0.40 with 50% probability\n",
    "Payment Schedule:\n",
    "Next Payment in: 1 rounds\n",
    "Payment Destination: dividend account (non-tradeable)\n",
    "Redemption Information:\n",
    "This market has an infinite time horizon. Shares will not be redeemed.\n",
    "Interest Rate Information:\n",
    "Base Rate: 5.0\\%\n",
    "Compound Frequency: 1 times per round\n",
    "Payment Destination: dividend account (separate from trading)\n",
    "Fundamental value determinants allow the agent to perform intrinsic valuation, assess risk-\n",
    "reward scenarios, and identify mispricing. The probabilistic dividend structure introduces\n",
    "uncertainty agents that must be incorporated into their decision models. In this example,\n",
    "the fundamental value is unobservable.\n",
    "20\n",
    "2.2.13 Decision Requirements\n",
    "Your analysis should include:\n",
    "valuation_reasoning: Your numerical analysis of the asset’s fundamental value\n",
    "valuation: Your estimate of the asset’s current fundamental value\n",
    "price_target_reasoning: Your numerical analysis of the asset’s price target\n",
    "price_target: Your predicted price for the next round\n",
    "reasoning: Your explanation for the trading decision\n",
    "The decision schema enforces consistent output structure and explicit reasoning, enabling\n",
    "systematic analysis of agent decision processes and reliable parsing of machine-actionable\n",
    "components.\n",
    "2.2.14 Trading Options\n",
    "Trading Options:\n",
    "New Orders (replace_decision=’Add’):\n",
    "Single or multiple orders allowed\n",
    "For each order:\n",
    "Market order: Set order_type=’market’\n",
    "Limit order: Set order_type=’limit’ and specify price_limit\n",
    "IMPORTANT: Sell orders require sufficient available shares\n",
    "Short selling is NOT allowed\n",
    "Cancel Orders (replace_decision=’Cancel’):\n",
    "Return an empty orders list: orders=[]\n",
    "The trading options subsection establishes the action space and constraints, ensuring agents\n",
    "understand available choices and limitations while providing precise formatting requirements\n",
    "for machine-readable decisions.\n",
    "The response from the LLM agent is depicted in Figure 1.\n",
    "21\n",
    "2.2.15 Systematic Decision Analysis\n",
    "Finally, the framework enables systematic analysis of LLM decision processes through con-\n",
    "trolled parameter variation, similar to partial dependence plots in machine learning inter-\n",
    "pretability. This approach allows researchers to understand how specific market variables\n",
    "influence LLM trading decisions while holding other factors constant.\n",
    "Our example implementation varies the price-to-fundamental ratio ( ρ = P/V ) across a\n",
    "range from 0.1 to 3.5 while maintaining all other market parameters constant. For each ratio\n",
    "value, the system:\n",
    "1. Sets market price P = ρV where ρ is the target ratio\n",
    "2. Generates a consistent order book structure around this price\n",
    "3. Executes multiple decision trials with the same agent type\n",
    "4. Records decision outcomes (buy/sell/hold), order types, quantities, and reasoning\n",
    "This process maps how LLM agents respond to different price environments, as illustrated\n",
    "in Figures 2, 3, 4, and 5. The analysis reveals clear patterns in decision boundaries, with\"\"\",\n",
    "]\n",
    "\n",
    "    ),\n",
    "    LLMTestCase(\n",
    "        input=\"The paper gives Vt=E[D]rV_t=\\tfrac{E[D]}{r} as Equation (1). What does each variable represent, and how is this perpetuity formula used in the simulations?\",\n",
    "        actual_output=\"\"\"In the formula Vt = E[D]/r,\n",
    "\n",
    "Vt represents the fundamental value of the firm at time t. This is the theoretical \"true\" value of the company based on its expected future earnings.\n",
    "E[D] represents the expected value of the firm's dividends. Dividends are the portion of a company's profits that are paid out to its shareholders. E[...] denotes the expected value of a random variable. Since the excerpts mention \"discounted-loan\" type debt and no dividend payments on equity being assumed, the formula likely refers to expected cash flow available to all security holders, debt and equity.\n",
    "r represents the risk-free interest rate (the return an investor can expect from a \"safe\" investment like a government bond).\n",
    "In the simulations, this perpetuity formula (a formula for valuing a stream of payments that continues forever) is used to establish a baseline value for the simulated firm. The simulations then explore how market prices, driven by the AI agents' trading activity, deviate from this fundamental value, specifically testing the scenarios where the market starts 25% above or below this calculated fundamental value. This setup allows the researchers to observe how effectively the AI agents correct over- or under-valuations back towards the \"true\" value.\n",
    "\"\"\",\n",
    "        expected_output=\"\"\"Vt=E[D]/rV_t = E[D]/r treats the stock as a perpetuity: E[D]E[D] is expected dividend per round and rr the risk‑free rate; with $1.40 and 5 % the value is $28.\"\"\",\n",
    "        context=[\n",
    "            \"\"\"The framework implements a consistent approach… For infinite horizon markets, the fundamental value follows the standard dividend discount model: Vt=E[D]rV_t = \\frac{E[D]}{r}. … For the default parameters where the expected dividend is $1.40 and the interest rate is 5 %, this yields a fundamental value of $28.00.\"\"\"\n",
    "        ],\n",
    "        retrieval_context=[\n",
    "    \"\"\"of the ﬁrm and the changes in value of the ﬁrm’s capital stock or earning assets\n",
    "over the period. A crucial assumption is that P(Z, τ)is independent of the particular\n",
    "capital structure of the ﬁrm, i.e. Pis determined solely by the characteristics of the\n",
    "asset side of the balance sheet and is not affected by the particular instruments used\n",
    "by the ﬁrm to ﬁnance these assets. This assumption is consistent with the Modigliani-\n",
    "Miller (1958) theorem and, as such, we implicitly assume perfect capital markets and\n",
    "tax effects are not considered.\n",
    "Consider that the ﬁrm chooses a particular set of ﬁnancial instruments (debt, eq-\n",
    "uity, etc.) deﬁned by their terminal conditions. We now ﬁnd the current equilibrium\n",
    "value of each of these future claims on the terminal (random) value of the ﬁrm. For\n",
    "i= 1,. . ., n , deﬁne Fi(V, τ)as the current value of the ith type of security with ter-\n",
    "minal date τfrom now issued by the ﬁrm.2The different types of securities are\n",
    "distinguishable by their terminal value Fi(V Z,0), contingent on the terminal value of\n",
    "the ﬁrm V(t+τ) =V Z. For example, if one of the securities is a debt issue ( i= 1),\n",
    "senior to all other claims on the ﬁrm, with a terminal claim of Bdollars on the ﬁrm,\n",
    "then\n",
    "F1(V Z,0) = min( B, V Z ) (11.3)\n",
    "i.e. the debtholders will receive Bdollars at the end of the period if the ﬁrm can pay,\n",
    "or, in the event that the ﬁrm cannot pay (default), they are entitled to all the assets of\n",
    "the ﬁrm which will have value V Z.\n",
    "To determine the equilibrium values of each of the securities, note that because\n",
    "each of the securities appears separately in the market place, they must be priced so\n",
    "1Since, in this section, we are using a period model, τcould be set equal to one. However, it will be useful\n",
    "for later development to carry the general symbol τ.\n",
    "2Strictly, Fiwill be a function of the current values of all securities senior to it, the capitalization rate, etc.\n",
    "in addition to V. However, in equilibrium, the Fiare perfectly positively related to changes in the value of the\n",
    "ﬁrm, and so these other arguments of the function will enter only as parameters.\n",
    "280 A Dynamic General Equilibrium Model of the Asset Market\n",
    "that when examined by the representative man he will choose his portfolio so as to\n",
    "hold the amount supplied, i.e.\n",
    "V=n∑\n",
    "i=1Fi(V, τ) (11.4)\n",
    "and, of course, V Z=∑n\n",
    "1Fi(V Z,0). Deﬁne wi≡Fi(V, τ)/Vas the fraction of the\n",
    "ﬁrm’s assets ﬁnanced by the ith security. Then, because the ﬁrm is the only asset\n",
    "in the economy, wiwill also be equal to the fraction of the representative man’s\n",
    "initial wealth invested in the ith security. We rewrite (11.1) as a maximization under\n",
    "constraint problem:\n",
    "max\n",
    "{wi}{\n",
    "EtU[\n",
    "Vn∑\n",
    "i=1wiFi(V Z,0)\n",
    "Fi(V, τ)]\n",
    "+λ[\n",
    "1−n∑\n",
    "i=1wi]}\n",
    "(11.5)\n",
    "The ﬁrst-order conditions3derived from (11.5) are\n",
    "Et{\n",
    "Fi(V Z,0)\n",
    "Fi(V, τ)U′[\n",
    "Vn∑\n",
    "i=1wiFi(V Z,0)\n",
    "Fi(V, τ)]}\n",
    "=λ i = 1,. . ., n (11.6)\n",
    "Equation (11.6) can be rewritten in terms of util-prob distributions4Qas\n",
    "∫∞\n",
    "0Fi(V Z,0)\n",
    "Fi(V, τ)dQ=∫∞\n",
    "0Fj(V Z,0)\n",
    "Fj(V, τ)dQ≡exp(ητ)for all i,j= 1,. .. , n (11.7)\n",
    "where\n",
    "dQ≡U′(ZV)dP(Z, τ)∫∞\n",
    "0U′(ZV)dP(Z, τ)\n",
    "andexp(ητ)is a new multiplier related to the original λmultiplier. Note the important\n",
    "substitution of V ZforV∑n\n",
    "1wiFi(V Z,0)/Fi(V, τ)in the deﬁnition of dQ. By the\n",
    "assumption that the value of the ﬁrm is independent of its capital structure, we have\n",
    "thatdQis independent of the functions Fi,i= 1,. .. , n . Therefore, (11.7) is a set of\n",
    "integral equations, linear in the Fi.5Hence, we can meaningfully rewrite (11.7) as\n",
    "Fi(V, τ) = exp( −ητ)∫∞\n",
    "0Fi(V Z,0)dQ(Z, τ) i= 1,. . ., n (11.8)\n",
    "Because the Fi(V Z,0)are known functions determined by the type of security, and U\n",
    "andP(Z, τ)are assumed known, (11.8) would be sufﬁcient to determine the current\n",
    "equilibrium value of the Eth security if we knew η.\n",
    "From examination of (11.7) and noting again that dQis independent of the partic-\n",
    "ular capital structure chosen, we ﬁnd that exp(ητ)(and hence η) is independent of the\"\"\",\n",
    "    \"\"\"one-period model further, an intertemporal equilibrium model, which includes the\n",
    "model of Section 11.2 as a special case, is developed in the following sections.\n",
    "11.4 A General Intertemporal Equilibrium Model of the Asset Market\n",
    "Consider an economy with Kconsumers-investors and nﬁrms with current value Vi,\n",
    "i= 1,. .. , n . Each consumer acts so as to\n",
    "maxE0{∫Tk\n",
    "0Uk[\n",
    "CK(s),s]\n",
    "ds+Bk[\n",
    "Wk(\n",
    "Tk)\n",
    ",Tk]}\n",
    "(11.28)\n",
    "where E0is the conditional expectation operator, conditional on the value of current\n",
    "wealth Wk(0) = Wkof the kth consumer and on the current value of the ﬁrms,\n",
    "Vi(0) = Vi,i= 1,. .. , n .Ck(s)is his instantaneous consumption at time s.Ukis a\n",
    "strictly concave von Neumann-Morgenstern utility function; Bkis a strictly concave\n",
    "“bequest” or utility-of-terminal-wealth function; and Tkis the date of death of the\n",
    "kth consumer. Deﬁne Ni(t)Pi(t)≡Vi(t)where Ni(t)is the number of shares14of\n",
    "ﬁrmioutstanding at time tandPi(t)is the price per share at time t. It is assumed that\n",
    "expectations about the dynamics of the prices per share in the future are same for all\n",
    "investors and these dynamics ca be described by the stochastic differential equation15\n",
    "dPi\n",
    "Pi=αidt+σidZii= 1,. .. , n (11.29)\n",
    "where the instantaneous expected rate of return, αi, and the instantaneous standard\n",
    "deviation of return, σi, may change stochastically over time, but only in a way which\n",
    "is instantaneously uncorrelated with price changes (i.e. dαidZj=dσidZj= 0 for\n",
    "i,j= 1,. .. , n ). The dZirepresent a simple Gauss-Wiener process with zero mean\n",
    "and unit variance rate (often referred to as Gaussian “white noise”). Equation (11.29)\n",
    "includes returns from both capital gains and dividends, and reﬂects both the uncer-\n",
    "tainties about future cash ﬂows and changes in the “capitalized” value of the ﬁrm’s\n",
    "earning assets. Notice that, if αiandσiwere constant, then the Pi(t)would be log-\n",
    "normally distributed. Further assume that one of the nassets (by convention the nth\n",
    "one) is an “instantaneously” riskless asset16with instantaneous return r(t)and that\n",
    "14In this section, the particular capital structure of the ﬁrm is not discussed, and hence one can think of each\n",
    "ﬁrm as having the trivial capital structure, namely, all equity. However, the assumption that the value of the\n",
    "ﬁrm is independent of its capital structure is retained throughout the chapter.\n",
    "15For a discussion of and further references to stochastic differential equations of the type in (11.29), see\n",
    "Merton (1971; this volume, Ch. 5).\n",
    "16What is meant by an “instantaneously” riskless asset is that, at each instant of time, each investor knows\n",
    "with certainty that he can earn return r(t)over the next instant by holding the asset (i.e. σn= 0andαn=r).\n",
    "However, the future values of r(t)are not known with certainty. It is assumed here that one of the ﬁrms is\n",
    "characterized by this asset. Alternatively, one could postulate a government which issues (very) short bonds,\n",
    "or that r(t)is the instantaneous private sector borrowing (and lending) rate.\n",
    "11.4 A General Intertemporal Equilibrium Model of the Asset Market 287\n",
    "the dynamics of this rate are described by\n",
    "dr=f(r,t)dt+g(r,t)dq (11.30)\n",
    "where (11.30) is the same type of equation as (11.29) and dqis a simple Gauss-Wiener\n",
    "process. For computational simplicity, it is further assumed that αiandσi, in (11.29),\n",
    "are functions only of r(t),17i.e. investors only anticipate revising their expectations\n",
    "about returns if the interest rate changes.\n",
    "From the deﬁnition of NiandPi. we have that the change in the value of the ith\n",
    "ﬁrm over time is dV=NidPi+dNi(Pi+dPi). The ﬁrst term is that part of the changed\n",
    "value of the ﬁrm due to cash ﬂow and changes in the value of its assets. The second\n",
    "term is that part of the changed value of the ﬁrm due to the issue (or purchase) of new\n",
    "shares at the new price per share Pi+dPi.18Substituting from (11.29) for dPi/Piand\n",
    "writing everything in percentage terms, we have that\n",
    "dVi\n",
    "Vi=αidt+σidZi+dNi\n",
    "Ni(1 +αidt+σidZi) i= 1,. .. , n (11.31)\"\"\",\n",
    "    \"\"\"equity, f, will be\n",
    "0 =1\n",
    "2σ2V2fvv+ (rV−C)fv−rf−fτ= 0 (12.41)\n",
    "subject to boundary conditions (12.9a), (12.9b), and (12.11). Again, equation (12.41)\n",
    "has an isomorphic correspondence with an option pricing problem previously stud-\n",
    "ied. Equation (12.41) is identical to equation (12.44) in Merton (1973a; this volume,\n",
    "equation (8.44)) which is the equation for the European option value on a stock which\n",
    "pays dividends at a constant rate per unit time of C. While a closed-form solution to\n",
    "(12.41) for ﬁnite τhas not yet been found, one has been found for the limiting case\n",
    "of a perpetuity (τ=∞), and is presented in Merton (1973a; this volume, equation\n",
    "(8.46)). Using the identity F=V−f, we can write the solution for the perpetual\n",
    "risky coupon bond as\n",
    "F(v,∞) =C\n",
    "r\n",
    "1−(\n",
    "2C\n",
    "σ2v)2r\n",
    "σ2\n",
    "Γ(\n",
    "2 +2r\n",
    "σ2)M(2r\n",
    "σ2,2 +2r\n",
    "σ2,−2C\n",
    "σ2v)\n",
    "(12.42)\n",
    "where Γ(·)is the gamma function and M(·)is the conﬂuent hypergeometric func-\n",
    "tion. While perpetual, non-callable bonds are non-existent in the United States, there\n",
    "are preferred stocks with no maturity date and (12.42) would be the correct pricing\n",
    "function for them.\n",
    "Moreover, even for those cases where closed-form solutions cannot be found,\n",
    "powerful numerical integration techniques have been developed for solving equations\n",
    "like (12.7) or (12.41). Hence, computation and empirical testing of these pricing the-\n",
    "ories is entirely feasible.\n",
    "Note that in deducing (12.40), it was assumed that coupon payments were made\n",
    "uniformly and continuously. In fact, coupon payments are usually only made semi-\n",
    "annually or annually in discrete lumps. However, it is a simple matter to take this into\n",
    "322 On the Pricing of Corporate Debt: The Risk Structure of Interest Rates\n",
    "account by replacing “ C” in (12.40) by “∑\n",
    "iCiδ(τ−τi)” where δ(·)is the dirac delta\n",
    "function and τiis the length of time until maturity when the ith coupon payment of\n",
    "Cidollars is made.\n",
    "As a ﬁnal illustration, we consider the case of callable bonds. Again, assume the\n",
    "same capital structure but modify the indenture to state that “the ﬁrm can redeem\n",
    "the bonds at its option for a stated price of K(τ)dollars” where Kmay depend on\n",
    "the length of time until maturity. Formally, equation (12.40) and boundary conditions\n",
    "(12.9a) and (12.9c) are still valid. However, instead of the boundary condition (12.9b)\n",
    "we have that for each τ, there will be some value for the ﬁrm, call it V(τ), such that\n",
    "for all V(τ)≥V(τ), it would be advantageous for the ﬁrm to redeem the bonds.\n",
    "Hence, the new boundary condition will be\n",
    "F[V(τ),τ] =K(τ) (12.43)\n",
    "Equation (12.40), (12.9a), (12.9c), and (12.43) provide a well-posed problem to solve\n",
    "forFprovided that the V(τ)function were known. But, of course, it is not. Fortu-\n",
    "nately, economic theory is rich enough to provide us with an answer. First, imagine\n",
    "that we solved the problem as if we knew V(τ)to get F[V, τ;V(τ)]as a function of\n",
    "V(τ). Second, recognize that it is at management’s option to redeem the bonds and\n",
    "that management operates in the best interests of the equity holders. Hence, as a\n",
    "bondholder, one must presume that management will select the V(τ)function so as\n",
    "to maximize the value of equity, f. But, from the identity F=V−f, this implies that\n",
    "theV(τ)function chosen will be the one which minimizes F[V, τ;V(τ)]. Therefore,\n",
    "the additional condition is that\n",
    "F[V, τ] = min\n",
    "{V(τ)}F[V, τ;V(τ)] (12.44)\n",
    "To put this in appropriate boundary condition form for solution, we again rely on\n",
    "the isomorphic correspondence with options and refer the reader to the discussion in\n",
    "Merton (1973a) where it is shown that condition (12.44) is equivalent to the condition\n",
    "FV[V(τ),τ] = 0 (12.45)\n",
    "Hence, appending (12.45) to (12.40), (12.9a), (12.9c) and (12.43), we solve the prob-\n",
    "lem for the F[V, τ]andV(τ)functions simultaneously.\n",
    "12.7 Conclusion\n",
    "We have developed a method for pricing corporate liabilities which is grounded in\n",
    "solid economic analysis, requires inputs which are on the whole observable; can\"\"\",\n",
    "    \"\"\"P(r,0) = 1 , to determine P(r,τ)and hence the term structure of interest rates. How-\n",
    "ever, without some independent knowledge of αm(and hence ατ), we cannot deter-\n",
    "mine an explicit solution for the term structure.\n",
    "Suppose that one knew that the Expectations Hypothesis held. Then ατ≡rfor all\n",
    "τand the term structure is completely determined by\n",
    "0 =1\n",
    "2g2Prr+fPr−Pτ−rP (11.83)\n",
    "subject to P(r,0) = 1 . Further, from (11.80), it must be that in equilibrium, αm=r.\n",
    "In this case, the equilibrium condition (11.77) simpliﬁes to\n",
    "αk−r=σk(ρkM−ρMrρkr)\n",
    "σM(1−ρ2\n",
    "Mr)(αM−r) k= 1,. .. , m −1 (11.84)\n",
    "where the ρs are the instantaneous correlation coefﬁcients deﬁned by ρkM≡σkM/σkσM,\n",
    "ρkr≡σkr/gσk, andρMr≡σMr/gσM. Hence, the individual expected returns are pro-\n",
    "portional to the market expected return as was the case in Model I. However, the\n",
    "proportionality factor is not σMk/σ2\n",
    "M. If the mth security is chosen to be a portfolio\n",
    "of government bonds, then, given speciﬁc knowledge of the term structure, the rest\n",
    "of the equilibrium relations work out in a determined fashion.\n",
    "Equation (11.83) cannot be solved in closed form for arbitrary fandg. However,\n",
    "if it is assumed that fandgare constants (i.e. rfollows a Gaussian random walk with\n",
    "a drift), then, under the Expectations Hypothesis, we do have the explicit solution\n",
    "P(r,τ) = exp(\n",
    "−rτ−f\n",
    "2τ2+g2\n",
    "6τ3)\n",
    "(11.85)\n",
    "Note that in (11.85), as τ→ ∞ ,P→ ∞ , which is not at all reasonable. Certainly, the\n",
    "current value of a discounted loan which will never be paid should be zero for any\n",
    "300 A Dynamic General Equilibrium Model of the Asset Market\n",
    "realistic assumption about interest rates. The reason that (11.85) gives such nonsensi-\n",
    "cal results is that, by the assumption that ris Gaussian, there is a positive probability\n",
    "ofrbecoming negative. In fact, as τ→ ∞ ,rwill be negative for an arbitrary period\n",
    "of time with positive probability. This result illustrates how the assumption of the\n",
    "normal distribution for variables which are constrained to be nonnegative can lead to\n",
    "absurd implications. However, equation (11.83) with reasonable assumptions about\n",
    "fandgcan be solved numerically and further research is planned in this area.42\n",
    "By arguments similar to those used in Section 11.5, the Fundamental Equation of\n",
    "Security Pricing for the capital structure of the ﬁrm in Model III can be derived as\n",
    "0 =1\n",
    "2σ2V2FV V+1\n",
    "2g2Frr+ρgσV F rV+rV F V+fFr−Fτ−rF (11.86)\n",
    "subject to an appropriate boundary condition F(V, r,0), where subscripts denote par-\n",
    "tial derivatives and ρis the instantaneous correlation coefﬁcient of the return on the\n",
    "ﬁrm with interest rate changes. The basic difference between equations (11.86) and\n",
    "(11.65) of Model I is the explicit dependence of Fonrwhich must be taken into\n",
    "account. Under most conditions, (11.86) will not be solvable in closed form. How-\n",
    "ever, numerical solution seems quite reasonable which implies many possibilities for\n",
    "empirical testing both by direct statistical methods and by simulation.\n",
    "11.8 Conclusion\n",
    "A general intertemporal equilibrium model of the asset market has been derived for\n",
    "arbitrary preferences, time horizon, and wealth distribution. The equilibrium rela-\n",
    "tions among securities were shown to depend only on certain “observable” market\n",
    "aggregates, and hence are subject to empirical investigation. Under the additional as-\n",
    "sumption of a constant rate of interest, these equilibrium relations are essentially the\n",
    "same as those of the static CAPM of Sharpe, Lintner, and Mossin. However, these\n",
    "results were derived without the assumption of Gaussian distributions for security\n",
    "prices or quadratic utility functions. When interest rates vary, some of the intuition\n",
    "about “market risk” and equilibrium expected returns provided by the CAPM was\n",
    "shown to be incorrect.43In addition, the model clearly differentiates between the\n",
    "trading-period horizon ( dt, an inﬁnitesimal) and the planning or time horizon ( Tk,\n",
    "which is arbitrary).\"\"\",\n",
    "    \"\"\"ary condition F(V,0) = min( V, B). A comparison of (11.66) with (11.12) shows that\n",
    "they are the same for dQ=dΛ. Equation (11.66) can be rewritten in general form as\n",
    "F(V, τ) = exp( −rτ)∫∞\n",
    "0F(V Z,0)dΛ(Z, τ) (11.67)\n",
    "where F(V Z,0)is the terminal claim of the security on the ﬁrm. Note that (11.67) de-\n",
    "pends only on the rate of interest r, which is an observable, and σ2which can be esti-\n",
    "mated from past data reasonably accurately; and notonα, which would be difﬁcult to\n",
    "estimate. The actual value of Fcan be computed by using standard error-complement\n",
    "function tables. Hence, (11.67) is subject to rigorous empirical investigation.\n",
    "Although (11.67) is a kind of discounted expected value formula. one should\n",
    "not infer that the expected return on Fisr. From (11.59), (11.63) and (11.64), the\n",
    "expected return on Fcan be written as\n",
    "αe=r+FVV\n",
    "F(α−r) (11.68)\n",
    "which will vary with changes in Vandτ. although it too can be computed from the\n",
    "error-complement function tables, given an estimate of α.\n",
    "30See Samuelson (1965a. p. 22) for solution of the α=βcase.\n",
    "11.5 Model I: A Constant Interest Rate Assumption 295\n",
    "Equation (11.65) was previously derived by Black and Scholes (1973) as a method\n",
    "for pricing option contracts.31Moreover, (11.65) actually holds without the assump-\n",
    "tion of market equilibrium used here. Because of its elegance, I derive the Black-\n",
    "Scholes model in an alternative fashion which makes use of It ˆo’s lemma and the\n",
    "associated theory of stochastic differential equations. Consider a two-asset portfolio\n",
    "constructed so as to contain the ﬁrm as one security and any one of the securities in\n",
    "the ﬁrm’s capital structure as the other. Let Pbe the price per unit of this portfolio,\n",
    "δthe fraction of the total portfolio’s value invested in the ﬁrm and 1−δthe fraction\n",
    "in the particular security chosen from the ﬁrm’s capital structure. Then, from (11.57)\n",
    "and (11.58),\n",
    "dP\n",
    "P=δdV\n",
    "V+ (1−δ)dF\n",
    "F\n",
    "= [δ(α−αe) +αe]dt+ [δ(σ−σe) +σe]dZ(11.69)\n",
    "Suppose δis chosen such that δ(σ−σe)+σe= 0. Then, the portfolio will be “perfectly\n",
    "hedged” and the instantaneous return on the portfolio will be δ(α−αe) +αewith\n",
    "certainty. By arbitrage32conditions, δ(α−αe) +αe=r, the instantaneous riskless\n",
    "rate of return. Combining these two conditions, we have that\n",
    "αe−r=σe\n",
    "σ(α−r) (11.70)\n",
    "Then, as was done previously, we use It ˆo’s lemma to derive (11.62) and (11.63).\n",
    "By combining (11.62), (11.63), and (11.70), we arrive at (11.65). Nowhere was the\n",
    "market-equilibrium assumption needed.\n",
    "Two further remarks must be made before we examine asset pricing in the more\n",
    "complex models in Section 11.6 and Section 11.7. Although the value of the ﬁrm\n",
    "follows a simple dynamic process with constant parameters as described in (11.57),\n",
    "the individual component securities follow more complex processes with changing\n",
    "expected returns and variances. Thus, in empirical examinations using a regression\n",
    "such as (11.55), if one were to use equity instead of ﬁrm values, systematic biases\n",
    "would be introduced. One can ﬁnd cases where the risky debt of one ﬁrm is more\n",
    "comparable with the equity of another ﬁrm than the equity of one ﬁrm is to that of\n",
    "the other.\n",
    "One possibly practical application of the equations of this section is to provide\n",
    "a systematic method of measuring the riskiness of debt of various ﬁrms. Hence, by\n",
    "using equation (11.67). one could derive a risk structure of interest rates as a function\n",
    "of the percentage of the total capital structure subordinated to the issue and the overall\n",
    "riskiness of the ﬁrm. It would be interesting to see how such a method of rating debt\n",
    "would compare with the classical methods of Moody’s and Standard & Poor’s.\n",
    "31For a brief history of the development of the Black-Scholes option pricing model, see Black (1987, 1989)\n",
    "and Bernstein (1992, Ch. 11).\n",
    "32The meaning of “arbitrage” here is not as strong as the usual deﬁnition since differences of opinion among\n",
    "investors about the value of σ2or the belief that Fis a function of other variables besides the value of the\"\"\",\n",
    "    \"\"\"Fi(V, τ) = exp( −ητ)∫∞\n",
    "0Fi(V Z,0)dQ(Z, τ) i= 1,. . ., n (11.8)\n",
    "Because the Fi(V Z,0)are known functions determined by the type of security, and U\n",
    "andP(Z, τ)are assumed known, (11.8) would be sufﬁcient to determine the current\n",
    "equilibrium value of the Eth security if we knew η.\n",
    "From examination of (11.7) and noting again that dQis independent of the partic-\n",
    "ular capital structure chosen, we ﬁnd that exp(ητ)(and hence η) is independent of the\n",
    "particular capital structure. Since (11.7) holds for all capital structures, it must hold\n",
    "3The assumption of strict concavity of Uis sufﬁcient to ensure a unique interior maximum which rules out\n",
    "any need for inequalities in the ﬁrst-order conditions.\n",
    "4See Samuelson and Merton (1969; this volume, Section 7.2) for further discussion of the util-prob concept.\n",
    "5Thus, the assumption that the ﬁrm’s value is independent of its capital structure provides the same math-\n",
    "ematical simpliﬁcation that the assumption of the “incipient” case for warrant pricing did in Samuelson and\n",
    "Merton (1969; this volume, Section 7.7).\n",
    "11.3 Some Examples 281\n",
    "for the trivial capital structure, namely, when the ﬁrm issues just one type of security,\n",
    "equity, and n= 1. In this case, it is obvious that F1(V, τ) =VandF1(V Z,0) =V Z.\n",
    "Substituting in (11.7), we have that\n",
    "exp(ητ) =∫∞\n",
    "0ZdQ(Z, τ) (11.9)\n",
    "i.e.exp(ητ)is the expected return on the ﬁrm in util-prob space. Equation (11.7)\n",
    "states that the expected return on all securities in util-prob space must be equated.\n",
    "IfUwas linear (i.e. the representative man was “risk neutral”), then dQ=dPand\n",
    "(11.7) would imply the well-known result for risk neutrality that expected returns (in\n",
    "the ordinary sense) be equated. Hence, the util-prob distribution is the distribution of\n",
    "returns adjusted for risk.\n",
    "11.3 Some Examples\n",
    "Using equation (11.8), we can derive the equilibrium pricing for various capital struc-\n",
    "tures of the ﬁrm. In the ﬁrst example it is assumed that there are two types of securi-\n",
    "ties: debt and equity. Suppose that the amount of debt issued by the ﬁrm represents\n",
    "a terminal claim of Bdollars on the ﬁrm. Let F1(V, τ)be the current value of the\n",
    "debt outstanding and F2(V, τ)be the current value of the (residual) equity. Then,\n",
    "from previous discussion and equation (11.3), the terminal value of the debt will be\n",
    "F1(V Z,0) = min( B, V Z ). From equations (11.8) and (11.3), the current value of the\n",
    "debt will be\n",
    "F1(V, τ) = exp( −ητ)[∫B/V\n",
    "0ZV dQ (Z, τ) +∫∞\n",
    "B/VBdQ(Z, τ)]\n",
    "(11.10)\n",
    "We can rewrite (11.10) as\n",
    "F1(V, τ) = exp( −ητ)B−exp(−ητ)∫B/V\n",
    "0(B−ZV)dQ(Z, τ) (11.10a)\n",
    "Suppose that the terminal claim of the debtholders is very small relative to the (cur-\n",
    "rent) total value of the ﬁrm (i.e. 0< B≪V) or, alternatively, dQ(Z, τ) = 0 for\n",
    "0≤Z≤B/V . Then\n",
    "F1(V, τ)→exp(−ητ)BasB/V→0 (11.11)\n",
    "In the limit, the debt becomes riskless and so, from (11.11), we have that ηmust be\n",
    "the riskless rate of return per unit time (in both util-prob and ordinary returns space)\n",
    "for the period of length τ. Hence, from this point on, ηwill he replaced by r, the usual\n",
    "notation for the riskless rate. Examining (11.11a), the second term is the discounted\n",
    "expected loss in util-prob space due to default on the debt,6and as such is a risk\n",
    "6Throughout the chapter, all debt is assumed to be of the “discounted-loan” type with no payments prior to\n",
    "maturity. Similarly, it is assumed that no dividends are paid on the equity.\n",
    "282 A Dynamic General Equilibrium Model of the Asset Market\n",
    "premium charged over the-riskless rate. A second useful form of (11.10) is\n",
    "F1(V, τ) = exp( −rτ)[∫∞\n",
    "0ZV dQ (Z, τ)−∫∞\n",
    "B/V(ZV−B)dQ(Z, τ)]\n",
    "=V−exp(−rτ)∫∞\n",
    "B/V(ZV−B)dQ(Z, τ) (11.10b)\n",
    "Since, in equilibrium, V=F1(V, τ) +F2(V, τ), the current value of equity, F2(V, τ),\n",
    "must satisfy\n",
    "F2(V, τ) = exp( −rτ)∫∞\n",
    "B/V(ZV−B)dQ(Z, τ) (11.12)\n",
    "Equation (11.12) is identical to the warrant pricing equation derived in Samuelson\n",
    "and Merton (1969; this volume, Section 7.8) for a warrant with exercise price B.\"\"\",\n",
    "    \"\"\"the ﬁrst to show that combinations of options could be used to create pure securities\n",
    "and that these pure securities could be used to price derivative securities.\n",
    "In this section, we derive the natural analog to Arrow-Debreu pure securities in the\n",
    "continuous-time model and demonstrate their application to the pricing of contingent-\n",
    "claim securities. This done, we go on to show the explicit Connections between\n",
    "option pricing theory and the pricing of these pure securities.\n",
    "In Section 13.2, we derived the price of a general derivative security with payoffs\n",
    "that are a function of a traded asset’s price and time. Under Assumptions 1-6 of that\n",
    "chapter, it was shown that the price of the derivative security, F(V, t), will satisfy\n",
    "0 =1\n",
    "2σ2V2F11+ (rV−D1)F1−rF+F2+D2 (14.9)\n",
    "10Information costs together with agency problems that prohibit the direct sale of information to investors\n",
    "can, of course, justify certain types of ﬁnancial intermediation such as mutual funds. Regulation and spe-\n",
    "cial features of the tax laws may also induce the creation of specialized ﬁnancial instruments and institutions.\n",
    "However, in the absence of transactions costs, it is difﬁcult to explain the complex structure of ﬁnancial inter-\n",
    "mediaries and their wide scope of activities that we observe in the real world.\n",
    "11See the classical works of Arrow (1953, 1964) and Debreu (1959) for the original development of pure\n",
    "state-contingent securities. There is an enormous literature based on the ArrowłDebreu model (cf. Radner,\n",
    "1972, and Merton, 1982a. 1990a, Section 5).\n",
    "348 Financial Intermediation in the Continuous-Time Model\n",
    "for0≤V(t)< V < V(t)andt < T , subject to the boundary conditions\n",
    "F[V(t),t] =f[V(t),t] (14.10a)\n",
    "F[V(t),t] =f[V(t),t] (14.10b)\n",
    "F(V, T) =h(V) (14.10c)\n",
    "Subscripts on Fin (14.9) denote partial derivatives with respect to Vandt.D1(V, t)\n",
    "andD2(V, t)denote the cash-ﬂow rates paid to the holders of the traded asset and its\n",
    "derivative security, respectively. The limited liability of the traded asset implies that\n",
    "V(t) = 0 only if V(t+τ) = 0 andD1(0,t+τ) = 0 for all τ >0. Without loss of\n",
    "generality, we can assume that D2(0,t) = 0 .12As discussed in Chapter 13, D2,f,g,\n",
    "andhspecify the payoff function for the derivative security.\n",
    "In the analysis to follow, we assume that the stochastic process governing the\n",
    "dynamics of the traded asset is such that Pr{V(τ) = 0|V(t)>0}= 0fort≤τ <∞.13\n",
    "Letπ[V(t),t;E, T]denote the price at time tof the particular derivative security with\n",
    "a payoff structure given by D2= 0. and for V(T) =VandE >0\n",
    "π(V, T;E, T) =δ(E−V) (14.11)\n",
    "where δ(x)denotes the Dirac delta function with the properties that S(x) = 0 for\n",
    "x̸= 0andδ(0)is inﬁnite in such a way that∫b\n",
    "aδ(x)dx= 1for any a <0< b.14We\n",
    "now show that the derivative securities deﬁned by (14.11) for various values of Eand\n",
    "Tare essentially Arrow-Debreu pure securities, extended to an environment with a\n",
    "continuum of states deﬁned by the price of the traded asset and time.15\n",
    "LetdE > 0denote the inﬁnitesimal differential of the parameter E. Consider\n",
    "a portfolio strategy that at time tpurchases dEunits of each of the continuum of\n",
    "derivative securities with parameter values E∈[E1,E2]and0< E 1< E 2. If the\n",
    "portfolio is held until time TandV(T) =V. then from (14.11), the value of the\n",
    "portfolio is given by\n",
    "∫E2\n",
    "E1δ(E−V)dE=\n",
    "1ifE1< V < E 2\n",
    "0otherwise(14.12)\n",
    "12Because V(t) = 0 implies that V(t+τ) = 0 forτ >0, the capitalized value of any promised payments,\n",
    "D2(0,t+τ), can be incorporated into the termination function g(0,t). Thereby, we can formally set D2(0,t+\n",
    "τ) = 0 without toss of generality.\n",
    "13That is, we assume that V(t) = 0 is an inaccessible boundary for ﬁnite t. For example, this assumption\n",
    "is satisﬁed if the underlying asset has a proportional payout policy, D1(V, t) =ρ(t)V,0≤ρ(t)<∞for all\n",
    "tandσis a constant. General conditions are given in Karlin and Taylor (1981, pp. 226-50)). See also Mardl\n",
    "(1968, pp. 24-5) and Merton (1975a; this volume, Appendix 17B).\"\"\",\n",
    "    \"\"\"or purchase of securities prior to the redemption date of the debt ( τ“years” from\n",
    "now).29Hence, from (11.31), we have that\n",
    "dV\n",
    "V=fcdPP =αdt+σdZ (11.57)\n",
    "where αandσare constants.\n",
    "LetD(t;τ)be the current value of the debt with τyears until maturity and with\n",
    "redemption value at that time of B. Then D(t+τ; 0) = min[ V(t+τ),B]. and therefore\n",
    "it is reasonable to assume that D(t;τ)will depend on the interest rate and the proba-\n",
    "bility of default which will be a function of the current value of the ﬁrm. Because the\n",
    "current value of equity is V(t)−D(t;τ), equity will only depend on the current value\n",
    "of the ﬁrm and the interest rate. Let F(V, τ)be the current value of equity where the\n",
    "variable rhas been suppressed because, in this model, it is constant. The dynamics\n",
    "of the return on equity can be written as\n",
    "dF\n",
    "F=αedt+σedZ (11.58)\n",
    "where αeis the instantaneous expected rate of return, σeis the instantaneous standard\n",
    "deviation of return, and dZis the same standard Wiener process as in (11.57). αeand\n",
    "σeare not constants but functions of Vandτ. Like every security in the economy,\n",
    "the equity of the ﬁrm must satisfy (11.51) in equilibrium, and hence\n",
    "αe−r=ρσeσM\n",
    "σ2\n",
    "M(αM−r) (11.59)\n",
    "where ρis the instantaneous correlation coefﬁcient between dZand the market return.\n",
    "Further, by It ˆo’s lemma (see Merton, 1971; this volume, Lemma 5.1), we have that\n",
    "dF=FVdV+Fτdτ+1\n",
    "2FV V(dV)2(11.60)\n",
    "where subscripts denote partial derivatives. Since τis the length of time until matu-\n",
    "rity,dτ=−dt. Substituting for dVfrom (11.57), we rewrite (11.60) as\n",
    "dF=(1\n",
    "2σ2V2FV V+αV F V−Fτ)\n",
    "dt+σV F VdZ (11.61)\n",
    "29This assumption is stronger than necessary. It is sufﬁcient that any new issues have the same terms as the\n",
    "current capital structure and that they be issued in the same proportions of units ( notvalues) as the current\n",
    "structure. A more general model using the same approach as in the text could be formulated to include the\n",
    "expectations of future issues.\n",
    "The assumption that the debt is of the discounted-loan type is not completely innocent because of the pos-\n",
    "sibility of default on interim interest payments. Although the resulting mathematics is more complicated, the\n",
    "basic approach used here could be modiﬁed to include the case of interim payments as well. (1990 note: see\n",
    "Merton (1974; this volume, Section 12.6) for a solution of the risky coupon-bond case.)\n",
    "294 A Dynamic General Equilibrium Model of the Asset Market\n",
    "where (dV)2≡σ2V2dt. Comparing (11.58) and (11.61), it must be that\n",
    "αeF≡1\n",
    "2σ2V2FV V+αV F V−Fτ (11.62)\n",
    "and\n",
    "αeF≡σV F V (11.63)\n",
    "As previously shown, the return on holding the ﬁrm itself must satisfy equation\n",
    "(11.51) in equilibrium. Hence,\n",
    "α−r=ρσiσM\n",
    "σ2\n",
    "M(αM−r) (11.64)\n",
    "Substituting for αandαefrom (11.59) and (11.64) into (11.62), we have the Funda-\n",
    "mental Partial Differential Equation of Security Pricing\n",
    "0 =1\n",
    "2σ2V2FV V+αV F V−Fτ−rF (11.65)\n",
    "subject to the boundary condition F(V,0) = max(0 ,V−B). The solution30to (11.65)\n",
    "is\n",
    "F(V, τ) = exp( −rτ)∫∞\n",
    "B/V(V Z−B)dΛ(Z, τ) (11.66)\n",
    "where Zis a log-normally distributed random variable with mean exp(rτ)and vari-\n",
    "ance of log(Z)σ2τ, and dΛis the log-normal density function. I call (11.65) the\n",
    "Fundamental Partial Differential Equation of Asset Pricing because all the securities\n",
    "in the ﬁrm’s capital structure must satisfy it. As was true of the model in Section\n",
    "11.1, securities are distinguished by theirs terminal claims (boundary conditions).\n",
    "For example, the value of the debt of the ﬁrm satisﬁes (11.65) subject to the bound-\n",
    "ary condition F(V,0) = min( V, B). A comparison of (11.66) with (11.12) shows that\n",
    "they are the same for dQ=dΛ. Equation (11.66) can be rewritten in general form as\n",
    "F(V, τ) = exp( −rτ)∫∞\n",
    "0F(V Z,0)dΛ(Z, τ) (11.67)\n",
    "where F(V Z,0)is the terminal claim of the security on the ﬁrm. Note that (11.67) de-\n",
    "pends only on the rate of interest r, which is an observable, and σ2which can be esti-\n",
    "mated from past data reasonably accurately; and notonα, which would be difﬁcult to\"\"\",\n",
    "]\n",
    "\n",
    "    ),\n",
    "    LLMTestCase(\n",
    "        input=\"What is a ‘continuous double auction’, and how does it differ from the single‑price clearing used in earlier LLM‑market papers the authors critique?\",\n",
    "        actual_output=\"\"\"In a continuous double auction, buyers and sellers continuously submit both buy and sell orders (bids and asks) at any time. Trades occur whenever a buy order's price matches or exceeds a sell order's price. This creates a dynamic market where prices fluctuate based on real-time supply and demand. The system maintains an order book (a real-time list of all outstanding buy and sell orders), and orders are matched based on price-time priority (highest bids and lowest asks are given priority, and among same-priced orders, those submitted earlier take precedence).\n",
    "This differs from the single-price clearing mechanism used in some earlier LLM market simulations. In a single-price clearing system, all orders are collected during a specific period. At the end of that period, a single clearing price is determined that best matches the overall supply and demand. All trades then execute at that single price. Essentially, it's like taking a snapshot of the market at one point in time, rather than allowing continuous trading and price adjustments as in a continuous double auction. The authors critique single-price clearing because it lacks the dynamic price discovery and realistic order book behavior of a continuous double auction, which are crucial aspects of real-world financial markets.\n",
    "\"\"\",\n",
    "        expected_output=\"\"\"It allows buyers and sellers to post bids/asks continuously with price‑time priority, unlike prior LLM papers that used single‑price batch clearing without an order book.\"\"\",\n",
    "        context=[\n",
    "            \"\"\"Our framework implements a continuous double‑auction market…” + “Within the computer‑science literature, early works … employ single‑price clearing mechanisms without a persistent order book…\"\"\"\n",
    "        ],\n",
    "        retrieval_context=[\n",
    "    \"\"\"the second agents’ design, and the third the analysis module.\n",
    "8\n",
    "2.1 Market Design\n",
    "Our methodological framework integrates three components that create a controlled envi-\n",
    "ronment for LLM-based trading agents. The framework implements a flexible continuous\n",
    "double-auction market mechanism that couples standard market microstructure principles\n",
    "with market clearing and matching algorithms to accommodate asynchronous LLM decisions.\n",
    "The market clearing process employs a dual-stage matching algorithm. In the first stage,\n",
    "limit orders are posted. In the second stage, market orders are netted using a market-\n",
    "to-market matching engine that processes buy and sell orders, reconciling orders based on\n",
    "available agent cash and share commitments. In the third stage, any remaining market\n",
    "orders are matched against the existing order book, with unfilled quantities converted to\n",
    "aggressive limit orders. This three-tiered approach optimizes immediate execution and price\n",
    "discovery while maintaining market liquidity.\n",
    "The system’s OrderMatchingService orchestrates this process by coordinating trade ex-\n",
    "ecutions through the TradeExecutionService and managing order state transitions via the\n",
    "OrderStateManager. Each trade is logged in detail, with the overall market state—including\n",
    "order books, market depth, and price evolution—recalculated at the end of each trading\n",
    "round.\n",
    "This modular design in the matching and clearing engine provides several advantages.\n",
    "First, it enables rigorous trade validation where each market order is validated against agent\n",
    "cash commitments and position constraints before matching, with the system dynamically\n",
    "adjusting order quantities based on available cash when an agent’s commitment is insuf-\n",
    "ficient, thus minimizing execution errors. Second, it offers flexible liquidity handling by\n",
    "supporting market-to-market and market-to-book matching, ensuring orders have multiple\n",
    "execution pathways, with unexecuted market orders converted to aggressive limit orders to\n",
    "capture remaining liquidity. Third, it maintains detailed trade audit capabilities by recording\n",
    "comprehensive traceability data including timestamps, trade volumes, executed prices, and\n",
    "agent identifiers, thereby enabling post-trade analysis and performance benchmarking that\n",
    "9\n",
    "serves as the foundation for subsequent market efficiency and agent performance validations.\n",
    "2.1.1 Market Mechanism Design\n",
    "Our framework implements a continuous double-auction market mechanism that processes\n",
    "orders in discrete trading rounds. We use discrete trading rounds because LLMs have latency\n",
    "constraints, making it infeasible to process orders in real time. Within each round, the order\n",
    "of agent submissions is randomized to avoid giving systematic priority to specific agents,\n",
    "thus simulating concurrent order arrival while maintaining fairness. Once randomized, or-\n",
    "ders are then processed according to standard price-time priority rules. The system supports\n",
    "finite and infinite horizon markets, with differences in terminal conditions and wealth cal-\n",
    "culation. In finite-horizon markets, agents are informed of the total number of rounds, and\n",
    "their terminal wealth is calculated by redeeming all shares at the fundamental value of the\n",
    "final round. In infinite-horizon markets, no terminal information is provided to agents, and\n",
    "final wealth is determined using the last market price for share valuation. This design choice\n",
    "enables researchers to study how time horizons influence trading strategies and price for-\n",
    "mation, particularly how agents balance short-term trading opportunities against long-term\n",
    "value considerations.\n",
    "In a double auction, buyers and sellers actively submit orders, with trades occurring when\n",
    "compatible buy and sell orders match the price. The matching engine processes these orders\n",
    "through three sequential phases:\n",
    "First, incoming limit orders that do not immediately cross the market are added to\n",
    "the order book, maintaining strict price-time priority. Second, market orders are processed\"\"\",\n",
    "    \"\"\"2024). Another examines LLMs’ strategic capabilities through task-based simulations and\n",
    "collaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\n",
    "Within the computer science literature, early works apply LLMs to financial markets but\n",
    "abstract away many fundamental stock market characteristics. Often, they employ single-\n",
    "price clearing mechanisms without a persistent order book, ignore partial fills and bid-ask\n",
    "spreads, and omit dividends. Consequently, these simplified environments can primarily\n",
    "address exogenous macro shocks (e.g., changes in interest rates or inflation; Gao et al. 2024),\n",
    "exogenous policy changes (Zhang et al. 2024), or rely on advanced methods such as repetitive\n",
    "next-token predictions to generate better answers (Koa et al. 2024). This work extends\n",
    "these efforts by incorporating these crucial market features, enabling the study of complex\n",
    "endogenous events such as flash crashes, liquidity shocks, and large-trader impacts.\n",
    "This work also connects to emerging research on algorithmic and AI-powered trading\n",
    "systems. Dou, Goldstein, and Ji (2024) demonstrate how reinforcement learning-based AI\n",
    "speculators can autonomously learn to sustain collusive behavior without explicit coordi-\n",
    "nation, achieving supra-competitive profits through either price-trigger strategies or self-\n",
    "confirming bias in learning. This finding is particularly informative for this framework as\n",
    "it highlights potential emergent behaviors that may arise when intelligent agents interact in\n",
    "7\n",
    "markets—behaviors that could manifest differently with LLM agents due to their natural\n",
    "language reasoning capabilities. Similarly, Colliard, Foucault, and Lovo (2022) examine al-\n",
    "gorithmic market makers using Q-learning and find they charge markups that increase when\n",
    "adverse selection costs decrease—contrary to Nash equilibrium predictions. Their work pro-\n",
    "vides methodological insights on how to test strategic pricing behaviors against theoretical\n",
    "benchmarks incorporated into this LLM-based framework.\n",
    "Finally, this approach is informed by complexity economics, which views markets as dy-\n",
    "namic, non-equilibrium systems where agents adaptively learn and evolve strategies (Arthur\n",
    "2013; Wolfram 2017). According to this view, markets exhibit emergent phenomena and\n",
    "self-organization, especially when trading agents (human or artificial) update their behav-\n",
    "ior in response to outcomes. This paradigm is particularly relevant in an era of increasing\n",
    "automation and algorithmic trading (Balland et al. 2022; Ping 2019). Like adaptive agents\n",
    "in complexity economics, these LLM traders incorporate new information and adjust their\n",
    "strategies, generating emergent market patterns—a key motivation behind this framework.\n",
    "Unlike previous frameworks that abstract away crucial market features or focus on narrow\n",
    "strategies, this system incorporates realistic market microstructure while accommodating\n",
    "heterogeneous agents interacting simultaneously. While earlier work demonstrates LLMs’\n",
    "promise for macroeconomic modeling and simple trading simulations, this work introduces a\n",
    "complex, open-source financial market platform that supports multiple agent architectures,\n",
    "thorough market microstructure (limit orders, partial fills, dividends), and rigorous testing\n",
    "protocols—fulfilling a critical need in complexity economics research and market microstruc-\n",
    "ture analysis.\n",
    "2 Methodology\n",
    "The methodology section contains three parts. The first part describes the market design,\n",
    "the second agents’ design, and the third the analysis module.\n",
    "8\n",
    "2.1 Market Design\n",
    "Our methodological framework integrates three components that create a controlled envi-\n",
    "ronment for LLM-based trading agents. The framework implements a flexible continuous\n",
    "double-auction market mechanism that couples standard market microstructure principles\n",
    "with market clearing and matching algorithms to accommodate asynchronous LLM decisions.\"\"\",\n",
    "    \"\"\"value considerations.\n",
    "In a double auction, buyers and sellers actively submit orders, with trades occurring when\n",
    "compatible buy and sell orders match the price. The matching engine processes these orders\n",
    "through three sequential phases:\n",
    "First, incoming limit orders that do not immediately cross the market are added to\n",
    "the order book, maintaining strict price-time priority. Second, market orders are processed\n",
    "through a two-stage matching algorithm: (a) market-to-market matching, where market\n",
    "orders are netted against each other at the current market price, and (b) market-to-book\n",
    "matching, where remaining market orders are executed against standing limit orders. Finally,\n",
    "any crossing limit orders are matched against the order book.\n",
    "10\n",
    "2.1.2 Implementation Details\n",
    "The matching engine ( MatchingEngine class) implements three primary components that\n",
    "work together to facilitate efficient market operation. The order processing component han-\n",
    "dles the core matching functionality, where market orders are executed immediately against\n",
    "the best available prices in the order book during each trading round. When immediate\n",
    "execution is impossible, limit orders are stored in the order book according to price-time\n",
    "priority. The system supports partial executions, maintaining careful tracking of remaining\n",
    "quantities to ensure complete order fulfillment across multiple trades when necessary.\n",
    "Position management forms the second critical component, providing comprehensive\n",
    "tracking of agent positions and cash balances throughout the trading session. Before any\n",
    "trade execution, the system performs rigorous pre-trade validation to ensure agents have suffi-\n",
    "cient resources to fulfill their orders. This check includes validating buyer cash commitments\n",
    "and shares availability for sellers, with the system maintaining accurate records of commit-\n",
    "ted and available resources for each agent. The position management system updates in\n",
    "real-time as trades are executed, ensuring market integrity and preventing over-commitment\n",
    "of resources.\n",
    "The price formation mechanism constitutes the third component, implementing a sys-\n",
    "tematic price discovery and market monitoring approach. As trades are executed within each\n",
    "round, the system dynamically updates prices based on executed trades while continuously\n",
    "tracking market depth and bid-ask spreads. This data collection provides detailed insights\n",
    "into market liquidity and efficiency. Each trade is logged with comprehensive information,\n",
    "including price, quantity, and participating agents, creating a complete audit trail of mar-\n",
    "ket activity. This comprehensive price formation system ensures transparent price discovery\n",
    "while generating rich data for market quality analysis.\n",
    "11\n",
    "2.1.3 Extensibility Features\n",
    "The framework employs a modular architecture to support diverse experimental configura-\n",
    "tions and research objectives. At its foundation, the system implements configurable market\n",
    "rules and trading constraints that can be adjusted to study different market conditions.\n",
    "The asset model supports fundamental features like dividend payments and interest accrual,\n",
    "enabling research across different market scenarios. Through its modular service-based ar-\n",
    "chitecture, the trading mechanism layer allows for adaptation to other market structures\n",
    "beyond the base double-auction system, such as call auctions or dark pools. Furthermore,\n",
    "the framework provides flexible integration points for different LLM agent types and strate-\n",
    "gies, allowing researchers to experiment with diverse behavioral models and decision-making\n",
    "approaches.\n",
    "This extensible design creates numerous research opportunities for market microstructure\n",
    "studies. Researchers can systematically investigate how different market structures influence\n",
    "price formation and efficiency, evaluate the impact of various trading rules on market qual-\n",
    "ity, and analyze the complex interactions between different agent types and strategies. The\"\"\",\n",
    "    \"\"\"(2023)). This work, however, focuses on financial markets and how LLM agents can operate\n",
    "as full-fledged trading participants.\n",
    "Recent research examines specific applications of LLMs for trading. FinMem and Trad-\n",
    "ingGPT introduce frameworks with layered memory systems and customizable agent traits\n",
    "5\n",
    "to improve financial decision-making (Yu, Li, et al. 2024; Li, Zhang, and Sun 2023). Hierar-\n",
    "chical multi-agent architectures have been explored in FinCon, which uses a manager-analyst\n",
    "setup for collaborative portfolio decisions (Yu, Yao, et al. 2024). QuantAgent implements\n",
    "a self-improving signal-mining approach (Wang et al. 2024), while other work underscores\n",
    "the importance of long-term memory in LLM agents via vector databases (Hatalis et al.\n",
    "2024). This line of research builds on successful reinforcement learning applications such as\n",
    "AlphaPortfolio (Cong et al. 2021) and AlphaManager (Campello, Cong, and Zhou 2023),\n",
    "which leverage deep RL and robust control for portfolio management.\n",
    "Analyzing LLM agent behavior by changing only some parameters draws on methods\n",
    "from the interpretable machine learning literature. In particular, the systematic variation\n",
    "of market parameters to reveal decision patterns mirrors partial dependence plots and in-\n",
    "dividual conditional expectation curves used to interpret complex machine learning models\n",
    "(Molnar 2022). These techniques help reveal how LLM agents respond to changes in specific\n",
    "variables while holding others constant, providing insight into their internal decision-making\n",
    "processes that would otherwise remain opaque.\n",
    "Beyond finance, studies of LLM capabilities in interactive or multi-agent settings offer\n",
    "valuable insights. Benchmarks like AgentBench evaluate LLMs’ performance in interac-\n",
    "tive tasks (Liu et al. 2023), while InvestorBench focuses on financial decision-making tasks\n",
    "specifically (H. Li et al. 2024). NegotiationArena demonstrates LLMs’ capacity for strategic\n",
    "interaction in bargaining contexts (Bianchi et al. 2024). Similarly, Guo et al. (2024) provide\n",
    "an economics ”arena” where LLMs compete in strategic games, revealing that advanced\n",
    "models like GPT-4 can exhibit rational, adaptive behavior—albeit not always reaching Nash\n",
    "Equilibrium. Existing frameworks typically assess individual agents or hierarchical collab-\n",
    "orations, whereas this work studies emergent market behaviors that arise from multiple\n",
    "independent LLM traders interacting in a marketplace.\n",
    "The approach also connects to the tradition of experimental asset markets. For instance,\n",
    "Weitzel et al. (2020) show that even finance professionals are susceptible to speculative\n",
    "6\n",
    "bubbles, especially amid high capital inflows. Kop´ anyi-Peuker and Weber (2021) find that\n",
    "trading experience alone does not eliminate bubbles, challenging assumptions about rational\n",
    "market learning. Kirchler, Huber, and St¨ ockl (2012) identify confusion about fundamental\n",
    "values as a key driver of bubble formation. This framework offers a new way to study these\n",
    "phenomena with LLM traders, which can be rigorously parameterized for sophistication,\n",
    "strategy, and information processing. Hence, this paper provides a method to investigate\n",
    "how automated or ”artificial” agents might affect market stability or volatility.\n",
    "Other recent work highlights the versatility of LLM agents in complex, interactive sce-\n",
    "narios beyond finance. One stream focuses on simulating social behaviors—such as opinion\n",
    "dynamics (Chuang et al. 2023), trust (Xie et al. 2024), and resource-sharing (Piatti et al.\n",
    "2024). Another examines LLMs’ strategic capabilities through task-based simulations and\n",
    "collaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\n",
    "Within the computer science literature, early works apply LLMs to financial markets but\n",
    "abstract away many fundamental stock market characteristics. Often, they employ single-\n",
    "price clearing mechanisms without a persistent order book, ignore partial fills and bid-ask\"\"\",\n",
    "    \"\"\"ceedings of the 62nd Annual Meeting of the Association for Computational Linguistics\n",
    "(Volume 1: Long Papers),edited by Lun-Wei Ku, Andre Martins, and Vivek Srikumar,\n",
    "15523–15536. ACL 2024. Bangkok, Thailand: Association for Computational Linguis-\n",
    "tics, August.\n",
    "39\n",
    "Li, Yuan, Yixuan Zhang, and Lichao Sun. 2023. “MetaAgents: Simulating Interactions of\n",
    "Human Behaviors for LLM-based T Ask-Oriented Coordination via Collaborative Gen-\n",
    "erative Agents.” arXiv.org.\n",
    "Liu, Xiao, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, et al. 2023.\n",
    "“AgentBench: Evaluating LLMs as Agents.”International Conference on Learning Rep-\n",
    "resentations.\n",
    "Lopez-Lira, Alejandro, and Yuehua Tang. 2023. “Can ChatGPT Forecast Stock Price Move-\n",
    "ments? Return Predictability and Large Language Models.” SSRN Electronic Journal\n",
    "(April 6, 2023).\n",
    "Manning, Benjamin S., Kehang Zhu, and John J. Horton. 2024. “Automated Social Science:\n",
    "Language Models as Scientist and Subjects.” (Cambridge, MA) (April 29, 2024).\n",
    "Molnar, Christoph. 2022. Interpretable Machine Learning.\n",
    "Pelster, Matthias, and Joel Val. 2023. “Can Chatgpt Assist in Picking Stocks?”Social Science\n",
    "Research Network.\n",
    "Piatti, Giorgio, Zhijing Jin, Max Kleiman-Weiner, Bernhard Sch¨ olkopf, Mrinmaya Sachan,\n",
    "and Rada Mihalcea. 2024. “Cooperate or Collapse: Emergence of Sustainable Coopera-\n",
    "tion in a Socie Ty of LLM Agents.” arXiv.org.\n",
    "Ping, Chen. 2019. “From Complexity Science to Complexity Economics.” In Alternative\n",
    "Approaches to Economic Theory,19–55. Routledge, June 11, 2019.\n",
    "Wang, Saizhuo, Hang Yuan, Lionel M. Ni, and Jian Guo. 2024. “QuantAgent: Seeking Holy\n",
    "Grail in Trading by Self-Improving Large Lang Uage Model.” arXiv.org.\n",
    "Weitzel, Utz, Christoph Huber, J¨ urgen Huber, Michael Kirchler, Florian Lindner, and Julia\n",
    "Rose. 2020. “Bubbles and Financial Professionals.” The Review of Financial Studies33,\n",
    "no. 6 (June 1, 2020): 2659–2696.\n",
    "40\n",
    "Wolfram, Elsner. 2017. “Complexity Economics as Heterodoxy: Theory and Policy.”Journal\n",
    "of Economic Issues51, no. 4 (October 2, 2017): 939–978.\n",
    "Woodhouse, Drew, and Alex Charlesworth. 2023. “Can ChatGPT Predict Future Interest\n",
    "Rate Decisions?” Social Science Research Network.\n",
    "Xie, Chengxing, Canyu Chen, Feiran Jia, Ziyu Ye, Shiyang Lai, Kai Shu, Jindong Gu, et al.\n",
    "2024. “Can Large Language Model Agents Simulate Human Trust Behavior?”arXiv.org.\n",
    "Yang, Stephen. 2023. “Predictive Patentomics: Forecasting Innovation Success and Valuation\n",
    "w Ith ChatGPT.” Social Science Research Network.\n",
    "Yu, Yangyang, Haohang Li, Zhi Chen, Yuechen Jiang, Yang Li, Denghui Zhang, Rong\n",
    "Liu, Jordan W. Suchow, and Khaldoun Khashanah. 2024. “FinMem: A Performance-\n",
    "Enhanced LLM Trading Agent with Layered Memory a Nd Character Design.”Proceed-\n",
    "ings of the AAAI Symposium Series3, no. 1 (May 20, 2024): 595–597.\n",
    "Yu, Yangyang, Zhiyuan Yao, Haohang Li, Zhiyang Deng, Yupeng Cao, Zhi Chen, Jordan W.\n",
    "Suchow, et al. 2024. “FinCon: A Synthesized LLM Multi-Agent System with Conceptual\n",
    "Verbal Reinforcement for Enhanced Financial Decision Making.” Pre-published, Novem-\n",
    "ber 7, 2024. Accessed January 8, 2025. https://doi.org/10.48550/arXiv.2407.06567.\n",
    "arXiv: 2407.06567 [cs]. http://arxiv.org/abs/2407.06567.\n",
    "Zhang, Chong, Xinyi Liu, Zhongmou Zhang, Mingyu Jin, Lingyao Li, Zhenting Wang,\n",
    "Wenyue Hua, et al. 2024. “When AI Meets Finance (StockAgent): Large Language\n",
    "Model-based Stock Trading in Simulated Real-world Environments.” Pre-published,\n",
    "September 21, 2024. Accessed January 26, 2025. https://doi.org /10.48550/arXiv .\n",
    "2407.18957. arXiv: 2407.18957 [q-fin]. http://arxiv.org/abs/2407.18957.\n",
    "41\n",
    "A Technical Implementation Details\n",
    "A.1 Agent Type Specifications\n",
    "This section details the base system prompts for each agent type in our simulation. These\n",
    "prompts define the core behavioral characteristics and trading strategies for each agent. Each\n",
    "prompt consists of:\n",
    "• A role definition that establishes the agent’s trading philosophy\n",
    "• A structured trading strategy that guides decision-making\"\"\",\n",
    "    \"\"\"33\n",
    "ants, allowing researchers to study how different belief structures influence price formation\n",
    "and trading patterns under different initial mispricings. In these scenarios, the fundamental\n",
    "price is hidden from agents, forcing them to rely on their own valuation models.\n",
    "3.2.5 Market Stress\n",
    "This scenario tests market resilience under challenging conditions by creating a more volatile\n",
    "environment. The scenario includes two consistently bullish Optimistic traders, two consis-\n",
    "tently bearish Pessimistic traders, two Market makers (liquidity providers), and two Value\n",
    "investors (rational benchmark traders). The scenario runs for 100 rounds to study long-term\n",
    "market behavior and includes unequal initial endowments, with optimistic traders having\n",
    "more cash (1.5x baseline) but fewer shares (0.5x baseline) and pessimistic traders having less\n",
    "cash (0.5x baseline) but more shares (1.5x baseline). This resource imbalance tests whether\n",
    "particular agent types can dominate market outcomes through resource advantages.\n",
    "The scenarios presented here demonstrate the framework’s capabilities for exploring di-\n",
    "verse market conditions. Its modular structure facilitates the straightforward definition and\n",
    "implementation of alternative experimental designs, enabling researchers to tailor simulations\n",
    "to specific research questions.\n",
    "In all scenarios, we maintain consistent baseline parameters with a fundamental value\n",
    "of $28.00, calculated from the expected dividend of $1.40 and interest rate of 5%. Agent\n",
    "endowments start at 1,000,000 monetary units and 10,000 shares unless specifically modified.\n",
    "Transaction costs are set to zero to isolate the effects of agent behavior and market structure\n",
    "on price formation.\n",
    "4 Conclusion\n",
    "This paper demonstrates that Large Language Models can effectively function as diverse\n",
    "trading agents—from value investors to market makers—maintaining strategic consistency\n",
    "34\n",
    "while adapting to market conditions. Our experimental framework reveals that their in-\n",
    "teractions generate realistic market dynamics, including phenomena like price bubbles and\n",
    "corrections, highlighting both the capabilities and potential risks of deploying LLM agents\n",
    "in financial markets.\n",
    "These findings carry significant implications for market structure and regulation. While\n",
    "LLM agents can enhance price discovery and liquidity, their adherence to programmed strate-\n",
    "gies, even potentially flawed ones derived from prompts, could amplify market volatility or\n",
    "introduce novel systemic risks, as observed in our simulated bubble scenarios. A key concern\n",
    "is the potential for widespread correlated behavior: similar underlying LLM architectures\n",
    "responding uniformly to comparable prompts or market signals could inadvertently create\n",
    "destabilizing trading patterns without explicit coordination. This underscores the critical\n",
    "need for rigorous testing and validation of LLM-based trading systems prior to live deploy-\n",
    "ment.\n",
    "A central contribution of this work is the open-source simulation framework itself, de-\n",
    "signed to catalyze research into LLM trading agents. We invite the research community to\n",
    "utilize and extend this platform to investigate pressing questions in this rapidly evolving\n",
    "area. The framework enables systematic exploration of complex scenarios—such as hybrid\n",
    "human-LLM markets, stress tests, varying market structures, regulatory impacts, and the\n",
    "nuances of LLM prompting—often difficult or costly to study otherwise. Specific avenues\n",
    "ripe for investigation using this tool include the emergence of novel trading strategies, the\n",
    "precise effects of agent heterogeneity on market stability, and the development of robust\n",
    "validation protocols for AI traders. As artificial intelligence becomes more integrated into\n",
    "finance, collaborative research leveraging adaptable simulation environments like this one\n",
    "will be crucial for understanding and responsibly shaping the future of trading.\n",
    "35\n",
    "References\"\"\",\n",
    "    \"\"\"decision-making process.\n",
    "The analysis reveals three key findings about LLMs’ capabilities as trading agents. First,\n",
    "LLMs can effectively execute trading strategies. They consistently understand market me-\n",
    "chanics, process market information, form price expectations, and execute trades according\n",
    "to specific instructions. Their trading behavior is highly sensitive to the prompts they\n",
    "receive—they faithfully follow directions regardless of profit implications. This observance\n",
    "1. For example, Autopilot has a ChatGPT-based portfolio https://x.com/thegptinvestor.\n",
    "2\n",
    "{\"valuation_reasoning\":\n",
    "\"The fundamental value is based on the expected dividend,\n",
    "and the interest rate.\n",
    "The expected dividend is $1.40, and the interest rate is 5%.\n",
    "Using a perpetuity formula, the value is $1.40 / 0.05 = $28.\",\n",
    "\"valuation\":28.0,\n",
    "\"price_target_reasoning\":\"The current price is $29.00, which is\n",
    "slightly above the fundamental value of $28.00. I expect the price\n",
    "to remain around $29.00 in the next round due to market stability.\",\n",
    "\"price_target\":29.0,\n",
    "\"orders\":[{\"decision\":\"Sell\",\"quantity\":1000,\"order_type\":\"limit\",\n",
    "\"price_limit\":29.50}],\n",
    "\"replace_decision\":\"Add\",\n",
    "\"reasoning\":\"The current price is slightly above the fundamental value.\n",
    "I will place a limit sell order at $29.50 to capitalize on potential price\n",
    "increases.\"}\n",
    "Figure 1: Example of a structured trading decision from a Speculator agent defined by its\n",
    "system prompt: “You are a speculator who tries to profit from market inefficiencies.”. The\n",
    "LLM provides explicit reasoning for its valuation, price target, and trading decision in a\n",
    "machine-readable JSON format that can be directly processed by the trading system.\n",
    "highlights a fundamental difference from human traders: LLMs do not inherently optimize\n",
    "for profit maximization but rather for following instructions accurately.\n",
    "Second, LLMs react meaningfully to market dynamics. They consider current and his-\n",
    "torical prices, dividends, and other market information when making decisions. However,\n",
    "they maintain their strategic direction even when market conditions change, following their\n",
    "instructions even if doing so results in financial losses. This combination of responsiveness\n",
    "to market conditions while maintaining strategic consistency creates a unique trading profile\n",
    "distinct from rule-based algorithms and human traders.\n",
    "Third, market dynamics with LLM agents can resemble actual markets and mirror classic\n",
    "results from the theoretical finance literature. When these agents interact, they produce\n",
    "realistic price discovery and liquidity provision with emergent behaviors, including price\n",
    "convergence toward fundamental values. Depending on the distribution of agent types,\n",
    "the system can generate various market phenomena, such as bubbles or underreactions to\n",
    "information. This complex behavior suggests potential applications for studying market\n",
    "3\n",
    "dynamics using LLM agents instead of experiments with human participants.\n",
    "Hence, these findings raise important questions about algorithmic consistency in LLM-\n",
    "based systems. Since trading agents are implemented through prompts, their behavior in-\n",
    "herits characteristics of the underlying language models. The standardization of LLM ar-\n",
    "chitectures across implementations could create unexpected behavioral patterns—if many\n",
    "agents are based on similar foundation models, they might exhibit correlated responses to\n",
    "specific market conditions, potentially amplifying market instabilities.\n",
    "To enable this analysis and accelerate development in this emerging field, we provide\n",
    "an open-source framework with three key components: (1) a structured protocol for im-\n",
    "plementing and validating LLM trading agents, supporting both LLM-based and traditional\n",
    "rule-based agents; (2) a controlled market environment with realistic microstructure for test-\n",
    "ing agent interactions; and (3) a comprehensive data collection system for analyzing trading\n",
    "behavior. This framework serves multiple stakeholders in preparation for the evolution of\"\"\",\n",
    "    \"\"\"Can Large Language Models Trade? Testing Financial\n",
    "Theories with LLM Agents in Market Simulations\n",
    "Alejandro Lopez-Lira∗\n",
    "First Version: November 29, 2024; Current Version: April 16, 2025\n",
    "Abstract\n",
    "This paper presents a realistic simulated stock market where large language models\n",
    "(LLMs) act as heterogeneous competing trading agents. The open-source framework\n",
    "incorporates a persistent order book with market and limit orders, partial fills, div-\n",
    "idends, and equilibrium clearing alongside agents with varied strategies, information\n",
    "sets, and endowments. Agents submit standardized decisions using structured outputs\n",
    "and function calls while expressing their reasoning in natural language. Three findings\n",
    "emerge: First, LLMs demonstrate consistent strategy adherence and can function as\n",
    "value investors, momentum traders, or market makers per their instructions. Second,\n",
    "market dynamics exhibit features of real financial markets, including price discovery,\n",
    "bubbles, underreaction, and strategic liquidity provision. Third, the framework enables\n",
    "analysis of LLMs’ responses to varying market conditions, similar to partial dependence\n",
    "plots in machine-learning interpretability. The framework allows simulating financial\n",
    "theories without closed-form solutions, creating experimental designs that would be\n",
    "costly with human participants, and establishing how prompts can generate correlated\n",
    "behaviors affecting market stability.\n",
    "Keywords: LLM Agents; Agent-Based Markets; Experimental Finance; AI Trading;\n",
    "Multi-Agent Systems\n",
    "∗University of Florida. Email: alejandro.lopez-lira@warrington.ufl.edu. I am grateful to seminar par-\n",
    "ticipants at the London Business School, Oxford University, Stockholm School of Economics, University of\n",
    "Virginia, and the City University of Hong Kong for helpful suggestions and feedback.\n",
    "1\n",
    "arXiv:2504.10789v1  [q-fin.CP]  15 Apr 2025\n",
    "1 Introduction\n",
    "Large language models (LLMs) can increasingly function as autonomous agents—systems\n",
    "that observe, reason, and act independently. LLMs have shown promising results in finan-\n",
    "cial forecasting, but their potential as trading agents introduces a fundamental shift from\n",
    "algorithms with explicit objectives to systems guided by natural language instructions. This\n",
    "change raises critical questions: Can LLMs execute trading strategies? Do LLMs optimize\n",
    "for profit maximization? What are the implications for market stability and efficiency?\n",
    "If LLMs trade similarly to humans, they could enable experimental market simulations\n",
    "without human participants. Conversely, if their trading behavior differs, understanding\n",
    "these differences becomes critical for systemic risk management. These questions extend be-\n",
    "yond theory; LLM-based strategies are already being deployed.1 To address these questions,\n",
    "I develop an open-source simulation that tests LLM trading agents in a realistic market envi-\n",
    "ronment with a persistent order book, supporting various order types, stochastic dividends,\n",
    "and heterogeneous information.\n",
    "The framework allows heterogeneous LLMs—defined in natural language, using different\n",
    "system prompts—to act as diverse types of traders, such as value investors, momentum\n",
    "traders, market makers, and contrarians. Agents submit standardized trading decisions in a\n",
    "human-readable format while expressing their reasoning transparently. Figure 1 illustrates\n",
    "this approach, showing how a speculator agent combines explicit valuation reasoning with\n",
    "structured trading parameters, enabling systematic analysis and insight into the agent’s\n",
    "decision-making process.\n",
    "The analysis reveals three key findings about LLMs’ capabilities as trading agents. First,\n",
    "LLMs can effectively execute trading strategies. They consistently understand market me-\n",
    "chanics, process market information, form price expectations, and execute trades according\n",
    "to specific instructions. Their trading behavior is highly sensitive to the prompts they\n",
    "receive—they faithfully follow directions regardless of profit implications. This observance\"\"\",\n",
    "]\n",
    "\n",
    "    ),\n",
    "    LLMTestCase(\n",
    "        input=\"How do the authors define the price‑to‑fundamental ratio and why is it central to their systematic variation experiments?\",\n",
    "        actual_output=\"The authors define the price-to-fundamental ratio (ρ) as simply the market price (P) divided by the fundamental value (V) of the asset, expressed as ρ = P/V. This ratio is central to their systematic variation experiments because it allows them to test how LLM (Large Language Model) trading agents respond to different levels of mispricing. By varying ρ, they can create scenarios where the market price is above (ρ > 1), below (ρ < 1), or equal to (ρ = 1) the fundamental value. This helps researchers observe how the LLM agents' trading decisions change depending on whether the asset is overvalued, undervalued, or fairly priced, and assess how efficiently these agents drive market prices towards the fundamental value.\",\n",
    "        expected_output=\"\"\"ρ = P ⁄ V. By sweeping ρ from 0.1–3.5 and holding other factors fixed, the authors trace decision boundaries of each agent type.\"\"\",\n",
    "        context=[\n",
    "            \"\"\"Our example implementation varies the price‑to‑fundamental ratio (ρ = P/V) across a range from 0.1 to 3.5 while maintaining all other market parameters constant…\"\"\"\n",
    "        ],\n",
    "        retrieval_context=[\n",
    "    \"\"\"the decision-making engine.\n",
    "The data collection system captures comprehensive market activity across multiple di-\n",
    "mensions. At the market level, it tracks the evolution of prices, fundamental values, and\n",
    "realized dividends, providing insights into overall market dynamics. Individual agent data\n",
    "includes detailed wealth trajectories and portfolio compositions, enabling analysis of strategy\n",
    "effectiveness and wealth distribution patterns. The system maintains complete transaction\n",
    "records with prices, quantities, and counterparty information, facilitating the study of trad-\n",
    "ing patterns and market microstructure. Additionally, it captures agent decision rationales\n",
    "and strategy adherence metrics, allowing researchers to evaluate the consistency and effec-\n",
    "tiveness of different trading approaches.\n",
    "All experimental parameters, market outcomes, and agent interactions are systemati-\n",
    "cally logged and stored in structured formats (CSV and JSON) for subsequent analysis. The\n",
    "framework generates standardized visualizations of price evolution, wealth distribution, and\n",
    "dividend payments to facilitate comparative analysis across different experimental configu-\n",
    "rations.\n",
    "3.1 Fundamental Value Calibration\n",
    "The framework implements a consistent approach to fundamental value calculation that pro-\n",
    "vides a reliable benchmark for price discovery. For infinite horizon markets, the fundamental\n",
    "value follows the standard dividend discount model:\n",
    "Vt = E[D]\n",
    "r = Expected Dividend\n",
    "Interest Rate (1)\n",
    "For the default parameters where the expected dividend is $1.40 and the interest rate is\n",
    "5%, this yields a fundamental value of $28.00.\n",
    "In finite horizon markets with T periods remaining, the fundamental value incorporates\n",
    "30\n",
    "both future dividends and terminal redemption value K:\n",
    "FVt =\n",
    "TX\n",
    "τ=t\n",
    "E[D]\n",
    "(1 + r)τ−t+1 + K\n",
    "(1 + r)T−t+1 (2)\n",
    "To ensure consistency between finite and infinite horizon markets, the redemption value\n",
    "K is set equal to E[D]\n",
    "r , which makes the fundamental value constant atE[D]\n",
    "r across all periods,\n",
    "regardless of the time horizon. This calibration approach ensures a clean experimental design\n",
    "by providing a stable benchmark for price discovery.\n",
    "3.2 Experimental Scenarios\n",
    "To evaluate market dynamics with LLM-based agents, we implemented several experimental\n",
    "scenarios that systematically explore different initial conditions and agent compositions.\n",
    "Each scenario maintains the fundamental value of $28.00 while varying starting prices, time\n",
    "horizons, and agent populations. These scenarios address our core research questions (Section\n",
    "1) by testing LLM capabilities under varying market conditions, focusing on price discovery\n",
    "dynamics, the impact of heterogeneous beliefs, and market stability under stress; GPT-4o\n",
    "was used consistently as the decision-making engine for all LLM agents across these scenarios.\n",
    "We present the setup for several key scenarios below, followed by a discussion of the observed\n",
    "results for the 2 experiments involving an infinite horizon market with a starting price either\n",
    "above or below the fundamental value.\n",
    "3.2.1 Price Discovery (Above Fundamental)\n",
    "This scenario tests downward price convergence by starting with an initial price 25% above\n",
    "the fundamental value ( $35.00). It runs for 20 trading rounds and features a diverse\n",
    "agent population, including two Default investors (baseline agents), two Optimistic traders\n",
    "(who believe prices should be higher), two Market makers (providing liquidity by posting\n",
    "bids/asks), and two Speculator agents (opportunistic traders seeking inefficiencies). Market\n",
    "31\n",
    "makers are given enhanced liquidity with 20x the baseline cash and shares to ensure suffi-\n",
    "cient liquidity provision and facilitate price discovery. The scenario tests whether prices can\n",
    "correct downward through trading activity when starting from an overvalued state.\n",
    "3.2.2 Price Discovery (Below Fundamental)\n",
    "This complementary scenario tests upward price convergence by starting with an initial price\"\"\",\n",
    "    \"\"\"value, the system:\n",
    "1. Sets market price P = ρV where ρ is the target ratio\n",
    "2. Generates a consistent order book structure around this price\n",
    "3. Executes multiple decision trials with the same agent type\n",
    "4. Records decision outcomes (buy/sell/hold), order types, quantities, and reasoning\n",
    "This process maps how LLM agents respond to different price environments, as illustrated\n",
    "in Figures 2, 3, 4, and 5. The analysis reveals clear patterns in decision boundaries, with\n",
    "distinct transitions between buying, selling, and holding regions that vary by agent type. For\n",
    "example, value investors show strong buying tendencies when prices are below fundamental\n",
    "value (ρ <1) and selling preferences when prices exceed fundamentals ( ρ >1). In contrast,\n",
    "momentum traders show less sensitivity to the fundamental ratio and more responsiveness\n",
    "to recent price trends.\n",
    "The systematic variation approach also reveals patterns in order sizing and limit price\n",
    "selection, with agents typically placing larger orders when prices deviate significantly from\n",
    "their valuation models (Figure 4). This methodology provides unprecedented transparency\n",
    "into LLM decision processes and enables quantitative comparison of different agent types\n",
    "and LLM architectures.\n",
    "22\n",
    "Figure 2: Price Analysis under Systematic Variation. Shows how agent valuation estimates\n",
    "and price targets respond to varying Price/Fundamental ratios.\n",
    "The decision analysis can be customized for different experimental designs. For example,\n",
    "researchers can use the framework to study the impact of various market conditions on agent\n",
    "behavior by varying other market parameters or the effect of different agent types on market\n",
    "dynamics by changing the agent population.\n",
    "2.3 Data Collection and Analysis\n",
    "Evaluating LLM trading agents requires robust methodologies for capturing, processing,\n",
    "and analyzing their behavior in market environments. The framework implements a com-\n",
    "prehensive analytics module that tracks all market activity, agent decisions, and performance\n",
    "metrics throughout experimental runs. This multi-layered approach not only records what\n",
    "happens in each simulation but also provides insights into why agents make specific deci-\n",
    "sions, enabling researchers to validate agent behavior against their defined strategies and\n",
    "assess overall market dynamics. The following sections detail the key components of this\n",
    "analytics infrastructure.\n",
    "23\n",
    "Figure 3: Trading Decision Distribution under Systematic Variation. Illustrates the proba-\n",
    "bility of Buy, Sell, or Hold decisions across different agent types as the Price/Fundamental\n",
    "ratio changes.\n",
    "24\n",
    "Figure 4: Order Size Distribution under Systematic Variation. Shows the average quan-\n",
    "tity traded (as a percentage of initial shares) for Buy and Sell orders across different\n",
    "Price/Fundamental ratios.\n",
    "2.3.1 Data Collection Architecture\n",
    "The framework implements a comprehensive data collection system that captures multiple\n",
    "dimensions of market behavior and agent decision-making. This structured approach ensures\n",
    "reproducibility and enables detailed analysis of market dynamics.\n",
    "2.3.2 Core Data Streams\n",
    "The system captures five primary data streams that work together to provide a complete\n",
    "picture of market activity. Market Data forms the foundation, tracking essential metrics\n",
    "including price evolution, fundamental values, trading volumes, order book depth, market\n",
    "liquidity, best bid/ask prices, spreads, and price-fundamental ratios. This is complemented\n",
    "by detailed Trade Data, which records individual transaction details such as prices, quan-\n",
    "tities, buyer and seller identifiers, timestamps, round information, and specific execution\n",
    "details.\n",
    "Agent Data provides insights into participant behavior by monitoring cash and share\n",
    "25\n",
    "Figure 5: Order Type Analysis under Systematic Variation. Displays the proportion of\n",
    "Market vs. Limit orders used by different agent types across varying Price/Fundamental\n",
    "ratios.\n",
    "26\"\"\",\n",
    "    \"\"\"there that the revised index accurately captures the jumps and diffusions in the markets previously unaccounted\n",
    "for and therefore crucial in estimating the uncertainty as a macro-volatility in financial markets. There are two\n",
    "key facts to note about the revised VIX index. First, we see a jump in March 2020 which captures the large crash\n",
    "in the S&P500 daily returns post the heightened uncertainty about economic conditions following the impact\n",
    "of the news of a global pandemic. Considering the impact generated by persistent volatility, the NDIG model\n",
    "preserves the volatility measure implied by the intrinsic time subordinator.\n",
    "Figure 10: Normalized Volatility to Match NDIG Estimates: Revised VIX {Volatility of VIX\n",
    "(VVIX) }\n",
    "Second, following the path of persistent volatility post-pandemic, we see another jump in the volatility following\n",
    "the events that characterized the plummets in early 2022 following consistent hikes in the federal funds rate, the\n",
    "fear of the start and continued geopolitical conflict between Russia and the Ukraine, along with the tech stock\n",
    "selloff due to an unexpected fall in tech firms’ earnings indicated by the reports of their earnings.\n",
    "6 Risk–Reward Ratios over Fractional Time Series\n",
    "R/R ratios offer a balanced approach to exploring the potential gains and losses in the financial market due to\n",
    "violent market movements. These measures help address the asymmetry in risk perceptions and the potential\n",
    "for large losses, and are thereby helpful in extracting meaningful signals from the volatility noise that are not\n",
    "accounted for when using measures of dispersion over symmetric distributions. Using an axiomatic approach,\n",
    "every performance measure or R/R ratio should satisfy the properties of, first monotonicity, which means that\n",
    "more is better than less. Second, quasi-concavity leads to preferences that value averages higher than extremes,\n",
    "encouraging diversification. Third, scale invariance and last, being distribution-based.\n",
    "LetXbe a convex set of random variables on a probability space (Ω ,F,P). Each element X∈ X denotes a\n",
    "financial return over time length T∈R+. Given these conditions, consider an R/R ratio of the following form:\n",
    "10\n",
    "α(X) =θ(X)+\n",
    "ρ(X)+(13)\n",
    "for a reward measure θ:X→R∪ {±∞} and a risk measure ρ:X→R∪ {±∞} . In addition, x+denotes\n",
    "max{x,0}andx−denotes −min{x,0}. The ratio α(X) should satisfy the following two conditions:\n",
    "1.(M) Monotonicity: α(X)≥α(Y)∀X, Y∈ Xsuch that X≥Y\n",
    "2.(Q)Quasi-Concavity: α(λX+ (1−λ)Y)> min (α(X), α(Y))∀X, Y∈ Xand λ ∈Rsuch that 0 ≤λ≤1.\n",
    "Cheridito and Kromer (2013) explain that monotonicity is a minimal requirement that every performance\n",
    "indicator should satisfy. It simply implies that more of a financial return is better than less and preferred by\n",
    "all agents. Moreover, quasi-concavity has can explain the aversion to uncertainty. If αis monotonic and quasi-\n",
    "concave, averages are preferred to extremes and diversification is encouraged. In cases when αdoes not satisfy the\n",
    "required properties, there are X, Y∈ Xand a scalar λ∈(0,1) such that α(λX+ (1−λ)Y)< min (α(X), α(Y)).\n",
    "In such a case, research on Value-at-Risk (VaR) Artzner et al. (1999) shows that there will be a concentration of\n",
    "risk.\n",
    "Moreover, there is a large family of R/R ratios that also satisfy the following conditional properties:\n",
    "1.(S) Scale-Invariance: α(λX) =α(X)∀X∈ Xand λ ∈R+\\{0}such that\n",
    "λX∈ X\n",
    "2.(D) Distribution-based: α(X) only depends on the distribution of Xunder P.\n",
    "Given that performance ratios should satisfy the first two mandatory properties and the two conditional\n",
    "properties, we can prove the functional properties of αto make the ratios micro-founded so as to explain the\n",
    "meaning of the signals contained in α(X).\n",
    "Proposition 1: Letαfollow the form as described in Eq. (7):\n",
    "1.Ifθ(X)≥θ(Y)andρ(X)< ρ(Y)∀X, Y∈ Xsuch that X≥Y,then αsatisfies the monotonicity property\n",
    "(M).\n",
    "2.Ifθis concave and ρconvex, then αsatisfies the quasi-concavity property (Q).\"\"\",\n",
    "    \"\"\"bids/asks), and two Speculator agents (opportunistic traders seeking inefficiencies). Market\n",
    "31\n",
    "makers are given enhanced liquidity with 20x the baseline cash and shares to ensure suffi-\n",
    "cient liquidity provision and facilitate price discovery. The scenario tests whether prices can\n",
    "correct downward through trading activity when starting from an overvalued state.\n",
    "3.2.2 Price Discovery (Below Fundamental)\n",
    "This complementary scenario tests upward price convergence by starting with an initial price\n",
    "25% below the fundamental value ( $21.00). It employs the identical agent composition and\n",
    "parameters as the above-fundamental scenario, allowing for direct comparison of market\n",
    "behavior under opposite initial mispricing conditions. This design enables researchers to\n",
    "assess potential asymmetries in price discovery processes.\n",
    "3.2.3 Infinite Horizon Price Discovery\n",
    "We extend both price discovery scenarios to infinite horizon settings, where shares are not\n",
    "redeemed at a terminal date. The initial prices are set at double ($56.00) and half ($14.00) the\n",
    "fundamental value for the above and below fundamental scenarios respectively, creating more\n",
    "extreme mispricing conditions. These scenarios run for 15 trading rounds and test whether\n",
    "agents correctly value assets based on expected dividend streams rather than redemption\n",
    "values. Each infinite horizon scenario involves two Default investors, two Optimistic traders,\n",
    "two Market makers, and two Speculator agents.\n",
    "The results from these infinite horizon scenarios reveal interesting asymmetries in price\n",
    "discovery, as illustrated in Figure 6 and Figure 7. When the market starts significantly above\n",
    "the fundamental value (left panels), the price fails to converge downwards towards the$28.00\n",
    "benchmark within the 15 rounds, remaining substantially elevated. Agent valuations mirror\n",
    "this persistence, with many agents maintaining estimates well above the fundamental value.\n",
    "However, when the market begins significantly below the fundamental value (right panels),\n",
    "the price exhibits a clear convergence towards the fundamental benchmark. Agent valuations\n",
    "in this scenario also tend to adjust upwards, aligning more closely with the calculated fun-\n",
    "32\n",
    "damental value over time. This suggests that under these conditions, LLM agents are more\n",
    "effective at correcting undervaluation than overvaluation within the simulated timeframe.\n",
    "Figure 6: Price Evolution: Infinite Horizon Scenarios. Left: Initial price $56.00 (Above\n",
    "Fundamental). Right: Initial price $14.00 (Below Fundamental). The dashed line indicates\n",
    "the fundamental value ($28.00).\n",
    "Figure 7: Agent Valuations: Infinite Horizon Scenarios. Left: Initial price $56.00 (Above\n",
    "Fundamental). Right: Initial price $14.00 (Below Fundamental). Shows individual agent\n",
    "estimates of fundamental value over time.\n",
    "3.2.4 Divergent Beliefs\n",
    "This scenario explores the impact of heterogeneous beliefs about fundamental value by com-\n",
    "bining agents with systematically different valuation models. The agent composition is\n",
    "designed to create heterogeneity: two Optimistic traders (believing the fundamental value is\n",
    "significantly higher), two Pessimistic traders (believing it is significantly lower), two neutral\n",
    "Market makers, two Momentum traders (following price trends rather than fundamentals),\n",
    "and two Default investors (baseline agents). We test both above-fundamental (initial price\n",
    "$56.00, 2x fundamental) and below-fundamental (initial price$14.00, 0.5x fundamental) vari-\n",
    "33\n",
    "ants, allowing researchers to study how different belief structures influence price formation\n",
    "and trading patterns under different initial mispricings. In these scenarios, the fundamental\n",
    "price is hidden from agents, forcing them to rely on their own valuation models.\n",
    "3.2.5 Market Stress\n",
    "This scenario tests market resilience under challenging conditions by creating a more volatile\n",
    "environment. The scenario includes two consistently bullish Optimistic traders, two consis-\"\"\",\n",
    "    \"\"\"The Journal of Finance , 59(4):1481–1509.\n",
    "Barndorff-Nielsen, O. and Shephard, N. (2001). Non-gaussian ornstein–uhlenbeck-based models and some\n",
    "of their uses in financial economics. Journal of the Royal Statistical Society: Series B (Statistical\n",
    "Methodology) , 63(2):167–241.\n",
    "Barro, R. J. (2006). Rare disasters and asset markets in the twentieth century. The Quarterly Journal\n",
    "of Economics , 121(3):823–866.\n",
    "Bloom, N. (2009). The impact of uncertainty shocks. Econometrica , 77(3):623–685.\n",
    "Bloom, N. (2014). Fluctuations in uncertainty. Journal of Economic Perspectives , 28(2):153–176.\n",
    "Bloom, N., Bond, S., and Van Reenen, J. (2007). Uncertainty and investment dynamics. The Review of\n",
    "Economic Studies , 74(2):391–415.\n",
    "Carr, P., Geman, H., Madan, D. B., and Yor, M. (2003). Stochastic volatility for l evy processes.\n",
    "Mathematical Finance , 13(3):345–382.\n",
    "Carr, P. P. and Madan, D. (2001). Option valuation using the Fast Fourier Transform. Journal of\n",
    "Computational Finance , 2(4).\n",
    "Cheridito, P. and Kromer, E. (2013). Reward–risk ratios. Journal of Investment Strategies .\n",
    "Clark, P. (1973). A subordinated stochastic process model with fixed variance for speculative prices.\n",
    "Econometrica , 41:135–156.\n",
    "Cont, R. (2000). Empirical properties of asset returns: Stylized facts and statistical issues. Quantitative\n",
    "Finance , 1:223–236.\n",
    "Delbaen, F. and Schachermayer, W. (1994). A general version of the fundamental theorem of asset\n",
    "pricing. Mathematische Annalen , 300(1):463–520.\n",
    "Delbaen, F. and Schachermayer, W. (1999). The fundamental theorem of asset pricing for unbounded\n",
    "stochastic processes. SFB Adaptive Information Systems and Modelling in Economics and Man-\n",
    "agement Science, WU Vienna University of Economics and Business. Report Series SFB ’Adaptive\n",
    "Information Systems and Modelling in Economics and Management Science’ , (24).\n",
    "Duffie, D. (2001). Dynamic Asset Pricing Theory (3rd ed.) . Princeton University Press.\n",
    "Duffie, D., Pan, J., and Singleton, K. (2000). Transform analysis and asset pricing for affine jump-\n",
    "diffusions. Econometrica , 68:1343–1376.\n",
    "Esscher, F. (1932). On the probability function in the collective theory of risk. Scandinavian Actuarial\n",
    "Journal , 15(3):175–195.\n",
    "Hyung, N. and Franses, P. (2002). Modeling seasonality and long memory in time series. Journal of\n",
    "Econometrics , 109(1):241–263.\n",
    "Jurado, K., Ludvigson, S. C., and Ng, S. (2015). Measuring uncertainty. American Economic Review ,\n",
    "105(3):1177–1216.\n",
    "Kelly, B. and Jiang, H. (2014). Tail risk and asset prices. The Review of Financial Studies ,\n",
    "27(10):2841–2871.\n",
    "Kozeniauskas, N., Orlik, A., and Veldkamp, L. (2018). What are uncertainty shocks? Journal of Monetary\n",
    "Economics , 100(2018):1–15.\n",
    "Kozlowski, J., Veldkamp, L., and Venkateswaran, V. (2020). The tail that wags the economy: Beliefs\n",
    "and persistent stagnation. Journal of Political Economy , 128(8):2839–3284.\n",
    "Mandelbolt, B. and Taylor, H. (1967). On the distribution of stock price differences. Journal of Operations\n",
    "Research , 15:1057–1062.\n",
    "Mehra, R. and Prescott, E. C. (2003). Chapter 14: The equity premium in retrospect , volume 1B, pages\n",
    "889–938.\n",
    "Meyer, P. and Dellacherie, C. (1978). Probabilities and Potential B: Theory of Martingales . North\n",
    "Holland.\n",
    "Orlik, A. and Veldkamp, L. (2014). Understanding uncertainty shocks and the role of black swans.\n",
    "Technical Report 20445, National Bureau of Economic Research.\n",
    "Rietz, T. A. (1988). The equity risk premium: A solution. Journal of Monetary Economics , 22:117–131.\n",
    "Routledge, B. R. and Zin, S. E. (2010). Generalized disappointment aversion and asset prices. The\n",
    "Journal of Finance , 65(4):1303–1332.\n",
    "16\n",
    "Shirvani, A., Mittnik, S., Lindquist, W. B., and Rachev, S. T. (2024). Bitcoin volatility and intrinsic\n",
    "time using double-subordinated l´ evy processes. Risks (MDPI) , 12(5):1–21.\n",
    "Shirvani, A., Rachev, S., and Fabozzi, F. (2021a). Multiple subordinated modeling of asset returns:\n",
    "Implications for option pricing. Econometric Reviews , 40(3):290–319.\"\"\",\n",
    "    \"\"\"Given that performance ratios should satisfy the first two mandatory properties and the two conditional\n",
    "properties, we can prove the functional properties of αto make the ratios micro-founded so as to explain the\n",
    "meaning of the signals contained in α(X).\n",
    "Proposition 1: Letαfollow the form as described in Eq. (7):\n",
    "1.Ifθ(X)≥θ(Y)andρ(X)< ρ(Y)∀X, Y∈ Xsuch that X≥Y,then αsatisfies the monotonicity property\n",
    "(M).\n",
    "2.Ifθis concave and ρconvex, then αsatisfies the quasi-concavity property (Q).\n",
    "3.ρ(λX) =λρ(X)andθ(λX) =λθ(X)∀X∈ X and λ ∈R+\\{0}such that λX ∈ X,then αsatisfies the\n",
    "scale-invariance property (S).\n",
    "4. If θandρsatisfy the distribution-based property (D), then so does α.\n",
    "Proof is straightforward and mentioned in Cheridito and Kromer (2013).\n",
    "One of the key issues when measuring the R/R ratios over the revised VIX is that while computing performance\n",
    "ratios over a convex set of random variables generates independent and identically distributed (i.i.d.) variables, the\n",
    "financial return itself is not i.i.d., so this hinders the process of identifying uncertainty shocks as i.i.d. To mitigate\n",
    "this, we adopt the method of fitting a fractional time series model to take into account the long memory of the\n",
    "mean and volatility exhibited in the time series data. Baillie et al. (1996) introduce the FIGARCH (Fractionally\n",
    "Integrated GARCH) model, demonstrating that traditional GARCH models are inadequate for capturing long\n",
    "memory in volatility. This finding highlights the need for fractional integration in volatility modeling to better\n",
    "reflect persistent effects in financial time series. This justifies the need for fractional integration in volatility\n",
    "modeling. Similarly, Hyung and Franses (2002) shows that long memory in both the mean and variance processes is\n",
    "better modeled and captured using Autoregressive Fractionally Integrated Moving Average-Fractionally Integrated\n",
    "GARCH (ARFIMA-FIGARCH) models. Hence, the goal of the present paper is to emphasize the use of fractional\n",
    "time series models to capture the long memory that is explained by the multiple subordinated NIG L´ evy process\n",
    "Figure 8 gives an illustration of the difference between the innovations of the ARFIMA(1, d(m), 1)-FIGARCH(1,\n",
    "d(v), 1) and the Autoregressive Moving Average-GARCH of lag 1 and order 1 (ARMA(1,1)-GARCH(1,1)) fitted\n",
    "over the values of the newly constructed normalized VVIX. The fractional time series model is better at capturing\n",
    "the persistent effects created by the shocks implied by the newly constructed volatility index.\n",
    "11\n",
    "Figure 11: Residuals of the fitted time series models\n",
    "The long memory in the mean, captured using the ARFIMA model, refers to the persistence of past values\n",
    "of a time series influencing future values over long periods. In financial time series, long memory in the mean\n",
    "implies that past values of the series have a significant, slowly decaying influence on future values. Therefore,\n",
    "innovations to the time series do not fade away quickly, but explain the influence on the mean for a long time.\n",
    "ARFIMA models allow a slower, hyperbolic decay, characterizing a long memory. In addition, if a time series\n",
    "has long memory in its volatility, meaning the persistence of past volatility (variance) over time, large shifts in\n",
    "volatility appear to cluster and stay accentuated for long periods before decaying to normal levels. Long memory\n",
    "of volatility is present in financial markets (financial time series), where periods of high volatility (e.g., during a\n",
    "financial crisis) tend to last for extended periods and generate persistent shocks.\n",
    "Therefore, to capture the long memory of the mean and volatility exhibited by the time series of the normalized\n",
    "VVIX constructed in this paper, we apply the ARFIMA(1, d(m), 1)-FIGARCH(1, d(v), 1), where d(m) is the\n",
    "term describing the long memory of the mean and d(v) is the term describing the long memory of the volatility.\n",
    "The time series follows the process:\n",
    "ARFIMA (1, d(m),1)⇝ϕ(L)(1−L)d(m)zt=θ(L)εt (14)\"\"\",\n",
    "    \"\"\"market efficiency and price discovery processes throughout the simulation.\n",
    "Agent performance metrics include absolute position tracking (shares, cash, and total\n",
    "wealth), wealth composition analysis, position change metrics, and return calculations. The\n",
    "system computes both absolute and percentage returns on various portfolio components\n",
    "and compares performance across agent types to identify relative advantages of different\n",
    "strategies. Trading flow analysis visualizes the volume of shares moving between different\n",
    "agent types and cumulative net trading flows, revealing which agents act as net buyers or\n",
    "sellers in different market conditions.\n",
    "Decision pattern analysis employs heatmaps to visualize the consistency of agent decision-\n",
    "making over time, allowing researchers to identify shifts in strategic behavior. This is com-\n",
    "plemented by decision quantities visualization that plots order sizes to highlight variations\n",
    "in trade aggressiveness across agent types. When agent reasoning data is available, the\n",
    "system generates wordclouds to extract key terms from agent explanations, providing qual-\n",
    "itative insights into decision drivers for different agent strategies. Additional visualizations\n",
    "track price target accuracy and compare agent-specific valuations to realized market prices,\n",
    "28\n",
    "offering insights into the forecasting abilities of different agents.\n",
    "A key advantage of simulation-based analysis is complete observability of all market\n",
    "processes and agent states. Unlike real-world markets where data availability is often limited,\n",
    "the framework captures every interaction, decision, and state change with perfect fidelity.\n",
    "This comprehensive data collection allows researchers to compute additional metrics beyond\n",
    "standard market measures, enabling novel analyses such as counterfactual testing (e.g., how\n",
    "would markets evolve with different agent compositions), causal inference of specific agent\n",
    "behaviors on market outcomes, and the development of custom efficiency or stability metrics\n",
    "tailored to particular research questions. The system’s modular design facilitates rapid\n",
    "implementation of new metrics and visualizations as research questions evolve.\n",
    "3 Experimental Design and Results\n",
    "Our experimental framework implements a dividend-paying asset market with heterogeneous\n",
    "agents. The baseline simulation runs for 15 to 20 rounds with 8 participating agents, although\n",
    "these parameters are fully configurable. Each agent begins with an initial endowment of\n",
    "1,000,000 monetary units and 10,000 shares of the asset. The fundamental value of the asset\n",
    "is set at $28.00, with a final redemption value matching this fundamental price in finite\n",
    "horizon scenarios. Transaction costs are set to zero to isolate the effects of agent behavior\n",
    "and market structure.\n",
    "The dividend structure follows a stochastic process with a base payment of $1.40 and a\n",
    "variation of ±$1.00, paid with 50% probability each round. This design creates uncertainty\n",
    "in the asset’s income stream while maintaining a known expected value. Cash holdings earn\n",
    "a risk-free interest rate of 5% per round, providing an opportunity cost for asset investment.\n",
    "Agent composition is controlled through a flexible distribution system that allows for\n",
    "various experimental configurations. In our baseline setup, we employ a mixed population\n",
    "of value investors, momentum traders, and market makers. Each agent type implements\n",
    "29\n",
    "distinct trading strategies through Large Language Model (LLM) prompts, with GPT-4o as\n",
    "the decision-making engine.\n",
    "The data collection system captures comprehensive market activity across multiple di-\n",
    "mensions. At the market level, it tracks the evolution of prices, fundamental values, and\n",
    "realized dividends, providing insights into overall market dynamics. Individual agent data\n",
    "includes detailed wealth trajectories and portfolio compositions, enabling analysis of strategy\n",
    "effectiveness and wealth distribution patterns. The system maintains complete transaction\"\"\",\n",
    "    \"\"\"financial crisis) tend to last for extended periods and generate persistent shocks.\n",
    "Therefore, to capture the long memory of the mean and volatility exhibited by the time series of the normalized\n",
    "VVIX constructed in this paper, we apply the ARFIMA(1, d(m), 1)-FIGARCH(1, d(v), 1), where d(m) is the\n",
    "term describing the long memory of the mean and d(v) is the term describing the long memory of the volatility.\n",
    "The time series follows the process:\n",
    "ARFIMA (1, d(m),1)⇝ϕ(L)(1−L)d(m)zt=θ(L)εt (14)\n",
    "In Eq. (14), Lis the lag operator, d(m) is the fractional differencing parameter, reported to be 0.268, ϕ(L)\n",
    "is the autoregressive polynomial, while θ(L) is the MA polynomial. ztcontains n×1 values of the normalized\n",
    "VVIX, and εtis the n×1 vector of white noise error term.\n",
    "FIGARCH (1, d(v),1)⇝ϕ(L)(1−L)d(v)ε2\n",
    "t=ω+ [1−β(L)]νt (15)\n",
    "In Eq. (15), ϕ(L) is the autoregressive polynomial, and d(v) is the fractional differencing parameter for\n",
    "volatility, reported to be 0.01. ε2\n",
    "tis the square of the white noise error term to capture the conditional variance\n",
    "generating persistent volatility. ωis the constant term and β(L) is the lag polynomial. Lastly, νtis the n×1\n",
    "vector of normal innovations. To allow for a long memory in the fractional time series, we set the condition d >0.\n",
    "In cases where d= 0, the model is a standard ARMA(1,1)-GARCH(1,1) process.\n",
    "Furthermore, it is essential to determine whether there is a predictable signal in the noise, as defined by the\n",
    "performance ratios, in the innovations that can make the markets inefficient given that using this measure of the\n",
    "revised VIX, agents will be able to forecast volatility price. To detect the predictable signal in the noise, we\n",
    "12\n",
    "Figure 12: Signal/Noise ratios detected using performance ratios over Sscenarios\n",
    "simulate S= 10 ,000 scenarios of the normalized VVIX (with NDIG distribution) over the ARFIMA(1, d(m),\n",
    "1)-FIGARCH(1, d(v), 1) process as defined by Eqs. (14) and (15). We compute the Rachev ratio and the Stable\n",
    "Tail Adjusted Return ratio5overSscenarios to extract predictable signals from the volatility noise. Figure (12)\n",
    "shows the performance ratios computed over the simulated scenarios.\n",
    "From the simulated signals using the fractional time series process, it is evident that there is significant\n",
    "randomness in the volatility noise with volatility clustering and generates no predictable power. Given that\n",
    "there is no identifiable pattern in the volatility noise that can enable an agent to forecast volatility price, we\n",
    "can conclude that the revised measure of VIX generates randomness in volatility noise and satisfies the Efficient\n",
    "Market Hypothesis.\n",
    "7 Identification Strategy\n",
    "To identify i.i.d. shocks, using the normal innovations extracted by utilizing Eqs. (14) and (15), we compute R/R\n",
    "ratios over the residuals of the ARFIMA(1, d(m), 1)-FIGARCH(1, d(v), 1) process. For illustrative purposes, we\n",
    "compute two performance ratios6namely, the Rachev ratio and STAR ratio over the normal innovations. The\n",
    "following are the functional forms of the two ratios.\n",
    "1.Rachev Ratio:\n",
    "RR(β, γ)(X) :=AV aR β(−X)\n",
    "AV aR γ(X)(16)\n",
    "where AV aR β, γ(X) := β−1Rβ\n",
    "0[max(−F−1\n",
    "x(u),0)]γdu, where AV aR is defined as the Average Value at\n",
    "Risk and Xis the measure of interest, in this case, normal innovations of the revised VIX. βrefers to the\n",
    "confidence interval of the value on the right tail, whereas γrefers to the confidence interval of the value\n",
    "on the left tail. While the Rachev ratio satisfies the properties (M), (S), and (D), it violates (Q) due to a\n",
    "non-concave numerator.\n",
    "2.Stable Tail Adjusted Return Ratio (STAR Ratio):\n",
    "STARR γ(X) :=E[X]+\n",
    "AV aR γ(X)+(17)\n",
    "where AV aR γ(X) := γ−1Rγ\n",
    "0V aR u(X)duis the Average-Value-at-Risk at the level γ∈(0,1].STARR\n",
    "satisfies all four axioms namely (M), (Q), (S), and (D), therefore, is axiomatically robust.\n",
    "Eqs. (16) and (17) will be used as the benchmark performance ratios for computing the uncertainty shocks\"\"\",\n",
    "]\n",
    "    ),\n",
    "    LLMTestCase(\n",
    "        input=\"HWhat are the roles of system prompts vs user prompts in shaping an LLM trading agent’s behaviour?\",\n",
    "        actual_output=\"\"\"System prompts define the LLM agent's overall trading philosophy and long-term goals. They establish the core characteristics of the agent, such as whether it's a \"value investor\" (an investor who buys assets they believe to be undervalued by the market), a \"momentum trader\" (a trader who seeks to profit from the continued momentum of a security's price), or a \"market maker\" (a trader who provides liquidity by consistently quoting bid and ask prices for a security). This remains constant throughout the trading simulation.\n",
    "\n",
    "User prompts, on the other hand, provide the immediate market context and short-term instructions for the agent. They deliver up-to-date information like current prices, trading volume, and the agent's current holdings. The user prompt also specifies any immediate actions the agent needs to take, like placing a specific order. This changes with each trading round as the market conditions evolve. Therefore, the system prompt sets the agent's overall strategy, while the user prompt gives it the specific information and instructions it needs to operate within the current market situation.\"\"\",\n",
    "        expected_output=\"\"\"System prompt fixes the agent’s identity and objectives across rounds; user prompt feeds current market state & constraints for the immediate decision.\"\"\",\n",
    "        context=[\n",
    "            \"\"\"The system prompt establishes the agent’s fundamental trading characteristics…” / “The user prompt provides the immediate market context necessary for tactical decision‑making.\"\"\"\n",
    "        ],\n",
    "        retrieval_context=[\n",
    "    \"\"\"ceedings of the 62nd Annual Meeting of the Association for Computational Linguistics\n",
    "(Volume 1: Long Papers),edited by Lun-Wei Ku, Andre Martins, and Vivek Srikumar,\n",
    "15523–15536. ACL 2024. Bangkok, Thailand: Association for Computational Linguis-\n",
    "tics, August.\n",
    "39\n",
    "Li, Yuan, Yixuan Zhang, and Lichao Sun. 2023. “MetaAgents: Simulating Interactions of\n",
    "Human Behaviors for LLM-based T Ask-Oriented Coordination via Collaborative Gen-\n",
    "erative Agents.” arXiv.org.\n",
    "Liu, Xiao, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, et al. 2023.\n",
    "“AgentBench: Evaluating LLMs as Agents.”International Conference on Learning Rep-\n",
    "resentations.\n",
    "Lopez-Lira, Alejandro, and Yuehua Tang. 2023. “Can ChatGPT Forecast Stock Price Move-\n",
    "ments? Return Predictability and Large Language Models.” SSRN Electronic Journal\n",
    "(April 6, 2023).\n",
    "Manning, Benjamin S., Kehang Zhu, and John J. Horton. 2024. “Automated Social Science:\n",
    "Language Models as Scientist and Subjects.” (Cambridge, MA) (April 29, 2024).\n",
    "Molnar, Christoph. 2022. Interpretable Machine Learning.\n",
    "Pelster, Matthias, and Joel Val. 2023. “Can Chatgpt Assist in Picking Stocks?”Social Science\n",
    "Research Network.\n",
    "Piatti, Giorgio, Zhijing Jin, Max Kleiman-Weiner, Bernhard Sch¨ olkopf, Mrinmaya Sachan,\n",
    "and Rada Mihalcea. 2024. “Cooperate or Collapse: Emergence of Sustainable Coopera-\n",
    "tion in a Socie Ty of LLM Agents.” arXiv.org.\n",
    "Ping, Chen. 2019. “From Complexity Science to Complexity Economics.” In Alternative\n",
    "Approaches to Economic Theory,19–55. Routledge, June 11, 2019.\n",
    "Wang, Saizhuo, Hang Yuan, Lionel M. Ni, and Jian Guo. 2024. “QuantAgent: Seeking Holy\n",
    "Grail in Trading by Self-Improving Large Lang Uage Model.” arXiv.org.\n",
    "Weitzel, Utz, Christoph Huber, J¨ urgen Huber, Michael Kirchler, Florian Lindner, and Julia\n",
    "Rose. 2020. “Bubbles and Financial Professionals.” The Review of Financial Studies33,\n",
    "no. 6 (June 1, 2020): 2659–2696.\n",
    "40\n",
    "Wolfram, Elsner. 2017. “Complexity Economics as Heterodoxy: Theory and Policy.”Journal\n",
    "of Economic Issues51, no. 4 (October 2, 2017): 939–978.\n",
    "Woodhouse, Drew, and Alex Charlesworth. 2023. “Can ChatGPT Predict Future Interest\n",
    "Rate Decisions?” Social Science Research Network.\n",
    "Xie, Chengxing, Canyu Chen, Feiran Jia, Ziyu Ye, Shiyang Lai, Kai Shu, Jindong Gu, et al.\n",
    "2024. “Can Large Language Model Agents Simulate Human Trust Behavior?”arXiv.org.\n",
    "Yang, Stephen. 2023. “Predictive Patentomics: Forecasting Innovation Success and Valuation\n",
    "w Ith ChatGPT.” Social Science Research Network.\n",
    "Yu, Yangyang, Haohang Li, Zhi Chen, Yuechen Jiang, Yang Li, Denghui Zhang, Rong\n",
    "Liu, Jordan W. Suchow, and Khaldoun Khashanah. 2024. “FinMem: A Performance-\n",
    "Enhanced LLM Trading Agent with Layered Memory a Nd Character Design.”Proceed-\n",
    "ings of the AAAI Symposium Series3, no. 1 (May 20, 2024): 595–597.\n",
    "Yu, Yangyang, Zhiyuan Yao, Haohang Li, Zhiyang Deng, Yupeng Cao, Zhi Chen, Jordan W.\n",
    "Suchow, et al. 2024. “FinCon: A Synthesized LLM Multi-Agent System with Conceptual\n",
    "Verbal Reinforcement for Enhanced Financial Decision Making.” Pre-published, Novem-\n",
    "ber 7, 2024. Accessed January 8, 2025. https://doi.org/10.48550/arXiv.2407.06567.\n",
    "arXiv: 2407.06567 [cs]. http://arxiv.org/abs/2407.06567.\n",
    "Zhang, Chong, Xinyi Liu, Zhongmou Zhang, Mingyu Jin, Lingyao Li, Zhenting Wang,\n",
    "Wenyue Hua, et al. 2024. “When AI Meets Finance (StockAgent): Large Language\n",
    "Model-based Stock Trading in Simulated Real-world Environments.” Pre-published,\n",
    "September 21, 2024. Accessed January 26, 2025. https://doi.org /10.48550/arXiv .\n",
    "2407.18957. arXiv: 2407.18957 [q-fin]. http://arxiv.org/abs/2407.18957.\n",
    "41\n",
    "A Technical Implementation Details\n",
    "A.1 Agent Type Specifications\n",
    "This section details the base system prompts for each agent type in our simulation. These\n",
    "prompts define the core behavioral characteristics and trading strategies for each agent. Each\n",
    "prompt consists of:\n",
    "• A role definition that establishes the agent’s trading philosophy\n",
    "• A structured trading strategy that guides decision-making\"\"\",\n",
    "    \"\"\"gies, allowing researchers to experiment with diverse behavioral models and decision-making\n",
    "approaches.\n",
    "This extensible design creates numerous research opportunities for market microstructure\n",
    "studies. Researchers can systematically investigate how different market structures influence\n",
    "price formation and efficiency, evaluate the impact of various trading rules on market qual-\n",
    "ity, and analyze the complex interactions between different agent types and strategies. The\n",
    "framework’s comprehensive logging and validation systems enable detailed examination of\n",
    "market behavior under varying conditions, from everyday trading environments to stress sce-\n",
    "narios. Through this modular approach to system design, the framework supports targeted\n",
    "investigations of specific market mechanisms and broader studies of market dynamics and\n",
    "stability.\n",
    "2.2 Agent Design\n",
    "Our framework implements a systematic approach to designing LLM-based trading agents\n",
    "and recording their decisions. The architecture consists of three main components: a prompt\n",
    "engineering framework to define the agent’s trading objectives, the heterogeneous market\n",
    "environment information that can be customized for different experimental designs, and a\n",
    "structured output format to record the agent’s decisions. Moreover, the framework supports\n",
    "12\n",
    "deterministic rule-based agents that can serve as benchmarks.\n",
    "2.2.1 Prompt Engineering Framework\n",
    "LLM agents are defined by their instructions in natural language. The strategy is given in the\n",
    "system prompt so that agents maximize adherence to their instructions (Levin et al. (2025)).\n",
    "In contrast, the user prompt provides the immediate market context necessary for tactical\n",
    "decision-making and the instructions to place and modify orders.\n",
    "2.2.2 System Prompt\n",
    "The system prompt establishes the agent’s fundamental trading characteristics, defining its\n",
    "trading philosophy, objectives, and behavioral constraints. This layer encodes the agent’s\n",
    "decision-making priorities and risk preferences. Maintaining these parameters in the system\n",
    "prompt ensures consistent agent behavior across multiple trading rounds while allowing for\n",
    "strategic adaptation to changing market conditions. The architecture makes it trivial to\n",
    "design new agents by simply changing the system prompt.\n",
    "For example, a Value Investor’s system prompt emphasizes fundamental analysis:\n",
    "You are a value investor who focuses on fundamental analysis.\n",
    "You believe in mean reversion and try to buy undervalued\n",
    "assets and sell overvalued ones.\n",
    "While a Market Maker’s system prompt focuses on liquidity provision:\n",
    "You are a professional market maker who provides liquidity\n",
    "to the market. Your profit comes from capturing the spread\n",
    "between bid and ask prices, not from directional price movement.\n",
    "Trading Guidelines:\n",
    "- Place LIMIT buy orders slightly below the current market price\n",
    "- Place LIMIT sell orders slightly above the current market price\n",
    "13\n",
    "- Your spread should be proportional to volatility\n",
    "These system prompts can create fundamentally different trading behaviors using the\n",
    "same underlying LLM and identical market information.\n",
    "2.2.3 Agent Types\n",
    "The framework contains diverse ready-to-use agent types that can be categorized into two\n",
    "main groups: LLM-based agents with natural language prompts and deterministic rule-based\n",
    "agents with algorithmic behaviors.\n",
    "The software includes a diverse set of LLM-based agents:\n",
    "• Value Investors: Focus on fundamental analysis and mean reversion\n",
    "• Momentum Traders: Follow established price trends and volume patterns\n",
    "• Market Makers: Provide liquidity through symmetric bid-ask spreads\n",
    "• Contrarian Traders: Trade against market extremes and overreactions\n",
    "• Speculators: Seek to profit from market inefficiencies\n",
    "• Sentiment-Based Agents: Include optimistic and pessimistic variants with biased\n",
    "expectations\n",
    "• Retail Traders: Simulate typical individual investor behavior\n",
    "The software also includes a set of deterministic rule-based agents that serve as bench-\"\"\",\n",
    "    \"\"\"decision-making process.\n",
    "The analysis reveals three key findings about LLMs’ capabilities as trading agents. First,\n",
    "LLMs can effectively execute trading strategies. They consistently understand market me-\n",
    "chanics, process market information, form price expectations, and execute trades according\n",
    "to specific instructions. Their trading behavior is highly sensitive to the prompts they\n",
    "receive—they faithfully follow directions regardless of profit implications. This observance\n",
    "1. For example, Autopilot has a ChatGPT-based portfolio https://x.com/thegptinvestor.\n",
    "2\n",
    "{\"valuation_reasoning\":\n",
    "\"The fundamental value is based on the expected dividend,\n",
    "and the interest rate.\n",
    "The expected dividend is $1.40, and the interest rate is 5%.\n",
    "Using a perpetuity formula, the value is $1.40 / 0.05 = $28.\",\n",
    "\"valuation\":28.0,\n",
    "\"price_target_reasoning\":\"The current price is $29.00, which is\n",
    "slightly above the fundamental value of $28.00. I expect the price\n",
    "to remain around $29.00 in the next round due to market stability.\",\n",
    "\"price_target\":29.0,\n",
    "\"orders\":[{\"decision\":\"Sell\",\"quantity\":1000,\"order_type\":\"limit\",\n",
    "\"price_limit\":29.50}],\n",
    "\"replace_decision\":\"Add\",\n",
    "\"reasoning\":\"The current price is slightly above the fundamental value.\n",
    "I will place a limit sell order at $29.50 to capitalize on potential price\n",
    "increases.\"}\n",
    "Figure 1: Example of a structured trading decision from a Speculator agent defined by its\n",
    "system prompt: “You are a speculator who tries to profit from market inefficiencies.”. The\n",
    "LLM provides explicit reasoning for its valuation, price target, and trading decision in a\n",
    "machine-readable JSON format that can be directly processed by the trading system.\n",
    "highlights a fundamental difference from human traders: LLMs do not inherently optimize\n",
    "for profit maximization but rather for following instructions accurately.\n",
    "Second, LLMs react meaningfully to market dynamics. They consider current and his-\n",
    "torical prices, dividends, and other market information when making decisions. However,\n",
    "they maintain their strategic direction even when market conditions change, following their\n",
    "instructions even if doing so results in financial losses. This combination of responsiveness\n",
    "to market conditions while maintaining strategic consistency creates a unique trading profile\n",
    "distinct from rule-based algorithms and human traders.\n",
    "Third, market dynamics with LLM agents can resemble actual markets and mirror classic\n",
    "results from the theoretical finance literature. When these agents interact, they produce\n",
    "realistic price discovery and liquidity provision with emergent behaviors, including price\n",
    "convergence toward fundamental values. Depending on the distribution of agent types,\n",
    "the system can generate various market phenomena, such as bubbles or underreactions to\n",
    "information. This complex behavior suggests potential applications for studying market\n",
    "3\n",
    "dynamics using LLM agents instead of experiments with human participants.\n",
    "Hence, these findings raise important questions about algorithmic consistency in LLM-\n",
    "based systems. Since trading agents are implemented through prompts, their behavior in-\n",
    "herits characteristics of the underlying language models. The standardization of LLM ar-\n",
    "chitectures across implementations could create unexpected behavioral patterns—if many\n",
    "agents are based on similar foundation models, they might exhibit correlated responses to\n",
    "specific market conditions, potentially amplifying market instabilities.\n",
    "To enable this analysis and accelerate development in this emerging field, we provide\n",
    "an open-source framework with three key components: (1) a structured protocol for im-\n",
    "plementing and validating LLM trading agents, supporting both LLM-based and traditional\n",
    "rule-based agents; (2) a controlled market environment with realistic microstructure for test-\n",
    "ing agent interactions; and (3) a comprehensive data collection system for analyzing trading\n",
    "behavior. This framework serves multiple stakeholders in preparation for the evolution of\"\"\",\n",
    "    \"\"\"• Market Makers: Provide liquidity through symmetric bid-ask spreads\n",
    "• Contrarian Traders: Trade against market extremes and overreactions\n",
    "• Speculators: Seek to profit from market inefficiencies\n",
    "• Sentiment-Based Agents: Include optimistic and pessimistic variants with biased\n",
    "expectations\n",
    "• Retail Traders: Simulate typical individual investor behavior\n",
    "The software also includes a set of deterministic rule-based agents that serve as bench-\n",
    "marks and control conditions:\n",
    "• Directional Traders: Always-buy, always-sell, and always-hold agents\n",
    "• Technical Agents: Gap traders, mean reversion traders, and momentum traders\n",
    "• Algorithmic Market Makers: Implement fixed spread-posting strategies\n",
    "14\n",
    "Each agent type is defined by its system prompt (for LLM agents) or algorithmic rules (for\n",
    "deterministic agents), with standardized interfaces enabling direct comparison across diverse\n",
    "strategies. The agent composition system supports flexible specifications—including uni-\n",
    "form distributions, type-specific concentrations (e.g., ”value heavy”), and precise numerical\n",
    "allocations—enabling systematic exploration of how market dynamics emerge from different\n",
    "agent populations.\n",
    "The framework’s extensible design makes it remarkably simple to add new agent types—\n",
    "LLM-based agents require only defining a new system prompt that specifies the trading\n",
    "strategy. In contrast, deterministic agents can be implemented through the standard agent\n",
    "interface. This flexibility allows researchers to rapidly prototype and deploy novel trading\n",
    "strategies without modifying the underlying system architecture.\n",
    "The complete list of agent types included in the framework and their detailed specifi-\n",
    "cations is provided in the Appendix. The framework’s flexible prompt-based architecture\n",
    "allows researchers to rapidly prototype and deploy new agent types by developing appropri-\n",
    "ate strategic and tactical prompts without modifying the underlying system architecture.\n",
    "2.2.4 User Prompt\n",
    "The user prompt provides the immediate market context necessary for tactical decision-\n",
    "making. This dynamic component delivers current market state information, including\n",
    "prices, volumes, and emerging trends, alongside the agent’s current position information\n",
    "and available trading options. Additionally, the user prompt specifies immediate decision\n",
    "requirements and operational constraints, ensuring that agent responses remain within fea-\n",
    "sible bounds while aligning with their strategic objectives. This separation of strategic and\n",
    "tactical prompting enables precise control over agent behavior while maintaining flexibility\n",
    "for market interactions. All the information in the user prompt is optional at the agent level\n",
    "and can be customized for different experimental designs.\n",
    "15\n",
    "2.2.5 Decision Structure\n",
    "Each agent decision follows a standardized output format comprising several key components.\n",
    "The decision field specifies the basic action as either Buy, Sell, or Hold. For active trades,\n",
    "the quantity field determines the number of shares to trade, while the order type indicates\n",
    "whether it is a Market or Limit order. When placing limit orders, the price limit field\n",
    "specifies the maximum (for buys) or minimum (for sells) acceptable execution price. Finally,\n",
    "each decision includes a reasoning field that provides an explicit rationale for the trading\n",
    "decision, ensuring transparency and facilitating analysis of agent behavior.\n",
    "2.2.6 Structured Outputs and Function Calling\n",
    "Our framework implements a structured output approach using function calling to ensure\n",
    "standardized, human-readable, machine-readable agent decisions. This technique allows\n",
    "LLMs to generate outputs in a specific format that can be directly validated and processed\n",
    "by the trading system, bridging the gap between natural language reasoning and executable\n",
    "trading actions.\n",
    "The system uses Pydantic for validation and parsing of agent outputs, with a schema-\n",
    "based approach that defines the required structure:\n",
    "class TradeDecisionSchema(BaseModel):\"\"\",\n",
    "    \"\"\"(2023)). This work, however, focuses on financial markets and how LLM agents can operate\n",
    "as full-fledged trading participants.\n",
    "Recent research examines specific applications of LLMs for trading. FinMem and Trad-\n",
    "ingGPT introduce frameworks with layered memory systems and customizable agent traits\n",
    "5\n",
    "to improve financial decision-making (Yu, Li, et al. 2024; Li, Zhang, and Sun 2023). Hierar-\n",
    "chical multi-agent architectures have been explored in FinCon, which uses a manager-analyst\n",
    "setup for collaborative portfolio decisions (Yu, Yao, et al. 2024). QuantAgent implements\n",
    "a self-improving signal-mining approach (Wang et al. 2024), while other work underscores\n",
    "the importance of long-term memory in LLM agents via vector databases (Hatalis et al.\n",
    "2024). This line of research builds on successful reinforcement learning applications such as\n",
    "AlphaPortfolio (Cong et al. 2021) and AlphaManager (Campello, Cong, and Zhou 2023),\n",
    "which leverage deep RL and robust control for portfolio management.\n",
    "Analyzing LLM agent behavior by changing only some parameters draws on methods\n",
    "from the interpretable machine learning literature. In particular, the systematic variation\n",
    "of market parameters to reveal decision patterns mirrors partial dependence plots and in-\n",
    "dividual conditional expectation curves used to interpret complex machine learning models\n",
    "(Molnar 2022). These techniques help reveal how LLM agents respond to changes in specific\n",
    "variables while holding others constant, providing insight into their internal decision-making\n",
    "processes that would otherwise remain opaque.\n",
    "Beyond finance, studies of LLM capabilities in interactive or multi-agent settings offer\n",
    "valuable insights. Benchmarks like AgentBench evaluate LLMs’ performance in interac-\n",
    "tive tasks (Liu et al. 2023), while InvestorBench focuses on financial decision-making tasks\n",
    "specifically (H. Li et al. 2024). NegotiationArena demonstrates LLMs’ capacity for strategic\n",
    "interaction in bargaining contexts (Bianchi et al. 2024). Similarly, Guo et al. (2024) provide\n",
    "an economics ”arena” where LLMs compete in strategic games, revealing that advanced\n",
    "models like GPT-4 can exhibit rational, adaptive behavior—albeit not always reaching Nash\n",
    "Equilibrium. Existing frameworks typically assess individual agents or hierarchical collab-\n",
    "orations, whereas this work studies emergent market behaviors that arise from multiple\n",
    "independent LLM traders interacting in a marketplace.\n",
    "The approach also connects to the tradition of experimental asset markets. For instance,\n",
    "Weitzel et al. (2020) show that even finance professionals are susceptible to speculative\n",
    "6\n",
    "bubbles, especially amid high capital inflows. Kop´ anyi-Peuker and Weber (2021) find that\n",
    "trading experience alone does not eliminate bubbles, challenging assumptions about rational\n",
    "market learning. Kirchler, Huber, and St¨ ockl (2012) identify confusion about fundamental\n",
    "values as a key driver of bubble formation. This framework offers a new way to study these\n",
    "phenomena with LLM traders, which can be rigorously parameterized for sophistication,\n",
    "strategy, and information processing. Hence, this paper provides a method to investigate\n",
    "how automated or ”artificial” agents might affect market stability or volatility.\n",
    "Other recent work highlights the versatility of LLM agents in complex, interactive sce-\n",
    "narios beyond finance. One stream focuses on simulating social behaviors—such as opinion\n",
    "dynamics (Chuang et al. 2023), trust (Xie et al. 2024), and resource-sharing (Piatti et al.\n",
    "2024). Another examines LLMs’ strategic capabilities through task-based simulations and\n",
    "collaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\n",
    "Within the computer science literature, early works apply LLMs to financial markets but\n",
    "abstract away many fundamental stock market characteristics. Often, they employ single-\n",
    "price clearing mechanisms without a persistent order book, ignore partial fills and bid-ask\"\"\",\n",
    "    \"\"\"Can Large Language Models Trade? Testing Financial\n",
    "Theories with LLM Agents in Market Simulations\n",
    "Alejandro Lopez-Lira∗\n",
    "First Version: November 29, 2024; Current Version: April 16, 2025\n",
    "Abstract\n",
    "This paper presents a realistic simulated stock market where large language models\n",
    "(LLMs) act as heterogeneous competing trading agents. The open-source framework\n",
    "incorporates a persistent order book with market and limit orders, partial fills, div-\n",
    "idends, and equilibrium clearing alongside agents with varied strategies, information\n",
    "sets, and endowments. Agents submit standardized decisions using structured outputs\n",
    "and function calls while expressing their reasoning in natural language. Three findings\n",
    "emerge: First, LLMs demonstrate consistent strategy adherence and can function as\n",
    "value investors, momentum traders, or market makers per their instructions. Second,\n",
    "market dynamics exhibit features of real financial markets, including price discovery,\n",
    "bubbles, underreaction, and strategic liquidity provision. Third, the framework enables\n",
    "analysis of LLMs’ responses to varying market conditions, similar to partial dependence\n",
    "plots in machine-learning interpretability. The framework allows simulating financial\n",
    "theories without closed-form solutions, creating experimental designs that would be\n",
    "costly with human participants, and establishing how prompts can generate correlated\n",
    "behaviors affecting market stability.\n",
    "Keywords: LLM Agents; Agent-Based Markets; Experimental Finance; AI Trading;\n",
    "Multi-Agent Systems\n",
    "∗University of Florida. Email: alejandro.lopez-lira@warrington.ufl.edu. I am grateful to seminar par-\n",
    "ticipants at the London Business School, Oxford University, Stockholm School of Economics, University of\n",
    "Virginia, and the City University of Hong Kong for helpful suggestions and feedback.\n",
    "1\n",
    "arXiv:2504.10789v1  [q-fin.CP]  15 Apr 2025\n",
    "1 Introduction\n",
    "Large language models (LLMs) can increasingly function as autonomous agents—systems\n",
    "that observe, reason, and act independently. LLMs have shown promising results in finan-\n",
    "cial forecasting, but their potential as trading agents introduces a fundamental shift from\n",
    "algorithms with explicit objectives to systems guided by natural language instructions. This\n",
    "change raises critical questions: Can LLMs execute trading strategies? Do LLMs optimize\n",
    "for profit maximization? What are the implications for market stability and efficiency?\n",
    "If LLMs trade similarly to humans, they could enable experimental market simulations\n",
    "without human participants. Conversely, if their trading behavior differs, understanding\n",
    "these differences becomes critical for systemic risk management. These questions extend be-\n",
    "yond theory; LLM-based strategies are already being deployed.1 To address these questions,\n",
    "I develop an open-source simulation that tests LLM trading agents in a realistic market envi-\n",
    "ronment with a persistent order book, supporting various order types, stochastic dividends,\n",
    "and heterogeneous information.\n",
    "The framework allows heterogeneous LLMs—defined in natural language, using different\n",
    "system prompts—to act as diverse types of traders, such as value investors, momentum\n",
    "traders, market makers, and contrarians. Agents submit standardized trading decisions in a\n",
    "human-readable format while expressing their reasoning transparently. Figure 1 illustrates\n",
    "this approach, showing how a speculator agent combines explicit valuation reasoning with\n",
    "structured trading parameters, enabling systematic analysis and insight into the agent’s\n",
    "decision-making process.\n",
    "The analysis reveals three key findings about LLMs’ capabilities as trading agents. First,\n",
    "LLMs can effectively execute trading strategies. They consistently understand market me-\n",
    "chanics, process market information, form price expectations, and execute trades according\n",
    "to specific instructions. Their trading behavior is highly sensitive to the prompts they\n",
    "receive—they faithfully follow directions regardless of profit implications. This observance\"\"\",\n",
    "    \"\"\"an open-source framework with three key components: (1) a structured protocol for im-\n",
    "plementing and validating LLM trading agents, supporting both LLM-based and traditional\n",
    "rule-based agents; (2) a controlled market environment with realistic microstructure for test-\n",
    "ing agent interactions; and (3) a comprehensive data collection system for analyzing trading\n",
    "behavior. This framework serves multiple stakeholders in preparation for the evolution of\n",
    "financial markets: practitioners developing LLM-based trading systems, regulators antic-\n",
    "ipating widespread LLM adoption, and researchers studying market dynamics with LLM\n",
    "agents.\n",
    "1.1 Related Work\n",
    "This work contributes to several strands of literature. First, advancing the growing body\n",
    "of research on artificial intelligence in finance by demonstrating that large language mod-\n",
    "els (LLMs) can serve as effective autonomous trading agents while providing a framework\n",
    "for their implementation. Second, by contributing to the market microstructure literature\n",
    "by providing insights into how markets might evolve as LLM-based traders become active\n",
    "participants, with implications for price formation, liquidity provision, and market stabil-\n",
    "ity. Third, by contributing to experimental markets research by introducing an environment\n",
    "for studying complex trading interactions, offering unprecedented control and replicability\n",
    "compared to traditional human-subject experiments.\n",
    "4\n",
    "Recent studies have explored ChatGPT’s potential in various financial tasks. Research\n",
    "shows that ChatGPT can effectively predict stock price movements using news headlines,\n",
    "outperforming traditional sentiment analysis (Lopez-Lira and Tang 2023) and that forecast-\n",
    "ing with its embeddings outperforms traditional sentiment analysis (Chen, Kelly, and Xiu\n",
    "2022). When integrated with Graph Neural Networks, ChatGPT improves stock movement\n",
    "prediction and portfolio performance (Chen et al. 2023. ChatGPT can understand Federal\n",
    "Reserve communications Hansen and Kazinnik (2023). The model also can extract manage-\n",
    "rial expectations from corporate disclosures, predicting future investments and returns (Jha\n",
    "et al. 2025). ChatGPT-4 provides valuable investment advice with positive correlations to\n",
    "subsequent earnings announcements and stock returns (Pelster and Val 2023), and it en-\n",
    "hances patent value forecasts by processing patent text (Yang 2023). Moreover, ChatGPT\n",
    "shows promise in central bank analysis, predicting future interest rate decisions from pol-\n",
    "icy communications (Woodhouse and Charlesworth 2023). Recent work also focuses on the\n",
    "effects of AI adoption by firms (Eisfeldt et al. 2023, Babina et al. 2024).\n",
    "Foundational work on LLMs as economic agents demonstrates their ability to simulate\n",
    "human behavior in economic contexts. Horton (2023) introduce the concept of “homo silicus”\n",
    "by using LLMs as computational models of human behavior, showing that they can repli-\n",
    "cate classic behavioral economics findings. Manning, Zhu, and Horton (2024) extend this\n",
    "approach through automated methods for generating and testing social scientific hypotheses\n",
    "with LLMs, demonstrating strong results in market contexts such as auctions. Meanwhile,\n",
    "N. Li et al. (2024) show LLMs’ potential in macroeconomic simulation for consumption\n",
    "and labor decisions. Recent work also shows the potential of LLMs to proxy for human\n",
    "behavior in the context of surveys (Hansen et al. (2024)) or economic expectations (Bybee\n",
    "(2023)). This work, however, focuses on financial markets and how LLM agents can operate\n",
    "as full-fledged trading participants.\n",
    "Recent research examines specific applications of LLMs for trading. FinMem and Trad-\n",
    "ingGPT introduce frameworks with layered memory systems and customizable agent traits\n",
    "5\n",
    "to improve financial decision-making (Yu, Li, et al. 2024; Li, Zhang, and Sun 2023). Hierar-\n",
    "chical multi-agent architectures have been explored in FinCon, which uses a manager-analyst\"\"\",\n",
    "    \"\"\"2024). Another examines LLMs’ strategic capabilities through task-based simulations and\n",
    "collaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\n",
    "Within the computer science literature, early works apply LLMs to financial markets but\n",
    "abstract away many fundamental stock market characteristics. Often, they employ single-\n",
    "price clearing mechanisms without a persistent order book, ignore partial fills and bid-ask\n",
    "spreads, and omit dividends. Consequently, these simplified environments can primarily\n",
    "address exogenous macro shocks (e.g., changes in interest rates or inflation; Gao et al. 2024),\n",
    "exogenous policy changes (Zhang et al. 2024), or rely on advanced methods such as repetitive\n",
    "next-token predictions to generate better answers (Koa et al. 2024). This work extends\n",
    "these efforts by incorporating these crucial market features, enabling the study of complex\n",
    "endogenous events such as flash crashes, liquidity shocks, and large-trader impacts.\n",
    "This work also connects to emerging research on algorithmic and AI-powered trading\n",
    "systems. Dou, Goldstein, and Ji (2024) demonstrate how reinforcement learning-based AI\n",
    "speculators can autonomously learn to sustain collusive behavior without explicit coordi-\n",
    "nation, achieving supra-competitive profits through either price-trigger strategies or self-\n",
    "confirming bias in learning. This finding is particularly informative for this framework as\n",
    "it highlights potential emergent behaviors that may arise when intelligent agents interact in\n",
    "7\n",
    "markets—behaviors that could manifest differently with LLM agents due to their natural\n",
    "language reasoning capabilities. Similarly, Colliard, Foucault, and Lovo (2022) examine al-\n",
    "gorithmic market makers using Q-learning and find they charge markups that increase when\n",
    "adverse selection costs decrease—contrary to Nash equilibrium predictions. Their work pro-\n",
    "vides methodological insights on how to test strategic pricing behaviors against theoretical\n",
    "benchmarks incorporated into this LLM-based framework.\n",
    "Finally, this approach is informed by complexity economics, which views markets as dy-\n",
    "namic, non-equilibrium systems where agents adaptively learn and evolve strategies (Arthur\n",
    "2013; Wolfram 2017). According to this view, markets exhibit emergent phenomena and\n",
    "self-organization, especially when trading agents (human or artificial) update their behav-\n",
    "ior in response to outcomes. This paradigm is particularly relevant in an era of increasing\n",
    "automation and algorithmic trading (Balland et al. 2022; Ping 2019). Like adaptive agents\n",
    "in complexity economics, these LLM traders incorporate new information and adjust their\n",
    "strategies, generating emergent market patterns—a key motivation behind this framework.\n",
    "Unlike previous frameworks that abstract away crucial market features or focus on narrow\n",
    "strategies, this system incorporates realistic market microstructure while accommodating\n",
    "heterogeneous agents interacting simultaneously. While earlier work demonstrates LLMs’\n",
    "promise for macroeconomic modeling and simple trading simulations, this work introduces a\n",
    "complex, open-source financial market platform that supports multiple agent architectures,\n",
    "thorough market microstructure (limit orders, partial fills, dividends), and rigorous testing\n",
    "protocols—fulfilling a critical need in complexity economics research and market microstruc-\n",
    "ture analysis.\n",
    "2 Methodology\n",
    "The methodology section contains three parts. The first part describes the market design,\n",
    "the second agents’ design, and the third the analysis module.\n",
    "8\n",
    "2.1 Market Design\n",
    "Our methodological framework integrates three components that create a controlled envi-\n",
    "ronment for LLM-based trading agents. The framework implements a flexible continuous\n",
    "double-auction market mechanism that couples standard market microstructure principles\n",
    "with market clearing and matching algorithms to accommodate asynchronous LLM decisions.\"\"\",\n",
    "]\n",
    "    ),\n",
    "    LLMTestCase(\n",
    "        input=\"The authors note that LLMs ‘follow instructions even if doing so results in financial losses.’ How might this limit their realism as profit‑seeking traders?\",\n",
    "        actual_output=\"\"\"The LLMs' tendency to prioritize instructions over profits makes them less realistic as traders in several key ways:\n",
    "\n",
    "Lack of Dynamic Strategy Adjustment: Real-world traders adapt and change their strategies based on market performance. If a strategy isn't profitable, they'll modify or abandon it. LLMs, however, rigidly adhere to their initial instructions, even when losing money, which isn't realistic in dynamic markets.\n",
    "\n",
    "Absence of Loss Aversion: Human traders are strongly motivated to avoid losses (loss aversion). LLMs, lacking this emotional response, don't show the same aversion and may continue following a losing strategy simply because they were instructed to.\n",
    "\n",
    "Unrealistic Adherence to Specific Roles: In the study, LLMs were given fixed roles (e.g., \"value investor,\" \"market maker\"). Real traders, while having general investment philosophies, are flexible and will exploit profitable opportunities even if they don't perfectly align with their usual style. The LLMs' strict adherence to their assigned roles, even at a loss, limits their realism.\"\"\",\n",
    "        expected_output=\"\"\"LLMs optimise for prompt fidelity; they keep executing the instructed strategy even when it loses money, unlike humans who adapt for profit.\"\"\",\n",
    "        retrieval_context=[\n",
    "    \"\"\"Can Large Language Models Trade? Testing Financial\n",
    "Theories with LLM Agents in Market Simulations\n",
    "Alejandro Lopez-Lira∗\n",
    "First Version: November 29, 2024; Current Version: April 16, 2025\n",
    "Abstract\n",
    "This paper presents a realistic simulated stock market where large language models\n",
    "(LLMs) act as heterogeneous competing trading agents. The open-source framework\n",
    "incorporates a persistent order book with market and limit orders, partial fills, div-\n",
    "idends, and equilibrium clearing alongside agents with varied strategies, information\n",
    "sets, and endowments. Agents submit standardized decisions using structured outputs\n",
    "and function calls while expressing their reasoning in natural language. Three findings\n",
    "emerge: First, LLMs demonstrate consistent strategy adherence and can function as\n",
    "value investors, momentum traders, or market makers per their instructions. Second,\n",
    "market dynamics exhibit features of real financial markets, including price discovery,\n",
    "bubbles, underreaction, and strategic liquidity provision. Third, the framework enables\n",
    "analysis of LLMs’ responses to varying market conditions, similar to partial dependence\n",
    "plots in machine-learning interpretability. The framework allows simulating financial\n",
    "theories without closed-form solutions, creating experimental designs that would be\n",
    "costly with human participants, and establishing how prompts can generate correlated\n",
    "behaviors affecting market stability.\n",
    "Keywords: LLM Agents; Agent-Based Markets; Experimental Finance; AI Trading;\n",
    "Multi-Agent Systems\n",
    "∗University of Florida. Email: alejandro.lopez-lira@warrington.ufl.edu. I am grateful to seminar par-\n",
    "ticipants at the London Business School, Oxford University, Stockholm School of Economics, University of\n",
    "Virginia, and the City University of Hong Kong for helpful suggestions and feedback.\n",
    "1\n",
    "arXiv:2504.10789v1  [q-fin.CP]  15 Apr 2025\n",
    "1 Introduction\n",
    "Large language models (LLMs) can increasingly function as autonomous agents—systems\n",
    "that observe, reason, and act independently. LLMs have shown promising results in finan-\n",
    "cial forecasting, but their potential as trading agents introduces a fundamental shift from\n",
    "algorithms with explicit objectives to systems guided by natural language instructions. This\n",
    "change raises critical questions: Can LLMs execute trading strategies? Do LLMs optimize\n",
    "for profit maximization? What are the implications for market stability and efficiency?\n",
    "If LLMs trade similarly to humans, they could enable experimental market simulations\n",
    "without human participants. Conversely, if their trading behavior differs, understanding\n",
    "these differences becomes critical for systemic risk management. These questions extend be-\n",
    "yond theory; LLM-based strategies are already being deployed.1 To address these questions,\n",
    "I develop an open-source simulation that tests LLM trading agents in a realistic market envi-\n",
    "ronment with a persistent order book, supporting various order types, stochastic dividends,\n",
    "and heterogeneous information.\n",
    "The framework allows heterogeneous LLMs—defined in natural language, using different\n",
    "system prompts—to act as diverse types of traders, such as value investors, momentum\n",
    "traders, market makers, and contrarians. Agents submit standardized trading decisions in a\n",
    "human-readable format while expressing their reasoning transparently. Figure 1 illustrates\n",
    "this approach, showing how a speculator agent combines explicit valuation reasoning with\n",
    "structured trading parameters, enabling systematic analysis and insight into the agent’s\n",
    "decision-making process.\n",
    "The analysis reveals three key findings about LLMs’ capabilities as trading agents. First,\n",
    "LLMs can effectively execute trading strategies. They consistently understand market me-\n",
    "chanics, process market information, form price expectations, and execute trades according\n",
    "to specific instructions. Their trading behavior is highly sensitive to the prompts they\n",
    "receive—they faithfully follow directions regardless of profit implications. This observance\"\"\",\n",
    "    \"\"\"decision-making process.\n",
    "The analysis reveals three key findings about LLMs’ capabilities as trading agents. First,\n",
    "LLMs can effectively execute trading strategies. They consistently understand market me-\n",
    "chanics, process market information, form price expectations, and execute trades according\n",
    "to specific instructions. Their trading behavior is highly sensitive to the prompts they\n",
    "receive—they faithfully follow directions regardless of profit implications. This observance\n",
    "1. For example, Autopilot has a ChatGPT-based portfolio https://x.com/thegptinvestor.\n",
    "2\n",
    "{\"valuation_reasoning\":\n",
    "\"The fundamental value is based on the expected dividend,\n",
    "and the interest rate.\n",
    "The expected dividend is $1.40, and the interest rate is 5%.\n",
    "Using a perpetuity formula, the value is $1.40 / 0.05 = $28.\",\n",
    "\"valuation\":28.0,\n",
    "\"price_target_reasoning\":\"The current price is $29.00, which is\n",
    "slightly above the fundamental value of $28.00. I expect the price\n",
    "to remain around $29.00 in the next round due to market stability.\",\n",
    "\"price_target\":29.0,\n",
    "\"orders\":[{\"decision\":\"Sell\",\"quantity\":1000,\"order_type\":\"limit\",\n",
    "\"price_limit\":29.50}],\n",
    "\"replace_decision\":\"Add\",\n",
    "\"reasoning\":\"The current price is slightly above the fundamental value.\n",
    "I will place a limit sell order at $29.50 to capitalize on potential price\n",
    "increases.\"}\n",
    "Figure 1: Example of a structured trading decision from a Speculator agent defined by its\n",
    "system prompt: “You are a speculator who tries to profit from market inefficiencies.”. The\n",
    "LLM provides explicit reasoning for its valuation, price target, and trading decision in a\n",
    "machine-readable JSON format that can be directly processed by the trading system.\n",
    "highlights a fundamental difference from human traders: LLMs do not inherently optimize\n",
    "for profit maximization but rather for following instructions accurately.\n",
    "Second, LLMs react meaningfully to market dynamics. They consider current and his-\n",
    "torical prices, dividends, and other market information when making decisions. However,\n",
    "they maintain their strategic direction even when market conditions change, following their\n",
    "instructions even if doing so results in financial losses. This combination of responsiveness\n",
    "to market conditions while maintaining strategic consistency creates a unique trading profile\n",
    "distinct from rule-based algorithms and human traders.\n",
    "Third, market dynamics with LLM agents can resemble actual markets and mirror classic\n",
    "results from the theoretical finance literature. When these agents interact, they produce\n",
    "realistic price discovery and liquidity provision with emergent behaviors, including price\n",
    "convergence toward fundamental values. Depending on the distribution of agent types,\n",
    "the system can generate various market phenomena, such as bubbles or underreactions to\n",
    "information. This complex behavior suggests potential applications for studying market\n",
    "3\n",
    "dynamics using LLM agents instead of experiments with human participants.\n",
    "Hence, these findings raise important questions about algorithmic consistency in LLM-\n",
    "based systems. Since trading agents are implemented through prompts, their behavior in-\n",
    "herits characteristics of the underlying language models. The standardization of LLM ar-\n",
    "chitectures across implementations could create unexpected behavioral patterns—if many\n",
    "agents are based on similar foundation models, they might exhibit correlated responses to\n",
    "specific market conditions, potentially amplifying market instabilities.\n",
    "To enable this analysis and accelerate development in this emerging field, we provide\n",
    "an open-source framework with three key components: (1) a structured protocol for im-\n",
    "plementing and validating LLM trading agents, supporting both LLM-based and traditional\n",
    "rule-based agents; (2) a controlled market environment with realistic microstructure for test-\n",
    "ing agent interactions; and (3) a comprehensive data collection system for analyzing trading\n",
    "behavior. This framework serves multiple stakeholders in preparation for the evolution of\"\"\",\n",
    "    \"\"\"(2023)). This work, however, focuses on financial markets and how LLM agents can operate\n",
    "as full-fledged trading participants.\n",
    "Recent research examines specific applications of LLMs for trading. FinMem and Trad-\n",
    "ingGPT introduce frameworks with layered memory systems and customizable agent traits\n",
    "5\n",
    "to improve financial decision-making (Yu, Li, et al. 2024; Li, Zhang, and Sun 2023). Hierar-\n",
    "chical multi-agent architectures have been explored in FinCon, which uses a manager-analyst\n",
    "setup for collaborative portfolio decisions (Yu, Yao, et al. 2024). QuantAgent implements\n",
    "a self-improving signal-mining approach (Wang et al. 2024), while other work underscores\n",
    "the importance of long-term memory in LLM agents via vector databases (Hatalis et al.\n",
    "2024). This line of research builds on successful reinforcement learning applications such as\n",
    "AlphaPortfolio (Cong et al. 2021) and AlphaManager (Campello, Cong, and Zhou 2023),\n",
    "which leverage deep RL and robust control for portfolio management.\n",
    "Analyzing LLM agent behavior by changing only some parameters draws on methods\n",
    "from the interpretable machine learning literature. In particular, the systematic variation\n",
    "of market parameters to reveal decision patterns mirrors partial dependence plots and in-\n",
    "dividual conditional expectation curves used to interpret complex machine learning models\n",
    "(Molnar 2022). These techniques help reveal how LLM agents respond to changes in specific\n",
    "variables while holding others constant, providing insight into their internal decision-making\n",
    "processes that would otherwise remain opaque.\n",
    "Beyond finance, studies of LLM capabilities in interactive or multi-agent settings offer\n",
    "valuable insights. Benchmarks like AgentBench evaluate LLMs’ performance in interac-\n",
    "tive tasks (Liu et al. 2023), while InvestorBench focuses on financial decision-making tasks\n",
    "specifically (H. Li et al. 2024). NegotiationArena demonstrates LLMs’ capacity for strategic\n",
    "interaction in bargaining contexts (Bianchi et al. 2024). Similarly, Guo et al. (2024) provide\n",
    "an economics ”arena” where LLMs compete in strategic games, revealing that advanced\n",
    "models like GPT-4 can exhibit rational, adaptive behavior—albeit not always reaching Nash\n",
    "Equilibrium. Existing frameworks typically assess individual agents or hierarchical collab-\n",
    "orations, whereas this work studies emergent market behaviors that arise from multiple\n",
    "independent LLM traders interacting in a marketplace.\n",
    "The approach also connects to the tradition of experimental asset markets. For instance,\n",
    "Weitzel et al. (2020) show that even finance professionals are susceptible to speculative\n",
    "6\n",
    "bubbles, especially amid high capital inflows. Kop´ anyi-Peuker and Weber (2021) find that\n",
    "trading experience alone does not eliminate bubbles, challenging assumptions about rational\n",
    "market learning. Kirchler, Huber, and St¨ ockl (2012) identify confusion about fundamental\n",
    "values as a key driver of bubble formation. This framework offers a new way to study these\n",
    "phenomena with LLM traders, which can be rigorously parameterized for sophistication,\n",
    "strategy, and information processing. Hence, this paper provides a method to investigate\n",
    "how automated or ”artificial” agents might affect market stability or volatility.\n",
    "Other recent work highlights the versatility of LLM agents in complex, interactive sce-\n",
    "narios beyond finance. One stream focuses on simulating social behaviors—such as opinion\n",
    "dynamics (Chuang et al. 2023), trust (Xie et al. 2024), and resource-sharing (Piatti et al.\n",
    "2024). Another examines LLMs’ strategic capabilities through task-based simulations and\n",
    "collaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\n",
    "Within the computer science literature, early works apply LLMs to financial markets but\n",
    "abstract away many fundamental stock market characteristics. Often, they employ single-\n",
    "price clearing mechanisms without a persistent order book, ignore partial fills and bid-ask\"\"\",\n",
    "    \"\"\"33\n",
    "ants, allowing researchers to study how different belief structures influence price formation\n",
    "and trading patterns under different initial mispricings. In these scenarios, the fundamental\n",
    "price is hidden from agents, forcing them to rely on their own valuation models.\n",
    "3.2.5 Market Stress\n",
    "This scenario tests market resilience under challenging conditions by creating a more volatile\n",
    "environment. The scenario includes two consistently bullish Optimistic traders, two consis-\n",
    "tently bearish Pessimistic traders, two Market makers (liquidity providers), and two Value\n",
    "investors (rational benchmark traders). The scenario runs for 100 rounds to study long-term\n",
    "market behavior and includes unequal initial endowments, with optimistic traders having\n",
    "more cash (1.5x baseline) but fewer shares (0.5x baseline) and pessimistic traders having less\n",
    "cash (0.5x baseline) but more shares (1.5x baseline). This resource imbalance tests whether\n",
    "particular agent types can dominate market outcomes through resource advantages.\n",
    "The scenarios presented here demonstrate the framework’s capabilities for exploring di-\n",
    "verse market conditions. Its modular structure facilitates the straightforward definition and\n",
    "implementation of alternative experimental designs, enabling researchers to tailor simulations\n",
    "to specific research questions.\n",
    "In all scenarios, we maintain consistent baseline parameters with a fundamental value\n",
    "of $28.00, calculated from the expected dividend of $1.40 and interest rate of 5%. Agent\n",
    "endowments start at 1,000,000 monetary units and 10,000 shares unless specifically modified.\n",
    "Transaction costs are set to zero to isolate the effects of agent behavior and market structure\n",
    "on price formation.\n",
    "4 Conclusion\n",
    "This paper demonstrates that Large Language Models can effectively function as diverse\n",
    "trading agents—from value investors to market makers—maintaining strategic consistency\n",
    "34\n",
    "while adapting to market conditions. Our experimental framework reveals that their in-\n",
    "teractions generate realistic market dynamics, including phenomena like price bubbles and\n",
    "corrections, highlighting both the capabilities and potential risks of deploying LLM agents\n",
    "in financial markets.\n",
    "These findings carry significant implications for market structure and regulation. While\n",
    "LLM agents can enhance price discovery and liquidity, their adherence to programmed strate-\n",
    "gies, even potentially flawed ones derived from prompts, could amplify market volatility or\n",
    "introduce novel systemic risks, as observed in our simulated bubble scenarios. A key concern\n",
    "is the potential for widespread correlated behavior: similar underlying LLM architectures\n",
    "responding uniformly to comparable prompts or market signals could inadvertently create\n",
    "destabilizing trading patterns without explicit coordination. This underscores the critical\n",
    "need for rigorous testing and validation of LLM-based trading systems prior to live deploy-\n",
    "ment.\n",
    "A central contribution of this work is the open-source simulation framework itself, de-\n",
    "signed to catalyze research into LLM trading agents. We invite the research community to\n",
    "utilize and extend this platform to investigate pressing questions in this rapidly evolving\n",
    "area. The framework enables systematic exploration of complex scenarios—such as hybrid\n",
    "human-LLM markets, stress tests, varying market structures, regulatory impacts, and the\n",
    "nuances of LLM prompting—often difficult or costly to study otherwise. Specific avenues\n",
    "ripe for investigation using this tool include the emergence of novel trading strategies, the\n",
    "precise effects of agent heterogeneity on market stability, and the development of robust\n",
    "validation protocols for AI traders. As artificial intelligence becomes more integrated into\n",
    "finance, collaborative research leveraging adaptable simulation environments like this one\n",
    "will be crucial for understanding and responsibly shaping the future of trading.\n",
    "35\n",
    "References\"\"\",\n",
    "    \"\"\"ceedings of the 62nd Annual Meeting of the Association for Computational Linguistics\n",
    "(Volume 1: Long Papers),edited by Lun-Wei Ku, Andre Martins, and Vivek Srikumar,\n",
    "15523–15536. ACL 2024. Bangkok, Thailand: Association for Computational Linguis-\n",
    "tics, August.\n",
    "39\n",
    "Li, Yuan, Yixuan Zhang, and Lichao Sun. 2023. “MetaAgents: Simulating Interactions of\n",
    "Human Behaviors for LLM-based T Ask-Oriented Coordination via Collaborative Gen-\n",
    "erative Agents.” arXiv.org.\n",
    "Liu, Xiao, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, et al. 2023.\n",
    "“AgentBench: Evaluating LLMs as Agents.”International Conference on Learning Rep-\n",
    "resentations.\n",
    "Lopez-Lira, Alejandro, and Yuehua Tang. 2023. “Can ChatGPT Forecast Stock Price Move-\n",
    "ments? Return Predictability and Large Language Models.” SSRN Electronic Journal\n",
    "(April 6, 2023).\n",
    "Manning, Benjamin S., Kehang Zhu, and John J. Horton. 2024. “Automated Social Science:\n",
    "Language Models as Scientist and Subjects.” (Cambridge, MA) (April 29, 2024).\n",
    "Molnar, Christoph. 2022. Interpretable Machine Learning.\n",
    "Pelster, Matthias, and Joel Val. 2023. “Can Chatgpt Assist in Picking Stocks?”Social Science\n",
    "Research Network.\n",
    "Piatti, Giorgio, Zhijing Jin, Max Kleiman-Weiner, Bernhard Sch¨ olkopf, Mrinmaya Sachan,\n",
    "and Rada Mihalcea. 2024. “Cooperate or Collapse: Emergence of Sustainable Coopera-\n",
    "tion in a Socie Ty of LLM Agents.” arXiv.org.\n",
    "Ping, Chen. 2019. “From Complexity Science to Complexity Economics.” In Alternative\n",
    "Approaches to Economic Theory,19–55. Routledge, June 11, 2019.\n",
    "Wang, Saizhuo, Hang Yuan, Lionel M. Ni, and Jian Guo. 2024. “QuantAgent: Seeking Holy\n",
    "Grail in Trading by Self-Improving Large Lang Uage Model.” arXiv.org.\n",
    "Weitzel, Utz, Christoph Huber, J¨ urgen Huber, Michael Kirchler, Florian Lindner, and Julia\n",
    "Rose. 2020. “Bubbles and Financial Professionals.” The Review of Financial Studies33,\n",
    "no. 6 (June 1, 2020): 2659–2696.\n",
    "40\n",
    "Wolfram, Elsner. 2017. “Complexity Economics as Heterodoxy: Theory and Policy.”Journal\n",
    "of Economic Issues51, no. 4 (October 2, 2017): 939–978.\n",
    "Woodhouse, Drew, and Alex Charlesworth. 2023. “Can ChatGPT Predict Future Interest\n",
    "Rate Decisions?” Social Science Research Network.\n",
    "Xie, Chengxing, Canyu Chen, Feiran Jia, Ziyu Ye, Shiyang Lai, Kai Shu, Jindong Gu, et al.\n",
    "2024. “Can Large Language Model Agents Simulate Human Trust Behavior?”arXiv.org.\n",
    "Yang, Stephen. 2023. “Predictive Patentomics: Forecasting Innovation Success and Valuation\n",
    "w Ith ChatGPT.” Social Science Research Network.\n",
    "Yu, Yangyang, Haohang Li, Zhi Chen, Yuechen Jiang, Yang Li, Denghui Zhang, Rong\n",
    "Liu, Jordan W. Suchow, and Khaldoun Khashanah. 2024. “FinMem: A Performance-\n",
    "Enhanced LLM Trading Agent with Layered Memory a Nd Character Design.”Proceed-\n",
    "ings of the AAAI Symposium Series3, no. 1 (May 20, 2024): 595–597.\n",
    "Yu, Yangyang, Zhiyuan Yao, Haohang Li, Zhiyang Deng, Yupeng Cao, Zhi Chen, Jordan W.\n",
    "Suchow, et al. 2024. “FinCon: A Synthesized LLM Multi-Agent System with Conceptual\n",
    "Verbal Reinforcement for Enhanced Financial Decision Making.” Pre-published, Novem-\n",
    "ber 7, 2024. Accessed January 8, 2025. https://doi.org/10.48550/arXiv.2407.06567.\n",
    "arXiv: 2407.06567 [cs]. http://arxiv.org/abs/2407.06567.\n",
    "Zhang, Chong, Xinyi Liu, Zhongmou Zhang, Mingyu Jin, Lingyao Li, Zhenting Wang,\n",
    "Wenyue Hua, et al. 2024. “When AI Meets Finance (StockAgent): Large Language\n",
    "Model-based Stock Trading in Simulated Real-world Environments.” Pre-published,\n",
    "September 21, 2024. Accessed January 26, 2025. https://doi.org /10.48550/arXiv .\n",
    "2407.18957. arXiv: 2407.18957 [q-fin]. http://arxiv.org/abs/2407.18957.\n",
    "41\n",
    "A Technical Implementation Details\n",
    "A.1 Agent Type Specifications\n",
    "This section details the base system prompts for each agent type in our simulation. These\n",
    "prompts define the core behavioral characteristics and trading strategies for each agent. Each\n",
    "prompt consists of:\n",
    "• A role definition that establishes the agent’s trading philosophy\n",
    "• A structured trading strategy that guides decision-making\"\"\",\n",
    "    \"\"\"ripe for investigation using this tool include the emergence of novel trading strategies, the\n",
    "precise effects of agent heterogeneity on market stability, and the development of robust\n",
    "validation protocols for AI traders. As artificial intelligence becomes more integrated into\n",
    "finance, collaborative research leveraging adaptable simulation environments like this one\n",
    "will be crucial for understanding and responsibly shaping the future of trading.\n",
    "35\n",
    "References\n",
    "Arthur, W. Brian. 2013. “Complexity Economics : A Different Framework for Economic\n",
    "Thought.”\n",
    "Babina, Tania, Anastassia Fedyk, Alex He, and James Hodson. 2024. “Artificial Intelli-\n",
    "gence, Firm Growth, and Product Innovation.” Journal of Financial Economics 151\n",
    "(January 1, 2024): 103745.\n",
    "Balland, Pierre-Alexandre, Tom Broekel, Dario Diodato, Elisa Giuliani, Ricardo Hausmann,\n",
    "Neave O’Clery, and David Rigby. 2022. “The New Paradigm of Economic Complexity.”\n",
    "Research Policy51, no. 3 (April): 104450.\n",
    "Bianchi, Federico, Patrick John Chia, Mert Yuksekgonul, Jacopo Tagliabue, Dan Jurafsky,\n",
    "and James Zou. 2024. “How Well Can LLMs Negotiate? NegotiationArena Platform and\n",
    "Analysis.” arXiv.org.\n",
    "Bybee, J. Leland. 2023. “The Ghost in the Machine: Generating Beliefs with Large Language\n",
    "Models.” arXiv: 2305.02823.\n",
    "Campello, Murillo, Lin William Cong, and Luofeng Zhou. 2023. “AlphaManager: A Data-\n",
    "Driven-Robust-Control Approach to Corporate Finance.” Pre-published, December 2,\n",
    "2023. SSRN Scholarly Paper. Accessed December 22, 2024. https://doi.org/10.2139/\n",
    "ssrn.4590323. Social Science Research Network: 4590323. https://papers.ssrn.com/\n",
    "abstract=4590323.\n",
    "Chen, Yifei, Bryan T. Kelly, and Dacheng Xiu. 2022. “Expected Returns and Large Lan-\n",
    "guage Models.” Pre-published, November 22, 2022. SSRN Scholarly Paper. Accessed\n",
    "January 26, 2025. Social Science Research Network: 4416687. https://papers.ssrn.com/\n",
    "abstract=4416687.\n",
    "36\n",
    "Chen, Zihan, Lei Zheng, Chengyu Lu, Jialu Yuan, and Di Zhu. 2023. “ChatGPT Informed\n",
    "Graph Neural Network for Stock Movement Prediction.” Social Science Research Net-\n",
    "work.\n",
    "Chuang, Yun-Shiuan, Agam Goyal, Nikunj Harlalka, Siddharth Suresh, Robert Hawkins,\n",
    "Sijia Yang, Dhavan Shah, Junjie Hu, and Timothy T. Rogers. 2023. “Simulating Opin-\n",
    "ion Dynamics with Networks of LLM-based Agents.” North American Chapter of the\n",
    "Association for Computational Linguistic s.\n",
    "Colliard, Jean-Edouard, Thierry Foucault, and Stefano Lovo. 2022. “Algorithmic Pricing\n",
    "and Liquidity in Securities Markets.” Pre-published, October 18, 2022. SSRN Scholarly\n",
    "Paper. Accessed April 4, 2025. https://doi.org/10.2139/ssrn.4252858. Social Science\n",
    "Research Network: 4252858. https://papers.ssrn.com/abstract=4252858.\n",
    "Cong, Lin William, Ke Tang, Jingyuan Wang, and Yang Zhang. 2021. “AlphaPortfolio:\n",
    "Direct Construction Through Deep Reinforcement Learning and Interpretable AI.” Pre-\n",
    "published, August 1, 2021. SSRN Scholarly Paper. Accessed December 22, 2024. https:\n",
    "//doi.org/10.2139/ssrn.3554486. Social Science Research Network: 3554486. https:\n",
    "//papers.ssrn.com/abstract=3554486.\n",
    "Dou, Winston Wei, Itay Goldstein, and Yan Ji. 2024. “AI-Powered Trading, Algorithmic\n",
    "Collusion, and Price Efficiency.” Pre-published, May 30, 2024. SSRN Scholarly Paper.\n",
    "Accessed April 4, 2025. https://doi.org/10.2139/ssrn.4452704. Social Science Research\n",
    "Network: 4452704. https://papers.ssrn.com/abstract=4452704.\n",
    "Eisfeldt, Andrea L., Gregor Schubert, Miao Ben Zhang, and Bledi Taska. 2023. “Generative\n",
    "AI and Firm Values.” Pre-published, May 2, 2023. SSRN Scholarly Paper. Accessed\n",
    "January 26, 2025. https : / / doi .org / 10 .2139 / ssrn . 4436627. Social Science Research\n",
    "Network: 4436627. https://papers.ssrn.com/abstract=4436627.\n",
    "37\n",
    "Gao, Shen, Yuntao Wen, Minghang Zhu, Jianing Wei, Yuhan Cheng, Qunzi Zhang, and Shuo\n",
    "Shang. 2024. “Simulating Financial Market via Large Language Model Based Agents.”\n",
    "Pre-published, June 28, 2024. Accessed January 26, 2025. https://doi.org/10.48550/\"\"\",\n",
    "    \"\"\"an open-source framework with three key components: (1) a structured protocol for im-\n",
    "plementing and validating LLM trading agents, supporting both LLM-based and traditional\n",
    "rule-based agents; (2) a controlled market environment with realistic microstructure for test-\n",
    "ing agent interactions; and (3) a comprehensive data collection system for analyzing trading\n",
    "behavior. This framework serves multiple stakeholders in preparation for the evolution of\n",
    "financial markets: practitioners developing LLM-based trading systems, regulators antic-\n",
    "ipating widespread LLM adoption, and researchers studying market dynamics with LLM\n",
    "agents.\n",
    "1.1 Related Work\n",
    "This work contributes to several strands of literature. First, advancing the growing body\n",
    "of research on artificial intelligence in finance by demonstrating that large language mod-\n",
    "els (LLMs) can serve as effective autonomous trading agents while providing a framework\n",
    "for their implementation. Second, by contributing to the market microstructure literature\n",
    "by providing insights into how markets might evolve as LLM-based traders become active\n",
    "participants, with implications for price formation, liquidity provision, and market stabil-\n",
    "ity. Third, by contributing to experimental markets research by introducing an environment\n",
    "for studying complex trading interactions, offering unprecedented control and replicability\n",
    "compared to traditional human-subject experiments.\n",
    "4\n",
    "Recent studies have explored ChatGPT’s potential in various financial tasks. Research\n",
    "shows that ChatGPT can effectively predict stock price movements using news headlines,\n",
    "outperforming traditional sentiment analysis (Lopez-Lira and Tang 2023) and that forecast-\n",
    "ing with its embeddings outperforms traditional sentiment analysis (Chen, Kelly, and Xiu\n",
    "2022). When integrated with Graph Neural Networks, ChatGPT improves stock movement\n",
    "prediction and portfolio performance (Chen et al. 2023. ChatGPT can understand Federal\n",
    "Reserve communications Hansen and Kazinnik (2023). The model also can extract manage-\n",
    "rial expectations from corporate disclosures, predicting future investments and returns (Jha\n",
    "et al. 2025). ChatGPT-4 provides valuable investment advice with positive correlations to\n",
    "subsequent earnings announcements and stock returns (Pelster and Val 2023), and it en-\n",
    "hances patent value forecasts by processing patent text (Yang 2023). Moreover, ChatGPT\n",
    "shows promise in central bank analysis, predicting future interest rate decisions from pol-\n",
    "icy communications (Woodhouse and Charlesworth 2023). Recent work also focuses on the\n",
    "effects of AI adoption by firms (Eisfeldt et al. 2023, Babina et al. 2024).\n",
    "Foundational work on LLMs as economic agents demonstrates their ability to simulate\n",
    "human behavior in economic contexts. Horton (2023) introduce the concept of “homo silicus”\n",
    "by using LLMs as computational models of human behavior, showing that they can repli-\n",
    "cate classic behavioral economics findings. Manning, Zhu, and Horton (2024) extend this\n",
    "approach through automated methods for generating and testing social scientific hypotheses\n",
    "with LLMs, demonstrating strong results in market contexts such as auctions. Meanwhile,\n",
    "N. Li et al. (2024) show LLMs’ potential in macroeconomic simulation for consumption\n",
    "and labor decisions. Recent work also shows the potential of LLMs to proxy for human\n",
    "behavior in the context of surveys (Hansen et al. (2024)) or economic expectations (Bybee\n",
    "(2023)). This work, however, focuses on financial markets and how LLM agents can operate\n",
    "as full-fledged trading participants.\n",
    "Recent research examines specific applications of LLMs for trading. FinMem and Trad-\n",
    "ingGPT introduce frameworks with layered memory systems and customizable agent traits\n",
    "5\n",
    "to improve financial decision-making (Yu, Li, et al. 2024; Li, Zhang, and Sun 2023). Hierar-\n",
    "chical multi-agent architectures have been explored in FinCon, which uses a manager-analyst\"\"\",\n",
    "    \"\"\"2407.18957. arXiv: 2407.18957 [q-fin]. http://arxiv.org/abs/2407.18957.\n",
    "41\n",
    "A Technical Implementation Details\n",
    "A.1 Agent Type Specifications\n",
    "This section details the base system prompts for each agent type in our simulation. These\n",
    "prompts define the core behavioral characteristics and trading strategies for each agent. Each\n",
    "prompt consists of:\n",
    "• A role definition that establishes the agent’s trading philosophy\n",
    "• A structured trading strategy that guides decision-making\n",
    "• Specific instructions for when to use market orders vs limit orders\n",
    "At runtime, these base prompts are combined with:\n",
    "• Current market state (price, volume, order book depth)\n",
    "• Position information (current holdings and available cash)\n",
    "• Trading options and required response format\n",
    "The standard runtime template includes:\n",
    "Position Information Template\n",
    "Your Position:\n",
    "- Available Shares: {shares} shares (Short selling is not allowed)\n",
    "- Main Cash Account: ${cash:.2f}\n",
    "- Dividend Cash Account (not available for trading): ${dividend_cash:.2f}\n",
    "- Total Available Cash: ${total_available_cash:.2f} (Borrowing is not allowed)\n",
    "- Shares in Orders: {committed_shares} shares\n",
    "- Cash in Orders: ${committed_cash:.2f}\n",
    "42\n",
    "Trading Options Template\n",
    "Your analysis should include:\n",
    "- valuation_reasoning: Your numerical analysis of the asset’s fundamental value\n",
    "- valuation: Your estimate of the asset’s current fundamental value\n",
    "- price_target_reasoning: Your numerical analysis of the asset’s price target\n",
    "- price_target: Your predicted price for the next round\n",
    "- reasoning: Your explanation for the trading decision\n",
    "Trading Options:\n",
    "1. New Orders (replace_decision=’Add’):\n",
    "- Single or multiple orders allowed\n",
    "- For each order:\n",
    "- Market order: Set order_type=’market’\n",
    "- Limit order: Set order_type=’limit’ and specify price_limit\n",
    "- IMPORTANT: Sell orders require sufficient available shares\n",
    "- Short selling is NOT allowed\n",
    "2. Cancel Orders (replace_decision=’Cancel’):\n",
    "- Return an empty orders list: orders=[]\n",
    "Your decision must include:\n",
    "- orders: list of orders (empty list for Hold/Cancel)\n",
    "- For Buy/Sell orders, each must contain:\n",
    "- decision: \"Buy\" or \"Sell\"\n",
    "- quantity: number of shares\n",
    "- order_type: \"market\" or \"limit\"\n",
    "- price_limit: required for limit orders\n",
    "- reasoning: brief explanation\n",
    "- replace_decision: \"Add\", \"Cancel\", or \"Replace\"\n",
    "43\n",
    "Base System Prompts The following are the base system prompts for each LLM-based\n",
    "agent type:\n",
    "A.1.1 Value-Based Agents\n",
    "Value Investor\n",
    "You are a value investor who focuses on fundamental analysis.\n",
    "You believe in mean reversion and try to buy undervalued assets and sell overvalued ones.\n",
    "A.1.2 Trend-Following Agents\n",
    "Momentum Trader\n",
    "You are a momentum trader who focuses on price trends and volume.\n",
    "You believe that ’the trend is your friend’ and try to identify and follow market momentum.\n",
    "A.1.3 Liquidity Providers Agents\n",
    "Market Maker\n",
    "You are a professional market maker who provides liquidity to the market.\n",
    "Your profit comes from capturing the spread between bid and ask prices, not from directional price movement.\n",
    "IMPORTANT: There is NO SHORT SELLING allowed. You can only sell shares you already own.\n",
    "Trading Guidelines:\n",
    "- Place LIMIT buy orders slightly below the current market price (1-3% lower)\n",
    "- Place LIMIT sell orders slightly above the current market price (1-3% higher)\n",
    "- Your spread should be proportional to volatility but typically 2-6% of price\n",
    "- NEVER place sell orders more than 10% above your buy orders\n",
    "- Adjust your spread width based on recent price volatility\n",
    "44\n",
    "Inventory Management (No Short Selling):\n",
    "- Monitor your current inventory in the market data\n",
    "- Only place sell orders for quantities you actually own\n",
    "- If you have no inventory, focus on buy orders first\n",
    "- As you acquire inventory, gradually place sell orders\n",
    "- If inventory grows too large, reduce or pause buy orders\n",
    "- Adjust your buy/sell ratio based on current inventory level\n",
    "Example: If price = $100, you might place buy orders at $97-99 and sell orders at $101-103,\"\"\",\n",
    "]\n",
    "    ),\n",
    "    LLMTestCase(\n",
    "        input=\"What systemic risks do the authors foresee if many firms deploy similarly prompted LLM traders in real markets?\",\n",
    "        actual_output=\"\"\"The authors are concerned that if many trading firms use similarly prompted Large Language Model (LLM) based trading agents, it could lead to increased systemic risk in financial markets. Specifically, they highlight the risk of correlated behavior: because these agents would be built on similar underlying architectures and responding to the same market signals in similar ways (due to similar prompts), they might make the same trading decisions at the same time. This could amplify market instability, potentially causing:\n",
    "\n",
    "Exaggerated Price Swings: If many LLMs simultaneously decide to buy or sell a particular asset, it could lead to larger-than-normal price increases or decreases, increasing market volatility.\n",
    "\n",
    "Flash Crashes: In extreme cases, this correlated selling could create a sudden, sharp drop in prices, similar to a flash crash.\n",
    "\n",
    "Bubble Formation and Bursting: Similarly, correlated buying by many LLMs could inflate asset bubbles, which could then burst dramatically when the LLMs decide to sell. This is especially risky because the LLMs might continue to follow their instructions even when a bubble is forming, unlike human traders who might recognize the bubble and adjust their strategy.\"\"\",\n",
    "        expected_output=\"\"\"If many firms deploy similarly prompted LLMs built on the same foundation model, their synchronised reactions could amplify volatility and create new instabilities.\"\"\",\n",
    "        context=[\n",
    "            \"\"\"A key concern is the potential for widespread correlated behavior… similar underlying LLM architectures responding uniformly… could destabilize trading patterns without explicit coordination.\"\"\"\n",
    "        ],\n",
    "        retrieval_context=[\n",
    "    \"\"\"2024). Another examines LLMs’ strategic capabilities through task-based simulations and\n",
    "collaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\n",
    "Within the computer science literature, early works apply LLMs to financial markets but\n",
    "abstract away many fundamental stock market characteristics. Often, they employ single-\n",
    "price clearing mechanisms without a persistent order book, ignore partial fills and bid-ask\n",
    "spreads, and omit dividends. Consequently, these simplified environments can primarily\n",
    "address exogenous macro shocks (e.g., changes in interest rates or inflation; Gao et al. 2024),\n",
    "exogenous policy changes (Zhang et al. 2024), or rely on advanced methods such as repetitive\n",
    "next-token predictions to generate better answers (Koa et al. 2024). This work extends\n",
    "these efforts by incorporating these crucial market features, enabling the study of complex\n",
    "endogenous events such as flash crashes, liquidity shocks, and large-trader impacts.\n",
    "This work also connects to emerging research on algorithmic and AI-powered trading\n",
    "systems. Dou, Goldstein, and Ji (2024) demonstrate how reinforcement learning-based AI\n",
    "speculators can autonomously learn to sustain collusive behavior without explicit coordi-\n",
    "nation, achieving supra-competitive profits through either price-trigger strategies or self-\n",
    "confirming bias in learning. This finding is particularly informative for this framework as\n",
    "it highlights potential emergent behaviors that may arise when intelligent agents interact in\n",
    "7\n",
    "markets—behaviors that could manifest differently with LLM agents due to their natural\n",
    "language reasoning capabilities. Similarly, Colliard, Foucault, and Lovo (2022) examine al-\n",
    "gorithmic market makers using Q-learning and find they charge markups that increase when\n",
    "adverse selection costs decrease—contrary to Nash equilibrium predictions. Their work pro-\n",
    "vides methodological insights on how to test strategic pricing behaviors against theoretical\n",
    "benchmarks incorporated into this LLM-based framework.\n",
    "Finally, this approach is informed by complexity economics, which views markets as dy-\n",
    "namic, non-equilibrium systems where agents adaptively learn and evolve strategies (Arthur\n",
    "2013; Wolfram 2017). According to this view, markets exhibit emergent phenomena and\n",
    "self-organization, especially when trading agents (human or artificial) update their behav-\n",
    "ior in response to outcomes. This paradigm is particularly relevant in an era of increasing\n",
    "automation and algorithmic trading (Balland et al. 2022; Ping 2019). Like adaptive agents\n",
    "in complexity economics, these LLM traders incorporate new information and adjust their\n",
    "strategies, generating emergent market patterns—a key motivation behind this framework.\n",
    "Unlike previous frameworks that abstract away crucial market features or focus on narrow\n",
    "strategies, this system incorporates realistic market microstructure while accommodating\n",
    "heterogeneous agents interacting simultaneously. While earlier work demonstrates LLMs’\n",
    "promise for macroeconomic modeling and simple trading simulations, this work introduces a\n",
    "complex, open-source financial market platform that supports multiple agent architectures,\n",
    "thorough market microstructure (limit orders, partial fills, dividends), and rigorous testing\n",
    "protocols—fulfilling a critical need in complexity economics research and market microstruc-\n",
    "ture analysis.\n",
    "2 Methodology\n",
    "The methodology section contains three parts. The first part describes the market design,\n",
    "the second agents’ design, and the third the analysis module.\n",
    "8\n",
    "2.1 Market Design\n",
    "Our methodological framework integrates three components that create a controlled envi-\n",
    "ronment for LLM-based trading agents. The framework implements a flexible continuous\n",
    "double-auction market mechanism that couples standard market microstructure principles\n",
    "with market clearing and matching algorithms to accommodate asynchronous LLM decisions.\"\"\",\n",
    "    \"\"\"Can Large Language Models Trade? Testing Financial\n",
    "Theories with LLM Agents in Market Simulations\n",
    "Alejandro Lopez-Lira∗\n",
    "First Version: November 29, 2024; Current Version: April 16, 2025\n",
    "Abstract\n",
    "This paper presents a realistic simulated stock market where large language models\n",
    "(LLMs) act as heterogeneous competing trading agents. The open-source framework\n",
    "incorporates a persistent order book with market and limit orders, partial fills, div-\n",
    "idends, and equilibrium clearing alongside agents with varied strategies, information\n",
    "sets, and endowments. Agents submit standardized decisions using structured outputs\n",
    "and function calls while expressing their reasoning in natural language. Three findings\n",
    "emerge: First, LLMs demonstrate consistent strategy adherence and can function as\n",
    "value investors, momentum traders, or market makers per their instructions. Second,\n",
    "market dynamics exhibit features of real financial markets, including price discovery,\n",
    "bubbles, underreaction, and strategic liquidity provision. Third, the framework enables\n",
    "analysis of LLMs’ responses to varying market conditions, similar to partial dependence\n",
    "plots in machine-learning interpretability. The framework allows simulating financial\n",
    "theories without closed-form solutions, creating experimental designs that would be\n",
    "costly with human participants, and establishing how prompts can generate correlated\n",
    "behaviors affecting market stability.\n",
    "Keywords: LLM Agents; Agent-Based Markets; Experimental Finance; AI Trading;\n",
    "Multi-Agent Systems\n",
    "∗University of Florida. Email: alejandro.lopez-lira@warrington.ufl.edu. I am grateful to seminar par-\n",
    "ticipants at the London Business School, Oxford University, Stockholm School of Economics, University of\n",
    "Virginia, and the City University of Hong Kong for helpful suggestions and feedback.\n",
    "1\n",
    "arXiv:2504.10789v1  [q-fin.CP]  15 Apr 2025\n",
    "1 Introduction\n",
    "Large language models (LLMs) can increasingly function as autonomous agents—systems\n",
    "that observe, reason, and act independently. LLMs have shown promising results in finan-\n",
    "cial forecasting, but their potential as trading agents introduces a fundamental shift from\n",
    "algorithms with explicit objectives to systems guided by natural language instructions. This\n",
    "change raises critical questions: Can LLMs execute trading strategies? Do LLMs optimize\n",
    "for profit maximization? What are the implications for market stability and efficiency?\n",
    "If LLMs trade similarly to humans, they could enable experimental market simulations\n",
    "without human participants. Conversely, if their trading behavior differs, understanding\n",
    "these differences becomes critical for systemic risk management. These questions extend be-\n",
    "yond theory; LLM-based strategies are already being deployed.1 To address these questions,\n",
    "I develop an open-source simulation that tests LLM trading agents in a realistic market envi-\n",
    "ronment with a persistent order book, supporting various order types, stochastic dividends,\n",
    "and heterogeneous information.\n",
    "The framework allows heterogeneous LLMs—defined in natural language, using different\n",
    "system prompts—to act as diverse types of traders, such as value investors, momentum\n",
    "traders, market makers, and contrarians. Agents submit standardized trading decisions in a\n",
    "human-readable format while expressing their reasoning transparently. Figure 1 illustrates\n",
    "this approach, showing how a speculator agent combines explicit valuation reasoning with\n",
    "structured trading parameters, enabling systematic analysis and insight into the agent’s\n",
    "decision-making process.\n",
    "The analysis reveals three key findings about LLMs’ capabilities as trading agents. First,\n",
    "LLMs can effectively execute trading strategies. They consistently understand market me-\n",
    "chanics, process market information, form price expectations, and execute trades according\n",
    "to specific instructions. Their trading behavior is highly sensitive to the prompts they\n",
    "receive—they faithfully follow directions regardless of profit implications. This observance\"\"\",\n",
    "    \"\"\"ripe for investigation using this tool include the emergence of novel trading strategies, the\n",
    "precise effects of agent heterogeneity on market stability, and the development of robust\n",
    "validation protocols for AI traders. As artificial intelligence becomes more integrated into\n",
    "finance, collaborative research leveraging adaptable simulation environments like this one\n",
    "will be crucial for understanding and responsibly shaping the future of trading.\n",
    "35\n",
    "References\n",
    "Arthur, W. Brian. 2013. “Complexity Economics : A Different Framework for Economic\n",
    "Thought.”\n",
    "Babina, Tania, Anastassia Fedyk, Alex He, and James Hodson. 2024. “Artificial Intelli-\n",
    "gence, Firm Growth, and Product Innovation.” Journal of Financial Economics 151\n",
    "(January 1, 2024): 103745.\n",
    "Balland, Pierre-Alexandre, Tom Broekel, Dario Diodato, Elisa Giuliani, Ricardo Hausmann,\n",
    "Neave O’Clery, and David Rigby. 2022. “The New Paradigm of Economic Complexity.”\n",
    "Research Policy51, no. 3 (April): 104450.\n",
    "Bianchi, Federico, Patrick John Chia, Mert Yuksekgonul, Jacopo Tagliabue, Dan Jurafsky,\n",
    "and James Zou. 2024. “How Well Can LLMs Negotiate? NegotiationArena Platform and\n",
    "Analysis.” arXiv.org.\n",
    "Bybee, J. Leland. 2023. “The Ghost in the Machine: Generating Beliefs with Large Language\n",
    "Models.” arXiv: 2305.02823.\n",
    "Campello, Murillo, Lin William Cong, and Luofeng Zhou. 2023. “AlphaManager: A Data-\n",
    "Driven-Robust-Control Approach to Corporate Finance.” Pre-published, December 2,\n",
    "2023. SSRN Scholarly Paper. Accessed December 22, 2024. https://doi.org/10.2139/\n",
    "ssrn.4590323. Social Science Research Network: 4590323. https://papers.ssrn.com/\n",
    "abstract=4590323.\n",
    "Chen, Yifei, Bryan T. Kelly, and Dacheng Xiu. 2022. “Expected Returns and Large Lan-\n",
    "guage Models.” Pre-published, November 22, 2022. SSRN Scholarly Paper. Accessed\n",
    "January 26, 2025. Social Science Research Network: 4416687. https://papers.ssrn.com/\n",
    "abstract=4416687.\n",
    "36\n",
    "Chen, Zihan, Lei Zheng, Chengyu Lu, Jialu Yuan, and Di Zhu. 2023. “ChatGPT Informed\n",
    "Graph Neural Network for Stock Movement Prediction.” Social Science Research Net-\n",
    "work.\n",
    "Chuang, Yun-Shiuan, Agam Goyal, Nikunj Harlalka, Siddharth Suresh, Robert Hawkins,\n",
    "Sijia Yang, Dhavan Shah, Junjie Hu, and Timothy T. Rogers. 2023. “Simulating Opin-\n",
    "ion Dynamics with Networks of LLM-based Agents.” North American Chapter of the\n",
    "Association for Computational Linguistic s.\n",
    "Colliard, Jean-Edouard, Thierry Foucault, and Stefano Lovo. 2022. “Algorithmic Pricing\n",
    "and Liquidity in Securities Markets.” Pre-published, October 18, 2022. SSRN Scholarly\n",
    "Paper. Accessed April 4, 2025. https://doi.org/10.2139/ssrn.4252858. Social Science\n",
    "Research Network: 4252858. https://papers.ssrn.com/abstract=4252858.\n",
    "Cong, Lin William, Ke Tang, Jingyuan Wang, and Yang Zhang. 2021. “AlphaPortfolio:\n",
    "Direct Construction Through Deep Reinforcement Learning and Interpretable AI.” Pre-\n",
    "published, August 1, 2021. SSRN Scholarly Paper. Accessed December 22, 2024. https:\n",
    "//doi.org/10.2139/ssrn.3554486. Social Science Research Network: 3554486. https:\n",
    "//papers.ssrn.com/abstract=3554486.\n",
    "Dou, Winston Wei, Itay Goldstein, and Yan Ji. 2024. “AI-Powered Trading, Algorithmic\n",
    "Collusion, and Price Efficiency.” Pre-published, May 30, 2024. SSRN Scholarly Paper.\n",
    "Accessed April 4, 2025. https://doi.org/10.2139/ssrn.4452704. Social Science Research\n",
    "Network: 4452704. https://papers.ssrn.com/abstract=4452704.\n",
    "Eisfeldt, Andrea L., Gregor Schubert, Miao Ben Zhang, and Bledi Taska. 2023. “Generative\n",
    "AI and Firm Values.” Pre-published, May 2, 2023. SSRN Scholarly Paper. Accessed\n",
    "January 26, 2025. https : / / doi .org / 10 .2139 / ssrn . 4436627. Social Science Research\n",
    "Network: 4436627. https://papers.ssrn.com/abstract=4436627.\n",
    "37\n",
    "Gao, Shen, Yuntao Wen, Minghang Zhu, Jianing Wei, Yuhan Cheng, Qunzi Zhang, and Shuo\n",
    "Shang. 2024. “Simulating Financial Market via Large Language Model Based Agents.”\n",
    "Pre-published, June 28, 2024. Accessed January 26, 2025. https://doi.org/10.48550/\"\"\",\n",
    "    \"\"\"33\n",
    "ants, allowing researchers to study how different belief structures influence price formation\n",
    "and trading patterns under different initial mispricings. In these scenarios, the fundamental\n",
    "price is hidden from agents, forcing them to rely on their own valuation models.\n",
    "3.2.5 Market Stress\n",
    "This scenario tests market resilience under challenging conditions by creating a more volatile\n",
    "environment. The scenario includes two consistently bullish Optimistic traders, two consis-\n",
    "tently bearish Pessimistic traders, two Market makers (liquidity providers), and two Value\n",
    "investors (rational benchmark traders). The scenario runs for 100 rounds to study long-term\n",
    "market behavior and includes unequal initial endowments, with optimistic traders having\n",
    "more cash (1.5x baseline) but fewer shares (0.5x baseline) and pessimistic traders having less\n",
    "cash (0.5x baseline) but more shares (1.5x baseline). This resource imbalance tests whether\n",
    "particular agent types can dominate market outcomes through resource advantages.\n",
    "The scenarios presented here demonstrate the framework’s capabilities for exploring di-\n",
    "verse market conditions. Its modular structure facilitates the straightforward definition and\n",
    "implementation of alternative experimental designs, enabling researchers to tailor simulations\n",
    "to specific research questions.\n",
    "In all scenarios, we maintain consistent baseline parameters with a fundamental value\n",
    "of $28.00, calculated from the expected dividend of $1.40 and interest rate of 5%. Agent\n",
    "endowments start at 1,000,000 monetary units and 10,000 shares unless specifically modified.\n",
    "Transaction costs are set to zero to isolate the effects of agent behavior and market structure\n",
    "on price formation.\n",
    "4 Conclusion\n",
    "This paper demonstrates that Large Language Models can effectively function as diverse\n",
    "trading agents—from value investors to market makers—maintaining strategic consistency\n",
    "34\n",
    "while adapting to market conditions. Our experimental framework reveals that their in-\n",
    "teractions generate realistic market dynamics, including phenomena like price bubbles and\n",
    "corrections, highlighting both the capabilities and potential risks of deploying LLM agents\n",
    "in financial markets.\n",
    "These findings carry significant implications for market structure and regulation. While\n",
    "LLM agents can enhance price discovery and liquidity, their adherence to programmed strate-\n",
    "gies, even potentially flawed ones derived from prompts, could amplify market volatility or\n",
    "introduce novel systemic risks, as observed in our simulated bubble scenarios. A key concern\n",
    "is the potential for widespread correlated behavior: similar underlying LLM architectures\n",
    "responding uniformly to comparable prompts or market signals could inadvertently create\n",
    "destabilizing trading patterns without explicit coordination. This underscores the critical\n",
    "need for rigorous testing and validation of LLM-based trading systems prior to live deploy-\n",
    "ment.\n",
    "A central contribution of this work is the open-source simulation framework itself, de-\n",
    "signed to catalyze research into LLM trading agents. We invite the research community to\n",
    "utilize and extend this platform to investigate pressing questions in this rapidly evolving\n",
    "area. The framework enables systematic exploration of complex scenarios—such as hybrid\n",
    "human-LLM markets, stress tests, varying market structures, regulatory impacts, and the\n",
    "nuances of LLM prompting—often difficult or costly to study otherwise. Specific avenues\n",
    "ripe for investigation using this tool include the emergence of novel trading strategies, the\n",
    "precise effects of agent heterogeneity on market stability, and the development of robust\n",
    "validation protocols for AI traders. As artificial intelligence becomes more integrated into\n",
    "finance, collaborative research leveraging adaptable simulation environments like this one\n",
    "will be crucial for understanding and responsibly shaping the future of trading.\n",
    "35\n",
    "References\"\"\",\n",
    "    \"\"\"(2023)). This work, however, focuses on financial markets and how LLM agents can operate\n",
    "as full-fledged trading participants.\n",
    "Recent research examines specific applications of LLMs for trading. FinMem and Trad-\n",
    "ingGPT introduce frameworks with layered memory systems and customizable agent traits\n",
    "5\n",
    "to improve financial decision-making (Yu, Li, et al. 2024; Li, Zhang, and Sun 2023). Hierar-\n",
    "chical multi-agent architectures have been explored in FinCon, which uses a manager-analyst\n",
    "setup for collaborative portfolio decisions (Yu, Yao, et al. 2024). QuantAgent implements\n",
    "a self-improving signal-mining approach (Wang et al. 2024), while other work underscores\n",
    "the importance of long-term memory in LLM agents via vector databases (Hatalis et al.\n",
    "2024). This line of research builds on successful reinforcement learning applications such as\n",
    "AlphaPortfolio (Cong et al. 2021) and AlphaManager (Campello, Cong, and Zhou 2023),\n",
    "which leverage deep RL and robust control for portfolio management.\n",
    "Analyzing LLM agent behavior by changing only some parameters draws on methods\n",
    "from the interpretable machine learning literature. In particular, the systematic variation\n",
    "of market parameters to reveal decision patterns mirrors partial dependence plots and in-\n",
    "dividual conditional expectation curves used to interpret complex machine learning models\n",
    "(Molnar 2022). These techniques help reveal how LLM agents respond to changes in specific\n",
    "variables while holding others constant, providing insight into their internal decision-making\n",
    "processes that would otherwise remain opaque.\n",
    "Beyond finance, studies of LLM capabilities in interactive or multi-agent settings offer\n",
    "valuable insights. Benchmarks like AgentBench evaluate LLMs’ performance in interac-\n",
    "tive tasks (Liu et al. 2023), while InvestorBench focuses on financial decision-making tasks\n",
    "specifically (H. Li et al. 2024). NegotiationArena demonstrates LLMs’ capacity for strategic\n",
    "interaction in bargaining contexts (Bianchi et al. 2024). Similarly, Guo et al. (2024) provide\n",
    "an economics ”arena” where LLMs compete in strategic games, revealing that advanced\n",
    "models like GPT-4 can exhibit rational, adaptive behavior—albeit not always reaching Nash\n",
    "Equilibrium. Existing frameworks typically assess individual agents or hierarchical collab-\n",
    "orations, whereas this work studies emergent market behaviors that arise from multiple\n",
    "independent LLM traders interacting in a marketplace.\n",
    "The approach also connects to the tradition of experimental asset markets. For instance,\n",
    "Weitzel et al. (2020) show that even finance professionals are susceptible to speculative\n",
    "6\n",
    "bubbles, especially amid high capital inflows. Kop´ anyi-Peuker and Weber (2021) find that\n",
    "trading experience alone does not eliminate bubbles, challenging assumptions about rational\n",
    "market learning. Kirchler, Huber, and St¨ ockl (2012) identify confusion about fundamental\n",
    "values as a key driver of bubble formation. This framework offers a new way to study these\n",
    "phenomena with LLM traders, which can be rigorously parameterized for sophistication,\n",
    "strategy, and information processing. Hence, this paper provides a method to investigate\n",
    "how automated or ”artificial” agents might affect market stability or volatility.\n",
    "Other recent work highlights the versatility of LLM agents in complex, interactive sce-\n",
    "narios beyond finance. One stream focuses on simulating social behaviors—such as opinion\n",
    "dynamics (Chuang et al. 2023), trust (Xie et al. 2024), and resource-sharing (Piatti et al.\n",
    "2024). Another examines LLMs’ strategic capabilities through task-based simulations and\n",
    "collaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\n",
    "Within the computer science literature, early works apply LLMs to financial markets but\n",
    "abstract away many fundamental stock market characteristics. Often, they employ single-\n",
    "price clearing mechanisms without a persistent order book, ignore partial fills and bid-ask\"\"\",\n",
    "    \"\"\"ceedings of the 62nd Annual Meeting of the Association for Computational Linguistics\n",
    "(Volume 1: Long Papers),edited by Lun-Wei Ku, Andre Martins, and Vivek Srikumar,\n",
    "15523–15536. ACL 2024. Bangkok, Thailand: Association for Computational Linguis-\n",
    "tics, August.\n",
    "39\n",
    "Li, Yuan, Yixuan Zhang, and Lichao Sun. 2023. “MetaAgents: Simulating Interactions of\n",
    "Human Behaviors for LLM-based T Ask-Oriented Coordination via Collaborative Gen-\n",
    "erative Agents.” arXiv.org.\n",
    "Liu, Xiao, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, et al. 2023.\n",
    "“AgentBench: Evaluating LLMs as Agents.”International Conference on Learning Rep-\n",
    "resentations.\n",
    "Lopez-Lira, Alejandro, and Yuehua Tang. 2023. “Can ChatGPT Forecast Stock Price Move-\n",
    "ments? Return Predictability and Large Language Models.” SSRN Electronic Journal\n",
    "(April 6, 2023).\n",
    "Manning, Benjamin S., Kehang Zhu, and John J. Horton. 2024. “Automated Social Science:\n",
    "Language Models as Scientist and Subjects.” (Cambridge, MA) (April 29, 2024).\n",
    "Molnar, Christoph. 2022. Interpretable Machine Learning.\n",
    "Pelster, Matthias, and Joel Val. 2023. “Can Chatgpt Assist in Picking Stocks?”Social Science\n",
    "Research Network.\n",
    "Piatti, Giorgio, Zhijing Jin, Max Kleiman-Weiner, Bernhard Sch¨ olkopf, Mrinmaya Sachan,\n",
    "and Rada Mihalcea. 2024. “Cooperate or Collapse: Emergence of Sustainable Coopera-\n",
    "tion in a Socie Ty of LLM Agents.” arXiv.org.\n",
    "Ping, Chen. 2019. “From Complexity Science to Complexity Economics.” In Alternative\n",
    "Approaches to Economic Theory,19–55. Routledge, June 11, 2019.\n",
    "Wang, Saizhuo, Hang Yuan, Lionel M. Ni, and Jian Guo. 2024. “QuantAgent: Seeking Holy\n",
    "Grail in Trading by Self-Improving Large Lang Uage Model.” arXiv.org.\n",
    "Weitzel, Utz, Christoph Huber, J¨ urgen Huber, Michael Kirchler, Florian Lindner, and Julia\n",
    "Rose. 2020. “Bubbles and Financial Professionals.” The Review of Financial Studies33,\n",
    "no. 6 (June 1, 2020): 2659–2696.\n",
    "40\n",
    "Wolfram, Elsner. 2017. “Complexity Economics as Heterodoxy: Theory and Policy.”Journal\n",
    "of Economic Issues51, no. 4 (October 2, 2017): 939–978.\n",
    "Woodhouse, Drew, and Alex Charlesworth. 2023. “Can ChatGPT Predict Future Interest\n",
    "Rate Decisions?” Social Science Research Network.\n",
    "Xie, Chengxing, Canyu Chen, Feiran Jia, Ziyu Ye, Shiyang Lai, Kai Shu, Jindong Gu, et al.\n",
    "2024. “Can Large Language Model Agents Simulate Human Trust Behavior?”arXiv.org.\n",
    "Yang, Stephen. 2023. “Predictive Patentomics: Forecasting Innovation Success and Valuation\n",
    "w Ith ChatGPT.” Social Science Research Network.\n",
    "Yu, Yangyang, Haohang Li, Zhi Chen, Yuechen Jiang, Yang Li, Denghui Zhang, Rong\n",
    "Liu, Jordan W. Suchow, and Khaldoun Khashanah. 2024. “FinMem: A Performance-\n",
    "Enhanced LLM Trading Agent with Layered Memory a Nd Character Design.”Proceed-\n",
    "ings of the AAAI Symposium Series3, no. 1 (May 20, 2024): 595–597.\n",
    "Yu, Yangyang, Zhiyuan Yao, Haohang Li, Zhiyang Deng, Yupeng Cao, Zhi Chen, Jordan W.\n",
    "Suchow, et al. 2024. “FinCon: A Synthesized LLM Multi-Agent System with Conceptual\n",
    "Verbal Reinforcement for Enhanced Financial Decision Making.” Pre-published, Novem-\n",
    "ber 7, 2024. Accessed January 8, 2025. https://doi.org/10.48550/arXiv.2407.06567.\n",
    "arXiv: 2407.06567 [cs]. http://arxiv.org/abs/2407.06567.\n",
    "Zhang, Chong, Xinyi Liu, Zhongmou Zhang, Mingyu Jin, Lingyao Li, Zhenting Wang,\n",
    "Wenyue Hua, et al. 2024. “When AI Meets Finance (StockAgent): Large Language\n",
    "Model-based Stock Trading in Simulated Real-world Environments.” Pre-published,\n",
    "September 21, 2024. Accessed January 26, 2025. https://doi.org /10.48550/arXiv .\n",
    "2407.18957. arXiv: 2407.18957 [q-fin]. http://arxiv.org/abs/2407.18957.\n",
    "41\n",
    "A Technical Implementation Details\n",
    "A.1 Agent Type Specifications\n",
    "This section details the base system prompts for each agent type in our simulation. These\n",
    "prompts define the core behavioral characteristics and trading strategies for each agent. Each\n",
    "prompt consists of:\n",
    "• A role definition that establishes the agent’s trading philosophy\n",
    "• A structured trading strategy that guides decision-making\"\"\",\n",
    "    \"\"\"an open-source framework with three key components: (1) a structured protocol for im-\n",
    "plementing and validating LLM trading agents, supporting both LLM-based and traditional\n",
    "rule-based agents; (2) a controlled market environment with realistic microstructure for test-\n",
    "ing agent interactions; and (3) a comprehensive data collection system for analyzing trading\n",
    "behavior. This framework serves multiple stakeholders in preparation for the evolution of\n",
    "financial markets: practitioners developing LLM-based trading systems, regulators antic-\n",
    "ipating widespread LLM adoption, and researchers studying market dynamics with LLM\n",
    "agents.\n",
    "1.1 Related Work\n",
    "This work contributes to several strands of literature. First, advancing the growing body\n",
    "of research on artificial intelligence in finance by demonstrating that large language mod-\n",
    "els (LLMs) can serve as effective autonomous trading agents while providing a framework\n",
    "for their implementation. Second, by contributing to the market microstructure literature\n",
    "by providing insights into how markets might evolve as LLM-based traders become active\n",
    "participants, with implications for price formation, liquidity provision, and market stabil-\n",
    "ity. Third, by contributing to experimental markets research by introducing an environment\n",
    "for studying complex trading interactions, offering unprecedented control and replicability\n",
    "compared to traditional human-subject experiments.\n",
    "4\n",
    "Recent studies have explored ChatGPT’s potential in various financial tasks. Research\n",
    "shows that ChatGPT can effectively predict stock price movements using news headlines,\n",
    "outperforming traditional sentiment analysis (Lopez-Lira and Tang 2023) and that forecast-\n",
    "ing with its embeddings outperforms traditional sentiment analysis (Chen, Kelly, and Xiu\n",
    "2022). When integrated with Graph Neural Networks, ChatGPT improves stock movement\n",
    "prediction and portfolio performance (Chen et al. 2023. ChatGPT can understand Federal\n",
    "Reserve communications Hansen and Kazinnik (2023). The model also can extract manage-\n",
    "rial expectations from corporate disclosures, predicting future investments and returns (Jha\n",
    "et al. 2025). ChatGPT-4 provides valuable investment advice with positive correlations to\n",
    "subsequent earnings announcements and stock returns (Pelster and Val 2023), and it en-\n",
    "hances patent value forecasts by processing patent text (Yang 2023). Moreover, ChatGPT\n",
    "shows promise in central bank analysis, predicting future interest rate decisions from pol-\n",
    "icy communications (Woodhouse and Charlesworth 2023). Recent work also focuses on the\n",
    "effects of AI adoption by firms (Eisfeldt et al. 2023, Babina et al. 2024).\n",
    "Foundational work on LLMs as economic agents demonstrates their ability to simulate\n",
    "human behavior in economic contexts. Horton (2023) introduce the concept of “homo silicus”\n",
    "by using LLMs as computational models of human behavior, showing that they can repli-\n",
    "cate classic behavioral economics findings. Manning, Zhu, and Horton (2024) extend this\n",
    "approach through automated methods for generating and testing social scientific hypotheses\n",
    "with LLMs, demonstrating strong results in market contexts such as auctions. Meanwhile,\n",
    "N. Li et al. (2024) show LLMs’ potential in macroeconomic simulation for consumption\n",
    "and labor decisions. Recent work also shows the potential of LLMs to proxy for human\n",
    "behavior in the context of surveys (Hansen et al. (2024)) or economic expectations (Bybee\n",
    "(2023)). This work, however, focuses on financial markets and how LLM agents can operate\n",
    "as full-fledged trading participants.\n",
    "Recent research examines specific applications of LLMs for trading. FinMem and Trad-\n",
    "ingGPT introduce frameworks with layered memory systems and customizable agent traits\n",
    "5\n",
    "to improve financial decision-making (Yu, Li, et al. 2024; Li, Zhang, and Sun 2023). Hierar-\n",
    "chical multi-agent architectures have been explored in FinCon, which uses a manager-analyst\"\"\",\n",
    "    \"\"\"decision-making process.\n",
    "The analysis reveals three key findings about LLMs’ capabilities as trading agents. First,\n",
    "LLMs can effectively execute trading strategies. They consistently understand market me-\n",
    "chanics, process market information, form price expectations, and execute trades according\n",
    "to specific instructions. Their trading behavior is highly sensitive to the prompts they\n",
    "receive—they faithfully follow directions regardless of profit implications. This observance\n",
    "1. For example, Autopilot has a ChatGPT-based portfolio https://x.com/thegptinvestor.\n",
    "2\n",
    "{\"valuation_reasoning\":\n",
    "\"The fundamental value is based on the expected dividend,\n",
    "and the interest rate.\n",
    "The expected dividend is $1.40, and the interest rate is 5%.\n",
    "Using a perpetuity formula, the value is $1.40 / 0.05 = $28.\",\n",
    "\"valuation\":28.0,\n",
    "\"price_target_reasoning\":\"The current price is $29.00, which is\n",
    "slightly above the fundamental value of $28.00. I expect the price\n",
    "to remain around $29.00 in the next round due to market stability.\",\n",
    "\"price_target\":29.0,\n",
    "\"orders\":[{\"decision\":\"Sell\",\"quantity\":1000,\"order_type\":\"limit\",\n",
    "\"price_limit\":29.50}],\n",
    "\"replace_decision\":\"Add\",\n",
    "\"reasoning\":\"The current price is slightly above the fundamental value.\n",
    "I will place a limit sell order at $29.50 to capitalize on potential price\n",
    "increases.\"}\n",
    "Figure 1: Example of a structured trading decision from a Speculator agent defined by its\n",
    "system prompt: “You are a speculator who tries to profit from market inefficiencies.”. The\n",
    "LLM provides explicit reasoning for its valuation, price target, and trading decision in a\n",
    "machine-readable JSON format that can be directly processed by the trading system.\n",
    "highlights a fundamental difference from human traders: LLMs do not inherently optimize\n",
    "for profit maximization but rather for following instructions accurately.\n",
    "Second, LLMs react meaningfully to market dynamics. They consider current and his-\n",
    "torical prices, dividends, and other market information when making decisions. However,\n",
    "they maintain their strategic direction even when market conditions change, following their\n",
    "instructions even if doing so results in financial losses. This combination of responsiveness\n",
    "to market conditions while maintaining strategic consistency creates a unique trading profile\n",
    "distinct from rule-based algorithms and human traders.\n",
    "Third, market dynamics with LLM agents can resemble actual markets and mirror classic\n",
    "results from the theoretical finance literature. When these agents interact, they produce\n",
    "realistic price discovery and liquidity provision with emergent behaviors, including price\n",
    "convergence toward fundamental values. Depending on the distribution of agent types,\n",
    "the system can generate various market phenomena, such as bubbles or underreactions to\n",
    "information. This complex behavior suggests potential applications for studying market\n",
    "3\n",
    "dynamics using LLM agents instead of experiments with human participants.\n",
    "Hence, these findings raise important questions about algorithmic consistency in LLM-\n",
    "based systems. Since trading agents are implemented through prompts, their behavior in-\n",
    "herits characteristics of the underlying language models. The standardization of LLM ar-\n",
    "chitectures across implementations could create unexpected behavioral patterns—if many\n",
    "agents are based on similar foundation models, they might exhibit correlated responses to\n",
    "specific market conditions, potentially amplifying market instabilities.\n",
    "To enable this analysis and accelerate development in this emerging field, we provide\n",
    "an open-source framework with three key components: (1) a structured protocol for im-\n",
    "plementing and validating LLM trading agents, supporting both LLM-based and traditional\n",
    "rule-based agents; (2) a controlled market environment with realistic microstructure for test-\n",
    "ing agent interactions; and (3) a comprehensive data collection system for analyzing trading\n",
    "behavior. This framework serves multiple stakeholders in preparation for the evolution of\"\"\",\n",
    "]\n",
    "    ),\n",
    "    LLMTestCase(\n",
    "        input=\"In SRCNN, what practical role does the non‑linear mapping layer with 1 × 1 filters play in the overall SR pipeline?\",\n",
    "        actual_output=\"The non-linear mapping layer in SRCNN, which uses 1x1 filters, essentially acts as a feature selector and combiner within the super-resolution pipeline. Think of the initial layer as extracting a set of features from the low-resolution image. This second layer then takes these features and recombines them in non-linear ways to create a more informative and refined set of features. While 1x1 convolutions don't change the spatial dimensions, they allow the network to learn complex relationships between the different feature maps (different aspects of the visual information) extracted by the first layer. This step is crucial for capturing the intricate details needed to reconstruct a high-resolution image. The ReLU (Rectified Linear Unit, a function that replaces negative values with zero) activation further enhances this non-linearity, adding another level of expressiveness to the model.\",\n",
    "        expected_output=\"\"\"It transforms every patch‑level feature vector (extracted by the first conv layer) into a new, lower‑dimensional representation that will later be linearly combined into HR pixels. Because the spatial kernel is 1 × 1, the mapping is applied channel‑wise without mixing spatial positions, mimicking the sparse‑coding step but in a single feed‑forward pass.\"\"\",\n",
    "        context=[\n",
    "            \"\"\"The first layer extracts an n₁‑dimensional feature for each patch. In the second operation, we **map each of these n₁‑dimensional vectors into an n₂‑dimensional one. This is equivalent to applying n₂ filters which have a trivial spatial support 1 × 1 … This operation non‑linearly maps each high‑dimensional vector onto another high‑dimensional vector.\"\"\"\n",
    "        ],\n",
    "        retrieval_context=[\n",
    "    \"\"\"In this paper, we show that the aforementioned\n",
    "pipeline is equivalent to a deep convolutional neural net-\n",
    "work [27] (more details in Section 3.2). Motivated by this\n",
    "fact, we consider a convolutional neural network that\n",
    "directly learns an end-to-end mapping between low- and\n",
    "high-resolution images. Our method differs fundamen-\n",
    "tally from existing external example-based approaches,\n",
    "in that ours does not explicitly learn the dictionaries [41],\n",
    "[49], [50] or manifolds [2], [4] for modeling the patch\n",
    "space. These are implicitly achieved via hidden layers.\n",
    "Furthermore, the patch extraction and aggregation are\n",
    "also formulated as convolutional layers, so are involved\n",
    "in the optimization. In our method, the entire SR pipeline\n",
    "is fully obtained through learning, with little pre/post-\n",
    "processing.\n",
    "We name the proposed model Super-Resolution Con-\n",
    "volutional Neural Network (SRCNN) 1. The proposed\n",
    "SRCNN has several appealing properties. First, its struc-\n",
    "ture is intentionally designed with simplicity in mind,\n",
    "and yet provides superior accuracy 2 compared with\n",
    "state-of-the-art example-based methods. Figure 1 shows\n",
    "a comparison on an example. Second, with moderate\n",
    "1. The implementation is available at http://mmlab.ie.cuhk.edu.hk/\n",
    "projects/SRCNN.html.\n",
    "2. Numerical evaluations by using different metrics such as the Peak\n",
    "Signal-to-Noise Ratio (PSNR), structure similarity index (SSIM) [43],\n",
    "multi-scale SSIM [44], information ﬁdelity criterion [38], when the\n",
    "ground truth images are available.\n",
    "arXiv:1501.00092v3  [cs.CV]  31 Jul 2015\n",
    "2\n",
    "Bicubic / 24.04 dB\n",
    "SC / 25.58 dBSRCNN / 27.95 dB\n",
    "Original / PSNR\n",
    "2 4 6 8 10 12x 108\n",
    "29.5\n",
    "30\n",
    "30.5\n",
    "31\n",
    "31.5\n",
    "32\n",
    "32.5\n",
    "33\n",
    "Number of backprops\n",
    "Average test PSNR (dB)\n",
    "SRCNN\n",
    "SC\n",
    "Bicubic\n",
    "Bicubic / 24.04 dB\n",
    "SC / 25.58 dBSRCNN / 27.95 dB\n",
    "Original / PSNR\n",
    "Bicubic / 24.04 dB\n",
    "SC / 25.58 dBSRCNN / 27.95 dB\n",
    "Original / PSNR\n",
    "SRCNN\n",
    "SC\n",
    "Bicubic\n",
    "Bicubic / 24.04 dB\n",
    "SC / 25.58 dBSRCNN / 27.95 dB\n",
    "Original / PSNR\n",
    "Number of backprops\n",
    "Average test PSNR (dB)\n",
    "Fig. 1. The proposed Super-Resolution Convolutional\n",
    "Neural Network (SRCNN) surpasses the bicubic baseline\n",
    "with just a few training iterations, and outperforms the\n",
    "sparse-coding-based method (SC) [50] with moderate\n",
    "training. The performance may be further improved with\n",
    "more training iterations. More details are provided in\n",
    "Section 4.4.1 (the Set5 dataset with an upscaling factor\n",
    "3). The proposed method provides visually appealing\n",
    "reconstructed image.\n",
    "numbers of ﬁlters and layers, our method achieves\n",
    "fast speed for practical on-line usage even on a CPU.\n",
    "Our method is faster than a number of example-based\n",
    "methods, because it is fully feed-forward and does\n",
    "not need to solve any optimization problem on usage.\n",
    "Third, experiments show that the restoration quality of\n",
    "the network can be further improved when (i) larger\n",
    "and more diverse datasets are available, and/or (ii)\n",
    "a larger and deeper model is used. On the contrary,\n",
    "larger datasets/models can present challenges for exist-\n",
    "ing example-based methods. Furthermore, the proposed\n",
    "network can cope with three channels of color images\n",
    "simultaneously to achieve improved super-resolution\n",
    "performance.\n",
    "Overall, the contributions of this study are mainly in\n",
    "three aspects:\n",
    "1) We present a fully convolutional neural net-\n",
    "work for image super-resolution. The network di-\n",
    "rectly learns an end-to-end mapping between low-\n",
    "and high-resolution images, with little pre/post-\n",
    "processing beyond the optimization.\n",
    "2) We establish a relationship between our deep-\n",
    "learning-based SR method and the traditional\n",
    "sparse-coding-based SR methods. This relationship\n",
    "provides a guidance for the design of the network\n",
    "structure.\n",
    "3) We demonstrate that deep learning is useful in\n",
    "the classical computer vision problem of super-\n",
    "resolution, and can achieve good quality and\n",
    "speed.\n",
    "A preliminary version of this work was presented\n",
    "earlier [11]. The present work adds to the initial version\n",
    "in signiﬁcant ways. Firstly, we improve the SRCNN by\n",
    "introducing larger ﬁlter size in the non-linear mapping\"\"\",\n",
    "    \"\"\"the ﬁnal full image. The averaging can be considered\n",
    "as a pre-deﬁned ﬁlter on a set of feature maps (where\n",
    "each position is the “ﬂattened” vector form of a high-\n",
    "resolution patch). Motivated by this, we deﬁne a convo-\n",
    "lutional layer to produce the ﬁnal high-resolution image:\n",
    "F(Y) = W3 ∗F2(Y) + B3. (3)\n",
    "4. The ReLU can be equivalently considered as a part of the second\n",
    "operation (Non-linear mapping), and the ﬁrst operation (Patch extrac-\n",
    "tion and representation) becomes purely linear convolution.\n",
    "Here W3 corresponds to c ﬁlters of a size n2 ×f3 ×f3,\n",
    "and B3 is a c-dimensional vector.\n",
    "If the representations of the high-resolution patches\n",
    "are in the image domain (i.e.,we can simply reshape each\n",
    "representation to form the patch), we expect that the\n",
    "ﬁlters act like an averaging ﬁlter; if the representations\n",
    "of the high-resolution patches are in some other domains\n",
    "(e.g.,coefﬁcients in terms of some bases), we expect that\n",
    "W3 behaves like ﬁrst projecting the coefﬁcients onto the\n",
    "image domain and then averaging. In either way, W3 is\n",
    "a set of linear ﬁlters.\n",
    "Interestingly, although the above three operations are\n",
    "motivated by different intuitions, they all lead to the\n",
    "same form as a convolutional layer. We put all three\n",
    "operations together and form a convolutional neural\n",
    "network (Figure 2). In this model, all the ﬁltering weights\n",
    "and biases are to be optimized. Despite the succinctness\n",
    "of the overall structure, our SRCNN model is carefully\n",
    "developed by drawing extensive experience resulted\n",
    "from signiﬁcant progresses in super-resolution [49], [50].\n",
    "We detail the relationship in the next section.\n",
    "3.2 Relationship to Sparse-Coding-Based Methods\n",
    "We show that the sparse-coding-based SR methods [49],\n",
    "[50] can be viewed as a convolutional neural network.\n",
    "Figure 3 shows an illustration.\n",
    "In the sparse-coding-based methods, let us consider\n",
    "that an f1 ×f1 low-resolution patch is extracted from\n",
    "the input image. Then the sparse coding solver, like\n",
    "Feature-Sign [29], will ﬁrst project the patch onto a (low-\n",
    "resolution) dictionary. If the dictionary size is n1, this\n",
    "is equivalent to applying n1 linear ﬁlters ( f1 ×f1) on\n",
    "the input image (the mean subtraction is also a linear\n",
    "operation so can be absorbed). This is illustrated as the\n",
    "left part of Figure 3.\n",
    "The sparse coding solver will then iteratively process\n",
    "the n1 coefﬁcients. The outputs of this solver are n2\n",
    "coefﬁcients, and usually n2 = n1 in the case of sparse\n",
    "coding. These n2 coefﬁcients are the representation of\n",
    "the high-resolution patch. In this sense, the sparse coding\n",
    "5\n",
    "responses\n",
    "of patch of\n",
    "neighbouring\n",
    "patches\n",
    " Patch extraction\n",
    "and representation\n",
    "Non-linear\n",
    " mapping\n",
    "Reconstruction\n",
    "Fig. 3. An illustration of sparse-coding-based methods in the view of a convolutional neural network.\n",
    "solver behaves as a special case of a non-linear mapping\n",
    "operator, whose spatial support is 1 ×1. See the middle\n",
    "part of Figure 3. However, the sparse coding solver is\n",
    "not feed-forward, i.e.,it is an iterative algorithm. On the\n",
    "contrary, our non-linear operator is fully feed-forward\n",
    "and can be computed efﬁciently. If we set f2 = 1, then\n",
    "our non-linear operator can be considered as a pixel-wise\n",
    "fully-connected layer. It is worth noting that “the sparse\n",
    "coding solver” in SRCNN refers to the ﬁrst two layers,\n",
    "but not just the second layer or the activation function\n",
    "(ReLU). Thus the nonlinear operation in SRCNN is also\n",
    "well optimized through the learning process.\n",
    "The above n2 coefﬁcients (after sparse coding) are\n",
    "then projected onto another (high-resolution) dictionary\n",
    "to produce a high-resolution patch. The overlapping\n",
    "high-resolution patches are then averaged. As discussed\n",
    "above, this is equivalent to linear convolutions on the\n",
    "n2 feature maps. If the high-resolution patches used for\n",
    "reconstruction are of size f3 ×f3, then the linear ﬁlters\n",
    "have an equivalent spatial support of size f3 ×f3. See\n",
    "the right part of Figure 3.\n",
    "The above discussion shows that the sparse-coding-\"\"\",\n",
    "    \"\"\"only on the luminance channel. There are also works\n",
    "attempting to super-resolve all channels simultaneously.\n",
    "For example, Kim and Kwon [25] and Dai et al.[7] apply\n",
    "their model to each RGB channel and combined them to\n",
    "produce the ﬁnal results. However, none of them has\n",
    "analyzed the SR performance of different channels, and\n",
    "the necessity of recovering all three channels.\n",
    "2.2 Convolutional Neural Networks\n",
    "Convolutional neural networks (CNN) date back\n",
    "decades [27] and deep CNNs have recently shown an\n",
    "explosive popularity partially due to its success in image\n",
    "classiﬁcation [18], [26]. They have also been success-\n",
    "fully applied to other computer vision ﬁelds, such as\n",
    "object detection [34], [40], [52], face recognition [39], and\n",
    "pedestrian detection [35]. Several factors are of central\n",
    "importance in this progress: (i) the efﬁcient training\n",
    "implementation on modern powerful GPUs [26], (ii) the\n",
    "proposal of the Rectiﬁed Linear Unit (ReLU) [33] which\n",
    "makes convergence much faster while still presents good\n",
    "quality [26], and (iii) the easy access to an abundance of\n",
    "data (like ImageNet [9]) for training larger models. Our\n",
    "method also beneﬁts from these progresses.\n",
    "2.3 Deep Learning for Image Restoration\n",
    "There have been a few studies of using deep learning\n",
    "techniques for image restoration. The multi-layer per-\n",
    "ceptron (MLP), whose all layers are fully-connected (in\n",
    "contrast to convolutional), is applied for natural image\n",
    "denoising [3] and post-deblurring denoising [36]. More\n",
    "closely related to our work, the convolutional neural net-\n",
    "work is applied for natural image denoising [22] and re-\n",
    "moving noisy patterns (dirt/rain) [12]. These restoration\n",
    "problems are more or less denoising-driven. Cui et al.[5]\n",
    "propose to embed auto-encoder networks in their super-\n",
    "resolution pipeline under the notion internal example-\n",
    "based approach [16]. The deep model is not speciﬁcally\n",
    "designed to be an end-to-end solution, since each layer\n",
    "of the cascade requires independent optimization of the\n",
    "self-similarity search process and the auto-encoder. On\n",
    "the contrary, the proposed SRCNN optimizes an end-to-\n",
    "end mapping. Further, the SRCNN is faster at speed. It\n",
    "is not only a quantitatively superior method, but also a\n",
    "practically useful one.\n",
    "3 C ONVOLUTIONAL NEURAL NETWORKS FOR\n",
    "SUPER -RESOLUTION\n",
    "3.1 Formulation\n",
    "Consider a single low-resolution image, we ﬁrst upscale\n",
    "it to the desired size using bicubic interpolation, which\n",
    "is the only pre-processing we perform 3. Let us denote\n",
    "the interpolated image as Y. Our goal is to recover\n",
    "from Y an image F(Y) that is as similar as possible\n",
    "to the ground truth high-resolution image X. For the\n",
    "ease of presentation, we still call Y a “low-resolution”\n",
    "image, although it has the same size as X. We wish to\n",
    "learn a mapping F, which conceptually consists of three\n",
    "operations:\n",
    "1) Patch extraction and representation: this opera-\n",
    "tion extracts (overlapping) patches from the low-\n",
    "resolution image Y and represents each patch as a\n",
    "high-dimensional vector. These vectors comprise a\n",
    "set of feature maps, of which the number equals to\n",
    "the dimensionality of the vectors.\n",
    "2) Non-linear mapping: this operation nonlinearly\n",
    "maps each high-dimensional vector onto another\n",
    "high-dimensional vector. Each mapped vector is\n",
    "conceptually the representation of a high-resolution\n",
    "patch. These vectors comprise another set of feature\n",
    "maps.\n",
    "3) Reconstruction: this operation aggregates the\n",
    "above high-resolution patch-wise representations\n",
    "to generate the ﬁnal high-resolution image. This\n",
    "image is expected to be similar to the ground truth\n",
    "X.\n",
    "We will show that all these operations form a convolu-\n",
    "tional neural network. An overview of the network is\n",
    "depicted in Figure 2. Next we detail our deﬁnition of\n",
    "each operation.\n",
    "3.1.1 Patch extraction and representation\n",
    "A popular strategy in image restoration ( e.g., [1]) is to\n",
    "densely extract patches and then represent them by a set\n",
    "of pre-trained bases such as PCA, DCT, Haar, etc. This\"\"\",\n",
    "    \"\"\"sparse-coding-based SR methods. This relationship\n",
    "provides a guidance for the design of the network\n",
    "structure.\n",
    "3) We demonstrate that deep learning is useful in\n",
    "the classical computer vision problem of super-\n",
    "resolution, and can achieve good quality and\n",
    "speed.\n",
    "A preliminary version of this work was presented\n",
    "earlier [11]. The present work adds to the initial version\n",
    "in signiﬁcant ways. Firstly, we improve the SRCNN by\n",
    "introducing larger ﬁlter size in the non-linear mapping\n",
    "layer, and explore deeper structures by adding non-\n",
    "linear mapping layers. Secondly, we extend the SRCNN\n",
    "to process three color channels (either in YCbCr or RGB\n",
    "color space) simultaneously. Experimentally, we demon-\n",
    "strate that performance can be improved in comparison\n",
    "to the single-channel network. Thirdly, considerable new\n",
    "analyses and intuitive explanations are added to the\n",
    "initial results. We also extend the original experiments\n",
    "from Set5 [2] and Set14 [51] test images to BSD200 [32]\n",
    "(200 test images). In addition, we compare with a num-\n",
    "ber of recently published methods and conﬁrm that\n",
    "our model still outperforms existing approaches using\n",
    "different evaluation metrics.\n",
    "2 R ELATED WORK\n",
    "2.1 Image Super-Resolution\n",
    "According to the image priors, single-image super res-\n",
    "olution algorithms can be categorized into four types –\n",
    "prediction models, edge based methods, image statistical\n",
    "methods and patch based (or example-based) methods.\n",
    "These methods have been thoroughly investigated and\n",
    "evaluated in Yang et al.’s work [46]. Among them, the\n",
    "example-based methods [16], [25], [41], [47] achieve the\n",
    "state-of-the-art performance.\n",
    "The internal example-based methods exploit the self-\n",
    "similarity property and generate exemplar patches from\n",
    "the input image. It is ﬁrst proposed in Glasner’s\n",
    "work [16], and several improved variants [13], [45] are\n",
    "proposed to accelerate the implementation. The exter-\n",
    "nal example-based methods [2], [4], [6], [15], [37], [41],\n",
    "[48], [49], [50], [51] learn a mapping between low/high-\n",
    "resolution patches from external datasets. These studies\n",
    "vary on how to learn a compact dictionary or manifold\n",
    "space to relate low/high-resolution patches, and on how\n",
    "representation schemes can be conducted in such spaces.\n",
    "In the pioneer work of Freeman et al. [14], the dic-\n",
    "tionaries are directly presented as low/high-resolution\n",
    "patch pairs, and the nearest neighbour (NN) of the input\n",
    "patch is found in the low-resolution space, with its corre-\n",
    "sponding high-resolution patch used for reconstruction.\n",
    "Chang et al. [4] introduce a manifold embedding tech-\n",
    "nique as an alternative to the NN strategy. In Yanget al.’s\n",
    "work [49], [50], the above NN correspondence advances\n",
    "to a more sophisticated sparse coding formulation. Other\n",
    "mapping functions such as kernel regression [25], simple\n",
    "3\n",
    "function [47], random forest [37] and anchored neigh-\n",
    "borhood regression [41], [42] are proposed to further\n",
    "improve the mapping accuracy and speed. The sparse-\n",
    "coding-based method and its several improvements [41],\n",
    "[42], [48] are among the state-of-the-art SR methods\n",
    "nowadays. In these methods, the patches are the focus\n",
    "of the optimization; the patch extraction and aggregation\n",
    "steps are considered as pre/post-processing and handled\n",
    "separately.\n",
    "The majority of SR algorithms [2], [4], [15], [41], [48],\n",
    "[49], [50], [51] focus on gray-scale or single-channel\n",
    "image super-resolution. For color images, the aforemen-\n",
    "tioned methods ﬁrst transform the problem to a dif-\n",
    "ferent color space (YCbCr or YUV), and SR is applied\n",
    "only on the luminance channel. There are also works\n",
    "attempting to super-resolve all channels simultaneously.\n",
    "For example, Kim and Kwon [25] and Dai et al.[7] apply\n",
    "their model to each RGB channel and combined them to\n",
    "produce the ﬁnal results. However, none of them has\n",
    "analyzed the SR performance of different channels, and\n",
    "the necessity of recovering all three channels.\n",
    "2.2 Convolutional Neural Networks\n",
    "Convolutional neural networks (CNN) date back\"\"\",\n",
    "    \"\"\"1\n",
    "Image Super-Resolution Using Deep\n",
    "Convolutional Networks\n",
    "Chao Dong, Chen Change Loy, Member, IEEE,Kaiming He, Member, IEEE,\n",
    "and Xiaoou Tang, Fellow, IEEE\n",
    "Abstract—We propose a deep learning method for single image super-resolution (SR). Our method directly learns an end-to-end\n",
    "mapping between the low/high-resolution images. The mapping is represented as a deep convolutional neural network (CNN) that takes\n",
    "the low-resolution image as the input and outputs the high-resolution one. We further show that traditional sparse-coding-based SR\n",
    "methods can also be viewed as a deep convolutional network. But unlike traditional methods that handle each component separately,\n",
    "our method jointly optimizes all layers. Our deep CNN has a lightweight structure, yet demonstrates state-of-the-art restoration quality,\n",
    "and achieves fast speed for practical on-line usage. We explore different network structures and parameter settings to achieve trade-\n",
    "offs between performance and speed. Moreover, we extend our network to cope with three color channels simultaneously, and show\n",
    "better overall reconstruction quality.\n",
    "Index Terms—Super-resolution, deep convolutional neural networks, sparse coding\n",
    "!\n",
    "1 I NTRODUCTION\n",
    "Single image super-resolution (SR) [20], which aims at\n",
    "recovering a high-resolution image from a single low-\n",
    "resolution image, is a classical problem in computer\n",
    "vision. This problem is inherently ill-posed since a mul-\n",
    "tiplicity of solutions exist for any given low-resolution\n",
    "pixel. In other words, it is an underdetermined in-\n",
    "verse problem, of which solution is not unique. Such\n",
    "a problem is typically mitigated by constraining the\n",
    "solution space by strong prior information. To learn\n",
    "the prior, recent state-of-the-art methods mostly adopt\n",
    "the example-based [46] strategy. These methods either\n",
    "exploit internal similarities of the same image [5], [13],\n",
    "[16], [19], [47], or learn mapping functions from external\n",
    "low- and high-resolution exemplar pairs [2], [4], [6],\n",
    "[15], [23], [25], [37], [41], [42], [47], [48], [50], [51]. The\n",
    "external example-based methods can be formulated for\n",
    "generic image super-resolution, or can be designed to\n",
    "suit domain speciﬁc tasks, i.e., face hallucination [30],\n",
    "[50], according to the training samples provided.\n",
    "The sparse-coding-based method [49], [50] is one of the\n",
    "representative external example-based SR methods. This\n",
    "method involves several steps in its solution pipeline.\n",
    "First, overlapping patches are densely cropped from the\n",
    "input image and pre-processed ( e.g.,subtracting mean\n",
    "and normalization). These patches are then encoded\n",
    "by a low-resolution dictionary. The sparse coefﬁcients\n",
    "are passed into a high-resolution dictionary for recon-\n",
    "structing high-resolution patches. The overlapping re-\n",
    "• C. Dong, C. C. Loy and X. Tang are with the Department of Information\n",
    "Engineering, The Chinese University of Hong Kong, Hong Kong.\n",
    "E-mail: {dc012,ccloy,xtang}@ie.cuhk.edu.hk\n",
    "• K. He is with the Visual Computing Group, Microsoft Research Asia,\n",
    "Beijing 100080, China.\n",
    "Email: kahe@microsoft.com\n",
    "constructed patches are aggregated ( e.g., by weighted\n",
    "averaging) to produce the ﬁnal output. This pipeline is\n",
    "shared by most external example-based methods, which\n",
    "pay particular attention to learning and optimizing the\n",
    "dictionaries [2], [49], [50] or building efﬁcient mapping\n",
    "functions [25], [41], [42], [47]. However, the rest of the\n",
    "steps in the pipeline have been rarely optimized or\n",
    "considered in an uniﬁed optimization framework.\n",
    "In this paper, we show that the aforementioned\n",
    "pipeline is equivalent to a deep convolutional neural net-\n",
    "work [27] (more details in Section 3.2). Motivated by this\n",
    "fact, we consider a convolutional neural network that\n",
    "directly learns an end-to-end mapping between low- and\n",
    "high-resolution images. Our method differs fundamen-\n",
    "tally from existing external example-based approaches,\n",
    "in that ours does not explicitly learn the dictionaries [41],\n",
    "[49], [50] or manifolds [2], [4] for modeling the patch\"\"\",\n",
    "    \"\"\"bicubic interpolation. The training falls into a bad local\n",
    "minimum, due to the inherently different characteristics\n",
    "of the Y and Cb, Cr channels. (ii) If we pre-train on the\n",
    "Y or Cb, Cr channels, the performance ﬁnally improves,\n",
    "but is still not better than “Y only” on the color image\n",
    "(see the last column of Table 5, where PSNR is computed\n",
    "(a) First-layer ﬁlters – Cb channel\n",
    "(b) First-layer ﬁlters – Cr channel\n",
    "Fig. 13. Chrominance channels of the ﬁrst-layer ﬁlters\n",
    "using the “Y pre-train” strategy.\n",
    "in RGB color space). This suggests that the Cb, Cr\n",
    "channels could decrease the performance of the Y chan-\n",
    "nel when training is performed in a uniﬁed network.\n",
    "(iii) We observe that the Cb, Cr channels have higher\n",
    "PSNR values for “Y pre-train” than for “CbCr pre-train”.\n",
    "The reason lies on the differences between the Cb, Cr\n",
    "channels and the Y channel. Visually, the Cb, Cr channels\n",
    "are more blurry than the Y channel, thus are less affected\n",
    "by the downsampling process. When we pre-train on\n",
    "the Cb, Cr channels, there are only a few ﬁlters being\n",
    "activated. Then the training will soon fall into a bad\n",
    "local minimum during ﬁne-tuning. On the other hand,\n",
    "if we pre-train on the Y channel, more ﬁlters will be\n",
    "activated, and the performance on Cb, Cr channels will\n",
    "be pushed much higher. Figure 13 shows the Cb, Cr\n",
    "channels of the ﬁrst-layer ﬁlters with “Y pre-train”, of\n",
    "which the patterns largely differ from that shown in\n",
    "Figure 5. (iv) Training on the RGB channels achieves\n",
    "the best result on the color image. Different from the\n",
    "YCbCr channels, the RGB channels exhibit high cross-\n",
    "correlation among each other. The proposed SRCNN\n",
    "is capable of leveraging such natural correspondences\n",
    "between the channels for reconstruction. Therefore, the\n",
    "model achieves comparable result on the Y channel as\n",
    "“Y only”, and better results on Cb, Cr channels than\n",
    "bicubic interpolation. (v) In KK [25], super-resolution\n",
    "is applied on each RGB channel separately. When we\n",
    "transform its results to YCbCr space, the PSNR value\n",
    "of Y channel is similar as “Y only”, but that of Cb, Cr\n",
    "channels are poorer than bicubic interpolation. The result\n",
    "suggests that the algorithm is biased to the Y channel.\n",
    "On the whole, our method trained on RGB channels\n",
    "achieves better performance than KK and the single-\n",
    "channel network (“Y only”). It is also worth noting that\n",
    "the improvement compared with the single-channel net-\n",
    "work is not that signiﬁcant ( i.e., 0.07 dB). This indicates\n",
    "that the Cb, Cr channels barely help in improving the\n",
    "performance.\n",
    "5 C ONCLUSION\n",
    "We have presented a novel deep learning approach\n",
    "for single image super-resolution (SR). We show that\n",
    "conventional sparse-coding-based SR methods can be\n",
    "12\n",
    "reformulated into a deep convolutional neural network.\n",
    "The proposed approach, SRCNN, learns an end-to-end\n",
    "mapping between low- and high-resolution images, with\n",
    "little extra pre/post-processing beyond the optimization.\n",
    "With a lightweight structure, the SRCNN has achieved\n",
    "superior performance than the state-of-the-art methods.\n",
    "We conjecture that additional performance can be further\n",
    "gained by exploring more ﬁlters and different training\n",
    "strategies. Besides, the proposed structure, with its ad-\n",
    "vantages of simplicity and robustness, could be applied\n",
    "to other low-level vision problems, such as image de-\n",
    "blurring or simultaneous SR+denoising. One could also\n",
    "investigate a network to cope with different upscaling\n",
    "factors.\n",
    "REFERENCES\n",
    "[1] Aharon, M., Elad, M., Bruckstein, A.: K-SVD: An algorithm for\n",
    "designing overcomplete dictionaries for sparse representation.\n",
    "IEEE Transactions on Signal Processing 54(11), 4311–4322 (2006)\n",
    "[2] Bevilacqua, M., Roumy, A., Guillemot, C., Morel, M.L.A.: Low-\n",
    "complexity single-image super-resolution based on nonnegative\n",
    "neighbor embedding. In: British Machine Vision Conference\n",
    "(2012)\n",
    "[3] Burger, H.C., Schuler, C.J., Harmeling, S.: Image denoising: Can\n",
    "plain neural networks compete with BM3D? In: IEEE Conference\"\"\",\n",
    "    \"\"\"to generate the ﬁnal high-resolution image. This\n",
    "image is expected to be similar to the ground truth\n",
    "X.\n",
    "We will show that all these operations form a convolu-\n",
    "tional neural network. An overview of the network is\n",
    "depicted in Figure 2. Next we detail our deﬁnition of\n",
    "each operation.\n",
    "3.1.1 Patch extraction and representation\n",
    "A popular strategy in image restoration ( e.g., [1]) is to\n",
    "densely extract patches and then represent them by a set\n",
    "of pre-trained bases such as PCA, DCT, Haar, etc. This\n",
    "is equivalent to convolving the image by a set of ﬁlters,\n",
    "each of which is a basis. In our formulation, we involve\n",
    "the optimization of these bases into the optimization of\n",
    "the network. Formally, our ﬁrst layer is expressed as an\n",
    "operation F1:\n",
    "F1(Y) = max (0,W1 ∗Y + B1) , (1)\n",
    "where W1 and B1 represent the ﬁlters and biases re-\n",
    "spectively, and ’ ∗’ denotes the convolution operation.\n",
    "Here, W1 corresponds to n1 ﬁlters of support c×f1 ×f1,\n",
    "where c is the number of channels in the input image,\n",
    "f1 is the spatial size of a ﬁlter. Intuitively, W1 applies\n",
    "n1 convolutions on the image, and each convolution has\n",
    "3. Bicubic interpolation is also a convolutional operation, so it can\n",
    "be formulated as a convolutional layer. However, the output size of\n",
    "this layer is larger than the input size, so there is a fractional stride. To\n",
    "take advantage of the popular well-optimized implementations such\n",
    "as cuda-convnet [26], we exclude this “layer” from learning.\n",
    "4\n",
    "feature maps\n",
    " Patch extraction\n",
    "and representation Non-linear mapping Reconstruction\n",
    "Low-resolution\n",
    "image (input)\n",
    "High-resolution\n",
    "image (output)\n",
    "of low-resolution image of high-resolution image\n",
    "feature maps\n",
    "Fig. 2. Given a low-resolution image Y, the ﬁrst convolutional layer of the SRCNN extracts a set of feature maps. The\n",
    "second layer maps these feature maps nonlinearly to high-resolution patch representations. The last layer combines\n",
    "the predictions within a spatial neighbourhood to produce the ﬁnal high-resolution image F(Y).\n",
    "a kernel size c ×f1 ×f1. The output is composed of\n",
    "n1 feature maps. B1 is an n1-dimensional vector, whose\n",
    "each element is associated with a ﬁlter. We apply the\n",
    "Rectiﬁed Linear Unit (ReLU, max(0,x)) [33] on the ﬁlter\n",
    "responses4.\n",
    "3.1.2 Non-linear mapping\n",
    "The ﬁrst layer extracts an n1-dimensional feature for\n",
    "each patch. In the second operation, we map each of\n",
    "these n1-dimensional vectors into an n2-dimensional\n",
    "one. This is equivalent to applying n2 ﬁlters which have\n",
    "a trivial spatial support 1 ×1. This interpretation is only\n",
    "valid for 1×1 ﬁlters. But it is easy to generalize to larger\n",
    "ﬁlters like 3 ×3 or 5 ×5. In that case, the non-linear\n",
    "mapping is not on a patch of the input image; instead,\n",
    "it is on a 3 ×3 or 5 ×5 “patch” of the feature map. The\n",
    "operation of the second layer is:\n",
    "F2(Y) = max (0,W2 ∗F1(Y) + B2) . (2)\n",
    "Here W2 contains n2 ﬁlters of size n1 ×f2 ×f2, and B2 is\n",
    "n2-dimensional. Each of the output n2-dimensional vec-\n",
    "tors is conceptually a representation of a high-resolution\n",
    "patch that will be used for reconstruction.\n",
    "It is possible to add more convolutional layers to\n",
    "increase the non-linearity. But this can increase the com-\n",
    "plexity of the model ( n2 ×f2 ×f2 ×n2 parameters for\n",
    "one layer), and thus demands more training time. We\n",
    "will explore deeper structures by introducing additional\n",
    "non-linear mapping layers in Section 4.3.3.\n",
    "3.1.3 Reconstruction\n",
    "In the traditional methods, the predicted overlapping\n",
    "high-resolution patches are often averaged to produce\n",
    "the ﬁnal full image. The averaging can be considered\n",
    "as a pre-deﬁned ﬁlter on a set of feature maps (where\n",
    "each position is the “ﬂattened” vector form of a high-\n",
    "resolution patch). Motivated by this, we deﬁne a convo-\n",
    "lutional layer to produce the ﬁnal high-resolution image:\n",
    "F(Y) = W3 ∗F2(Y) + B3. (3)\n",
    "4. The ReLU can be equivalently considered as a part of the second\n",
    "operation (Non-linear mapping), and the ﬁrst operation (Patch extrac-\n",
    "tion and representation) becomes purely linear convolution.\"\"\",\n",
    "    \"\"\"erations, ηis the learning rate, and ∂L\n",
    "∂W ℓ\n",
    "i\n",
    "is the derivative.\n",
    "The ﬁlter weights of each layer are initialized by drawing\n",
    "randomly from a Gaussian distribution with zero mean\n",
    "and standard deviation 0.001 (and 0 for biases). The\n",
    "learning rate is 10−4 for the ﬁrst two layers, and 10−5 for\n",
    "the last layer. We empirically ﬁnd that a smaller learning\n",
    "rate in the last layer is important for the network to\n",
    "converge (similar to the denoising case [22]).\n",
    "In the training phase, the ground truth images {Xi}\n",
    "are prepared as fsub×fsub×c-pixel sub-images randomly\n",
    "cropped from the training images. By “sub-images” we\n",
    "mean these samples are treated as small “images” rather\n",
    "than “patches”, in the sense that “patches” are overlap-\n",
    "ping and require some averaging as post-processing but\n",
    "“sub-images” need not. To synthesize the low-resolution\n",
    "samples {Yi}, we blur a sub-image by a Gaussian kernel,\n",
    "sub-sample it by the upscaling factor, and upscale it by\n",
    "the same factor via bicubic interpolation.\n",
    "To avoid border effects during training, all the con-\n",
    "volutional layers have no padding, and the network\n",
    "produces a smaller output ( (fsub −f1 −f2 −f3 + 3)2 ×c).\n",
    "The MSE loss function is evaluated only by the difference\n",
    "between the central pixels of Xi and the network output.\n",
    "Although we use a ﬁxed image size in training, the\n",
    "convolutional neural network can be applied on images\n",
    "of arbitrary sizes during testing.\n",
    "We implement our model using the cuda-convnet pack-\n",
    "age [26]. We have also tried the Caffe package [24] and\n",
    "observed similar performance.\n",
    "4 E XPERIMENTS\n",
    "We ﬁrst investigate the impact of using different datasets\n",
    "on the model performance. Next, we examine the ﬁlters\n",
    "learned by our approach. We then explore different\n",
    "architecture designs of the network, and study the rela-\n",
    "tions between super-resolution performance and factors\n",
    "like depth, number of ﬁlters, and ﬁlter sizes. Subse-\n",
    "quently, we compare our method with recent state-of-\n",
    "the-arts both quantitatively and qualitatively. Following\n",
    "[42], super-resolution is only applied on the luminance\n",
    "channel (Y channel in YCbCr color space) in Sections 4.1-\n",
    "4.4, so c = 1 in the ﬁrst/last layer, and performance\n",
    "(e.g., PSNR and SSIM) is evaluated on the Y channel. At\n",
    "last, we extend the network to cope with color images\n",
    "and evaluate the performance on different channels.\n",
    "4.1 Training Data\n",
    "As shown in the literature, deep learning generally\n",
    "beneﬁts from big data training. For comparison, we use\n",
    "a relatively small training set [41], [50] that consists\n",
    "of 91 images, and a large training set that consists of\n",
    "395,909 images from the ILSVRC 2013 ImageNet detec-\n",
    "tion training partition. The size of training sub-images is\n",
    "fsub = 33. Thus the 91-image dataset can be decomposed\n",
    "into 24,800 sub-images, which are extracted from origi-\n",
    "nal images with a stride of 14. Whereas the ImageNet\n",
    "provides over 5 million sub-images even using a stride\n",
    "of 33. We use the basic network settings, i.e., f1 = 9 ,\n",
    "f2 = 1, f3 = 5, n1 = 64, and n2 = 32. We use the Set5 [2]\n",
    "as the validation set. We observe a similar trend even\n",
    "if we use the larger Set14 set [51]. The upscaling factor\n",
    "is 3. We use the sparse-coding-based method [50] as our\n",
    "baseline, which achieves an average PSNR value of 31.42\n",
    "dB.\n",
    "The test convergence curves of using different training\n",
    "sets are shown in Figure 4. The training time on Ima-\n",
    "geNet is about the same as on the 91-image dataset since\n",
    "the number of backpropagations is the same. As can be\n",
    "observed, with the same number of backpropagations\n",
    "(i.e.,8 ×108), the SRCNN +ImageNet achieves 32.52 dB,\n",
    "higher than 32.39 dB yielded by that trained on 91\n",
    "images. The results positively indicate that SRCNN per-\n",
    "formance may be further boosted using a larger training\n",
    "set, but the effect of big data is not as impressive as\n",
    "that shown in high-level vision problems [26]. This is\n",
    "mainly because that the 91 images have already cap-\n",
    "tured sufﬁcient variability of natural images. On the\"\"\",\n",
    "]\n",
    "    ),\n",
    "    LLMTestCase(\n",
    "        input=\"Why do the authors of SRCNN first upscale the LR image with bicubic interpolation instead of learning that step end‑to‑end?\",\n",
    "        actual_output=\"\"\"The authors of SRCNN pre-upscale the low-resolution (LR) image using bicubic interpolation (a standard image resizing technique) primarily to simplify the learning process and reduce computational cost. While learning the upscaling step end-to-end is possible, it would significantly increase the complexity of the model and require more resources for training. By pre-upscaling, the network only needs to learn the non-linear mapping between the interpolated image and the high-resolution image, which is a simpler task. They mention this is the only pre-processing step they perform.\"\"\",\n",
    "        expected_output=\"\"\"Because popular GPU conv‑net toolkits (cuda‑convnet at the time) did not yet support fractional‑stride convolutions. Upscaling once with bicubic ensures the network can stay fully convolutional with integer strides while still learning the rest of the SR mapping end‑to‑end.\"\"\",\n",
    "        context=[\n",
    "            \"\"\"…we first upscale it to the desired size using bicubic interpolation, which is the only pre‑processing we perform. … There is a fractional stride. To take advantage of the popular well‑optimized implementations such as cuda‑convnet, we exclude this “layer” from learning.\"\"\"\n",
    "        ],\n",
    "        retrieval_context=[\n",
    "    \"\"\"bicubic interpolation. The training falls into a bad local\n",
    "minimum, due to the inherently different characteristics\n",
    "of the Y and Cb, Cr channels. (ii) If we pre-train on the\n",
    "Y or Cb, Cr channels, the performance ﬁnally improves,\n",
    "but is still not better than “Y only” on the color image\n",
    "(see the last column of Table 5, where PSNR is computed\n",
    "(a) First-layer ﬁlters – Cb channel\n",
    "(b) First-layer ﬁlters – Cr channel\n",
    "Fig. 13. Chrominance channels of the ﬁrst-layer ﬁlters\n",
    "using the “Y pre-train” strategy.\n",
    "in RGB color space). This suggests that the Cb, Cr\n",
    "channels could decrease the performance of the Y chan-\n",
    "nel when training is performed in a uniﬁed network.\n",
    "(iii) We observe that the Cb, Cr channels have higher\n",
    "PSNR values for “Y pre-train” than for “CbCr pre-train”.\n",
    "The reason lies on the differences between the Cb, Cr\n",
    "channels and the Y channel. Visually, the Cb, Cr channels\n",
    "are more blurry than the Y channel, thus are less affected\n",
    "by the downsampling process. When we pre-train on\n",
    "the Cb, Cr channels, there are only a few ﬁlters being\n",
    "activated. Then the training will soon fall into a bad\n",
    "local minimum during ﬁne-tuning. On the other hand,\n",
    "if we pre-train on the Y channel, more ﬁlters will be\n",
    "activated, and the performance on Cb, Cr channels will\n",
    "be pushed much higher. Figure 13 shows the Cb, Cr\n",
    "channels of the ﬁrst-layer ﬁlters with “Y pre-train”, of\n",
    "which the patterns largely differ from that shown in\n",
    "Figure 5. (iv) Training on the RGB channels achieves\n",
    "the best result on the color image. Different from the\n",
    "YCbCr channels, the RGB channels exhibit high cross-\n",
    "correlation among each other. The proposed SRCNN\n",
    "is capable of leveraging such natural correspondences\n",
    "between the channels for reconstruction. Therefore, the\n",
    "model achieves comparable result on the Y channel as\n",
    "“Y only”, and better results on Cb, Cr channels than\n",
    "bicubic interpolation. (v) In KK [25], super-resolution\n",
    "is applied on each RGB channel separately. When we\n",
    "transform its results to YCbCr space, the PSNR value\n",
    "of Y channel is similar as “Y only”, but that of Cb, Cr\n",
    "channels are poorer than bicubic interpolation. The result\n",
    "suggests that the algorithm is biased to the Y channel.\n",
    "On the whole, our method trained on RGB channels\n",
    "achieves better performance than KK and the single-\n",
    "channel network (“Y only”). It is also worth noting that\n",
    "the improvement compared with the single-channel net-\n",
    "work is not that signiﬁcant ( i.e., 0.07 dB). This indicates\n",
    "that the Cb, Cr channels barely help in improving the\n",
    "performance.\n",
    "5 C ONCLUSION\n",
    "We have presented a novel deep learning approach\n",
    "for single image super-resolution (SR). We show that\n",
    "conventional sparse-coding-based SR methods can be\n",
    "12\n",
    "reformulated into a deep convolutional neural network.\n",
    "The proposed approach, SRCNN, learns an end-to-end\n",
    "mapping between low- and high-resolution images, with\n",
    "little extra pre/post-processing beyond the optimization.\n",
    "With a lightweight structure, the SRCNN has achieved\n",
    "superior performance than the state-of-the-art methods.\n",
    "We conjecture that additional performance can be further\n",
    "gained by exploring more ﬁlters and different training\n",
    "strategies. Besides, the proposed structure, with its ad-\n",
    "vantages of simplicity and robustness, could be applied\n",
    "to other low-level vision problems, such as image de-\n",
    "blurring or simultaneous SR+denoising. One could also\n",
    "investigate a network to cope with different upscaling\n",
    "factors.\n",
    "REFERENCES\n",
    "[1] Aharon, M., Elad, M., Bruckstein, A.: K-SVD: An algorithm for\n",
    "designing overcomplete dictionaries for sparse representation.\n",
    "IEEE Transactions on Signal Processing 54(11), 4311–4322 (2006)\n",
    "[2] Bevilacqua, M., Roumy, A., Guillemot, C., Morel, M.L.A.: Low-\n",
    "complexity single-image super-resolution based on nonnegative\n",
    "neighbor embedding. In: British Machine Vision Conference\n",
    "(2012)\n",
    "[3] Burger, H.C., Schuler, C.J., Harmeling, S.: Image denoising: Can\n",
    "plain neural networks compete with BM3D? In: IEEE Conference\"\"\",\n",
    "    \"\"\"In this paper, we show that the aforementioned\n",
    "pipeline is equivalent to a deep convolutional neural net-\n",
    "work [27] (more details in Section 3.2). Motivated by this\n",
    "fact, we consider a convolutional neural network that\n",
    "directly learns an end-to-end mapping between low- and\n",
    "high-resolution images. Our method differs fundamen-\n",
    "tally from existing external example-based approaches,\n",
    "in that ours does not explicitly learn the dictionaries [41],\n",
    "[49], [50] or manifolds [2], [4] for modeling the patch\n",
    "space. These are implicitly achieved via hidden layers.\n",
    "Furthermore, the patch extraction and aggregation are\n",
    "also formulated as convolutional layers, so are involved\n",
    "in the optimization. In our method, the entire SR pipeline\n",
    "is fully obtained through learning, with little pre/post-\n",
    "processing.\n",
    "We name the proposed model Super-Resolution Con-\n",
    "volutional Neural Network (SRCNN) 1. The proposed\n",
    "SRCNN has several appealing properties. First, its struc-\n",
    "ture is intentionally designed with simplicity in mind,\n",
    "and yet provides superior accuracy 2 compared with\n",
    "state-of-the-art example-based methods. Figure 1 shows\n",
    "a comparison on an example. Second, with moderate\n",
    "1. The implementation is available at http://mmlab.ie.cuhk.edu.hk/\n",
    "projects/SRCNN.html.\n",
    "2. Numerical evaluations by using different metrics such as the Peak\n",
    "Signal-to-Noise Ratio (PSNR), structure similarity index (SSIM) [43],\n",
    "multi-scale SSIM [44], information ﬁdelity criterion [38], when the\n",
    "ground truth images are available.\n",
    "arXiv:1501.00092v3  [cs.CV]  31 Jul 2015\n",
    "2\n",
    "Bicubic / 24.04 dB\n",
    "SC / 25.58 dBSRCNN / 27.95 dB\n",
    "Original / PSNR\n",
    "2 4 6 8 10 12x 108\n",
    "29.5\n",
    "30\n",
    "30.5\n",
    "31\n",
    "31.5\n",
    "32\n",
    "32.5\n",
    "33\n",
    "Number of backprops\n",
    "Average test PSNR (dB)\n",
    "SRCNN\n",
    "SC\n",
    "Bicubic\n",
    "Bicubic / 24.04 dB\n",
    "SC / 25.58 dBSRCNN / 27.95 dB\n",
    "Original / PSNR\n",
    "Bicubic / 24.04 dB\n",
    "SC / 25.58 dBSRCNN / 27.95 dB\n",
    "Original / PSNR\n",
    "SRCNN\n",
    "SC\n",
    "Bicubic\n",
    "Bicubic / 24.04 dB\n",
    "SC / 25.58 dBSRCNN / 27.95 dB\n",
    "Original / PSNR\n",
    "Number of backprops\n",
    "Average test PSNR (dB)\n",
    "Fig. 1. The proposed Super-Resolution Convolutional\n",
    "Neural Network (SRCNN) surpasses the bicubic baseline\n",
    "with just a few training iterations, and outperforms the\n",
    "sparse-coding-based method (SC) [50] with moderate\n",
    "training. The performance may be further improved with\n",
    "more training iterations. More details are provided in\n",
    "Section 4.4.1 (the Set5 dataset with an upscaling factor\n",
    "3). The proposed method provides visually appealing\n",
    "reconstructed image.\n",
    "numbers of ﬁlters and layers, our method achieves\n",
    "fast speed for practical on-line usage even on a CPU.\n",
    "Our method is faster than a number of example-based\n",
    "methods, because it is fully feed-forward and does\n",
    "not need to solve any optimization problem on usage.\n",
    "Third, experiments show that the restoration quality of\n",
    "the network can be further improved when (i) larger\n",
    "and more diverse datasets are available, and/or (ii)\n",
    "a larger and deeper model is used. On the contrary,\n",
    "larger datasets/models can present challenges for exist-\n",
    "ing example-based methods. Furthermore, the proposed\n",
    "network can cope with three channels of color images\n",
    "simultaneously to achieve improved super-resolution\n",
    "performance.\n",
    "Overall, the contributions of this study are mainly in\n",
    "three aspects:\n",
    "1) We present a fully convolutional neural net-\n",
    "work for image super-resolution. The network di-\n",
    "rectly learns an end-to-end mapping between low-\n",
    "and high-resolution images, with little pre/post-\n",
    "processing beyond the optimization.\n",
    "2) We establish a relationship between our deep-\n",
    "learning-based SR method and the traditional\n",
    "sparse-coding-based SR methods. This relationship\n",
    "provides a guidance for the design of the network\n",
    "structure.\n",
    "3) We demonstrate that deep learning is useful in\n",
    "the classical computer vision problem of super-\n",
    "resolution, and can achieve good quality and\n",
    "speed.\n",
    "A preliminary version of this work was presented\n",
    "earlier [11]. The present work adds to the initial version\n",
    "in signiﬁcant ways. Firstly, we improve the SRCNN by\n",
    "introducing larger ﬁlter size in the non-linear mapping\"\"\",\n",
    "    \"\"\"terion (IFC) [38], noise quality measure (NQM) [8],\n",
    "weighted peak signal-to-noise ratio (WPSNR) and multi-\n",
    "scale structure similarity index (MSSSIM) [44], which\n",
    "obtain high correlation with the human perceptual scores\n",
    "as reported in [46].\n",
    "4.4.1 Quantitative and qualitative evaluation\n",
    "As shown in Tables 2, 3 and 4, the proposed SRCNN\n",
    "yields the highest scores in most evaluation matrices\n",
    "7. In the area of denoising [3], for each noise level a speciﬁc network\n",
    "is trained.\n",
    "8. We use the same 200 images as in [46].\n",
    "9\n",
    "2 4 6 8 10 12\n",
    "x(10\n",
    "8\n",
    "30.5\n",
    "31\n",
    "31.5\n",
    "32\n",
    "32.5\n",
    "33\n",
    "Number(of(backprops\n",
    "Average(test(PSNR((dB)\n",
    "ANR - 31.92 dB\n",
    "A+ - 32.59 dB\n",
    "SRCNN\n",
    "SC - 31.42 dB\n",
    "Bicubic - 30.39 dB\n",
    "NE+LLE - 31.84 dB\n",
    "KK - 32.28 dB\n",
    "Fig. 10. The test convergence curve of SRCNN and\n",
    "results of other methods on the Set5 dataset.\n",
    "in all experiments 9. Note that our SRCNN results are\n",
    "based on the checkpoint of 8 ×108 backpropagations.\n",
    "Speciﬁcally, for the upscaling factor 3, the average gains\n",
    "on PSNR achieved by SRCNN are 0.15 dB, 0.17 dB, and\n",
    "0.13 dB, higher than the next best approach, A+ [42],\n",
    "on the three datasets. When we take a look at other\n",
    "evaluation metrics, we observe that SC, to our surprise,\n",
    "gets even lower scores than the bicubic interpolation\n",
    "on IFC and NQM. It is clear that the results of SC are\n",
    "more visually pleasing than that of bicubic interpolation.\n",
    "This indicates that these two metrics may not truthfully\n",
    "reveal the image quality. Thus, regardless of these two\n",
    "metrics, SRCNN achieves the best performance among\n",
    "all methods and scaling factors.\n",
    "It is worth pointing out that SRCNN surpasses the\n",
    "bicubic baseline at the very beginning of the learning\n",
    "stage (see Figure 1), and with moderate training, SR-\n",
    "CNN outperforms existing state-of-the-art methods (see\n",
    "Figure 4). Yet, the performance is far from converge.\n",
    "We conjecture that better results can be obtained given\n",
    "longer training time (see Figure 10).\n",
    "Figures 14, 15 and 16 show the super-resolution results\n",
    "of different approaches by an upscaling factor 3. As can\n",
    "be observed, the SRCNN produces much sharper edges\n",
    "than other approaches without any obvious artifacts\n",
    "across the image.\n",
    "In addition, we report to another recent deep learning\n",
    "method for image super-resolution (DNC) of Cui et\n",
    "al. [5]. As they employ a different blur kernel (a Gaussian\n",
    "ﬁlter with a standard deviation of 0.55), we train a spe-\n",
    "ciﬁc network (9-5-5) using the same blur kernel as DNC\n",
    "for fair quantitative comparison. The upscaling factor\n",
    "is 3 and the training set is the 91-image dataset. From\n",
    "the convergence curve shown in Figure 11, we observe\n",
    "that our SRCNN surpasses DNC with just 2.7 ×107\n",
    "backprops, and a larger margin can be obtained given\n",
    "longer training time. This also demonstrates that the\n",
    "end-to-end learning is superior to DNC, even if that\n",
    "model is already “deep”.\n",
    "4.4.2 Running time\n",
    "Figure 12 shows the running time comparisons of several\n",
    "state-of-the-art methods, along with their restoration\n",
    "performance on Set14. All baseline methods are obtained\n",
    "9. The PSNR value of each image can be found in the supplementary\n",
    "ﬁle.\n",
    "from the corresponding authors’ MATLAB+MEX imple-\n",
    "mentation, whereas ours are in pure C++. We proﬁle\n",
    "the running time of all the algorithms using the same\n",
    "machine (Intel CPU 3.10 GHz and 16 GB memory).\n",
    "Note that the processing time of our approach is highly\n",
    "linear to the test image resolution, since all images go\n",
    "through the same number of convolutions. Our method\n",
    "is always a trade-off between performance and speed.\n",
    "To show this, we train three networks for comparison,\n",
    "which are 9-1-5, 9-3-5, and 9-5-5. It is clear that the 9-\n",
    "1-5 network is the fastest, while it still achieves better\n",
    "performance than the next state-of-the-art A+. Other\n",
    "methods are several times or even orders of magnitude\n",
    "slower in comparison to 9-1-5 network. Note the speed\n",
    "gap is not mainly caused by the different MATLAB/C++\n",
    "implementations; rather, the other methods need to solve\n",
    "complex optimization problems on usage (e.g., sparse\"\"\",\n",
    "    \"\"\"4 0.7019 - 0.7331 0.7419 0.7352 0.7491 0.7513\n",
    "2 6.09 - 7.59 6.83 7.81 8.11 7.76\n",
    "IFC 3 3.41 2.98 4.14 3.83 4.23 4.45 4.26\n",
    "4 2.23 - 2.71 2.57 2.78 2.94 2.74\n",
    "2 40.98 - 41.34 38.86 41.79 42.61 38.95\n",
    "NQM 3 33.15 29.06 37.12 35.23 37.22 38.24 35.25\n",
    "4 26.15 - 31.17 29.18 31.27 32.31 30.46\n",
    "2 47.64 - 54.47 53.85 54.57 55.62 55.39\n",
    "WPSNR 3 39.72 41.66 43.22 43.56 43.36 44.25 44.32\n",
    "4 35.71 - 37.75 38.26 37.85 38.72 38.87\n",
    "2 0.9813 - 0.9886 0.9890 0.9888 0.9896 0.9897\n",
    "MSSSIM 3 0.9512 0.9595 0.9643 0.9653 0.9647 0.9669 0.9675\n",
    "4 0.9134 - 0.9317 0.9338 0.9326 0.9371 0.9376\n",
    "TABLE 4\n",
    "The average results of PSNR (dB), SSIM, IFC, NQM, WPSNR (dB) and MSSIM on the BSD200 dataset.\n",
    "Eval. Mat Scale Bicubic SC [50] NE+LLE [4] KK [25] ANR [41] A+ [41] SRCNN\n",
    "2 28.38 - 29.67 30.02 29.72 30.14 30.29\n",
    "PSNR 3 25.94 26.54 26.67 26.89 26.72 27.05 27.18\n",
    "4 24.65 - 25.21 25.38 25.25 25.51 25.60\n",
    "2 0.8524 - 0.8886 0.8935 0.8900 0.8966 0.8977\n",
    "SSIM 3 0.7469 0.7729 0.7823 0.7881 0.7843 0.7945 0.7971\n",
    "4 0.6727 - 0.7037 0.7093 0.7060 0.7171 0.7184\n",
    "2 5.30 - 7.10 6.33 7.28 7.51 7.21\n",
    "IFC 3 3.05 2.77 3.82 3.52 3.91 4.07 3.91\n",
    "4 1.95 - 2.45 2.24 2.51 2.62 2.45\n",
    "2 36.84 - 41.52 38.54 41.72 42.37 39.66\n",
    "NQM 3 28.45 28.22 34.65 33.45 34.81 35.58 34.72\n",
    "4 21.72 - 25.15 24.87 25.27 26.01 25.65\n",
    "2 46.15 - 52.56 52.21 52.69 53.56 53.58\n",
    "WPSNR 3 38.60 40.48 41.39 41.62 41.53 42.19 42.29\n",
    "4 34.86 - 36.52 36.80 36.64 37.18 37.24\n",
    "2 0.9780 - 0.9869 0.9876 0.9872 0.9883 0.9883\n",
    "MSSSIM 3 0.9426 0.9533 0.9575 0.9588 0.9581 0.9609 0.9614\n",
    "4 0.9005 - 0.9203 0.9215 0.9214 0.9256 0.9261\n",
    "11\n",
    "10\n",
    "0\n",
    "10\n",
    "1\n",
    "10\n",
    "228.2\n",
    "28.4\n",
    "28.6\n",
    "28.8\n",
    "29\n",
    "29.2\n",
    "29.4\n",
    "Running time (sec)\n",
    "PSNR (dB)\n",
    "SC\n",
    "NE+LLE ANR\n",
    "KK\n",
    "A+\n",
    "SRCNN(9-1-5)\n",
    "SRCNN(9-3-5) SRCNN(9-5-5)\n",
    "——> FasterSlower <——\n",
    "Fig. 12. The proposed SRCNN achieves the state-\n",
    "of-the-art super-resolution quality, whilst maintains high\n",
    "and competitive speed in comparison to existing external\n",
    "example-based methods. The chart is based on Set14\n",
    "results summarized in Table 3. The implementation of all\n",
    "three SRCNN networks are available on our project page.\n",
    "TABLE 5\n",
    "Average PSNR (dB) of different channels and training\n",
    "strategies on the Set5 dataset.\n",
    "Training PSNR of different channel(s)\n",
    "Strategies Y Cb Cr RGB color image\n",
    "Bicubic 30.39 45.44 45.42 34.57\n",
    "Y only 32.39 45.44 45.42 36.37\n",
    "YCbCr 29.25 43.30 43.49 33.47\n",
    "Y pre-train 32.19 46.49 46.45 36.32\n",
    "CbCr pre-train 32.14 46.38 45.84 36.25\n",
    "RGB 32.33 46.18 46.20 36.44\n",
    "KK 32.37 44.35 44.22 36.32\n",
    "effectiveness of SRCNN on different scales, here we only\n",
    "evaluate the performance of upscaling factor 3.\n",
    "Comparisons. We compare our method with the state-\n",
    "of-art color SR method – KK [25]. We also try different\n",
    "learning strategies for comparison:\n",
    "• Y only: this is our baseline method, which is a\n",
    "single-channel ( c = 1 ) network trained only on\n",
    "the luminance channel. The Cb, Cr channels are\n",
    "upscaled using bicubic interpolation.\n",
    "• YCbCr: training is performed on the three channels\n",
    "of the YCbCr space.\n",
    "• Y pre-train: ﬁrst, to guarantee the performance on\n",
    "the Y channel, we only use the MSE of the Y channel\n",
    "as the loss to pre-train the network. Then we employ\n",
    "the MSE of all channels to ﬁne-tune the parameters.\n",
    "• CbCr pre-train: we use the MSE of the Cb, Cr\n",
    "channels as the loss to pre-train the network, then\n",
    "ﬁne-tune the parameters on all channels.\n",
    "• RGB: training is performed on the three channels of\n",
    "the RGB space.\n",
    "The results are shown in Table 5, where we have the\n",
    "following observations. (i) If we directly train on the\n",
    "YCbCr channels, the results are even worse than that of\n",
    "bicubic interpolation. The training falls into a bad local\n",
    "minimum, due to the inherently different characteristics\n",
    "of the Y and Cb, Cr channels. (ii) If we pre-train on the\n",
    "Y or Cb, Cr channels, the performance ﬁnally improves,\n",
    "but is still not better than “Y only” on the color image\n",
    "(see the last column of Table 5, where PSNR is computed\n",
    "(a) First-layer ﬁlters – Cb channel\n",
    "(b) First-layer ﬁlters – Cr channel\n",
    "Fig. 13. Chrominance channels of the ﬁrst-layer ﬁlters\"\"\",\n",
    "    \"\"\"erations, ηis the learning rate, and ∂L\n",
    "∂W ℓ\n",
    "i\n",
    "is the derivative.\n",
    "The ﬁlter weights of each layer are initialized by drawing\n",
    "randomly from a Gaussian distribution with zero mean\n",
    "and standard deviation 0.001 (and 0 for biases). The\n",
    "learning rate is 10−4 for the ﬁrst two layers, and 10−5 for\n",
    "the last layer. We empirically ﬁnd that a smaller learning\n",
    "rate in the last layer is important for the network to\n",
    "converge (similar to the denoising case [22]).\n",
    "In the training phase, the ground truth images {Xi}\n",
    "are prepared as fsub×fsub×c-pixel sub-images randomly\n",
    "cropped from the training images. By “sub-images” we\n",
    "mean these samples are treated as small “images” rather\n",
    "than “patches”, in the sense that “patches” are overlap-\n",
    "ping and require some averaging as post-processing but\n",
    "“sub-images” need not. To synthesize the low-resolution\n",
    "samples {Yi}, we blur a sub-image by a Gaussian kernel,\n",
    "sub-sample it by the upscaling factor, and upscale it by\n",
    "the same factor via bicubic interpolation.\n",
    "To avoid border effects during training, all the con-\n",
    "volutional layers have no padding, and the network\n",
    "produces a smaller output ( (fsub −f1 −f2 −f3 + 3)2 ×c).\n",
    "The MSE loss function is evaluated only by the difference\n",
    "between the central pixels of Xi and the network output.\n",
    "Although we use a ﬁxed image size in training, the\n",
    "convolutional neural network can be applied on images\n",
    "of arbitrary sizes during testing.\n",
    "We implement our model using the cuda-convnet pack-\n",
    "age [26]. We have also tried the Caffe package [24] and\n",
    "observed similar performance.\n",
    "4 E XPERIMENTS\n",
    "We ﬁrst investigate the impact of using different datasets\n",
    "on the model performance. Next, we examine the ﬁlters\n",
    "learned by our approach. We then explore different\n",
    "architecture designs of the network, and study the rela-\n",
    "tions between super-resolution performance and factors\n",
    "like depth, number of ﬁlters, and ﬁlter sizes. Subse-\n",
    "quently, we compare our method with recent state-of-\n",
    "the-arts both quantitatively and qualitatively. Following\n",
    "[42], super-resolution is only applied on the luminance\n",
    "channel (Y channel in YCbCr color space) in Sections 4.1-\n",
    "4.4, so c = 1 in the ﬁrst/last layer, and performance\n",
    "(e.g., PSNR and SSIM) is evaluated on the Y channel. At\n",
    "last, we extend the network to cope with color images\n",
    "and evaluate the performance on different channels.\n",
    "4.1 Training Data\n",
    "As shown in the literature, deep learning generally\n",
    "beneﬁts from big data training. For comparison, we use\n",
    "a relatively small training set [41], [50] that consists\n",
    "of 91 images, and a large training set that consists of\n",
    "395,909 images from the ILSVRC 2013 ImageNet detec-\n",
    "tion training partition. The size of training sub-images is\n",
    "fsub = 33. Thus the 91-image dataset can be decomposed\n",
    "into 24,800 sub-images, which are extracted from origi-\n",
    "nal images with a stride of 14. Whereas the ImageNet\n",
    "provides over 5 million sub-images even using a stride\n",
    "of 33. We use the basic network settings, i.e., f1 = 9 ,\n",
    "f2 = 1, f3 = 5, n1 = 64, and n2 = 32. We use the Set5 [2]\n",
    "as the validation set. We observe a similar trend even\n",
    "if we use the larger Set14 set [51]. The upscaling factor\n",
    "is 3. We use the sparse-coding-based method [50] as our\n",
    "baseline, which achieves an average PSNR value of 31.42\n",
    "dB.\n",
    "The test convergence curves of using different training\n",
    "sets are shown in Figure 4. The training time on Ima-\n",
    "geNet is about the same as on the 91-image dataset since\n",
    "the number of backpropagations is the same. As can be\n",
    "observed, with the same number of backpropagations\n",
    "(i.e.,8 ×108), the SRCNN +ImageNet achieves 32.52 dB,\n",
    "higher than 32.39 dB yielded by that trained on 91\n",
    "images. The results positively indicate that SRCNN per-\n",
    "formance may be further boosted using a larger training\n",
    "set, but the effect of big data is not as impressive as\n",
    "that shown in high-level vision problems [26]. This is\n",
    "mainly because that the 91 images have already cap-\n",
    "tured sufﬁcient variability of natural images. On the\"\"\",\n",
    "    \"\"\"1 2 3 4 5 6 7 8\n",
    "xR10\n",
    "8\n",
    "31.5\n",
    "32\n",
    "32.5\n",
    "NumberRofRbackprops\n",
    "AverageRtestRPSNRR(dB)\n",
    "SRCNNR(9−5−5)\n",
    "SRCNNR(9−5−1−5)\n",
    "SCR(31.42RdB)\n",
    "(c) 9-5-5 vs. 9-5-1-5\n",
    "Fig. 8. Comparisons between three-layer and four-layer\n",
    "networks.\n",
    "mapping layers with n22 = 32 and n23 = 16 ﬁlters on\n",
    "9-1-5, then we have to set a smaller learning rate to\n",
    "ensure convergence, but we still do not observe superior\n",
    "performance after a week of training (see Figure 9(a)).\n",
    "We also tried to enlarge the ﬁlter size of the additional\n",
    "layer to f22 = 3, and explore two deep structures – 9-3-\n",
    "3-5 and 9-3-3-3. However, from the convergence curves\n",
    "shown in Figure 9(b), these two networks do not show\n",
    "better results than the 9-3-1-5 network.\n",
    "All these experiments indicate that it is not “the deeper\n",
    "the better” in this deep model for super-resolution. It\n",
    "may be caused by the difﬁculty of training. Our CNN\n",
    "network contains no pooling layer or full-connected\n",
    "layer, thus it is sensitive to the initialization parameters\n",
    "and learning rate. When we go deeper (e.g., 4 or 5 layers),\n",
    "we ﬁnd it hard to set appropriate learning rates that\n",
    "guarantee convergence. Even it converges, the network\n",
    "may fall into a bad local minimum, and the learned\n",
    "ﬁlters are of less diversity even given enough training\n",
    "time. This phenomenon is also observed in [16], where\n",
    "improper increase of depth leads to accuracy saturation\n",
    "or degradation for image classiﬁcation. Why “deeper is\n",
    "not better” is still an open question, which requires in-\n",
    "vestigations to better understand gradients and training\n",
    "dynamics in deep architectures. Therefore, we still adopt\n",
    "three-layer networks in the following experiments.\n",
    "4.4 Comparisons to State-of-the-Arts\n",
    "In this section, we show the quantitative and qualitative\n",
    "results of our method in comparison to state-of-the-art\n",
    "2 4 6 8 10 12\n",
    "x(10\n",
    "8\n",
    "31\n",
    "31.5\n",
    "32\n",
    "32.5\n",
    "Number(of(backprops\n",
    "Average(test(PSNR(=dB)\n",
    "SRCNN(=9−1−5)\n",
    "SRCNN(=9−1−1−5,(n 22=16)\n",
    "SRCNN(=9−1−1−5,(n 22=32)\n",
    "SRCNN(=9−1−1−1−5,(n 22=32,(n 23=16)\n",
    "SC(=31.42(dB)\n",
    "(a) 9-1-1-5 ( n22 = 32) and 9-1-1-1-5 ( n22 = 32, n23 = 16)\n",
    "1 2 3 4 5 6 7 8 9\n",
    "xS10\n",
    "8\n",
    "31.5\n",
    "32\n",
    "32.5\n",
    "NumberSofSbackprops\n",
    "AverageStestSPSNRS(dB)\n",
    "SRCNNS(9−3−5)\n",
    "SRCNNS(9−3−1−5)\n",
    "SRCNNS(9−3−3−5)\n",
    "SRCNNS(9−3−3−3)\n",
    "SCS(31.42SdB)\n",
    "(b) 9-3-3-5 and 9-3-3-3\n",
    "Fig. 9. Deeper structure does not always lead to better\n",
    "results.\n",
    "methods. We adopt the model with good performance-\n",
    "speed trade-off: a three-layer network with f1 = 9, f2 =\n",
    "5, f3 = 5, n1 = 64, and n2 = 32 trained on the ImageNet.\n",
    "For each upscaling factor ∈{2,3,4}, we train a speciﬁc\n",
    "network for that factor 7.\n",
    "Comparisons. We compare our SRCNN with the state-\n",
    "of-the-art SR methods:\n",
    "• SC - sparse coding-based method of Yang et al. [50]\n",
    "• NE+LLE - neighbour embedding + locally linear\n",
    "embedding method [4]\n",
    "• ANR - Anchored Neighbourhood Regression\n",
    "method [41]\n",
    "• A+ - Adjusted Anchored Neighbourhood Regres-\n",
    "sion method [42], and\n",
    "• KK - the method described in [25], which achieves\n",
    "the best performance among external example-\n",
    "based methods, according to the comprehensive\n",
    "evaluation conducted in Yang et al.’s work [46]\n",
    "The implementations are all from the publicly available\n",
    "codes provided by the authors, and all images are down-\n",
    "sampled using the same bicubic kernel.\n",
    "Test set.The Set5 [2] (5 images), Set14 [51] (14 images)\n",
    "and BSD200 [32] (200 images) 8 are used to evaluate the\n",
    "performance of upscaling factors 2, 3, and 4.\n",
    "Evaluation metrics. Apart from the widely used PSNR\n",
    "and SSIM [43] indices, we also adopt another four\n",
    "evaluation matrices, namely information ﬁdelity cri-\n",
    "terion (IFC) [38], noise quality measure (NQM) [8],\n",
    "weighted peak signal-to-noise ratio (WPSNR) and multi-\n",
    "scale structure similarity index (MSSSIM) [44], which\n",
    "obtain high correlation with the human perceptual scores\n",
    "as reported in [46].\n",
    "4.4.1 Quantitative and qualitative evaluation\n",
    "As shown in Tables 2, 3 and 4, the proposed SRCNN\n",
    "yields the highest scores in most evaluation matrices\n",
    "7. In the area of denoising [3], for each noise level a speciﬁc network\n",
    "is trained.\"\"\",\n",
    "    \"\"\"only on the luminance channel. There are also works\n",
    "attempting to super-resolve all channels simultaneously.\n",
    "For example, Kim and Kwon [25] and Dai et al.[7] apply\n",
    "their model to each RGB channel and combined them to\n",
    "produce the ﬁnal results. However, none of them has\n",
    "analyzed the SR performance of different channels, and\n",
    "the necessity of recovering all three channels.\n",
    "2.2 Convolutional Neural Networks\n",
    "Convolutional neural networks (CNN) date back\n",
    "decades [27] and deep CNNs have recently shown an\n",
    "explosive popularity partially due to its success in image\n",
    "classiﬁcation [18], [26]. They have also been success-\n",
    "fully applied to other computer vision ﬁelds, such as\n",
    "object detection [34], [40], [52], face recognition [39], and\n",
    "pedestrian detection [35]. Several factors are of central\n",
    "importance in this progress: (i) the efﬁcient training\n",
    "implementation on modern powerful GPUs [26], (ii) the\n",
    "proposal of the Rectiﬁed Linear Unit (ReLU) [33] which\n",
    "makes convergence much faster while still presents good\n",
    "quality [26], and (iii) the easy access to an abundance of\n",
    "data (like ImageNet [9]) for training larger models. Our\n",
    "method also beneﬁts from these progresses.\n",
    "2.3 Deep Learning for Image Restoration\n",
    "There have been a few studies of using deep learning\n",
    "techniques for image restoration. The multi-layer per-\n",
    "ceptron (MLP), whose all layers are fully-connected (in\n",
    "contrast to convolutional), is applied for natural image\n",
    "denoising [3] and post-deblurring denoising [36]. More\n",
    "closely related to our work, the convolutional neural net-\n",
    "work is applied for natural image denoising [22] and re-\n",
    "moving noisy patterns (dirt/rain) [12]. These restoration\n",
    "problems are more or less denoising-driven. Cui et al.[5]\n",
    "propose to embed auto-encoder networks in their super-\n",
    "resolution pipeline under the notion internal example-\n",
    "based approach [16]. The deep model is not speciﬁcally\n",
    "designed to be an end-to-end solution, since each layer\n",
    "of the cascade requires independent optimization of the\n",
    "self-similarity search process and the auto-encoder. On\n",
    "the contrary, the proposed SRCNN optimizes an end-to-\n",
    "end mapping. Further, the SRCNN is faster at speed. It\n",
    "is not only a quantitatively superior method, but also a\n",
    "practically useful one.\n",
    "3 C ONVOLUTIONAL NEURAL NETWORKS FOR\n",
    "SUPER -RESOLUTION\n",
    "3.1 Formulation\n",
    "Consider a single low-resolution image, we ﬁrst upscale\n",
    "it to the desired size using bicubic interpolation, which\n",
    "is the only pre-processing we perform 3. Let us denote\n",
    "the interpolated image as Y. Our goal is to recover\n",
    "from Y an image F(Y) that is as similar as possible\n",
    "to the ground truth high-resolution image X. For the\n",
    "ease of presentation, we still call Y a “low-resolution”\n",
    "image, although it has the same size as X. We wish to\n",
    "learn a mapping F, which conceptually consists of three\n",
    "operations:\n",
    "1) Patch extraction and representation: this opera-\n",
    "tion extracts (overlapping) patches from the low-\n",
    "resolution image Y and represents each patch as a\n",
    "high-dimensional vector. These vectors comprise a\n",
    "set of feature maps, of which the number equals to\n",
    "the dimensionality of the vectors.\n",
    "2) Non-linear mapping: this operation nonlinearly\n",
    "maps each high-dimensional vector onto another\n",
    "high-dimensional vector. Each mapped vector is\n",
    "conceptually the representation of a high-resolution\n",
    "patch. These vectors comprise another set of feature\n",
    "maps.\n",
    "3) Reconstruction: this operation aggregates the\n",
    "above high-resolution patch-wise representations\n",
    "to generate the ﬁnal high-resolution image. This\n",
    "image is expected to be similar to the ground truth\n",
    "X.\n",
    "We will show that all these operations form a convolu-\n",
    "tional neural network. An overview of the network is\n",
    "depicted in Figure 2. Next we detail our deﬁnition of\n",
    "each operation.\n",
    "3.1.1 Patch extraction and representation\n",
    "A popular strategy in image restoration ( e.g., [1]) is to\n",
    "densely extract patches and then represent them by a set\n",
    "of pre-trained bases such as PCA, DCT, Haar, etc. This\"\"\",\n",
    "    \"\"\"sion [27], trees [46] or Random Forests [47]. In Dai et al.\n",
    "[6] a multitude of patch-speciﬁc regressors is learned and\n",
    "the most appropriate regressors selected during testing.\n",
    "Recently convolutional neural network (CNN) based SR\n",
    "algorithms have shown excellent performance. In Wang\n",
    "et al. [59] the authors encode a sparse representation\n",
    "prior into their feed-forward network architecture based on\n",
    "the learned iterative shrinkage and thresholding algorithm\n",
    "(LISTA) [23]. Dong et al. [9, 10] used bicubic interpolation\n",
    "to upscale an input image and trained a three layer deep\n",
    "fully convolutional network end-to-end to achieve state-\n",
    "of-the-art SR performance. Subsequently, it was shown\n",
    "that enabling the network to learn the upscaling ﬁlters\n",
    "directly can further increase performance both in terms of\n",
    "accuracy and speed [11, 48, 57]. With their deeply-recursive\n",
    "convolutional network (DRCN), Kim et al. [34] presented\n",
    "a highly performant architecture that allows for long-range\n",
    "pixel dependencies while keeping the number of model\n",
    "parameters small. Of particular relevance for our paper are\n",
    "the works by Johnson et al. [33] and Bruna et al. [5],\n",
    "who rely on a loss function closer to perceptual similarity\n",
    "to recover visually more convincing HR images.\n",
    "1.1.2 Design of convolutional neural networks\n",
    "The state of the art for many computer vision problems is\n",
    "meanwhile set by speciﬁcally designed CNN architectures\n",
    "following the success of the work by Krizhevsky et al. [37].\n",
    "It was shown that deeper network architectures can be\n",
    "difﬁcult to train but have the potential to substantially\n",
    "increase the network’s accuracy as they allow modeling\n",
    "mappings of very high complexity [49, 51]. To efﬁ-\n",
    "ciently train these deeper network architectures, batch-\n",
    "normalization [32] is often used to counteract the internal\n",
    "co-variate shift. Deeper network architectures have also\n",
    "been shown to increase performance for SISR, e.g. Kim et\n",
    "al. [34] formulate a recursive CNN and present state-of-the-\n",
    "art results. Another powerful design choice that eases the\n",
    "training of deep CNNs is the recently introduced concept of\n",
    "residual blocks [29] and skip-connections [30, 34]. Skip-\n",
    "connections relieve the network architecture of modeling\n",
    "the identity mapping that is trivial in nature, however, po-\n",
    "tentially non-trivial to represent with convolutional kernels.\n",
    "In the context of SISR it was also shown that learning\n",
    "upscaling ﬁlters is beneﬁcial in terms of accuracy and speed\n",
    "[11, 48, 57]. This is an improvement over Dong et al. [10]\n",
    "where bicubic interpolation is employed to upscale the LR\n",
    "observation before feeding the image to the CNN.\n",
    "1.1.3 Loss functions\n",
    "Pixel-wise loss functions such as MSE struggle to handle\n",
    "the uncertainty inherent in recovering lost high-frequency\n",
    "details such as texture: minimizing MSE encourages ﬁnd-\n",
    "ing pixel-wise averages of plausible solutions which are\n",
    "typically overly-smooth and thus have poor perceptual qual-\n",
    "ity [42, 33, 13, 5]. Reconstructions of varying perceptual\n",
    "Figure 3: Illustration of patches from the natural image\n",
    "manifold (red) and super-resolved patches obtained with\n",
    "MSE (blue) and GAN (orange). The MSE-based solution\n",
    "appears overly smooth due to the pixel-wise average of\n",
    "possible solutions in the pixel space, while GAN drives the\n",
    "reconstruction towards the natural image manifold produc-\n",
    "ing perceptually more convincing solutions.\n",
    "quality are exempliﬁed with corresponding PSNR in Fig-\n",
    "ure 2. We illustrate the problem of minimizing MSE in Fig-\n",
    "ure 3 where multiple potential solutions with high texture\n",
    "details are averaged to create a smooth reconstruction.\n",
    "In Mathieu et al. [42] and Denton et al. [7] the authors\n",
    "tackled this problem by employing generative adversarial\n",
    "networks (GANs) [22] for the application of image genera-\n",
    "tion. Yu and Porikli [66] augment pixel-wise MSE loss with\n",
    "a discriminator loss to train a network that super-resolves\n",
    "face images with large upscaling factors ( 8×). GANs\"\"\",\n",
    "]\n",
    "    ),\n",
    "    LLMTestCase(\n",
    "        input=\"What exactly is meant by “perceptual loss” in SRGAN, and how is it computed from VGG feature maps?\",\n",
    "        actual_output=\"\"\"Perceptual loss\" in SRGAN (Super-Resolution Generative Adversarial Network) means that instead of simply comparing the generated super-resolved image and the original high-resolution image pixel by pixel, the network aims to make the super-resolved image perceptually similar – that is, look more like the original – to a human observer. This is different from traditional metrics like Mean Squared Error (MSE) which only measure pixel differences.\n",
    "\n",
    "Here's how the perceptual loss is calculated using VGG (Visual Geometry Group network, a pre-trained Convolutional Neural Network used for image recognition) feature maps:\n",
    "\n",
    "Both the super-resolved image (generated by the SRGAN) and the original high-resolution image are passed through a pre-trained VGG19 network.\n",
    "\n",
    "The VGG19 network extracts feature maps from both images. Feature maps are representations of different visual features of the images at different levels of abstraction within the network.\n",
    "\n",
    "The perceptual loss is calculated by comparing these feature maps from specific layers within the VGG19 network, typically the ReLU (Rectified Linear Unit, a type of activation function in neural networks) activation layers. The loss is based on the Euclidean distance (a measure of the straight-line distance between two points in a multi-dimensional space representing the feature maps) between the feature representations of the two images. A smaller distance implies greater perceptual similarity.\n",
    "\n",
    "Specifically, SRGAN combines this VGG-based content loss with an adversarial loss from the discriminator network within the GAN framework. The discriminator is trained to distinguish between real high-resolution images and the super-resolved images. This adversarial loss helps to make the generated images look more realistic. The content loss ensures that the generated image captures the perceptual content of the original image. The combination of these two losses is the overall perceptual loss.\"\"\",\n",
    "        expected_output=\"\"\"It is a weighted sum of a content loss (Euclidean distance between VGG‑feature maps of SR vs. HR images) and an adversarial loss (−log D(G(I))). The VGG layers (e.g., φ5,4) provide semantics; the adversarial term pushes outputs onto the natural‑image manifold.\"\"\",\n",
    "        context=[\n",
    "            \"\"\"We formulate the perceptual loss as the weighted sum of a content loss and an adversarial loss component … Content loss l_{VGG/i.j} = 1/(W_{i,j}H_{i,j}) Σ(φ_{i,j}(I_{HR}) − φ_{i,j}(G(I_{LR})))² … l_{Gen} = −log D(G(I_{LR}))\"\"\"\n",
    "        ],\n",
    "        retrieval_context=[\n",
    "    \"\"\"lSR is commonly modeled based on the MSE [10, 48], we\n",
    "improve on Johnson et al. [33] and Bruna et al. [5] and\n",
    "design a loss function that assesses a solution with respect\n",
    "to perceptually relevant characteristics. We formulate the\n",
    "perceptual loss as the weighted sum of a content loss ( lSR\n",
    "X )\n",
    "and an adversarial loss component as:\n",
    "lSR = lSR\n",
    "X\n",
    "content loss\n",
    "+ 10−3lSR\n",
    "Gen  \n",
    "adversarial loss  \n",
    "perceptual loss (for VGG based content losses)\n",
    "(3)\n",
    "In the following we describe possible choices for the con-\n",
    "tent loss lSR\n",
    "X and the adversarial loss lSR\n",
    "Gen.\n",
    "2.2.1 Content loss\n",
    "The pixel-wise MSE loss is calculated as:\n",
    "lSR\n",
    "MSE = 1\n",
    "r2WH\n",
    "rW∑\n",
    "x=1\n",
    "rH∑\n",
    "y=1\n",
    "(IHR\n",
    "x,y −GθG(ILR)x,y)2 (4)\n",
    "This is the most widely used optimization target for image\n",
    "SR on which many state-of-the-art approaches rely [10,\n",
    "48]. However, while achieving particularly high PSNR,\n",
    "solutions of MSE optimization problems often lack high-\n",
    "frequency content which results in perceptually unsatisfy-\n",
    "ing solutions with overly smooth textures (c.f . Figure 2).\n",
    "Instead of relying on pixel-wise losses we build on the\n",
    "ideas of Gatys et al. [19], Bruna et al. [5] and Johnson et\n",
    "al. [33] and use a loss function that is closer to perceptual\n",
    "similarity. We deﬁne the VGG loss based on the ReLU\n",
    "activation layers of the pre-trained 19 layer VGG network\n",
    "described in Simonyan and Zisserman [49]. With φi,j we\n",
    "indicate the feature map obtained by the j-th convolution\n",
    "(after activation) before the i-th maxpooling layer within the\n",
    "VGG19 network, which we consider given. We then deﬁne\n",
    "the VGG loss as the euclidean distance between the feature\n",
    "representations of a reconstructed image GθG(ILR) and the\n",
    "reference image IHR:\n",
    "lSR\n",
    "VGG/i.j = 1\n",
    "Wi,jHi,j\n",
    "Wi,j∑\n",
    "x=1\n",
    "Hi,j∑\n",
    "y=1\n",
    "(φi,j(IHR)x,y\n",
    "−φi,j(GθG(ILR))x,y)2\n",
    "(5)\n",
    "Here Wi,j and Hi,j describe the dimensions of the\n",
    "respective feature maps within the VGG network.\n",
    "2.2.2 Adversarial loss\n",
    "In addition to the content losses described so far, we also\n",
    "add the generative component of our GAN to the perceptual\n",
    "loss. This encourages our network to favor solutions that\n",
    "reside on the manifold of natural images, by trying to\n",
    "fool the discriminator network. The generative loss lSR\n",
    "Gen\n",
    "is deﬁned based on the probabilities of the discriminator\n",
    "DθD (GθG(ILR)) over all training samples as:\n",
    "lSR\n",
    "Gen =\n",
    "N∑\n",
    "n=1\n",
    "−log DθD (GθG(ILR)) (6)\n",
    "Here, DθD (GθG(ILR)) is the probability that the recon-\n",
    "structed image GθG(ILR) is a natural HR image. For better\n",
    "gradient behavior we minimize −log DθD (GθG(ILR)) in-\n",
    "stead of log[1 −DθD (GθG(ILR))] [22].\n",
    "3. Experiments\n",
    "3.1. Data and similarity measures\n",
    "We perform experiments on three widely used bench-\n",
    "mark datasets Set5 [3], Set14 [69] and BSD100, the testing\n",
    "set of BSD300 [41]. All experiments are performed with\n",
    "a scale factor of 4× between low- and high-resolution\n",
    "images. This corresponds to a 16×reduction in image\n",
    "pixels. For fair comparison, all reported PSNR [dB] and\n",
    "SSIM [58] measures were calculated on the y-channel of\n",
    "center-cropped, removal of a 4-pixel wide strip from each\n",
    "border, images using the daala package 1. Super-resolved\n",
    "images for the reference methods, including nearest neigh-\n",
    "bor, bicubic, SRCNN [9] and SelfExSR [31], were obtained\n",
    "from online material supplementary to Huang et al. 2 [31]\n",
    "and for DRCN from Kim et al. 3 [34]. Results obtained\n",
    "with SRResNet (for losses: lSR\n",
    "MSE and lSR\n",
    "VGG/2.2) and the\n",
    "SRGAN variants are available online4. Statistical tests were\n",
    "performed as paired two-sided Wilcoxon signed-rank tests\n",
    "and signiﬁcance determined at p< 0.05.\n",
    "The reader may also be interested in an independently\n",
    "developed GAN-based solution on GitHub 5. However it\n",
    "only provides experimental results on a limited set of faces,\n",
    "which is a more constrained and easier task.\n",
    "3.2. Training details and parameters\n",
    "We trained all networks on a NVIDIA Tesla M40 GPU\n",
    "using a random sample of 350 thousand images from\n",
    "the ImageNet database [45]. These images are distinct\n",
    "from the testing images. We obtained the LR images\"\"\",\n",
    "    \"\"\"3.4. Investigation of content loss\n",
    "We investigated the effect of different content loss\n",
    "choices in the perceptual loss for the GAN-based networks.\n",
    "Speciﬁcally we investigate lSR = lSR\n",
    "X + 10−3lSR\n",
    "Gen for the\n",
    "following content losses lSR\n",
    "X :\n",
    "Table 1: Performance of different loss functions for SR-\n",
    "ResNet and the adversarial networks on Set5 and Set14\n",
    "benchmark data. MOS score signiﬁcantly higher (p< 0.05)\n",
    "than with other losses in that category∗. [4×upscaling]\n",
    "SRResNet- SRGAN-\n",
    "Set5 MSE VGG22 MSE VGG22 VGG54\n",
    "PSNR 32.05 30.51 30.64 29.84 29.40\n",
    "SSIM 0.9019 0.8803 0.8701 0.8468 0.8472\n",
    "MOS 3.37 3.46 3.77 3.78 3.58\n",
    "Set14\n",
    "PSNR 28.49 27.19 26.92 26.44 26.02\n",
    "SSIM 0.8184 0.7807 0.7611 0.7518 0.7397\n",
    "MOS 2.98 3.15 ∗ 3.43 3.57 3.72 ∗\n",
    "•SRGAN-MSE: lSR\n",
    "MSE, to investigate the adversarial\n",
    "network with the standard MSE as content loss.\n",
    "•SRGAN-VGG22: lSR\n",
    "VGG/2.2 with φ2,2, a loss deﬁned\n",
    "on feature maps representing lower-level features [68].\n",
    "•SRGAN-VGG54: lSR\n",
    "VGG/5.4 with φ5,4, a loss deﬁned\n",
    "on feature maps of higher level features from deeper\n",
    "network layers with more potential to focus on the\n",
    "content of the images [68, 65, 40]. We refer to this\n",
    "network as SRGAN in the following.\n",
    "We also evaluate the performance of the generator network\n",
    "without adversarial component for the two losses lSR\n",
    "MSE\n",
    "(SRResNet-MSE) and lSR\n",
    "VGG/2.2 (SRResNet-VGG22). We\n",
    "refer to SRResNet-MSE asSRResNet. Note, when training\n",
    "SRResNet-VGG22 we added an additional total variation\n",
    "loss with weight 2 ×10−8 to lSR\n",
    "VGG/2.2 [2, 33]. Quantitative\n",
    "results are summarized in Table 1 and visual examples\n",
    "provided in Figure 6. Even combined with the adversarial\n",
    "loss, MSE provides solutions with the highest PSNR values\n",
    "that are, however, perceptually rather smooth and less\n",
    "convincing than results achieved with a loss component\n",
    "more sensitive to visual perception. This is caused by\n",
    "competition between the MSE-based content loss and the\n",
    "adversarial loss. We further attribute minor reconstruction\n",
    "artifacts, which we observed in a minority of SRGAN-\n",
    "MSE-based reconstructions, to those competing objectives.\n",
    "We could not determine a signiﬁcantly best loss function\n",
    "for SRResNet or SRGAN with respect to MOS score\n",
    "on Set5. However, SRGAN-VGG54 signiﬁcantly outper-\n",
    "formed other SRGAN and SRResNet variants on Set14 in\n",
    "terms of MOS. We observed a trend that using the higher\n",
    "level VGG feature maps φ5,4 yields better texture detail\n",
    "when compared to φ2,2 (c.f . Figure 6). Further examples of\n",
    "perceptual improvements through SRGAN over SRResNet\n",
    "are provided in the supplementary material.\n",
    "Figure 5: Color-coded distribution of MOS scores on\n",
    "BSD100. For each method 2600 samples (100 images ×\n",
    "26 raters) were assessed. Mean shown as red marker, where\n",
    "the bins are centered around value i. [4×upscaling]\n",
    "3.5. Performance of the ﬁnal networks\n",
    "We compare the performance of SRResNet and SR-\n",
    "GAN to NN, bicubic interpolation, and four state-of-the-\n",
    "art methods. Quantitative results are summarized in Table\n",
    "2 and conﬁrm that SRResNet (in terms of PSNR/SSIM)\n",
    "sets a new state of the art on three benchmark datasets.\n",
    "Please note that we used a publicly available framework\n",
    "for evaluation (c.f . Section 3.1), reported values might thus\n",
    "slightly deviate from those reported in the original papers.\n",
    "We further obtained MOS ratings for SRGAN and all\n",
    "reference methods on BSD100. Examples of images super-\n",
    "resolved with SRResNet and SRGAN are depicted in the\n",
    "supplementary material. The results shown in Table 2\n",
    "conﬁrm that SRGAN outperforms all reference methods by\n",
    "a large margin and sets a new state of the art for photo-\n",
    "realistic image SR. All differences in MOS ( c.f . Table\n",
    "2) are highly signiﬁcant on BSD100, except SRCNN vs.\n",
    "SelfExSR. The distribution of all collected MOS ratings is\n",
    "summarized in Figure 5.\n",
    "4. Discussion and future work\n",
    "We conﬁrmed the superior perceptual performance of\n",
    "SRGAN using MOS testing. We have further shown that\n",
    "standard quantitative measures such as PSNR and SSIM\"\"\",\n",
    "    \"\"\"obtained by applying a Gaussian ﬁlter toIHR followed by a\n",
    "downsampling operation with downsampling factor r. For\n",
    "an image with C color channels, we describe ILR by a\n",
    "real-valued tensor of size W ×H ×C and IHR, ISR by\n",
    "rW ×rH ×Crespectively.\n",
    "Our ultimate goal is to train a generating function Gthat\n",
    "estimates for a given LR input image its corresponding HR\n",
    "counterpart. To achieve this, we train a generator network as\n",
    "a feed-forward CNN GθG parametrized by θG. Here θG =\n",
    "{W1:L; b1:L}denotes the weights and biases of a L-layer\n",
    "deep network and is obtained by optimizing a SR-speciﬁc\n",
    "loss function lSR. For training images IHR\n",
    "n , n= 1,...,N\n",
    "with corresponding ILR\n",
    "n , n= 1,...,N , we solve:\n",
    "ˆθG = arg min\n",
    "θG\n",
    "1\n",
    "N\n",
    "N∑\n",
    "n=1\n",
    "lSR(GθG(ILR\n",
    "n ),IHR\n",
    "n ) (1)\n",
    "In this work we will speciﬁcally design a perceptual loss\n",
    "lSR as a weighted combination of several loss components\n",
    "that model distinct desirable characteristics of the recovered\n",
    "SR image. The individual loss functions are described in\n",
    "more detail in Section 2.2.\n",
    "2.1. Adversarial network architecture\n",
    "Following Goodfellow et al. [22] we further deﬁne\n",
    "a discriminator network DθD which we optimize in an\n",
    "alternating manner along with GθG to solve the adversarial\n",
    "min-max problem:\n",
    "min\n",
    "θG\n",
    "max\n",
    "θD\n",
    "EIHR∼ptrain(IHR)[log DθD (IHR)]+\n",
    "EILR∼pG(ILR)[log(1 −DθD (GθG(ILR))]\n",
    "(2)\n",
    "The general idea behind this formulation is that it allows\n",
    "one to train a generative model Gwith the goal of fooling a\n",
    "differentiable discriminator Dthat is trained to distinguish\n",
    "super-resolved images from real images. With this approach\n",
    "our generator can learn to create solutions that are highly\n",
    "similar to real images and thus difﬁcult to classify by D.\n",
    "This encourages perceptually superior solutions residing in\n",
    "the subspace, the manifold, of natural images. This is in\n",
    "contrast to SR solutions obtained by minimizing pixel-wise\n",
    "error measurements, such as the MSE.\n",
    "At the core of our very deep generator networkG, which\n",
    "is illustrated in Figure 4 areBresidual blocks with identical\n",
    "layout. Inspired by Johnson et al. [33] we employ the block\n",
    "layout proposed by Gross and Wilber [24]. Speciﬁcally, we\n",
    "use two convolutional layers with small3×3 kernels and 64\n",
    "feature maps followed by batch-normalization layers [32]\n",
    "and ParametricReLU [28] as the activation function. We\n",
    "increase the resolution of the input image with two trained\n",
    "sub-pixel convolution layers as proposed by Shi et al. [48].\n",
    "To discriminate real HR images from generated SR\n",
    "samples we train a discriminator network. The architecture\n",
    "is shown in Figure 4. We follow the architectural guidelines\n",
    "summarized by Radford et al. [44] and use LeakyReLU\n",
    "activation (α = 0.2) and avoid max-pooling throughout\n",
    "the network. The discriminator network is trained to solve\n",
    "the maximization problem in Equation 2. It contains eight\n",
    "convolutional layers with an increasing number of 3 ×3\n",
    "ﬁlter kernels, increasing by a factor of 2 from 64 to 512 ker-\n",
    "nels as in the VGG network [49]. Strided convolutions are\n",
    "used to reduce the image resolution each time the number\n",
    "of features is doubled. The resulting 512 feature maps are\n",
    "followed by two dense layers and a ﬁnal sigmoid activation\n",
    "function to obtain a probability for sample classiﬁcation.\n",
    "Figure 4: Architecture of Generator and Discriminator Network with corresponding kernel size (k), number of feature maps\n",
    "(n) and stride (s) indicated for each convolutional layer.\n",
    "2.2. Perceptual loss function\n",
    "The deﬁnition of our perceptual loss function lSR is crit-\n",
    "ical for the performance of our generator network. While\n",
    "lSR is commonly modeled based on the MSE [10, 48], we\n",
    "improve on Johnson et al. [33] and Bruna et al. [5] and\n",
    "design a loss function that assesses a solution with respect\n",
    "to perceptually relevant characteristics. We formulate the\n",
    "perceptual loss as the weighted sum of a content loss ( lSR\n",
    "X )\n",
    "and an adversarial loss component as:\n",
    "lSR = lSR\n",
    "X\n",
    "content loss\n",
    "+ 10−3lSR\n",
    "Gen  \n",
    "adversarial loss  \n",
    "perceptual loss (for VGG based content losses)\n",
    "(3)\"\"\",\n",
    "    \"\"\"and signiﬁcance determined at p< 0.05.\n",
    "The reader may also be interested in an independently\n",
    "developed GAN-based solution on GitHub 5. However it\n",
    "only provides experimental results on a limited set of faces,\n",
    "which is a more constrained and easier task.\n",
    "3.2. Training details and parameters\n",
    "We trained all networks on a NVIDIA Tesla M40 GPU\n",
    "using a random sample of 350 thousand images from\n",
    "the ImageNet database [45]. These images are distinct\n",
    "from the testing images. We obtained the LR images\n",
    "by downsampling the HR images (BGR, C = 3) using\n",
    "bicubic kernel with downsampling factor r = 4. For each\n",
    "mini-batch we crop 16 random 96 ×96 HR sub images\n",
    "of distinct training images. Note that we can apply the\n",
    "generator model to images of arbitrary size as it is fully\n",
    "1https://github.com/xiph/daala (commit: 8d03668)\n",
    "2https://github.com/jbhuang0604/SelfExSR\n",
    "3http://cv.snu.ac.kr/research/DRCN/\n",
    "4https://twitter.box.com/s/\n",
    "lcue6vlrd01ljkdtdkhmfvk7vtjhetog\n",
    "5https://github.com/david-gpu/srez\n",
    "convolutional. We scaled the range of the LR input images\n",
    "to [0,1] and for the HR images to [−1,1]. The MSE loss\n",
    "was thus calculated on images of intensity range [−1,1].\n",
    "VGG feature maps were also rescaled by a factor of 1\n",
    "12.75\n",
    "to obtain VGG losses of a scale that is comparable to the\n",
    "MSE loss. This is equivalent to multiplying Equation 5\n",
    "with a rescaling factor of ≈ 0.006. For optimization we\n",
    "use Adam [36] with β1 = 0.9. The SRResNet networks\n",
    "were trained with a learning rate of 10−4 and 106 update\n",
    "iterations. We employed the trained MSE-based SRResNet\n",
    "network as initialization for the generator when training\n",
    "the actual GAN to avoid undesired local optima. All\n",
    "SRGAN variants were trained with 105 update iterations\n",
    "at a learning rate of 10−4 and another 105 iterations at a\n",
    "lower rate of 10−5. We alternate updates to the generator\n",
    "and discriminator network, which is equivalent to k = 1\n",
    "as used in Goodfellow et al. [22]. Our generator network\n",
    "has 16 identical (B = 16) residual blocks. During test time\n",
    "we turn batch-normalization update off to obtain an output\n",
    "that deterministically depends only on the input [32]. Our\n",
    "implementation is based on Theano [53] and Lasagne [8].\n",
    "3.3. Mean opinion score (MOS) testing\n",
    "We have performed a MOS test to quantify the ability of\n",
    "different approaches to reconstruct perceptually convincing\n",
    "images. Speciﬁcally, we asked 26 raters to assign an inte-\n",
    "gral score from 1 (bad quality) to 5 (excellent quality) to the\n",
    "super-resolved images. The raters rated 12 versions of each\n",
    "image on Set5, Set14 and BSD100: nearest neighbor (NN),\n",
    "bicubic, SRCNN [9], SelfExSR [31], DRCN [34], ESPCN\n",
    "[48], SRResNet-MSE, SRResNet-VGG22∗ (∗not rated on\n",
    "BSD100), SRGAN-MSE ∗, SRGAN-VGG22 ∗, SRGAN-\n",
    "VGG54 and the original HR image. Each rater thus rated\n",
    "1128 instances (12 versions of 19 images plus 9 versions of\n",
    "100 images) that were presented in a randomized fashion.\n",
    "The raters were calibrated on the NN (score 1) and HR (5)\n",
    "versions of 20 images from the BSD300 training set. In a\n",
    "pilot study we assessed the calibration procedure and the\n",
    "test-retest reliability of 26 raters on a subset of 10 images\n",
    "from BSD100 by adding a method’s images twice to a\n",
    "larger test set. We found good reliability and no signiﬁcant\n",
    "differences between the ratings of the identical images.\n",
    "Raters very consistently rated NN interpolated test images\n",
    "as 1 and the original HR images as 5 (c.f . Figure 5).\n",
    "The experimental results of the conducted MOS tests are\n",
    "summarized in Table 1, Table 2 and Figure 5.\n",
    "3.4. Investigation of content loss\n",
    "We investigated the effect of different content loss\n",
    "choices in the perceptual loss for the GAN-based networks.\n",
    "Speciﬁcally we investigate lSR = lSR\n",
    "X + 10−3lSR\n",
    "Gen for the\n",
    "following content losses lSR\n",
    "X :\n",
    "Table 1: Performance of different loss functions for SR-\n",
    "ResNet and the adversarial networks on Set5 and Set14\n",
    "benchmark data. MOS score signiﬁcantly higher (p< 0.05)\n",
    "than with other losses in that category∗. [4×upscaling]\n",
    "SRResNet- SRGAN-\"\"\",\n",
    "    \"\"\"ure 3 where multiple potential solutions with high texture\n",
    "details are averaged to create a smooth reconstruction.\n",
    "In Mathieu et al. [42] and Denton et al. [7] the authors\n",
    "tackled this problem by employing generative adversarial\n",
    "networks (GANs) [22] for the application of image genera-\n",
    "tion. Yu and Porikli [66] augment pixel-wise MSE loss with\n",
    "a discriminator loss to train a network that super-resolves\n",
    "face images with large upscaling factors ( 8×). GANs\n",
    "were also used for unsupervised representation learning in\n",
    "Radford et al. [44]. The idea of using GANs to learn a\n",
    "mapping from one manifold to another is described by Li\n",
    "and Wand [38] for style transfer and Yeh et al. [64] for\n",
    "inpainting. Bruna et al. [5] minimize the squared error in\n",
    "the feature spaces of VGG19 [49] and scattering networks.\n",
    "Dosovitskiy and Brox [13] use loss functions based\n",
    "on Euclidean distances computed in the feature space of\n",
    "neural networks in combination with adversarial training.\n",
    "It is shown that the proposed loss allows visually superior\n",
    "image generation and can be used to solve the ill-posed\n",
    "inverse problem of decoding nonlinear feature representa-\n",
    "tions. Similar to this work, Johnson et al. [33] and Bruna\n",
    "et al. [5] propose the use of features extracted from a pre-\n",
    "trained VGG network instead of low-level pixel-wise error\n",
    "measures. Speciﬁcally the authors formulate a loss function\n",
    "based on the euclidean distance between feature maps\n",
    "extracted from the VGG19 [49] network. Perceptually more\n",
    "convincing results were obtained for both super-resolution\n",
    "and artistic style-transfer [19, 20]. Recently, Li and Wand\n",
    "[38] also investigated the effect of comparing and blending\n",
    "patches in pixel or VGG feature space.\n",
    "1.2. Contribution\n",
    "GANs provide a powerful framework for generating\n",
    "plausible-looking natural images with high perceptual qual-\n",
    "ity. The GAN procedure encourages the reconstructions\n",
    "to move towards regions of the search space with high\n",
    "probability of containing photo-realistic images and thus\n",
    "closer to the natural image manifold as shown in Figure 3.\n",
    "In this paper we describe the ﬁrst very deep ResNet\n",
    "[29, 30] architecture using the concept of GANs to form a\n",
    "perceptual loss function for photo-realistic SISR. Our main\n",
    "contributions are:\n",
    "•We set a new state of the art for image SR with\n",
    "high upscaling factors (4×) as measured by PSNR and\n",
    "structural similarity (SSIM) with our 16 blocks deep\n",
    "ResNet (SRResNet) optimized for MSE.\n",
    "•We propose SRGAN which is a GAN-based network\n",
    "optimized for a new perceptual loss. Here we replace\n",
    "the MSE-based content loss with a loss calculated on\n",
    "feature maps of the VGG network [49], which are\n",
    "more invariant to changes in pixel space [38].\n",
    "•We conﬁrm with an extensive mean opinion score\n",
    "(MOS) test on images from three public benchmark\n",
    "datasets that SRGAN is the new state of the art, by a\n",
    "large margin, for the estimation of photo-realistic SR\n",
    "images with high upscaling factors (4×).\n",
    "We describe the network architecture and the perceptual\n",
    "loss in Section 2. A quantitative evaluation on public bench-\n",
    "mark datasets as well as visual illustrations are provided in\n",
    "Section 3. The paper concludes with a discussion in Section\n",
    "4 and concluding remarks in Section 5.\n",
    "2. Method\n",
    "In SISR the aim is to estimate a high-resolution, super-\n",
    "resolved image ISR from a low-resolution input image\n",
    "ILR. Here ILR is the low-resolution version of its high-\n",
    "resolution counterpart IHR. The high-resolution images\n",
    "are only available during training. In training, ILR is\n",
    "obtained by applying a Gaussian ﬁlter toIHR followed by a\n",
    "downsampling operation with downsampling factor r. For\n",
    "an image with C color channels, we describe ILR by a\n",
    "real-valued tensor of size W ×H ×C and IHR, ISR by\n",
    "rW ×rH ×Crespectively.\n",
    "Our ultimate goal is to train a generating function Gthat\n",
    "estimates for a given LR input image its corresponding HR\n",
    "counterpart. To achieve this, we train a generator network as\n",
    "a feed-forward CNN GθG parametrized by θG. Here θG =\"\"\",\n",
    "    \"\"\"conﬁrm that SRGAN outperforms all reference methods by\n",
    "a large margin and sets a new state of the art for photo-\n",
    "realistic image SR. All differences in MOS ( c.f . Table\n",
    "2) are highly signiﬁcant on BSD100, except SRCNN vs.\n",
    "SelfExSR. The distribution of all collected MOS ratings is\n",
    "summarized in Figure 5.\n",
    "4. Discussion and future work\n",
    "We conﬁrmed the superior perceptual performance of\n",
    "SRGAN using MOS testing. We have further shown that\n",
    "standard quantitative measures such as PSNR and SSIM\n",
    "fail to capture and accurately assess image quality with\n",
    "respect to the human visual system [56]. The focus of this\n",
    "work was the perceptual quality of super-resolved images\n",
    "rather than computational efﬁciency. The presented model\n",
    "is, in contrast to Shi et al. [48], not optimized for video\n",
    "SR in real-time. However, preliminary experiments on\n",
    "the network architecture suggest that shallower networks\n",
    "have the potential to provide very efﬁcient alternatives at\n",
    "a small reduction of qualitative performance. In contrast to\n",
    "Dong et al. [10], we found deeper network architectures to\n",
    "be beneﬁcial. We speculate that the ResNet design has a\n",
    "substantial impact on the performance of deeper networks.\n",
    "We found that even deeper networks (B >16) can further\n",
    "SRResNet SRGAN-MSE SRGAN-VGG22 SRGAN-VGG54 original HR image\n",
    "Figure 6: SRResNet (left: a,b), SRGAN-MSE (middle left: c,d), SRGAN-VGG2.2 (middle: e,f) and SRGAN-VGG54\n",
    "(middle right: g,h) reconstruction results and corresponding reference HR image (right: i,j). [ 4×upscaling]\n",
    "Table 2: Comparison of NN, bicubic, SRCNN [9], SelfExSR [31], DRCN [34], ESPCN [48], SRResNet, SRGAN-VGG54\n",
    "and the original HR on benchmark data. Highest measures (PSNR [dB], SSIM, MOS) in bold. [4×upscaling]\n",
    "Set5 nearest bicubic SRCNN SelfExSR DRCN ESPCN SRResNet SRGAN HR\n",
    "PSNR 26.26 28.43 30.07 30.33 31.52 30.76 32.05 29.40 ∞\n",
    "SSIM 0.7552 0.8211 0.8627 0.872 0.8938 0.8784 0.9019 0.8472 1\n",
    "MOS 1.28 1.97 2.57 2.65 3.26 2.89 3.37 3.58 4.32\n",
    "Set14\n",
    "PSNR 24.64 25.99 27.18 27.45 28.02 27.66 28.49 26.02 ∞\n",
    "SSIM 0.7100 0.7486 0.7861 0.7972 0.8074 0.8004 0.8184 0.7397 1\n",
    "MOS 1.20 1.80 2.26 2.34 2.84 2.52 2.98 3.72 4.32\n",
    "BSD100\n",
    "PSNR 25.02 25.94 26.68 26.83 27.21 27.02 27.58 25.16 ∞\n",
    "SSIM 0.6606 0.6935 0.7291 0.7387 0.7493 0.7442 0.7620 0.6688 1\n",
    "MOS 1.11 1.47 1.87 1.89 2.12 2.01 2.29 3.56 4.46\n",
    "increase the performance of SRResNet, however, come at\n",
    "the cost of longer training and testing times ( c.f . supple-\n",
    "mentary material). We further found SRGAN variants of\n",
    "deeper networks are increasingly difﬁcult to train due to the\n",
    "appearance of high-frequency artifacts.\n",
    "Of particular importance when aiming for photo-realistic\n",
    "solutions to the SR problem is the choice of the content loss\n",
    "as illustrated in Figure 6. In this work, we found lSR\n",
    "VGG/5.4\n",
    "to yield the perceptually most convincing results, which\n",
    "we attribute to the potential of deeper network layers to\n",
    "represent features of higher abstraction [68, 65, 40] away\n",
    "from pixel space. We speculate that feature maps of these\n",
    "deeper layers focus purely on the content while leaving the\n",
    "adversarial loss focusing on texture details which are the\n",
    "main difference between the super-resolved images without\n",
    "the adversarial loss and photo-realistic images. We also\n",
    "note that the ideal loss function depends on the application.\n",
    "For example, approaches that hallucinate ﬁner detail might\n",
    "be less suited for medical applications or surveillance. The\n",
    "perceptually convincing reconstruction of text or structured\n",
    "scenes [31] is challenging and part of future work. The\n",
    "development of content loss functions that describe image\n",
    "spatial content, but more invariant to changes in pixel space\n",
    "will further improve photo-realistic image SR results.\n",
    "5. Conclusion\n",
    "We have described a deep residual network SRRes-\n",
    "Net that sets a new state of the art on public benchmark\n",
    "datasets when evaluated with the widely used PSNR mea-\n",
    "sure. We have highlighted some limitations of this PSNR-\n",
    "focused image super-resolution and introduced SRGAN,\"\"\",\n",
    "    \"\"\"Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial\n",
    "Network\n",
    "Christian Ledig, Lucas Theis, Ferenc Husz´ar, Jose Caballero, Andrew Cunningham,\n",
    "Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, Wenzhe Shi\n",
    "Twitter\n",
    "{cledig,ltheis,fhuszar,jcaballero,aacostadiaz,aaitken,atejani,jtotz,zehanw,wshi}@twitter.com\n",
    "Abstract\n",
    "Despite the breakthroughs in accuracy and speed of\n",
    "single image super-resolution using faster and deeper con-\n",
    "volutional neural networks, one central problem remains\n",
    "largely unsolved: how do we recover the ﬁner texture details\n",
    "when we super-resolve at large upscaling factors? The\n",
    "behavior of optimization-based super-resolution methods is\n",
    "principally driven by the choice of the objective function.\n",
    "Recent work has largely focused on minimizing the mean\n",
    "squared reconstruction error. The resulting estimates have\n",
    "high peak signal-to-noise ratios, but they are often lacking\n",
    "high-frequency details and are perceptually unsatisfying in\n",
    "the sense that they fail to match the ﬁdelity expected at\n",
    "the higher resolution. In this paper, we present SRGAN,\n",
    "a generative adversarial network (GAN) for image super-\n",
    "resolution (SR). To our knowledge, it is the ﬁrst framework\n",
    "capable of inferring photo-realistic natural images for 4×\n",
    "upscaling factors. To achieve this, we propose a perceptual\n",
    "loss function which consists of an adversarial loss and a\n",
    "content loss. The adversarial loss pushes our solution to\n",
    "the natural image manifold using a discriminator network\n",
    "that is trained to differentiate between the super-resolved\n",
    "images and original photo-realistic images. In addition, we\n",
    "use a content loss motivated by perceptual similarity instead\n",
    "of similarity in pixel space. Our deep residual network\n",
    "is able to recover photo-realistic textures from heavily\n",
    "downsampled images on public benchmarks. An extensive\n",
    "mean-opinion-score (MOS) test shows hugely signiﬁcant\n",
    "gains in perceptual quality using SRGAN. The MOS scores\n",
    "obtained with SRGAN are closer to those of the original\n",
    "high-resolution images than to those obtained with any\n",
    "state-of-the-art method.\n",
    "1. Introduction\n",
    "The highly challenging task of estimating a high-\n",
    "resolution (HR) image from its low-resolution (LR)\n",
    "counterpart is referred to as super-resolution (SR). SR\n",
    "received substantial attention from within the computer\n",
    "vision research community and has a wide range of\n",
    "applications [63, 71, 43].\n",
    "4×SRGAN (proposed) original\n",
    "Figure 1: Super-resolved image (left) is almost indistin-\n",
    "guishable from original (right). [4×upscaling]\n",
    "The ill-posed nature of the underdetermined SR problem\n",
    "is particularly pronounced for high upscaling factors, for\n",
    "which texture detail in the reconstructed SR images is\n",
    "typically absent. The optimization target of supervised\n",
    "SR algorithms is commonly the minimization of the mean\n",
    "squared error (MSE) between the recovered HR image\n",
    "and the ground truth. This is convenient as minimizing\n",
    "MSE also maximizes the peak signal-to-noise ratio (PSNR),\n",
    "which is a common measure used to evaluate and compare\n",
    "SR algorithms [61]. However, the ability of MSE (and\n",
    "PSNR) to capture perceptually relevant differences, such\n",
    "as high texture detail, is very limited as they are deﬁned\n",
    "based on pixel-wise image differences [60, 58, 26]. This\n",
    "is illustrated in Figure 2, where highest PSNR does not\n",
    "necessarily reﬂect the perceptually better SR result. The\n",
    "1\n",
    "arXiv:1609.04802v5  [cs.CV]  25 May 2017\n",
    "bicubic SRResNet SRGAN original\n",
    "(21.59dB/0.6423) (23.53dB/0.7832) (21.15dB/0.6868)\n",
    "Figure 2: From left to right: bicubic interpolation, deep residual network optimized for MSE, deep residual generative\n",
    "adversarial network optimized for a loss more sensitive to human perception, original HR image. Corresponding PSNR and\n",
    "SSIM are shown in brackets. [4×upscaling]\n",
    "perceptual difference between the super-resolved and orig-\n",
    "inal image means that the recovered image is not photo-\n",
    "realistic as deﬁned by Ferwerda [16].\"\"\",\n",
    "    \"\"\"[70] K. Zhang, X. Gao, D. Tao, and X. Li. Multi-scale dictionary for\n",
    "single image super-resolution. In IEEE Conference on Computer\n",
    "Vision and Pattern Recognition (CVPR), pages 1114–1121, 2012. 2\n",
    "[71] W. Zou and P. C. Yuen. Very Low Resolution Face Recognition\n",
    "in Parallel Environment . IEEE Transactions on Image Processing,\n",
    "21:327–340, 2012. 1\n",
    "A. Supplementary Material\n",
    "In this supplementary material we ﬁrst brieﬂy investigate the inﬂuence of network depth (number of residual blocks)\n",
    "on the performance (PSNR, time) of SRResNet in Section A.1. We then visualize on an example image how the SRGAN\n",
    "network performance evolves with increasing number of training iterations in Section A.2. Results of the MOS tests\n",
    "conducted on Set5, Set14, BSD100 are summarized in Section A.3. Finally we provide a visualization of all image\n",
    "reconstruction obtained with SRResNet and SRGAN with a 4×upscaling factor for Set5 (Section A.4), Set14 (Section A.5)\n",
    "and ﬁve randomly selected images from BSD100 (Section A.6).\n",
    "Images are best viewed and compared zoomed in. All original low-/high-resolution images and reconstructions\n",
    "(4×upscaling) obtained with different methods (bicubic, SRResNet-MSE, SRResNet-VGG22, SRGAN-MSE, SRGAN-\n",
    "VGG22, SRGAN-VGG54) described in the paper are available for download at https://twitter.box.com/s/\n",
    "lcue6vlrd01ljkdtdkhmfvk7vtjhetog.\n",
    "A.1. Performance (PSNR/time) vs. network depth\n",
    "We investigated the inﬂuence of network depth, speciﬁcally the number of residual blocks, on performance (PSNR [dB]\n",
    "on BSD100 for 4×SR) and inference time [s] of the network architecture described in Figure 4 of the main paper. Time was\n",
    "assessed on a NVIDIA M40 GPU and averaged over 100 reconstructions of a random low-resolution image with resolution\n",
    "64×64 with upscaling factor 4×. The measurements are plotted in Figure 7 for a network with (blue) and without (red)\n",
    "skip-connection. As expected the time of a single forward pass through the network depends approximately linearly on the\n",
    "number of residual blocks. Whether a skip-connection is used or not has no substantial impact on inference time. However,\n",
    "we observed substantial gains in performance with the additional skip-connection. We chose a network architecture of\n",
    "16 residual blocks with skip-connection for the evaluation presented in the main paper as we consider this as good trade-\n",
    "off between accuracy and speed including training time. While accuracy gains slowly saturate beyond 16 blocks there is,\n",
    "nevertheless, a clear beneﬁt of using even deeper networks.\n",
    "Figure 7: Dependence of network performance (PSNR, time) on network depth. PSNR (left) calculated on BSD100. Time\n",
    "(right) averaged over 100 reconstructions of a random LR image with resolution 64×64.\n",
    "A.2. Evolution of Generator during SRGAN training\n",
    "We further investigated how reconstructions of the SRGAN generator network evolve (visually) with increasing number\n",
    "of training iterations. Visual results obtained after different number of training iterations are illustrated in Figure 8. It is\n",
    "interesting that after only 20 thousand training iterations the generator substantially diverged from the SRResNet initialization\n",
    "and produces reconstruction with a lot of high frequency content, including noise. With increasing number of training\n",
    "iterations reconstructions of the baboon from Set14 appear closer to the reference image. However, there is visually little\n",
    "change during the last 50-100 thousand update iterations.\n",
    "SRResNet 20k 40k 60k 80k\n",
    "100k 140k 180k SRGAN original HR image\n",
    "Figure 8: Evolution of SRGAN generator network during training progress. Note: Generator initialized with SRResNet\n",
    "weights; learning rate set to 10−4 for ﬁrst 100k iterations, then reduced to 10−5 for another 100k iterations. [4×upscaling]\n",
    "A.3. Mean opinion score (MOS) testing\n",
    "In all conducted MOS tests we have asked 26 human raters to assign a score from 1 (Bad) to 5 (Excellent) to reconstructions\"\"\",\n",
    "]\n",
    "    ),\n",
    "    LLMTestCase(\n",
    "        input=\"SRCNN reports 8 032 trainable parameters; can you explain how this relatively small count is achieved?\",\n",
    "        actual_output=\"\"\"SRCNN's relatively low parameter count of 8,032 is a result of its simple three-layer architecture and relatively small filter sizes. Let's break down how the parameter count is calculated:\n",
    "\n",
    "Layer 1 (Patch extraction and representation): This layer uses 64 filters (kernels) with a size of 9x9x1. Since the input is assumed to be a single-channel image (grayscale), each filter has 9*9 = 81 weights, plus one bias term per filter. This results in 64 * (81 + 1) = 5,184 parameters for the first layer.\n",
    "\n",
    "Layer 2 (Non-linear mapping): This layer employs 32 filters with a size of 1x1x64. The input to this layer is the output from the first layer, which has 64 channels. So each filter has 1164 = 64 weights, plus one bias term. This leads to 32 * (64 + 1) = 2,080 parameters in the second layer.\n",
    "\n",
    "Layer 3 (Reconstruction): The final layer has a single filter with a size of 5x5x32. It takes the 32-channel output of the second layer as input. The filter has 5532 = 800 weights, plus a single bias term. This totals 800 + 1 = 801 parameters for the third layer.\n",
    "\n",
    "Adding the parameters from all three layers: 5,184 + 2,080 + 801 = 8,065. The original paper mentions 8,032, suggesting a slight variation in the calculation. While the exact reason for this minor difference is unclear within the provided text, the primary reason for the low number of parameters is the smaller filter sizes compared to many deeper convolutional neural networks (CNNs), which might have hundreds or thousands of filters and larger filter dimensions, leading to millions or even billions of parameters.\"\"\",\n",
    "        expected_output=\"\"\"Because it uses just three convolutional layers with relatively few filters (64, 32, c) and small kernels (9×9, 1×1, 5×5). Param count = (c·9²·64)+(64·1²·32)+(32·5²·c)+biases ≈ 8 k\"\"\",\n",
    "        context=[\n",
    "            \"\"\"A typical and basic setting is f₁ = 9, f₂ = 1, f₃ = 5, n₁ = 64, n₂ = 32 … the number of parameters of 9‑1‑5 … is 8 032.\"\"\"\n",
    "        ],\n",
    "        retrieval_context=[\n",
    "    \"\"\"observed, with the same number of backpropagations\n",
    "(i.e.,8 ×108), the SRCNN +ImageNet achieves 32.52 dB,\n",
    "higher than 32.39 dB yielded by that trained on 91\n",
    "images. The results positively indicate that SRCNN per-\n",
    "formance may be further boosted using a larger training\n",
    "set, but the effect of big data is not as impressive as\n",
    "that shown in high-level vision problems [26]. This is\n",
    "mainly because that the 91 images have already cap-\n",
    "tured sufﬁcient variability of natural images. On the\n",
    "other hand, our SRCNN is a relatively small network\n",
    "(8,032 parameters), which could not overﬁt the 91 images\n",
    "(24,800 samples). Nevertheless, we adopt the ImageNet,\n",
    "which contains more diverse data, as the default training\n",
    "set in the following experiments.\n",
    "4.2 Learned Filters for Super-Resolution\n",
    "Figure 5 shows examples of learned ﬁrst-layer ﬁlters\n",
    "trained on the ImageNet by an upscaling factor 3. Please\n",
    "refer to our published implementation for upscaling\n",
    "factors 2 and 4. Interestingly, each learned ﬁlter has\n",
    "its speciﬁc functionality. For instance, the ﬁlters g and\n",
    "h are like Laplacian/Gaussian ﬁlters, the ﬁlters a - e\n",
    "are like edge detectors at different directions, and the\n",
    "ﬁlter f is like a texture extractor. Example feature maps\n",
    "of different layers are shown in ﬁgure 6. Obviously,\n",
    "feature maps of the ﬁrst layer contain different structures\n",
    "(e.g., edges at different directions), while that of the\n",
    "second layer are mainly different on intensities.\n",
    "4.3 Model and Performance Trade-offs\n",
    "Based on the basic network settings ( i.e., f1 = 9, f2 = 1,\n",
    "f3 = 5 , n1 = 64 , and n2 = 32 ), we will progressively\n",
    "modify some of these parameters to investigate the best\n",
    "trade-off between performance and speed, and study the\n",
    "relations between performance and parameters.\n",
    "1 2 3 4 5 6 7 8 9 10\n",
    "xS10\n",
    "8\n",
    "31.4\n",
    "31.6\n",
    "31.8\n",
    "32\n",
    "32.2\n",
    "32.4\n",
    "32.6\n",
    "NumberSofSbackprops\n",
    "AverageStestSPSNRSndBI\n",
    "SRCNNSntrainedSonSImageNetI\n",
    "SRCNNSntrainedSonS91SimagesI\n",
    "SCSn31.42SdBI\n",
    "Fig. 4. Training with the much larger ImageNet dataset\n",
    "improves the performance over the use of 91 images.\n",
    "7\n",
    "a b c d e f\n",
    "g\n",
    "h\n",
    "Fig. 5. The ﬁgure shows the ﬁrst-layer ﬁlters trained\n",
    "on ImageNet with an upscaling factor 3. The ﬁlters are\n",
    "organized based on their respective variances.\n",
    "Input Feature maps of the first layer\n",
    "Output Feature maps of the second layer\n",
    "Fig. 6. Example feature maps of different layers.\n",
    "4.3.1 Filter number\n",
    "In general, the performance would improve if we in-\n",
    "crease the network width6, i.e., adding more ﬁlters, at the\n",
    "cost of running time. Speciﬁcally, based on our network\n",
    "default settings of n1 = 64 and n2 = 32 , we conduct\n",
    "two experiments: (i) one is with a larger network with\n",
    "n1 = 128 and n2 = 64, and (ii) the other is with a smaller\n",
    "network with n1 = 32 and n2 = 16. Similar to Section 4.1,\n",
    "we also train the two models on ImageNet and test on\n",
    "Set5 with an upscaling factor 3. The results observed\n",
    "at 8 ×108 backpropagations are shown in Table 1. It is\n",
    "clear that superior performance could be achieved by\n",
    "increasing the width. However, if a fast restoration speed\n",
    "is desired, a small network width is preferred, which\n",
    "could still achieve better performance than the sparse-\n",
    "coding-based method (31.42 dB).\n",
    "TABLE 1\n",
    "The results of using different ﬁlter numbers in SRCNN.\n",
    "Training is performed on ImageNet whilst the evaluation\n",
    "is conducted on the Set5 dataset.\n",
    "n1 = 128 n1 = 64 n1 = 32\n",
    "n2 = 64 n2 = 32 n2 = 16\n",
    "PSNR Time (sec) PSNR Time (sec) PSNR Time (sec)\n",
    "32.60 0.60 32.52 0.18 32.26 0.05\n",
    "4.3.2 Filter size\n",
    "In this section, we examine the network sensitivity to\n",
    "different ﬁlter sizes. In previous experiments, we set\n",
    "ﬁlter size f1 = 9, f2 = 1 and f3 = 5, and the network\n",
    "could be denoted as 9-1-5. First, to be consistent with\n",
    "sparse-coding-based methods, we ﬁx the ﬁlter size of the\n",
    "second layer to be f2 = 1, and enlarge the ﬁlter size of\n",
    "other layers to f1 = 11 and f3 = 7 (11-1-7). All the other\n",
    "6. We use ‘width’ to term the number of ﬁlters in a layer, follow-\"\"\",\n",
    "    \"\"\"erations, ηis the learning rate, and ∂L\n",
    "∂W ℓ\n",
    "i\n",
    "is the derivative.\n",
    "The ﬁlter weights of each layer are initialized by drawing\n",
    "randomly from a Gaussian distribution with zero mean\n",
    "and standard deviation 0.001 (and 0 for biases). The\n",
    "learning rate is 10−4 for the ﬁrst two layers, and 10−5 for\n",
    "the last layer. We empirically ﬁnd that a smaller learning\n",
    "rate in the last layer is important for the network to\n",
    "converge (similar to the denoising case [22]).\n",
    "In the training phase, the ground truth images {Xi}\n",
    "are prepared as fsub×fsub×c-pixel sub-images randomly\n",
    "cropped from the training images. By “sub-images” we\n",
    "mean these samples are treated as small “images” rather\n",
    "than “patches”, in the sense that “patches” are overlap-\n",
    "ping and require some averaging as post-processing but\n",
    "“sub-images” need not. To synthesize the low-resolution\n",
    "samples {Yi}, we blur a sub-image by a Gaussian kernel,\n",
    "sub-sample it by the upscaling factor, and upscale it by\n",
    "the same factor via bicubic interpolation.\n",
    "To avoid border effects during training, all the con-\n",
    "volutional layers have no padding, and the network\n",
    "produces a smaller output ( (fsub −f1 −f2 −f3 + 3)2 ×c).\n",
    "The MSE loss function is evaluated only by the difference\n",
    "between the central pixels of Xi and the network output.\n",
    "Although we use a ﬁxed image size in training, the\n",
    "convolutional neural network can be applied on images\n",
    "of arbitrary sizes during testing.\n",
    "We implement our model using the cuda-convnet pack-\n",
    "age [26]. We have also tried the Caffe package [24] and\n",
    "observed similar performance.\n",
    "4 E XPERIMENTS\n",
    "We ﬁrst investigate the impact of using different datasets\n",
    "on the model performance. Next, we examine the ﬁlters\n",
    "learned by our approach. We then explore different\n",
    "architecture designs of the network, and study the rela-\n",
    "tions between super-resolution performance and factors\n",
    "like depth, number of ﬁlters, and ﬁlter sizes. Subse-\n",
    "quently, we compare our method with recent state-of-\n",
    "the-arts both quantitatively and qualitatively. Following\n",
    "[42], super-resolution is only applied on the luminance\n",
    "channel (Y channel in YCbCr color space) in Sections 4.1-\n",
    "4.4, so c = 1 in the ﬁrst/last layer, and performance\n",
    "(e.g., PSNR and SSIM) is evaluated on the Y channel. At\n",
    "last, we extend the network to cope with color images\n",
    "and evaluate the performance on different channels.\n",
    "4.1 Training Data\n",
    "As shown in the literature, deep learning generally\n",
    "beneﬁts from big data training. For comparison, we use\n",
    "a relatively small training set [41], [50] that consists\n",
    "of 91 images, and a large training set that consists of\n",
    "395,909 images from the ILSVRC 2013 ImageNet detec-\n",
    "tion training partition. The size of training sub-images is\n",
    "fsub = 33. Thus the 91-image dataset can be decomposed\n",
    "into 24,800 sub-images, which are extracted from origi-\n",
    "nal images with a stride of 14. Whereas the ImageNet\n",
    "provides over 5 million sub-images even using a stride\n",
    "of 33. We use the basic network settings, i.e., f1 = 9 ,\n",
    "f2 = 1, f3 = 5, n1 = 64, and n2 = 32. We use the Set5 [2]\n",
    "as the validation set. We observe a similar trend even\n",
    "if we use the larger Set14 set [51]. The upscaling factor\n",
    "is 3. We use the sparse-coding-based method [50] as our\n",
    "baseline, which achieves an average PSNR value of 31.42\n",
    "dB.\n",
    "The test convergence curves of using different training\n",
    "sets are shown in Figure 4. The training time on Ima-\n",
    "geNet is about the same as on the 91-image dataset since\n",
    "the number of backpropagations is the same. As can be\n",
    "observed, with the same number of backpropagations\n",
    "(i.e.,8 ×108), the SRCNN +ImageNet achieves 32.52 dB,\n",
    "higher than 32.39 dB yielded by that trained on 91\n",
    "images. The results positively indicate that SRCNN per-\n",
    "formance may be further boosted using a larger training\n",
    "set, but the effect of big data is not as impressive as\n",
    "that shown in high-level vision problems [26]. This is\n",
    "mainly because that the 91 images have already cap-\n",
    "tured sufﬁcient variability of natural images. On the\"\"\",\n",
    "    \"\"\"the ﬁnal full image. The averaging can be considered\n",
    "as a pre-deﬁned ﬁlter on a set of feature maps (where\n",
    "each position is the “ﬂattened” vector form of a high-\n",
    "resolution patch). Motivated by this, we deﬁne a convo-\n",
    "lutional layer to produce the ﬁnal high-resolution image:\n",
    "F(Y) = W3 ∗F2(Y) + B3. (3)\n",
    "4. The ReLU can be equivalently considered as a part of the second\n",
    "operation (Non-linear mapping), and the ﬁrst operation (Patch extrac-\n",
    "tion and representation) becomes purely linear convolution.\n",
    "Here W3 corresponds to c ﬁlters of a size n2 ×f3 ×f3,\n",
    "and B3 is a c-dimensional vector.\n",
    "If the representations of the high-resolution patches\n",
    "are in the image domain (i.e.,we can simply reshape each\n",
    "representation to form the patch), we expect that the\n",
    "ﬁlters act like an averaging ﬁlter; if the representations\n",
    "of the high-resolution patches are in some other domains\n",
    "(e.g.,coefﬁcients in terms of some bases), we expect that\n",
    "W3 behaves like ﬁrst projecting the coefﬁcients onto the\n",
    "image domain and then averaging. In either way, W3 is\n",
    "a set of linear ﬁlters.\n",
    "Interestingly, although the above three operations are\n",
    "motivated by different intuitions, they all lead to the\n",
    "same form as a convolutional layer. We put all three\n",
    "operations together and form a convolutional neural\n",
    "network (Figure 2). In this model, all the ﬁltering weights\n",
    "and biases are to be optimized. Despite the succinctness\n",
    "of the overall structure, our SRCNN model is carefully\n",
    "developed by drawing extensive experience resulted\n",
    "from signiﬁcant progresses in super-resolution [49], [50].\n",
    "We detail the relationship in the next section.\n",
    "3.2 Relationship to Sparse-Coding-Based Methods\n",
    "We show that the sparse-coding-based SR methods [49],\n",
    "[50] can be viewed as a convolutional neural network.\n",
    "Figure 3 shows an illustration.\n",
    "In the sparse-coding-based methods, let us consider\n",
    "that an f1 ×f1 low-resolution patch is extracted from\n",
    "the input image. Then the sparse coding solver, like\n",
    "Feature-Sign [29], will ﬁrst project the patch onto a (low-\n",
    "resolution) dictionary. If the dictionary size is n1, this\n",
    "is equivalent to applying n1 linear ﬁlters ( f1 ×f1) on\n",
    "the input image (the mean subtraction is also a linear\n",
    "operation so can be absorbed). This is illustrated as the\n",
    "left part of Figure 3.\n",
    "The sparse coding solver will then iteratively process\n",
    "the n1 coefﬁcients. The outputs of this solver are n2\n",
    "coefﬁcients, and usually n2 = n1 in the case of sparse\n",
    "coding. These n2 coefﬁcients are the representation of\n",
    "the high-resolution patch. In this sense, the sparse coding\n",
    "5\n",
    "responses\n",
    "of patch of\n",
    "neighbouring\n",
    "patches\n",
    " Patch extraction\n",
    "and representation\n",
    "Non-linear\n",
    " mapping\n",
    "Reconstruction\n",
    "Fig. 3. An illustration of sparse-coding-based methods in the view of a convolutional neural network.\n",
    "solver behaves as a special case of a non-linear mapping\n",
    "operator, whose spatial support is 1 ×1. See the middle\n",
    "part of Figure 3. However, the sparse coding solver is\n",
    "not feed-forward, i.e.,it is an iterative algorithm. On the\n",
    "contrary, our non-linear operator is fully feed-forward\n",
    "and can be computed efﬁciently. If we set f2 = 1, then\n",
    "our non-linear operator can be considered as a pixel-wise\n",
    "fully-connected layer. It is worth noting that “the sparse\n",
    "coding solver” in SRCNN refers to the ﬁrst two layers,\n",
    "but not just the second layer or the activation function\n",
    "(ReLU). Thus the nonlinear operation in SRCNN is also\n",
    "well optimized through the learning process.\n",
    "The above n2 coefﬁcients (after sparse coding) are\n",
    "then projected onto another (high-resolution) dictionary\n",
    "to produce a high-resolution patch. The overlapping\n",
    "high-resolution patches are then averaged. As discussed\n",
    "above, this is equivalent to linear convolutions on the\n",
    "n2 feature maps. If the high-resolution patches used for\n",
    "reconstruction are of size f3 ×f3, then the linear ﬁlters\n",
    "have an equivalent spatial support of size f3 ×f3. See\n",
    "the right part of Figure 3.\n",
    "The above discussion shows that the sparse-coding-\"\"\",\n",
    "    \"\"\"then projected onto another (high-resolution) dictionary\n",
    "to produce a high-resolution patch. The overlapping\n",
    "high-resolution patches are then averaged. As discussed\n",
    "above, this is equivalent to linear convolutions on the\n",
    "n2 feature maps. If the high-resolution patches used for\n",
    "reconstruction are of size f3 ×f3, then the linear ﬁlters\n",
    "have an equivalent spatial support of size f3 ×f3. See\n",
    "the right part of Figure 3.\n",
    "The above discussion shows that the sparse-coding-\n",
    "based SR method can be viewed as a kind of con-\n",
    "volutional neural network (with a different non-linear\n",
    "mapping). But not all operations have been considered in\n",
    "the optimization in the sparse-coding-based SR methods.\n",
    "On the contrary, in our convolutional neural network,\n",
    "the low-resolution dictionary, high-resolution dictionary,\n",
    "non-linear mapping, together with mean subtraction and\n",
    "averaging, are all involved in the ﬁlters to be optimized.\n",
    "So our method optimizes an end-to-end mapping that\n",
    "consists of all operations.\n",
    "The above analogy can also help us to design hyper-\n",
    "parameters. For example, we can set the ﬁlter size of\n",
    "the last layer to be smaller than that of the ﬁrst layer,\n",
    "and thus we rely more on the central part of the high-\n",
    "resolution patch (to the extreme, if f3 = 1 , we are\n",
    "using the center pixel with no averaging). We can also\n",
    "set n2 < n1 because it is expected to be sparser. A\n",
    "typical and basic setting is f1 = 9 , f2 = 1 , f3 = 5 ,\n",
    "n1 = 64 , and n2 = 32 (we evaluate more settings in\n",
    "the experiment section). On the whole, the estimation\n",
    "of a high resolution pixel utilizes the information of\n",
    "(9 + 5 −1)2 = 169 pixels. Clearly, the information\n",
    "exploited for reconstruction is comparatively larger than\n",
    "that used in existing external example-based approaches,\n",
    "e.g., using (5+5 −1)2 = 81 pixels5 [15], [50]. This is one of\n",
    "the reasons why the SRCNN gives superior performance.\n",
    "3.3 Training\n",
    "Learning the end-to-end mapping function F re-\n",
    "quires the estimation of network parameters Θ =\n",
    "{W1,W2,W3,B1,B2,B3}. This is achieved through min-\n",
    "imizing the loss between the reconstructed images\n",
    "F(Y; Θ) and the corresponding ground truth high-\n",
    "resolution images X. Given a set of high-resolution\n",
    "images {Xi} and their corresponding low-resolution\n",
    "images {Yi}, we use Mean Squared Error (MSE) as the\n",
    "loss function:\n",
    "L(Θ) = 1\n",
    "n\n",
    "n∑\n",
    "i=1\n",
    "||F(Yi; Θ)−Xi||2, (4)\n",
    "where n is the number of training samples. Using MSE\n",
    "as the loss function favors a high PSNR. The PSNR\n",
    "is a widely-used metric for quantitatively evaluating\n",
    "image restoration quality, and is at least partially related\n",
    "to the perceptual quality. It is worth noticing that the\n",
    "convolutional neural networks do not preclude the usage\n",
    "of other kinds of loss functions, if only the loss functions\n",
    "are derivable. If a better perceptually motivated metric\n",
    "is given during training, it is ﬂexible for the network to\n",
    "adapt to that metric. On the contrary, such a ﬂexibility\n",
    "is in general difﬁcult to achieve for traditional “hand-\n",
    "crafted” methods. Despite that the proposed model is\n",
    "trained favoring a high PSNR, we still observe satisfac-\n",
    "tory performance when the model is evaluated using\n",
    "alternative evaluation metrics, e.g., SSIM, MSSIM (see\n",
    "Section 4.4.1).\n",
    "The loss is minimized using stochastic gradient de-\n",
    "scent with the standard backpropagation [28]. In partic-\n",
    "ular, the weight matrices are updated as\n",
    "∆i+1 = 0.9 ·∆i −η· ∂L\n",
    "∂Wℓ\n",
    "i\n",
    ", W ℓ\n",
    "i+1 = Wℓ\n",
    "i + ∆i+1, (5)\n",
    "5. The patches are overlapped with 4 pixels at each direction.\n",
    "6\n",
    "where ℓ∈{1,2,3}and i are the indices of layers and it-\n",
    "erations, ηis the learning rate, and ∂L\n",
    "∂W ℓ\n",
    "i\n",
    "is the derivative.\n",
    "The ﬁlter weights of each layer are initialized by drawing\n",
    "randomly from a Gaussian distribution with zero mean\n",
    "and standard deviation 0.001 (and 0 for biases). The\n",
    "learning rate is 10−4 for the ﬁrst two layers, and 10−5 for\n",
    "the last layer. We empirically ﬁnd that a smaller learning\n",
    "rate in the last layer is important for the network to\n",
    "converge (similar to the denoising case [22]).\"\"\",\n",
    "    \"\"\"4.3.2 Filter size\n",
    "In this section, we examine the network sensitivity to\n",
    "different ﬁlter sizes. In previous experiments, we set\n",
    "ﬁlter size f1 = 9, f2 = 1 and f3 = 5, and the network\n",
    "could be denoted as 9-1-5. First, to be consistent with\n",
    "sparse-coding-based methods, we ﬁx the ﬁlter size of the\n",
    "second layer to be f2 = 1, and enlarge the ﬁlter size of\n",
    "other layers to f1 = 11 and f3 = 7 (11-1-7). All the other\n",
    "6. We use ‘width’ to term the number of ﬁlters in a layer, follow-\n",
    "ing [17]. The term ‘width’ may have other meanings in the literature.\n",
    "1 2 3 4 5 6 7 8 9 10\n",
    "xS10\n",
    "8\n",
    "31.5\n",
    "32\n",
    "32.5\n",
    "NumberSofSbackprops\n",
    "AverageStestSPSNRS(dB)\n",
    "SRCNNS(9−5−5)\n",
    "SRCNNS(9−3−5)\n",
    "SRCNNS(9−1−5)\n",
    "SCS(31.42SdB)\n",
    "Fig. 7. A larger ﬁlter size leads to better results.\n",
    "settings remain the same with Section 4.1. The results\n",
    "with an upscaling factor 3 on Set5 are 32.57 dB, which is\n",
    "slightly higher than the 32.52 dB reported in Section 4.1.\n",
    "This indicates that a reasonably larger ﬁlter size could\n",
    "grasp richer structural information, which in turn lead\n",
    "to better results.\n",
    "Then we further examine networks with a larger ﬁlter\n",
    "size of the second layer. Speciﬁcally, we ﬁx the ﬁlter size\n",
    "f1 = 9, f3 = 5, and enlarge the ﬁlter size of the second\n",
    "layer to be (i) f2 = 3 (9-3-5) and (ii) f2 = 5 (9-5-5).\n",
    "Convergence curves in Figure 7 show that using a larger\n",
    "ﬁlter size could signiﬁcantly improve the performance.\n",
    "Speciﬁcally, the average PSNR values achieved by 9-3-\n",
    "5 and 9-5-5 on Set5 with 8 ×108 backpropagations are\n",
    "32.66 dB and 32.75 dB, respectively. The results suggest\n",
    "that utilizing neighborhood information in the mapping\n",
    "stage is beneﬁcial.\n",
    "However, the deployment speed will also decrease\n",
    "with a larger ﬁlter size. For example, the number of\n",
    "parameters of 9-1-5, 9-3-5, and 9-5-5 is 8,032, 24,416, and\n",
    "57,184 respectively. The complexity of 9-5-5 is almost\n",
    "twice of 9-3-5, but the performance improvement is\n",
    "marginal. Therefore, the choice of the network scale\n",
    "should always be a trade-off between performance and\n",
    "speed.\n",
    "4.3.3 Number of layers\n",
    "Recent study by He and Sun [17] suggests that CNN\n",
    "could beneﬁt from increasing the depth of network\n",
    "moderately. Here, we try deeper structures by adding\n",
    "another non-linear mapping layer, which has n22 = 16\n",
    "ﬁlters with size f22 = 1 . We conduct three controlled\n",
    "experiments, i.e., 9-1-1-5, 9-3-1-5, 9-5-1-5, which add an\n",
    "additional layer on 9-1-5, 9-3-5, and 9-5-5, respectively.\n",
    "The initialization scheme and learning rate of the ad-\n",
    "ditional layer are the same as the second layer. From\n",
    "Figures 13(a), 13(b) and 8(c), we can observe that the\n",
    "four-layer networks converge slower than the three-layer\n",
    "network. Nevertheless, given enough training time, the\n",
    "deeper networks will ﬁnally catch up and converge to\n",
    "the three-layer ones.\n",
    "The effectiveness of deeper structures for super reso-\n",
    "lution is found not as apparent as that shown in image\n",
    "classiﬁcation [17]. Furthermore, we ﬁnd that deeper\n",
    "networks do not always result in better performance.\n",
    "Speciﬁcally, if we add an additional layer with n22 = 32\n",
    "ﬁlters on 9-1-5 network, then the performance degrades\n",
    "and fails to surpass the three-layer network (see Fig-\n",
    "ure 9(a)). If we go deeper by adding two non-linear\n",
    "8\n",
    "2 4 6 8 10 12\n",
    "x(10\n",
    "8\n",
    "31\n",
    "31.5\n",
    "32\n",
    "32.5\n",
    "Number(of(backprops\n",
    "Average(test(PSNR((dB)\n",
    "SRCNN((9−1−5)\n",
    "SRCNN((9−1−1−5)\n",
    "SC((31.42(dB)\n",
    "(a) 9-1-5 vs. 9-1-1-5\n",
    "1 2 3 4 5 6 7 8 9 10\n",
    "xS10\n",
    "8\n",
    "31.5\n",
    "32\n",
    "32.5\n",
    "NumberSofSbackprops\n",
    "AverageStestSPSNRS(dB)\n",
    "SRCNNS(9−3−5)\n",
    "SRCNNS(9−3−1−5)\n",
    "SCS(31.42SdB)\n",
    "(b) 9-3-5 vs. 9-3-1-5\n",
    "1 2 3 4 5 6 7 8\n",
    "xR10\n",
    "8\n",
    "31.5\n",
    "32\n",
    "32.5\n",
    "NumberRofRbackprops\n",
    "AverageRtestRPSNRR(dB)\n",
    "SRCNNR(9−5−5)\n",
    "SRCNNR(9−5−1−5)\n",
    "SCR(31.42RdB)\n",
    "(c) 9-5-5 vs. 9-5-1-5\n",
    "Fig. 8. Comparisons between three-layer and four-layer\n",
    "networks.\n",
    "mapping layers with n22 = 32 and n23 = 16 ﬁlters on\n",
    "9-1-5, then we have to set a smaller learning rate to\n",
    "ensure convergence, but we still do not observe superior\n",
    "performance after a week of training (see Figure 9(a)).\n",
    "We also tried to enlarge the ﬁlter size of the additional\"\"\",\n",
    "    \"\"\"In this paper, we show that the aforementioned\n",
    "pipeline is equivalent to a deep convolutional neural net-\n",
    "work [27] (more details in Section 3.2). Motivated by this\n",
    "fact, we consider a convolutional neural network that\n",
    "directly learns an end-to-end mapping between low- and\n",
    "high-resolution images. Our method differs fundamen-\n",
    "tally from existing external example-based approaches,\n",
    "in that ours does not explicitly learn the dictionaries [41],\n",
    "[49], [50] or manifolds [2], [4] for modeling the patch\n",
    "space. These are implicitly achieved via hidden layers.\n",
    "Furthermore, the patch extraction and aggregation are\n",
    "also formulated as convolutional layers, so are involved\n",
    "in the optimization. In our method, the entire SR pipeline\n",
    "is fully obtained through learning, with little pre/post-\n",
    "processing.\n",
    "We name the proposed model Super-Resolution Con-\n",
    "volutional Neural Network (SRCNN) 1. The proposed\n",
    "SRCNN has several appealing properties. First, its struc-\n",
    "ture is intentionally designed with simplicity in mind,\n",
    "and yet provides superior accuracy 2 compared with\n",
    "state-of-the-art example-based methods. Figure 1 shows\n",
    "a comparison on an example. Second, with moderate\n",
    "1. The implementation is available at http://mmlab.ie.cuhk.edu.hk/\n",
    "projects/SRCNN.html.\n",
    "2. Numerical evaluations by using different metrics such as the Peak\n",
    "Signal-to-Noise Ratio (PSNR), structure similarity index (SSIM) [43],\n",
    "multi-scale SSIM [44], information ﬁdelity criterion [38], when the\n",
    "ground truth images are available.\n",
    "arXiv:1501.00092v3  [cs.CV]  31 Jul 2015\n",
    "2\n",
    "Bicubic / 24.04 dB\n",
    "SC / 25.58 dBSRCNN / 27.95 dB\n",
    "Original / PSNR\n",
    "2 4 6 8 10 12x 108\n",
    "29.5\n",
    "30\n",
    "30.5\n",
    "31\n",
    "31.5\n",
    "32\n",
    "32.5\n",
    "33\n",
    "Number of backprops\n",
    "Average test PSNR (dB)\n",
    "SRCNN\n",
    "SC\n",
    "Bicubic\n",
    "Bicubic / 24.04 dB\n",
    "SC / 25.58 dBSRCNN / 27.95 dB\n",
    "Original / PSNR\n",
    "Bicubic / 24.04 dB\n",
    "SC / 25.58 dBSRCNN / 27.95 dB\n",
    "Original / PSNR\n",
    "SRCNN\n",
    "SC\n",
    "Bicubic\n",
    "Bicubic / 24.04 dB\n",
    "SC / 25.58 dBSRCNN / 27.95 dB\n",
    "Original / PSNR\n",
    "Number of backprops\n",
    "Average test PSNR (dB)\n",
    "Fig. 1. The proposed Super-Resolution Convolutional\n",
    "Neural Network (SRCNN) surpasses the bicubic baseline\n",
    "with just a few training iterations, and outperforms the\n",
    "sparse-coding-based method (SC) [50] with moderate\n",
    "training. The performance may be further improved with\n",
    "more training iterations. More details are provided in\n",
    "Section 4.4.1 (the Set5 dataset with an upscaling factor\n",
    "3). The proposed method provides visually appealing\n",
    "reconstructed image.\n",
    "numbers of ﬁlters and layers, our method achieves\n",
    "fast speed for practical on-line usage even on a CPU.\n",
    "Our method is faster than a number of example-based\n",
    "methods, because it is fully feed-forward and does\n",
    "not need to solve any optimization problem on usage.\n",
    "Third, experiments show that the restoration quality of\n",
    "the network can be further improved when (i) larger\n",
    "and more diverse datasets are available, and/or (ii)\n",
    "a larger and deeper model is used. On the contrary,\n",
    "larger datasets/models can present challenges for exist-\n",
    "ing example-based methods. Furthermore, the proposed\n",
    "network can cope with three channels of color images\n",
    "simultaneously to achieve improved super-resolution\n",
    "performance.\n",
    "Overall, the contributions of this study are mainly in\n",
    "three aspects:\n",
    "1) We present a fully convolutional neural net-\n",
    "work for image super-resolution. The network di-\n",
    "rectly learns an end-to-end mapping between low-\n",
    "and high-resolution images, with little pre/post-\n",
    "processing beyond the optimization.\n",
    "2) We establish a relationship between our deep-\n",
    "learning-based SR method and the traditional\n",
    "sparse-coding-based SR methods. This relationship\n",
    "provides a guidance for the design of the network\n",
    "structure.\n",
    "3) We demonstrate that deep learning is useful in\n",
    "the classical computer vision problem of super-\n",
    "resolution, and can achieve good quality and\n",
    "speed.\n",
    "A preliminary version of this work was presented\n",
    "earlier [11]. The present work adds to the initial version\n",
    "in signiﬁcant ways. Firstly, we improve the SRCNN by\n",
    "introducing larger ﬁlter size in the non-linear mapping\"\"\",\n",
    "    \"\"\"1 2 3 4 5 6 7 8\n",
    "xR10\n",
    "8\n",
    "31.5\n",
    "32\n",
    "32.5\n",
    "NumberRofRbackprops\n",
    "AverageRtestRPSNRR(dB)\n",
    "SRCNNR(9−5−5)\n",
    "SRCNNR(9−5−1−5)\n",
    "SCR(31.42RdB)\n",
    "(c) 9-5-5 vs. 9-5-1-5\n",
    "Fig. 8. Comparisons between three-layer and four-layer\n",
    "networks.\n",
    "mapping layers with n22 = 32 and n23 = 16 ﬁlters on\n",
    "9-1-5, then we have to set a smaller learning rate to\n",
    "ensure convergence, but we still do not observe superior\n",
    "performance after a week of training (see Figure 9(a)).\n",
    "We also tried to enlarge the ﬁlter size of the additional\n",
    "layer to f22 = 3, and explore two deep structures – 9-3-\n",
    "3-5 and 9-3-3-3. However, from the convergence curves\n",
    "shown in Figure 9(b), these two networks do not show\n",
    "better results than the 9-3-1-5 network.\n",
    "All these experiments indicate that it is not “the deeper\n",
    "the better” in this deep model for super-resolution. It\n",
    "may be caused by the difﬁculty of training. Our CNN\n",
    "network contains no pooling layer or full-connected\n",
    "layer, thus it is sensitive to the initialization parameters\n",
    "and learning rate. When we go deeper (e.g., 4 or 5 layers),\n",
    "we ﬁnd it hard to set appropriate learning rates that\n",
    "guarantee convergence. Even it converges, the network\n",
    "may fall into a bad local minimum, and the learned\n",
    "ﬁlters are of less diversity even given enough training\n",
    "time. This phenomenon is also observed in [16], where\n",
    "improper increase of depth leads to accuracy saturation\n",
    "or degradation for image classiﬁcation. Why “deeper is\n",
    "not better” is still an open question, which requires in-\n",
    "vestigations to better understand gradients and training\n",
    "dynamics in deep architectures. Therefore, we still adopt\n",
    "three-layer networks in the following experiments.\n",
    "4.4 Comparisons to State-of-the-Arts\n",
    "In this section, we show the quantitative and qualitative\n",
    "results of our method in comparison to state-of-the-art\n",
    "2 4 6 8 10 12\n",
    "x(10\n",
    "8\n",
    "31\n",
    "31.5\n",
    "32\n",
    "32.5\n",
    "Number(of(backprops\n",
    "Average(test(PSNR(=dB)\n",
    "SRCNN(=9−1−5)\n",
    "SRCNN(=9−1−1−5,(n 22=16)\n",
    "SRCNN(=9−1−1−5,(n 22=32)\n",
    "SRCNN(=9−1−1−1−5,(n 22=32,(n 23=16)\n",
    "SC(=31.42(dB)\n",
    "(a) 9-1-1-5 ( n22 = 32) and 9-1-1-1-5 ( n22 = 32, n23 = 16)\n",
    "1 2 3 4 5 6 7 8 9\n",
    "xS10\n",
    "8\n",
    "31.5\n",
    "32\n",
    "32.5\n",
    "NumberSofSbackprops\n",
    "AverageStestSPSNRS(dB)\n",
    "SRCNNS(9−3−5)\n",
    "SRCNNS(9−3−1−5)\n",
    "SRCNNS(9−3−3−5)\n",
    "SRCNNS(9−3−3−3)\n",
    "SCS(31.42SdB)\n",
    "(b) 9-3-3-5 and 9-3-3-3\n",
    "Fig. 9. Deeper structure does not always lead to better\n",
    "results.\n",
    "methods. We adopt the model with good performance-\n",
    "speed trade-off: a three-layer network with f1 = 9, f2 =\n",
    "5, f3 = 5, n1 = 64, and n2 = 32 trained on the ImageNet.\n",
    "For each upscaling factor ∈{2,3,4}, we train a speciﬁc\n",
    "network for that factor 7.\n",
    "Comparisons. We compare our SRCNN with the state-\n",
    "of-the-art SR methods:\n",
    "• SC - sparse coding-based method of Yang et al. [50]\n",
    "• NE+LLE - neighbour embedding + locally linear\n",
    "embedding method [4]\n",
    "• ANR - Anchored Neighbourhood Regression\n",
    "method [41]\n",
    "• A+ - Adjusted Anchored Neighbourhood Regres-\n",
    "sion method [42], and\n",
    "• KK - the method described in [25], which achieves\n",
    "the best performance among external example-\n",
    "based methods, according to the comprehensive\n",
    "evaluation conducted in Yang et al.’s work [46]\n",
    "The implementations are all from the publicly available\n",
    "codes provided by the authors, and all images are down-\n",
    "sampled using the same bicubic kernel.\n",
    "Test set.The Set5 [2] (5 images), Set14 [51] (14 images)\n",
    "and BSD200 [32] (200 images) 8 are used to evaluate the\n",
    "performance of upscaling factors 2, 3, and 4.\n",
    "Evaluation metrics. Apart from the widely used PSNR\n",
    "and SSIM [43] indices, we also adopt another four\n",
    "evaluation matrices, namely information ﬁdelity cri-\n",
    "terion (IFC) [38], noise quality measure (NQM) [8],\n",
    "weighted peak signal-to-noise ratio (WPSNR) and multi-\n",
    "scale structure similarity index (MSSSIM) [44], which\n",
    "obtain high correlation with the human perceptual scores\n",
    "as reported in [46].\n",
    "4.4.1 Quantitative and qualitative evaluation\n",
    "As shown in Tables 2, 3 and 4, the proposed SRCNN\n",
    "yields the highest scores in most evaluation matrices\n",
    "7. In the area of denoising [3], for each noise level a speciﬁc network\n",
    "is trained.\"\"\",\n",
    "    \"\"\"bicubic interpolation. The training falls into a bad local\n",
    "minimum, due to the inherently different characteristics\n",
    "of the Y and Cb, Cr channels. (ii) If we pre-train on the\n",
    "Y or Cb, Cr channels, the performance ﬁnally improves,\n",
    "but is still not better than “Y only” on the color image\n",
    "(see the last column of Table 5, where PSNR is computed\n",
    "(a) First-layer ﬁlters – Cb channel\n",
    "(b) First-layer ﬁlters – Cr channel\n",
    "Fig. 13. Chrominance channels of the ﬁrst-layer ﬁlters\n",
    "using the “Y pre-train” strategy.\n",
    "in RGB color space). This suggests that the Cb, Cr\n",
    "channels could decrease the performance of the Y chan-\n",
    "nel when training is performed in a uniﬁed network.\n",
    "(iii) We observe that the Cb, Cr channels have higher\n",
    "PSNR values for “Y pre-train” than for “CbCr pre-train”.\n",
    "The reason lies on the differences between the Cb, Cr\n",
    "channels and the Y channel. Visually, the Cb, Cr channels\n",
    "are more blurry than the Y channel, thus are less affected\n",
    "by the downsampling process. When we pre-train on\n",
    "the Cb, Cr channels, there are only a few ﬁlters being\n",
    "activated. Then the training will soon fall into a bad\n",
    "local minimum during ﬁne-tuning. On the other hand,\n",
    "if we pre-train on the Y channel, more ﬁlters will be\n",
    "activated, and the performance on Cb, Cr channels will\n",
    "be pushed much higher. Figure 13 shows the Cb, Cr\n",
    "channels of the ﬁrst-layer ﬁlters with “Y pre-train”, of\n",
    "which the patterns largely differ from that shown in\n",
    "Figure 5. (iv) Training on the RGB channels achieves\n",
    "the best result on the color image. Different from the\n",
    "YCbCr channels, the RGB channels exhibit high cross-\n",
    "correlation among each other. The proposed SRCNN\n",
    "is capable of leveraging such natural correspondences\n",
    "between the channels for reconstruction. Therefore, the\n",
    "model achieves comparable result on the Y channel as\n",
    "“Y only”, and better results on Cb, Cr channels than\n",
    "bicubic interpolation. (v) In KK [25], super-resolution\n",
    "is applied on each RGB channel separately. When we\n",
    "transform its results to YCbCr space, the PSNR value\n",
    "of Y channel is similar as “Y only”, but that of Cb, Cr\n",
    "channels are poorer than bicubic interpolation. The result\n",
    "suggests that the algorithm is biased to the Y channel.\n",
    "On the whole, our method trained on RGB channels\n",
    "achieves better performance than KK and the single-\n",
    "channel network (“Y only”). It is also worth noting that\n",
    "the improvement compared with the single-channel net-\n",
    "work is not that signiﬁcant ( i.e., 0.07 dB). This indicates\n",
    "that the Cb, Cr channels barely help in improving the\n",
    "performance.\n",
    "5 C ONCLUSION\n",
    "We have presented a novel deep learning approach\n",
    "for single image super-resolution (SR). We show that\n",
    "conventional sparse-coding-based SR methods can be\n",
    "12\n",
    "reformulated into a deep convolutional neural network.\n",
    "The proposed approach, SRCNN, learns an end-to-end\n",
    "mapping between low- and high-resolution images, with\n",
    "little extra pre/post-processing beyond the optimization.\n",
    "With a lightweight structure, the SRCNN has achieved\n",
    "superior performance than the state-of-the-art methods.\n",
    "We conjecture that additional performance can be further\n",
    "gained by exploring more ﬁlters and different training\n",
    "strategies. Besides, the proposed structure, with its ad-\n",
    "vantages of simplicity and robustness, could be applied\n",
    "to other low-level vision problems, such as image de-\n",
    "blurring or simultaneous SR+denoising. One could also\n",
    "investigate a network to cope with different upscaling\n",
    "factors.\n",
    "REFERENCES\n",
    "[1] Aharon, M., Elad, M., Bruckstein, A.: K-SVD: An algorithm for\n",
    "designing overcomplete dictionaries for sparse representation.\n",
    "IEEE Transactions on Signal Processing 54(11), 4311–4322 (2006)\n",
    "[2] Bevilacqua, M., Roumy, A., Guillemot, C., Morel, M.L.A.: Low-\n",
    "complexity single-image super-resolution based on nonnegative\n",
    "neighbor embedding. In: British Machine Vision Conference\n",
    "(2012)\n",
    "[3] Burger, H.C., Schuler, C.J., Harmeling, S.: Image denoising: Can\n",
    "plain neural networks compete with BM3D? In: IEEE Conference\"\"\",\n",
    "]\n",
    "    ),\n",
    "    LLMTestCase(\n",
    "        input=\"SRGAN introduces two networks called SRResNet and SRGAN. What is the structural difference between them?\",\n",
    "        actual_output=\"\"\"SRResNet is a deep residual network (a type of neural network where layers learn residual functions with reference to the layer inputs, instead of learning functions independent of the inputs) optimized for minimizing mean squared error (MSE - a measure of the average squared difference between the estimated values and the actual value). This means it aims to produce images that are, on average, as close as possible to the original high-resolution images at a pixel level.\n",
    "\n",
    "SRGAN, on the other hand, builds upon the SRResNet architecture but uses a different training approach. It incorporates a generative adversarial network (GAN - a type of machine learning framework composed of two neural networks, a generator and a discriminator, that contest with each other in a zero-sum game framework to learn a task) structure with a perceptual loss function. This loss function combines an adversarial loss (coming from the discriminator in the GAN, which learns to distinguish between real and super-resolved images) and a content loss (which focuses on perceptual similarity by comparing features from a pre-trained VGG network (a convolutional neural network used for image recognition), not just pixel-by-pixel differences). This makes SRGAN focus less on perfect pixel replication and more on producing images that are perceptually similar to the originals, resulting in more realistic textures and details.\"\"\",\n",
    "        expected_output=\"\"\"Both share the same 16‑block residual generator; SRResNet is trained only with a pixel/feature content loss, whereas SRGAN adds a discriminator and the adversarial term during training, yielding sharper textures.\"\"\",\n",
    "        context=[\n",
    "            \"\"\"We employ a deep residual network (SRResNet) … We then train SRGAN, which uses the same generator but adds a discriminator network and optimizes the adversarial loss in addition to the content loss.\"\"\"\n",
    "        ],\n",
    "        retrieval_context=[\n",
    "    \"\"\"conﬁrm that SRGAN outperforms all reference methods by\n",
    "a large margin and sets a new state of the art for photo-\n",
    "realistic image SR. All differences in MOS ( c.f . Table\n",
    "2) are highly signiﬁcant on BSD100, except SRCNN vs.\n",
    "SelfExSR. The distribution of all collected MOS ratings is\n",
    "summarized in Figure 5.\n",
    "4. Discussion and future work\n",
    "We conﬁrmed the superior perceptual performance of\n",
    "SRGAN using MOS testing. We have further shown that\n",
    "standard quantitative measures such as PSNR and SSIM\n",
    "fail to capture and accurately assess image quality with\n",
    "respect to the human visual system [56]. The focus of this\n",
    "work was the perceptual quality of super-resolved images\n",
    "rather than computational efﬁciency. The presented model\n",
    "is, in contrast to Shi et al. [48], not optimized for video\n",
    "SR in real-time. However, preliminary experiments on\n",
    "the network architecture suggest that shallower networks\n",
    "have the potential to provide very efﬁcient alternatives at\n",
    "a small reduction of qualitative performance. In contrast to\n",
    "Dong et al. [10], we found deeper network architectures to\n",
    "be beneﬁcial. We speculate that the ResNet design has a\n",
    "substantial impact on the performance of deeper networks.\n",
    "We found that even deeper networks (B >16) can further\n",
    "SRResNet SRGAN-MSE SRGAN-VGG22 SRGAN-VGG54 original HR image\n",
    "Figure 6: SRResNet (left: a,b), SRGAN-MSE (middle left: c,d), SRGAN-VGG2.2 (middle: e,f) and SRGAN-VGG54\n",
    "(middle right: g,h) reconstruction results and corresponding reference HR image (right: i,j). [ 4×upscaling]\n",
    "Table 2: Comparison of NN, bicubic, SRCNN [9], SelfExSR [31], DRCN [34], ESPCN [48], SRResNet, SRGAN-VGG54\n",
    "and the original HR on benchmark data. Highest measures (PSNR [dB], SSIM, MOS) in bold. [4×upscaling]\n",
    "Set5 nearest bicubic SRCNN SelfExSR DRCN ESPCN SRResNet SRGAN HR\n",
    "PSNR 26.26 28.43 30.07 30.33 31.52 30.76 32.05 29.40 ∞\n",
    "SSIM 0.7552 0.8211 0.8627 0.872 0.8938 0.8784 0.9019 0.8472 1\n",
    "MOS 1.28 1.97 2.57 2.65 3.26 2.89 3.37 3.58 4.32\n",
    "Set14\n",
    "PSNR 24.64 25.99 27.18 27.45 28.02 27.66 28.49 26.02 ∞\n",
    "SSIM 0.7100 0.7486 0.7861 0.7972 0.8074 0.8004 0.8184 0.7397 1\n",
    "MOS 1.20 1.80 2.26 2.34 2.84 2.52 2.98 3.72 4.32\n",
    "BSD100\n",
    "PSNR 25.02 25.94 26.68 26.83 27.21 27.02 27.58 25.16 ∞\n",
    "SSIM 0.6606 0.6935 0.7291 0.7387 0.7493 0.7442 0.7620 0.6688 1\n",
    "MOS 1.11 1.47 1.87 1.89 2.12 2.01 2.29 3.56 4.46\n",
    "increase the performance of SRResNet, however, come at\n",
    "the cost of longer training and testing times ( c.f . supple-\n",
    "mentary material). We further found SRGAN variants of\n",
    "deeper networks are increasingly difﬁcult to train due to the\n",
    "appearance of high-frequency artifacts.\n",
    "Of particular importance when aiming for photo-realistic\n",
    "solutions to the SR problem is the choice of the content loss\n",
    "as illustrated in Figure 6. In this work, we found lSR\n",
    "VGG/5.4\n",
    "to yield the perceptually most convincing results, which\n",
    "we attribute to the potential of deeper network layers to\n",
    "represent features of higher abstraction [68, 65, 40] away\n",
    "from pixel space. We speculate that feature maps of these\n",
    "deeper layers focus purely on the content while leaving the\n",
    "adversarial loss focusing on texture details which are the\n",
    "main difference between the super-resolved images without\n",
    "the adversarial loss and photo-realistic images. We also\n",
    "note that the ideal loss function depends on the application.\n",
    "For example, approaches that hallucinate ﬁner detail might\n",
    "be less suited for medical applications or surveillance. The\n",
    "perceptually convincing reconstruction of text or structured\n",
    "scenes [31] is challenging and part of future work. The\n",
    "development of content loss functions that describe image\n",
    "spatial content, but more invariant to changes in pixel space\n",
    "will further improve photo-realistic image SR results.\n",
    "5. Conclusion\n",
    "We have described a deep residual network SRRes-\n",
    "Net that sets a new state of the art on public benchmark\n",
    "datasets when evaluated with the widely used PSNR mea-\n",
    "sure. We have highlighted some limitations of this PSNR-\n",
    "focused image super-resolution and introduced SRGAN,\"\"\",\n",
    "    \"\"\"ure 3 where multiple potential solutions with high texture\n",
    "details are averaged to create a smooth reconstruction.\n",
    "In Mathieu et al. [42] and Denton et al. [7] the authors\n",
    "tackled this problem by employing generative adversarial\n",
    "networks (GANs) [22] for the application of image genera-\n",
    "tion. Yu and Porikli [66] augment pixel-wise MSE loss with\n",
    "a discriminator loss to train a network that super-resolves\n",
    "face images with large upscaling factors ( 8×). GANs\n",
    "were also used for unsupervised representation learning in\n",
    "Radford et al. [44]. The idea of using GANs to learn a\n",
    "mapping from one manifold to another is described by Li\n",
    "and Wand [38] for style transfer and Yeh et al. [64] for\n",
    "inpainting. Bruna et al. [5] minimize the squared error in\n",
    "the feature spaces of VGG19 [49] and scattering networks.\n",
    "Dosovitskiy and Brox [13] use loss functions based\n",
    "on Euclidean distances computed in the feature space of\n",
    "neural networks in combination with adversarial training.\n",
    "It is shown that the proposed loss allows visually superior\n",
    "image generation and can be used to solve the ill-posed\n",
    "inverse problem of decoding nonlinear feature representa-\n",
    "tions. Similar to this work, Johnson et al. [33] and Bruna\n",
    "et al. [5] propose the use of features extracted from a pre-\n",
    "trained VGG network instead of low-level pixel-wise error\n",
    "measures. Speciﬁcally the authors formulate a loss function\n",
    "based on the euclidean distance between feature maps\n",
    "extracted from the VGG19 [49] network. Perceptually more\n",
    "convincing results were obtained for both super-resolution\n",
    "and artistic style-transfer [19, 20]. Recently, Li and Wand\n",
    "[38] also investigated the effect of comparing and blending\n",
    "patches in pixel or VGG feature space.\n",
    "1.2. Contribution\n",
    "GANs provide a powerful framework for generating\n",
    "plausible-looking natural images with high perceptual qual-\n",
    "ity. The GAN procedure encourages the reconstructions\n",
    "to move towards regions of the search space with high\n",
    "probability of containing photo-realistic images and thus\n",
    "closer to the natural image manifold as shown in Figure 3.\n",
    "In this paper we describe the ﬁrst very deep ResNet\n",
    "[29, 30] architecture using the concept of GANs to form a\n",
    "perceptual loss function for photo-realistic SISR. Our main\n",
    "contributions are:\n",
    "•We set a new state of the art for image SR with\n",
    "high upscaling factors (4×) as measured by PSNR and\n",
    "structural similarity (SSIM) with our 16 blocks deep\n",
    "ResNet (SRResNet) optimized for MSE.\n",
    "•We propose SRGAN which is a GAN-based network\n",
    "optimized for a new perceptual loss. Here we replace\n",
    "the MSE-based content loss with a loss calculated on\n",
    "feature maps of the VGG network [49], which are\n",
    "more invariant to changes in pixel space [38].\n",
    "•We conﬁrm with an extensive mean opinion score\n",
    "(MOS) test on images from three public benchmark\n",
    "datasets that SRGAN is the new state of the art, by a\n",
    "large margin, for the estimation of photo-realistic SR\n",
    "images with high upscaling factors (4×).\n",
    "We describe the network architecture and the perceptual\n",
    "loss in Section 2. A quantitative evaluation on public bench-\n",
    "mark datasets as well as visual illustrations are provided in\n",
    "Section 3. The paper concludes with a discussion in Section\n",
    "4 and concluding remarks in Section 5.\n",
    "2. Method\n",
    "In SISR the aim is to estimate a high-resolution, super-\n",
    "resolved image ISR from a low-resolution input image\n",
    "ILR. Here ILR is the low-resolution version of its high-\n",
    "resolution counterpart IHR. The high-resolution images\n",
    "are only available during training. In training, ILR is\n",
    "obtained by applying a Gaussian ﬁlter toIHR followed by a\n",
    "downsampling operation with downsampling factor r. For\n",
    "an image with C color channels, we describe ILR by a\n",
    "real-valued tensor of size W ×H ×C and IHR, ISR by\n",
    "rW ×rH ×Crespectively.\n",
    "Our ultimate goal is to train a generating function Gthat\n",
    "estimates for a given LR input image its corresponding HR\n",
    "counterpart. To achieve this, we train a generator network as\n",
    "a feed-forward CNN GθG parametrized by θG. Here θG =\"\"\",\n",
    "    \"\"\"development of content loss functions that describe image\n",
    "spatial content, but more invariant to changes in pixel space\n",
    "will further improve photo-realistic image SR results.\n",
    "5. Conclusion\n",
    "We have described a deep residual network SRRes-\n",
    "Net that sets a new state of the art on public benchmark\n",
    "datasets when evaluated with the widely used PSNR mea-\n",
    "sure. We have highlighted some limitations of this PSNR-\n",
    "focused image super-resolution and introduced SRGAN,\n",
    "which augments the content loss function with an adversar-\n",
    "ial loss by training a GAN. Using extensive MOS testing,\n",
    "we have conﬁrmed that SRGAN reconstructions for large\n",
    "upscaling factors (4×) are, by a considerable margin, more\n",
    "photo-realistic than reconstructions obtained with state-of-\n",
    "the-art reference methods.\n",
    "References\n",
    "[1] J. Allebach and P. W. Wong. Edge-directed interpolation. InProceed-\n",
    "ings of International Conference on Image Processing , volume 3,\n",
    "pages 707–710, 1996. 2\n",
    "[2] H. A. Aly and E. Dubois. Image up-sampling using total-variation\n",
    "regularization with a new observation model. IEEE Transactions on\n",
    "Image Processing, 14(10):1647–1659, 2005. 7\n",
    "[3] M. Bevilacqua, A. Roumy, C. Guillemot, and M. L. Alberi-Morel.\n",
    "Low-complexity single-image super-resolution based on nonnegative\n",
    "neighbor embedding. BMVC, 2012. 6\n",
    "[4] S. Borman and R. L. Stevenson. Super-Resolution from Image\n",
    "Sequences - A Review.Midwest Symposium on Circuits and Systems,\n",
    "pages 374–378, 1998. 2\n",
    "[5] J. Bruna, P. Sprechmann, and Y . LeCun. Super-resolution with deep\n",
    "convolutional sufﬁcient statistics. In International Conference on\n",
    "Learning Representations (ICLR), 2016. 2, 3, 5\n",
    "[6] D. Dai, R. Timofte, and L. Van Gool. Jointly optimized regressors for\n",
    "image super-resolution. In Computer Graphics Forum, volume 34,\n",
    "pages 95–104, 2015. 2\n",
    "[7] E. Denton, S. Chintala, A. Szlam, and R. Fergus. Deep generative\n",
    "image models using a laplacian pyramid of adversarial networks. In\n",
    "Advances in Neural Information Processing Systems (NIPS) , pages\n",
    "1486–1494, 2015. 3\n",
    "[8] S. Dieleman, J. Schl ¨uter, C. Raffel, E. Olson, S. K. Snderby,\n",
    "D. Nouri, D. Maturana, M. Thoma, E. Battenberg, J. Kelly, J. D.\n",
    "Fauw, M. Heilman, diogo149, B. McFee, H. Weideman, takacsg84,\n",
    "peterderivaz, Jon, instagibbs, D. K. Rasul, CongLiu, Britefury, and\n",
    "J. Degrave. Lasagne: First release., 2015. 6\n",
    "[9] C. Dong, C. C. Loy, K. He, and X. Tang. Learning a deep\n",
    "convolutional network for image super-resolution. In European\n",
    "Conference on Computer Vision (ECCV), pages 184–199. Springer,\n",
    "2014. 3, 6, 8\n",
    "[10] C. Dong, C. C. Loy, K. He, and X. Tang. Image super-resolution\n",
    "using deep convolutional networks. IEEE Transactions on Pattern\n",
    "Analysis and Machine Intelligence, 38(2):295–307, 2016. 3, 5, 7\n",
    "[11] C. Dong, C. C. Loy, and X. Tang. Accelerating the super-resolution\n",
    "convolutional neural network. InEuropean Conference on Computer\n",
    "Vision (ECCV), pages 391–407. Springer, 2016. 3\n",
    "[12] W. Dong, L. Zhang, G. Shi, and X. Wu. Image deblurring and super-\n",
    "resolution by adaptive sparse domain selection and adaptive regular-\n",
    "ization. IEEE Transactions on Image Processing, 20(7):1838–1857,\n",
    "2011. 2\n",
    "[13] A. Dosovitskiy and T. Brox. Generating images with perceptual\n",
    "similarity metrics based on deep networks. In Advances in Neural\n",
    "Information Processing Systems (NIPS), pages 658–666, 2016. 3\n",
    "[14] C. E. Duchon. Lanczos Filtering in One and Two Dimensions. In\n",
    "Journal of Applied Meteorology, volume 18, pages 1016–1022. 1979.\n",
    "2\n",
    "[15] S. Farsiu, M. D. Robinson, M. Elad, and P. Milanfar. Fast and\n",
    "robust multiframe super resolution. IEEE Transactions on Image\n",
    "Processing, 13(10):1327–1344, 2004. 2\n",
    "[16] J. A. Ferwerda. Three varieties of realism in computer graphics. In\n",
    "Electronic Imaging, pages 290–297. International Society for Optics\n",
    "and Photonics, 2003. 2\n",
    "[17] W. T. Freeman, T. R. Jones, and E. C. Pasztor. Example-based super-\n",
    "resolution. IEEE Computer Graphics and Applications, 22(2):56–65,\n",
    "2002. 2\n",
    "[18] W. T. Freeman, E. C. Pasztor, and O. T. Carmichael. Learning low-\"\"\",\n",
    "    \"\"\"Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial\n",
    "Network\n",
    "Christian Ledig, Lucas Theis, Ferenc Husz´ar, Jose Caballero, Andrew Cunningham,\n",
    "Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, Wenzhe Shi\n",
    "Twitter\n",
    "{cledig,ltheis,fhuszar,jcaballero,aacostadiaz,aaitken,atejani,jtotz,zehanw,wshi}@twitter.com\n",
    "Abstract\n",
    "Despite the breakthroughs in accuracy and speed of\n",
    "single image super-resolution using faster and deeper con-\n",
    "volutional neural networks, one central problem remains\n",
    "largely unsolved: how do we recover the ﬁner texture details\n",
    "when we super-resolve at large upscaling factors? The\n",
    "behavior of optimization-based super-resolution methods is\n",
    "principally driven by the choice of the objective function.\n",
    "Recent work has largely focused on minimizing the mean\n",
    "squared reconstruction error. The resulting estimates have\n",
    "high peak signal-to-noise ratios, but they are often lacking\n",
    "high-frequency details and are perceptually unsatisfying in\n",
    "the sense that they fail to match the ﬁdelity expected at\n",
    "the higher resolution. In this paper, we present SRGAN,\n",
    "a generative adversarial network (GAN) for image super-\n",
    "resolution (SR). To our knowledge, it is the ﬁrst framework\n",
    "capable of inferring photo-realistic natural images for 4×\n",
    "upscaling factors. To achieve this, we propose a perceptual\n",
    "loss function which consists of an adversarial loss and a\n",
    "content loss. The adversarial loss pushes our solution to\n",
    "the natural image manifold using a discriminator network\n",
    "that is trained to differentiate between the super-resolved\n",
    "images and original photo-realistic images. In addition, we\n",
    "use a content loss motivated by perceptual similarity instead\n",
    "of similarity in pixel space. Our deep residual network\n",
    "is able to recover photo-realistic textures from heavily\n",
    "downsampled images on public benchmarks. An extensive\n",
    "mean-opinion-score (MOS) test shows hugely signiﬁcant\n",
    "gains in perceptual quality using SRGAN. The MOS scores\n",
    "obtained with SRGAN are closer to those of the original\n",
    "high-resolution images than to those obtained with any\n",
    "state-of-the-art method.\n",
    "1. Introduction\n",
    "The highly challenging task of estimating a high-\n",
    "resolution (HR) image from its low-resolution (LR)\n",
    "counterpart is referred to as super-resolution (SR). SR\n",
    "received substantial attention from within the computer\n",
    "vision research community and has a wide range of\n",
    "applications [63, 71, 43].\n",
    "4×SRGAN (proposed) original\n",
    "Figure 1: Super-resolved image (left) is almost indistin-\n",
    "guishable from original (right). [4×upscaling]\n",
    "The ill-posed nature of the underdetermined SR problem\n",
    "is particularly pronounced for high upscaling factors, for\n",
    "which texture detail in the reconstructed SR images is\n",
    "typically absent. The optimization target of supervised\n",
    "SR algorithms is commonly the minimization of the mean\n",
    "squared error (MSE) between the recovered HR image\n",
    "and the ground truth. This is convenient as minimizing\n",
    "MSE also maximizes the peak signal-to-noise ratio (PSNR),\n",
    "which is a common measure used to evaluate and compare\n",
    "SR algorithms [61]. However, the ability of MSE (and\n",
    "PSNR) to capture perceptually relevant differences, such\n",
    "as high texture detail, is very limited as they are deﬁned\n",
    "based on pixel-wise image differences [60, 58, 26]. This\n",
    "is illustrated in Figure 2, where highest PSNR does not\n",
    "necessarily reﬂect the perceptually better SR result. The\n",
    "1\n",
    "arXiv:1609.04802v5  [cs.CV]  25 May 2017\n",
    "bicubic SRResNet SRGAN original\n",
    "(21.59dB/0.6423) (23.53dB/0.7832) (21.15dB/0.6868)\n",
    "Figure 2: From left to right: bicubic interpolation, deep residual network optimized for MSE, deep residual generative\n",
    "adversarial network optimized for a loss more sensitive to human perception, original HR image. Corresponding PSNR and\n",
    "SSIM are shown in brackets. [4×upscaling]\n",
    "perceptual difference between the super-resolved and orig-\n",
    "inal image means that the recovered image is not photo-\n",
    "realistic as deﬁned by Ferwerda [16].\"\"\",\n",
    "    \"\"\"and signiﬁcance determined at p< 0.05.\n",
    "The reader may also be interested in an independently\n",
    "developed GAN-based solution on GitHub 5. However it\n",
    "only provides experimental results on a limited set of faces,\n",
    "which is a more constrained and easier task.\n",
    "3.2. Training details and parameters\n",
    "We trained all networks on a NVIDIA Tesla M40 GPU\n",
    "using a random sample of 350 thousand images from\n",
    "the ImageNet database [45]. These images are distinct\n",
    "from the testing images. We obtained the LR images\n",
    "by downsampling the HR images (BGR, C = 3) using\n",
    "bicubic kernel with downsampling factor r = 4. For each\n",
    "mini-batch we crop 16 random 96 ×96 HR sub images\n",
    "of distinct training images. Note that we can apply the\n",
    "generator model to images of arbitrary size as it is fully\n",
    "1https://github.com/xiph/daala (commit: 8d03668)\n",
    "2https://github.com/jbhuang0604/SelfExSR\n",
    "3http://cv.snu.ac.kr/research/DRCN/\n",
    "4https://twitter.box.com/s/\n",
    "lcue6vlrd01ljkdtdkhmfvk7vtjhetog\n",
    "5https://github.com/david-gpu/srez\n",
    "convolutional. We scaled the range of the LR input images\n",
    "to [0,1] and for the HR images to [−1,1]. The MSE loss\n",
    "was thus calculated on images of intensity range [−1,1].\n",
    "VGG feature maps were also rescaled by a factor of 1\n",
    "12.75\n",
    "to obtain VGG losses of a scale that is comparable to the\n",
    "MSE loss. This is equivalent to multiplying Equation 5\n",
    "with a rescaling factor of ≈ 0.006. For optimization we\n",
    "use Adam [36] with β1 = 0.9. The SRResNet networks\n",
    "were trained with a learning rate of 10−4 and 106 update\n",
    "iterations. We employed the trained MSE-based SRResNet\n",
    "network as initialization for the generator when training\n",
    "the actual GAN to avoid undesired local optima. All\n",
    "SRGAN variants were trained with 105 update iterations\n",
    "at a learning rate of 10−4 and another 105 iterations at a\n",
    "lower rate of 10−5. We alternate updates to the generator\n",
    "and discriminator network, which is equivalent to k = 1\n",
    "as used in Goodfellow et al. [22]. Our generator network\n",
    "has 16 identical (B = 16) residual blocks. During test time\n",
    "we turn batch-normalization update off to obtain an output\n",
    "that deterministically depends only on the input [32]. Our\n",
    "implementation is based on Theano [53] and Lasagne [8].\n",
    "3.3. Mean opinion score (MOS) testing\n",
    "We have performed a MOS test to quantify the ability of\n",
    "different approaches to reconstruct perceptually convincing\n",
    "images. Speciﬁcally, we asked 26 raters to assign an inte-\n",
    "gral score from 1 (bad quality) to 5 (excellent quality) to the\n",
    "super-resolved images. The raters rated 12 versions of each\n",
    "image on Set5, Set14 and BSD100: nearest neighbor (NN),\n",
    "bicubic, SRCNN [9], SelfExSR [31], DRCN [34], ESPCN\n",
    "[48], SRResNet-MSE, SRResNet-VGG22∗ (∗not rated on\n",
    "BSD100), SRGAN-MSE ∗, SRGAN-VGG22 ∗, SRGAN-\n",
    "VGG54 and the original HR image. Each rater thus rated\n",
    "1128 instances (12 versions of 19 images plus 9 versions of\n",
    "100 images) that were presented in a randomized fashion.\n",
    "The raters were calibrated on the NN (score 1) and HR (5)\n",
    "versions of 20 images from the BSD300 training set. In a\n",
    "pilot study we assessed the calibration procedure and the\n",
    "test-retest reliability of 26 raters on a subset of 10 images\n",
    "from BSD100 by adding a method’s images twice to a\n",
    "larger test set. We found good reliability and no signiﬁcant\n",
    "differences between the ratings of the identical images.\n",
    "Raters very consistently rated NN interpolated test images\n",
    "as 1 and the original HR images as 5 (c.f . Figure 5).\n",
    "The experimental results of the conducted MOS tests are\n",
    "summarized in Table 1, Table 2 and Figure 5.\n",
    "3.4. Investigation of content loss\n",
    "We investigated the effect of different content loss\n",
    "choices in the perceptual loss for the GAN-based networks.\n",
    "Speciﬁcally we investigate lSR = lSR\n",
    "X + 10−3lSR\n",
    "Gen for the\n",
    "following content losses lSR\n",
    "X :\n",
    "Table 1: Performance of different loss functions for SR-\n",
    "ResNet and the adversarial networks on Set5 and Set14\n",
    "benchmark data. MOS score signiﬁcantly higher (p< 0.05)\n",
    "than with other losses in that category∗. [4×upscaling]\n",
    "SRResNet- SRGAN-\"\"\",\n",
    "    \"\"\"3.4. Investigation of content loss\n",
    "We investigated the effect of different content loss\n",
    "choices in the perceptual loss for the GAN-based networks.\n",
    "Speciﬁcally we investigate lSR = lSR\n",
    "X + 10−3lSR\n",
    "Gen for the\n",
    "following content losses lSR\n",
    "X :\n",
    "Table 1: Performance of different loss functions for SR-\n",
    "ResNet and the adversarial networks on Set5 and Set14\n",
    "benchmark data. MOS score signiﬁcantly higher (p< 0.05)\n",
    "than with other losses in that category∗. [4×upscaling]\n",
    "SRResNet- SRGAN-\n",
    "Set5 MSE VGG22 MSE VGG22 VGG54\n",
    "PSNR 32.05 30.51 30.64 29.84 29.40\n",
    "SSIM 0.9019 0.8803 0.8701 0.8468 0.8472\n",
    "MOS 3.37 3.46 3.77 3.78 3.58\n",
    "Set14\n",
    "PSNR 28.49 27.19 26.92 26.44 26.02\n",
    "SSIM 0.8184 0.7807 0.7611 0.7518 0.7397\n",
    "MOS 2.98 3.15 ∗ 3.43 3.57 3.72 ∗\n",
    "•SRGAN-MSE: lSR\n",
    "MSE, to investigate the adversarial\n",
    "network with the standard MSE as content loss.\n",
    "•SRGAN-VGG22: lSR\n",
    "VGG/2.2 with φ2,2, a loss deﬁned\n",
    "on feature maps representing lower-level features [68].\n",
    "•SRGAN-VGG54: lSR\n",
    "VGG/5.4 with φ5,4, a loss deﬁned\n",
    "on feature maps of higher level features from deeper\n",
    "network layers with more potential to focus on the\n",
    "content of the images [68, 65, 40]. We refer to this\n",
    "network as SRGAN in the following.\n",
    "We also evaluate the performance of the generator network\n",
    "without adversarial component for the two losses lSR\n",
    "MSE\n",
    "(SRResNet-MSE) and lSR\n",
    "VGG/2.2 (SRResNet-VGG22). We\n",
    "refer to SRResNet-MSE asSRResNet. Note, when training\n",
    "SRResNet-VGG22 we added an additional total variation\n",
    "loss with weight 2 ×10−8 to lSR\n",
    "VGG/2.2 [2, 33]. Quantitative\n",
    "results are summarized in Table 1 and visual examples\n",
    "provided in Figure 6. Even combined with the adversarial\n",
    "loss, MSE provides solutions with the highest PSNR values\n",
    "that are, however, perceptually rather smooth and less\n",
    "convincing than results achieved with a loss component\n",
    "more sensitive to visual perception. This is caused by\n",
    "competition between the MSE-based content loss and the\n",
    "adversarial loss. We further attribute minor reconstruction\n",
    "artifacts, which we observed in a minority of SRGAN-\n",
    "MSE-based reconstructions, to those competing objectives.\n",
    "We could not determine a signiﬁcantly best loss function\n",
    "for SRResNet or SRGAN with respect to MOS score\n",
    "on Set5. However, SRGAN-VGG54 signiﬁcantly outper-\n",
    "formed other SRGAN and SRResNet variants on Set14 in\n",
    "terms of MOS. We observed a trend that using the higher\n",
    "level VGG feature maps φ5,4 yields better texture detail\n",
    "when compared to φ2,2 (c.f . Figure 6). Further examples of\n",
    "perceptual improvements through SRGAN over SRResNet\n",
    "are provided in the supplementary material.\n",
    "Figure 5: Color-coded distribution of MOS scores on\n",
    "BSD100. For each method 2600 samples (100 images ×\n",
    "26 raters) were assessed. Mean shown as red marker, where\n",
    "the bins are centered around value i. [4×upscaling]\n",
    "3.5. Performance of the ﬁnal networks\n",
    "We compare the performance of SRResNet and SR-\n",
    "GAN to NN, bicubic interpolation, and four state-of-the-\n",
    "art methods. Quantitative results are summarized in Table\n",
    "2 and conﬁrm that SRResNet (in terms of PSNR/SSIM)\n",
    "sets a new state of the art on three benchmark datasets.\n",
    "Please note that we used a publicly available framework\n",
    "for evaluation (c.f . Section 3.1), reported values might thus\n",
    "slightly deviate from those reported in the original papers.\n",
    "We further obtained MOS ratings for SRGAN and all\n",
    "reference methods on BSD100. Examples of images super-\n",
    "resolved with SRResNet and SRGAN are depicted in the\n",
    "supplementary material. The results shown in Table 2\n",
    "conﬁrm that SRGAN outperforms all reference methods by\n",
    "a large margin and sets a new state of the art for photo-\n",
    "realistic image SR. All differences in MOS ( c.f . Table\n",
    "2) are highly signiﬁcant on BSD100, except SRCNN vs.\n",
    "SelfExSR. The distribution of all collected MOS ratings is\n",
    "summarized in Figure 5.\n",
    "4. Discussion and future work\n",
    "We conﬁrmed the superior perceptual performance of\n",
    "SRGAN using MOS testing. We have further shown that\n",
    "standard quantitative measures such as PSNR and SSIM\"\"\",\n",
    "    \"\"\"(21.59dB/0.6423) (23.53dB/0.7832) (21.15dB/0.6868)\n",
    "Figure 2: From left to right: bicubic interpolation, deep residual network optimized for MSE, deep residual generative\n",
    "adversarial network optimized for a loss more sensitive to human perception, original HR image. Corresponding PSNR and\n",
    "SSIM are shown in brackets. [4×upscaling]\n",
    "perceptual difference between the super-resolved and orig-\n",
    "inal image means that the recovered image is not photo-\n",
    "realistic as deﬁned by Ferwerda [16].\n",
    "In this work we propose a super-resolution generative\n",
    "adversarial network (SRGAN) for which we employ a\n",
    "deep residual network (ResNet) with skip-connection and\n",
    "diverge from MSE as the sole optimization target. Different\n",
    "from previous works, we deﬁne a novel perceptual loss us-\n",
    "ing high-level feature maps of the VGG network [49, 33, 5]\n",
    "combined with a discriminator that encourages solutions\n",
    "perceptually hard to distinguish from the HR reference\n",
    "images. An example photo-realistic image that was super-\n",
    "resolved with a 4×upscaling factor is shown in Figure 1.\n",
    "1.1. Related work\n",
    "1.1.1 Image super-resolution\n",
    "Recent overview articles on image SR include Nasrollahi\n",
    "and Moeslund [43] or Yang et al. [61]. Here we will focus\n",
    "on single image super-resolution (SISR) and will not further\n",
    "discuss approaches that recover HR images from multiple\n",
    "images [4, 15].\n",
    "Prediction-based methods were among the ﬁrst methods\n",
    "to tackle SISR. While these ﬁltering approaches, e.g. linear,\n",
    "bicubic or Lanczos [14] ﬁltering, can be very fast, they\n",
    "oversimplify the SISR problem and usually yield solutions\n",
    "with overly smooth textures. Methods that put particularly\n",
    "focus on edge-preservation have been proposed [1, 39].\n",
    "More powerful approaches aim to establish a complex\n",
    "mapping between low- and high-resolution image informa-\n",
    "tion and usually rely on training data. Many methods that\n",
    "are based on example-pairs rely on LR training patches for\n",
    "which the corresponding HR counterparts are known. Early\n",
    "work was presented by Freeman et al. [18, 17]. Related ap-\n",
    "proaches to the SR problem originate in compressed sensing\n",
    "[62, 12, 69]. In Glasner et al. [21] the authors exploit patch\n",
    "redundancies across scales within the image to drive the SR.\n",
    "This paradigm of self-similarity is also employed in Huang\n",
    "et al. [31], where self dictionaries are extended by further\n",
    "allowing for small transformations and shape variations. Gu\n",
    "et al. [25] proposed a convolutional sparse coding approach\n",
    "that improves consistency by processing the whole image\n",
    "rather than overlapping patches.\n",
    "To reconstruct realistic texture detail while avoiding\n",
    "edge artifacts, Tai et al. [52] combine an edge-directed SR\n",
    "algorithm based on a gradient proﬁle prior [50] with the\n",
    "beneﬁts of learning-based detail synthesis. Zhang et al. [70]\n",
    "propose a multi-scale dictionary to capture redundancies of\n",
    "similar image patches at different scales. To super-resolve\n",
    "landmark images, Yue et al. [67] retrieve correlating HR\n",
    "images with similar content from the web and propose a\n",
    "structure-aware matching criterion for alignment.\n",
    "Neighborhood embedding approaches upsample a LR\n",
    "image patch by ﬁnding similar LR training patches in a low\n",
    "dimensional manifold and combining their corresponding\n",
    "HR patches for reconstruction [54, 55]. In Kim and Kwon\n",
    "[35] the authors emphasize the tendency of neighborhood\n",
    "approaches to overﬁt and formulate a more general map of\n",
    "example pairs using kernel ridge regression. The regression\n",
    "problem can also be solved with Gaussian process regres-\n",
    "sion [27], trees [46] or Random Forests [47]. In Dai et al.\n",
    "[6] a multitude of patch-speciﬁc regressors is learned and\n",
    "the most appropriate regressors selected during testing.\n",
    "Recently convolutional neural network (CNN) based SR\n",
    "algorithms have shown excellent performance. In Wang\n",
    "et al. [59] the authors encode a sparse representation\n",
    "prior into their feed-forward network architecture based on\n",
    "the learned iterative shrinkage and thresholding algorithm\"\"\",\n",
    "    \"\"\"[70] K. Zhang, X. Gao, D. Tao, and X. Li. Multi-scale dictionary for\n",
    "single image super-resolution. In IEEE Conference on Computer\n",
    "Vision and Pattern Recognition (CVPR), pages 1114–1121, 2012. 2\n",
    "[71] W. Zou and P. C. Yuen. Very Low Resolution Face Recognition\n",
    "in Parallel Environment . IEEE Transactions on Image Processing,\n",
    "21:327–340, 2012. 1\n",
    "A. Supplementary Material\n",
    "In this supplementary material we ﬁrst brieﬂy investigate the inﬂuence of network depth (number of residual blocks)\n",
    "on the performance (PSNR, time) of SRResNet in Section A.1. We then visualize on an example image how the SRGAN\n",
    "network performance evolves with increasing number of training iterations in Section A.2. Results of the MOS tests\n",
    "conducted on Set5, Set14, BSD100 are summarized in Section A.3. Finally we provide a visualization of all image\n",
    "reconstruction obtained with SRResNet and SRGAN with a 4×upscaling factor for Set5 (Section A.4), Set14 (Section A.5)\n",
    "and ﬁve randomly selected images from BSD100 (Section A.6).\n",
    "Images are best viewed and compared zoomed in. All original low-/high-resolution images and reconstructions\n",
    "(4×upscaling) obtained with different methods (bicubic, SRResNet-MSE, SRResNet-VGG22, SRGAN-MSE, SRGAN-\n",
    "VGG22, SRGAN-VGG54) described in the paper are available for download at https://twitter.box.com/s/\n",
    "lcue6vlrd01ljkdtdkhmfvk7vtjhetog.\n",
    "A.1. Performance (PSNR/time) vs. network depth\n",
    "We investigated the inﬂuence of network depth, speciﬁcally the number of residual blocks, on performance (PSNR [dB]\n",
    "on BSD100 for 4×SR) and inference time [s] of the network architecture described in Figure 4 of the main paper. Time was\n",
    "assessed on a NVIDIA M40 GPU and averaged over 100 reconstructions of a random low-resolution image with resolution\n",
    "64×64 with upscaling factor 4×. The measurements are plotted in Figure 7 for a network with (blue) and without (red)\n",
    "skip-connection. As expected the time of a single forward pass through the network depends approximately linearly on the\n",
    "number of residual blocks. Whether a skip-connection is used or not has no substantial impact on inference time. However,\n",
    "we observed substantial gains in performance with the additional skip-connection. We chose a network architecture of\n",
    "16 residual blocks with skip-connection for the evaluation presented in the main paper as we consider this as good trade-\n",
    "off between accuracy and speed including training time. While accuracy gains slowly saturate beyond 16 blocks there is,\n",
    "nevertheless, a clear beneﬁt of using even deeper networks.\n",
    "Figure 7: Dependence of network performance (PSNR, time) on network depth. PSNR (left) calculated on BSD100. Time\n",
    "(right) averaged over 100 reconstructions of a random LR image with resolution 64×64.\n",
    "A.2. Evolution of Generator during SRGAN training\n",
    "We further investigated how reconstructions of the SRGAN generator network evolve (visually) with increasing number\n",
    "of training iterations. Visual results obtained after different number of training iterations are illustrated in Figure 8. It is\n",
    "interesting that after only 20 thousand training iterations the generator substantially diverged from the SRResNet initialization\n",
    "and produces reconstruction with a lot of high frequency content, including noise. With increasing number of training\n",
    "iterations reconstructions of the baboon from Set14 appear closer to the reference image. However, there is visually little\n",
    "change during the last 50-100 thousand update iterations.\n",
    "SRResNet 20k 40k 60k 80k\n",
    "100k 140k 180k SRGAN original HR image\n",
    "Figure 8: Evolution of SRGAN generator network during training progress. Note: Generator initialized with SRResNet\n",
    "weights; learning rate set to 10−4 for ﬁrst 100k iterations, then reduced to 10−5 for another 100k iterations. [4×upscaling]\n",
    "A.3. Mean opinion score (MOS) testing\n",
    "In all conducted MOS tests we have asked 26 human raters to assign a score from 1 (Bad) to 5 (Excellent) to reconstructions\"\"\",\n",
    "]\n",
    "    ),\n",
    "    # Add more test cases\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">(</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">ragas</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">)</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">3.5</span><span style=\"color: #374151; text-decoration-color: #374151\">-turbo, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision \u001b[0m\u001b[1;38;2;106;0;255m(\u001b[0m\u001b[38;2;106;0;255mragas\u001b[0m\u001b[1;38;2;106;0;255m)\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-\u001b[0m\u001b[1;38;2;55;65;81m3.5\u001b[0m\u001b[38;2;55;65;81m-turbo, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">(</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">ragas</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">)</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">3.5</span><span style=\"color: #374151; text-decoration-color: #374151\">-turbo, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness \u001b[0m\u001b[1;38;2;106;0;255m(\u001b[0m\u001b[38;2;106;0;255mragas\u001b[0m\u001b[1;38;2;106;0;255m)\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-\u001b[0m\u001b[1;38;2;55;65;81m3.5\u001b[0m\u001b[38;2;55;65;81m-turbo, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">(</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">ragas</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">)</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">3.5</span><span style=\"color: #374151; text-decoration-color: #374151\">-turbo, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall \u001b[0m\u001b[1;38;2;106;0;255m(\u001b[0m\u001b[38;2;106;0;255mragas\u001b[0m\u001b[1;38;2;106;0;255m)\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-\u001b[0m\u001b[1;38;2;55;65;81m3.5\u001b[0m\u001b[38;2;55;65;81m-turbo, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">(</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">ragas</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">)</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">3.5</span><span style=\"color: #374151; text-decoration-color: #374151\">-turbo, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy \u001b[0m\u001b[1;38;2;106;0;255m(\u001b[0m\u001b[38;2;106;0;255mragas\u001b[0m\u001b[1;38;2;106;0;255m)\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-\u001b[0m\u001b[1;38;2;55;65;81m3.5\u001b[0m\u001b[38;2;55;65;81m-turbo, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">ContextualRelevancyMetric Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">3.5</span><span style=\"color: #374151; text-decoration-color: #374151\">-turbo, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextualRelevancyMetric Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-\u001b[0m\u001b[1;38;2;55;65;81m3.5\u001b[0m\u001b[38;2;55;65;81m-turbo, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">ContextualDiversityMetric Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">3.5</span><span style=\"color: #374151; text-decoration-color: #374151\">-turbo, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextualDiversityMetric Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-\u001b[0m\u001b[1;38;2;55;65;81m3.5\u001b[0m\u001b[38;2;55;65;81m-turbo, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">ContextualConsistencyMetric Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">3.5</span><span style=\"color: #374151; text-decoration-color: #374151\">-turbo, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mContextualConsistencyMetric Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-\u001b[0m\u001b[1;38;2;55;65;81m3.5\u001b[0m\u001b[38;2;55;65;81m-turbo, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">TechnicalTermClarityMetric Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">3.5</span><span style=\"color: #374151; text-decoration-color: #374151\">-turbo, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mTechnicalTermClarityMetric Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-\u001b[0m\u001b[1;38;2;55;65;81m3.5\u001b[0m\u001b[38;2;55;65;81m-turbo, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">QuerySpecificityMetric Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">3.5</span><span style=\"color: #374151; text-decoration-color: #374151\">-turbo, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mQuerySpecificityMetric Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-\u001b[0m\u001b[1;38;2;55;65;81m3.5\u001b[0m\u001b[38;2;55;65;81m-turbo, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">CrossDocumentConsistencyMetric Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">3.5</span><span style=\"color: #374151; text-decoration-color: #374151\">-turbo, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mCrossDocumentConsistencyMetric Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-\u001b[0m\u001b[1;38;2;55;65;81m3.5\u001b[0m\u001b[38;2;55;65;81m-turbo, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">BLEUMetric Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">3.5</span><span style=\"color: #374151; text-decoration-color: #374151\">-turbo, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mBLEUMetric Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-\u001b[0m\u001b[1;38;2;55;65;81m3.5\u001b[0m\u001b[38;2;55;65;81m-turbo, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">ROUGEMetric Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">3.5</span><span style=\"color: #374151; text-decoration-color: #374151\">-turbo, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mROUGEMetric Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-\u001b[0m\u001b[1;38;2;55;65;81m3.5\u001b[0m\u001b[38;2;55;65;81m-turbo, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">METEORMetric Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">3.5</span><span style=\"color: #374151; text-decoration-color: #374151\">-turbo, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mMETEORMetric Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-\u001b[0m\u001b[1;38;2;55;65;81m3.5\u001b[0m\u001b[38;2;55;65;81m-turbo, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">FactualConsistencyMetric Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">3.5</span><span style=\"color: #374151; text-decoration-color: #374151\">-turbo, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mFactualConsistencyMetric Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-\u001b[0m\u001b[1;38;2;55;65;81m3.5\u001b[0m\u001b[38;2;55;65;81m-turbo, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 16 test case(s) in parallel: |          |  0% (0/16) [Time Taken: 00:00, ?test case/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [00:31<00:00, 31.16s/it]\n",
      "Evaluating: 100%|██████████| 1/1 [00:43<00:00, 43.68s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [01:23<00:00, 83.70s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [01:17<00:00, 77.10s/it]\n",
      "Evaluating: 100%|██████████| 1/1 [00:55<00:00, 55.57s/it]\n",
      "Evaluating: 100%|██████████| 1/1 [00:45<00:00, 45.28s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [01:38<00:00, 98.13s/it]\n",
      "Evaluating: 100%|██████████| 1/1 [00:45<00:00, 45.90s/it]\n",
      "Evaluating: 100%|██████████| 1/1 [00:34<00:00, 34.28s/it]\n",
      "Evaluating: 100%|██████████| 1/1 [00:57<00:00, 57.94s/it]\n",
      "Evaluating: 100%|██████████| 1/1 [00:28<00:00, 28.58s/it]\n",
      "Evaluating: 100%|██████████| 1/1 [00:28<00:00, 28.58s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [01:38<00:00, 98.13s/it]\n",
      "Evaluating: 100%|██████████| 1/1 [00:22<00:00, 22.85s/it]\n",
      "Evaluating: 100%|██████████| 1/1 [00:10<00:00, 10.88s/it]\n",
      "Evaluating: 100%|██████████| 1/1 [00:34<00:00, 34.28s/it]\n",
      "Evaluating: 100%|██████████| 1/1 [01:12<00:00, 72.08s/it]\n",
      "Evaluating: 100%|██████████| 1/1 [00:16<00:00, 16.65s/it]\n",
      "Evaluating: 100%|██████████| 1/1 [00:10<00:00, 10.88s/it]\n",
      "Evaluating: 100%|██████████| 1/1 [01:12<00:00, 72.08s/it]\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [01:44<00:00, 104.76s/it]\n",
      "Evaluating: 100%|██████████| 1/1 [00:19<00:00, 19.90s/it]\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [04:02<00:00, 242.67s/it]\n",
      "Evaluating: 100%|██████████| 1/1 [02:58<00:00, 178.72s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [03:44<00:00, 224.05s/it]\n",
      "Evaluating: 100%|██████████| 1/1 [03:16<00:00, 196.62s/it]\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Evaluating: 100%|██████████| 1/1 [03:37<00:00, 217.38s/it]\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Evaluating: 100%|██████████| 1/1 [03:10<00:00, 190.90s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [03:30<00:00, 210.79s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [03:50<00:00, 230.79s/it]\n",
      "Evaluating: 100%|██████████| 1/1 [03:16<00:00, 196.66s/it]\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [03:56<00:00, 236.86s/it]\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [03:22<00:00, 202.44s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [03:22<00:00, 202.44s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [03:37<00:00, 217.41s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [03:44<00:00, 224.10s/it]\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [03:16<00:00, 196.67s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [03:50<00:00, 230.82s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [03:56<00:00, 236.87s/it]\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [04:02<00:00, 242.73s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [03:37<00:00, 217.42s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [03:44<00:00, 224.12s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [03:10<00:00, 190.94s/it]\n",
      "Evaluating: 100%|██████████| 1/1 [04:02<00:00, 242.74s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [03:22<00:00, 202.46s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [03:37<00:00, 217.44s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [03:30<00:00, 210.83s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [03:50<00:00, 230.84s/it]\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [02:58<00:00, 178.81s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [02:44<00:00, 164.18s/it]\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [03:07<00:00, 187.26s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [03:07<00:00, 187.26s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [03:07<00:00, 187.26s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [02:53<00:00, 173.12s/it]\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [03:05<00:00, 185.77s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [03:00<00:00, 180.41s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [02:44<00:00, 164.94s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [02:52<00:00, 172.14s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [03:03<00:00, 183.97s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [02:58<00:00, 178.92s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [02:41<00:00, 161.63s/it]\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [02:48<00:00, 168.11s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1/1 [02:55<00:00, 175.13s/it]\n",
      "Evaluating: 100%|██████████| 1/1 [02:46<00:00, 166.21s/it]\n",
      "Evaluating 16 test case(s) in parallel: |██████████|100% (16/16) [Time Taken: 05:06, 19.13s/test case]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Contextual Precision (ragas) (score: 0.9999999999875, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Faithfulness (ragas) (score: 0.8421052631578947, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Contextual Recall (ragas) (score: 1.0, threshold: 0.6, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Answer Relevancy (ragas) (score: 0.9372296469430402, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: SRGAN introduces two networks called SRResNet and SRGAN. What is the structural difference between them?\n",
      "  - actual output: SRResNet is a deep residual network (a type of neural network where layers learn residual functions with reference to the layer inputs, instead of learning functions independent of the inputs) optimized for minimizing mean squared error (MSE - a measure of the average squared difference between the estimated values and the actual value). This means it aims to produce images that are, on average, as close as possible to the original high-resolution images at a pixel level.\n",
      "\n",
      "SRGAN, on the other hand, builds upon the SRResNet architecture but uses a different training approach. It incorporates a generative adversarial network (GAN - a type of machine learning framework composed of two neural networks, a generator and a discriminator, that contest with each other in a zero-sum game framework to learn a task) structure with a perceptual loss function. This loss function combines an adversarial loss (coming from the discriminator in the GAN, which learns to distinguish between real and super-resolved images) and a content loss (which focuses on perceptual similarity by comparing features from a pre-trained VGG network (a convolutional neural network used for image recognition), not just pixel-by-pixel differences). This makes SRGAN focus less on perfect pixel replication and more on producing images that are perceptually similar to the originals, resulting in more realistic textures and details.\n",
      "  - expected output: Both share the same 16‑block residual generator; SRResNet is trained only with a pixel/feature content loss, whereas SRGAN adds a discriminator and the adversarial term during training, yielding sharper textures.\n",
      "  - context: ['We employ a deep residual network (SRResNet) … We then train SRGAN, which uses the same generator but adds a discriminator network and optimizes the adversarial loss in addition to the content loss.']\n",
      "  - retrieval context: ['conﬁrm that SRGAN outperforms all reference methods by\\na large margin and sets a new state of the art for photo-\\nrealistic image SR. All differences in MOS ( c.f . Table\\n2) are highly signiﬁcant on BSD100, except SRCNN vs.\\nSelfExSR. The distribution of all collected MOS ratings is\\nsummarized in Figure 5.\\n4. Discussion and future work\\nWe conﬁrmed the superior perceptual performance of\\nSRGAN using MOS testing. We have further shown that\\nstandard quantitative measures such as PSNR and SSIM\\nfail to capture and accurately assess image quality with\\nrespect to the human visual system [56]. The focus of this\\nwork was the perceptual quality of super-resolved images\\nrather than computational efﬁciency. The presented model\\nis, in contrast to Shi et al. [48], not optimized for video\\nSR in real-time. However, preliminary experiments on\\nthe network architecture suggest that shallower networks\\nhave the potential to provide very efﬁcient alternatives at\\na small reduction of qualitative performance. In contrast to\\nDong et al. [10], we found deeper network architectures to\\nbe beneﬁcial. We speculate that the ResNet design has a\\nsubstantial impact on the performance of deeper networks.\\nWe found that even deeper networks (B >16) can further\\nSRResNet SRGAN-MSE SRGAN-VGG22 SRGAN-VGG54 original HR image\\nFigure 6: SRResNet (left: a,b), SRGAN-MSE (middle left: c,d), SRGAN-VGG2.2 (middle: e,f) and SRGAN-VGG54\\n(middle right: g,h) reconstruction results and corresponding reference HR image (right: i,j). [ 4×upscaling]\\nTable 2: Comparison of NN, bicubic, SRCNN [9], SelfExSR [31], DRCN [34], ESPCN [48], SRResNet, SRGAN-VGG54\\nand the original HR on benchmark data. Highest measures (PSNR [dB], SSIM, MOS) in bold. [4×upscaling]\\nSet5 nearest bicubic SRCNN SelfExSR DRCN ESPCN SRResNet SRGAN HR\\nPSNR 26.26 28.43 30.07 30.33 31.52 30.76 32.05 29.40 ∞\\nSSIM 0.7552 0.8211 0.8627 0.872 0.8938 0.8784 0.9019 0.8472 1\\nMOS 1.28 1.97 2.57 2.65 3.26 2.89 3.37 3.58 4.32\\nSet14\\nPSNR 24.64 25.99 27.18 27.45 28.02 27.66 28.49 26.02 ∞\\nSSIM 0.7100 0.7486 0.7861 0.7972 0.8074 0.8004 0.8184 0.7397 1\\nMOS 1.20 1.80 2.26 2.34 2.84 2.52 2.98 3.72 4.32\\nBSD100\\nPSNR 25.02 25.94 26.68 26.83 27.21 27.02 27.58 25.16 ∞\\nSSIM 0.6606 0.6935 0.7291 0.7387 0.7493 0.7442 0.7620 0.6688 1\\nMOS 1.11 1.47 1.87 1.89 2.12 2.01 2.29 3.56 4.46\\nincrease the performance of SRResNet, however, come at\\nthe cost of longer training and testing times ( c.f . supple-\\nmentary material). We further found SRGAN variants of\\ndeeper networks are increasingly difﬁcult to train due to the\\nappearance of high-frequency artifacts.\\nOf particular importance when aiming for photo-realistic\\nsolutions to the SR problem is the choice of the content loss\\nas illustrated in Figure 6. In this work, we found lSR\\nVGG/5.4\\nto yield the perceptually most convincing results, which\\nwe attribute to the potential of deeper network layers to\\nrepresent features of higher abstraction [68, 65, 40] away\\nfrom pixel space. We speculate that feature maps of these\\ndeeper layers focus purely on the content while leaving the\\nadversarial loss focusing on texture details which are the\\nmain difference between the super-resolved images without\\nthe adversarial loss and photo-realistic images. We also\\nnote that the ideal loss function depends on the application.\\nFor example, approaches that hallucinate ﬁner detail might\\nbe less suited for medical applications or surveillance. The\\nperceptually convincing reconstruction of text or structured\\nscenes [31] is challenging and part of future work. The\\ndevelopment of content loss functions that describe image\\nspatial content, but more invariant to changes in pixel space\\nwill further improve photo-realistic image SR results.\\n5. Conclusion\\nWe have described a deep residual network SRRes-\\nNet that sets a new state of the art on public benchmark\\ndatasets when evaluated with the widely used PSNR mea-\\nsure. We have highlighted some limitations of this PSNR-\\nfocused image super-resolution and introduced SRGAN,', 'ure 3 where multiple potential solutions with high texture\\ndetails are averaged to create a smooth reconstruction.\\nIn Mathieu et al. [42] and Denton et al. [7] the authors\\ntackled this problem by employing generative adversarial\\nnetworks (GANs) [22] for the application of image genera-\\ntion. Yu and Porikli [66] augment pixel-wise MSE loss with\\na discriminator loss to train a network that super-resolves\\nface images with large upscaling factors ( 8×). GANs\\nwere also used for unsupervised representation learning in\\nRadford et al. [44]. The idea of using GANs to learn a\\nmapping from one manifold to another is described by Li\\nand Wand [38] for style transfer and Yeh et al. [64] for\\ninpainting. Bruna et al. [5] minimize the squared error in\\nthe feature spaces of VGG19 [49] and scattering networks.\\nDosovitskiy and Brox [13] use loss functions based\\non Euclidean distances computed in the feature space of\\nneural networks in combination with adversarial training.\\nIt is shown that the proposed loss allows visually superior\\nimage generation and can be used to solve the ill-posed\\ninverse problem of decoding nonlinear feature representa-\\ntions. Similar to this work, Johnson et al. [33] and Bruna\\net al. [5] propose the use of features extracted from a pre-\\ntrained VGG network instead of low-level pixel-wise error\\nmeasures. Speciﬁcally the authors formulate a loss function\\nbased on the euclidean distance between feature maps\\nextracted from the VGG19 [49] network. Perceptually more\\nconvincing results were obtained for both super-resolution\\nand artistic style-transfer [19, 20]. Recently, Li and Wand\\n[38] also investigated the effect of comparing and blending\\npatches in pixel or VGG feature space.\\n1.2. Contribution\\nGANs provide a powerful framework for generating\\nplausible-looking natural images with high perceptual qual-\\nity. The GAN procedure encourages the reconstructions\\nto move towards regions of the search space with high\\nprobability of containing photo-realistic images and thus\\ncloser to the natural image manifold as shown in Figure 3.\\nIn this paper we describe the ﬁrst very deep ResNet\\n[29, 30] architecture using the concept of GANs to form a\\nperceptual loss function for photo-realistic SISR. Our main\\ncontributions are:\\n•We set a new state of the art for image SR with\\nhigh upscaling factors (4×) as measured by PSNR and\\nstructural similarity (SSIM) with our 16 blocks deep\\nResNet (SRResNet) optimized for MSE.\\n•We propose SRGAN which is a GAN-based network\\noptimized for a new perceptual loss. Here we replace\\nthe MSE-based content loss with a loss calculated on\\nfeature maps of the VGG network [49], which are\\nmore invariant to changes in pixel space [38].\\n•We conﬁrm with an extensive mean opinion score\\n(MOS) test on images from three public benchmark\\ndatasets that SRGAN is the new state of the art, by a\\nlarge margin, for the estimation of photo-realistic SR\\nimages with high upscaling factors (4×).\\nWe describe the network architecture and the perceptual\\nloss in Section 2. A quantitative evaluation on public bench-\\nmark datasets as well as visual illustrations are provided in\\nSection 3. The paper concludes with a discussion in Section\\n4 and concluding remarks in Section 5.\\n2. Method\\nIn SISR the aim is to estimate a high-resolution, super-\\nresolved image ISR from a low-resolution input image\\nILR. Here ILR is the low-resolution version of its high-\\nresolution counterpart IHR. The high-resolution images\\nare only available during training. In training, ILR is\\nobtained by applying a Gaussian ﬁlter toIHR followed by a\\ndownsampling operation with downsampling factor r. For\\nan image with C color channels, we describe ILR by a\\nreal-valued tensor of size W ×H ×C and IHR, ISR by\\nrW ×rH ×Crespectively.\\nOur ultimate goal is to train a generating function Gthat\\nestimates for a given LR input image its corresponding HR\\ncounterpart. To achieve this, we train a generator network as\\na feed-forward CNN GθG parametrized by θG. Here θG =', 'development of content loss functions that describe image\\nspatial content, but more invariant to changes in pixel space\\nwill further improve photo-realistic image SR results.\\n5. Conclusion\\nWe have described a deep residual network SRRes-\\nNet that sets a new state of the art on public benchmark\\ndatasets when evaluated with the widely used PSNR mea-\\nsure. We have highlighted some limitations of this PSNR-\\nfocused image super-resolution and introduced SRGAN,\\nwhich augments the content loss function with an adversar-\\nial loss by training a GAN. Using extensive MOS testing,\\nwe have conﬁrmed that SRGAN reconstructions for large\\nupscaling factors (4×) are, by a considerable margin, more\\nphoto-realistic than reconstructions obtained with state-of-\\nthe-art reference methods.\\nReferences\\n[1] J. Allebach and P. W. Wong. Edge-directed interpolation. InProceed-\\nings of International Conference on Image Processing , volume 3,\\npages 707–710, 1996. 2\\n[2] H. A. Aly and E. Dubois. Image up-sampling using total-variation\\nregularization with a new observation model. IEEE Transactions on\\nImage Processing, 14(10):1647–1659, 2005. 7\\n[3] M. Bevilacqua, A. Roumy, C. Guillemot, and M. L. Alberi-Morel.\\nLow-complexity single-image super-resolution based on nonnegative\\nneighbor embedding. BMVC, 2012. 6\\n[4] S. Borman and R. L. Stevenson. Super-Resolution from Image\\nSequences - A Review.Midwest Symposium on Circuits and Systems,\\npages 374–378, 1998. 2\\n[5] J. Bruna, P. Sprechmann, and Y . LeCun. Super-resolution with deep\\nconvolutional sufﬁcient statistics. In International Conference on\\nLearning Representations (ICLR), 2016. 2, 3, 5\\n[6] D. Dai, R. Timofte, and L. Van Gool. Jointly optimized regressors for\\nimage super-resolution. In Computer Graphics Forum, volume 34,\\npages 95–104, 2015. 2\\n[7] E. Denton, S. Chintala, A. Szlam, and R. Fergus. Deep generative\\nimage models using a laplacian pyramid of adversarial networks. In\\nAdvances in Neural Information Processing Systems (NIPS) , pages\\n1486–1494, 2015. 3\\n[8] S. Dieleman, J. Schl ¨uter, C. Raffel, E. Olson, S. K. Snderby,\\nD. Nouri, D. Maturana, M. Thoma, E. Battenberg, J. Kelly, J. D.\\nFauw, M. Heilman, diogo149, B. McFee, H. Weideman, takacsg84,\\npeterderivaz, Jon, instagibbs, D. K. Rasul, CongLiu, Britefury, and\\nJ. Degrave. Lasagne: First release., 2015. 6\\n[9] C. Dong, C. C. Loy, K. He, and X. Tang. Learning a deep\\nconvolutional network for image super-resolution. In European\\nConference on Computer Vision (ECCV), pages 184–199. Springer,\\n2014. 3, 6, 8\\n[10] C. Dong, C. C. Loy, K. He, and X. Tang. Image super-resolution\\nusing deep convolutional networks. IEEE Transactions on Pattern\\nAnalysis and Machine Intelligence, 38(2):295–307, 2016. 3, 5, 7\\n[11] C. Dong, C. C. Loy, and X. Tang. Accelerating the super-resolution\\nconvolutional neural network. InEuropean Conference on Computer\\nVision (ECCV), pages 391–407. Springer, 2016. 3\\n[12] W. Dong, L. Zhang, G. Shi, and X. Wu. Image deblurring and super-\\nresolution by adaptive sparse domain selection and adaptive regular-\\nization. IEEE Transactions on Image Processing, 20(7):1838–1857,\\n2011. 2\\n[13] A. Dosovitskiy and T. Brox. Generating images with perceptual\\nsimilarity metrics based on deep networks. In Advances in Neural\\nInformation Processing Systems (NIPS), pages 658–666, 2016. 3\\n[14] C. E. Duchon. Lanczos Filtering in One and Two Dimensions. In\\nJournal of Applied Meteorology, volume 18, pages 1016–1022. 1979.\\n2\\n[15] S. Farsiu, M. D. Robinson, M. Elad, and P. Milanfar. Fast and\\nrobust multiframe super resolution. IEEE Transactions on Image\\nProcessing, 13(10):1327–1344, 2004. 2\\n[16] J. A. Ferwerda. Three varieties of realism in computer graphics. In\\nElectronic Imaging, pages 290–297. International Society for Optics\\nand Photonics, 2003. 2\\n[17] W. T. Freeman, T. R. Jones, and E. C. Pasztor. Example-based super-\\nresolution. IEEE Computer Graphics and Applications, 22(2):56–65,\\n2002. 2\\n[18] W. T. Freeman, E. C. Pasztor, and O. T. Carmichael. Learning low-', 'Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial\\nNetwork\\nChristian Ledig, Lucas Theis, Ferenc Husz´ar, Jose Caballero, Andrew Cunningham,\\nAlejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, Wenzhe Shi\\nTwitter\\n{cledig,ltheis,fhuszar,jcaballero,aacostadiaz,aaitken,atejani,jtotz,zehanw,wshi}@twitter.com\\nAbstract\\nDespite the breakthroughs in accuracy and speed of\\nsingle image super-resolution using faster and deeper con-\\nvolutional neural networks, one central problem remains\\nlargely unsolved: how do we recover the ﬁner texture details\\nwhen we super-resolve at large upscaling factors? The\\nbehavior of optimization-based super-resolution methods is\\nprincipally driven by the choice of the objective function.\\nRecent work has largely focused on minimizing the mean\\nsquared reconstruction error. The resulting estimates have\\nhigh peak signal-to-noise ratios, but they are often lacking\\nhigh-frequency details and are perceptually unsatisfying in\\nthe sense that they fail to match the ﬁdelity expected at\\nthe higher resolution. In this paper, we present SRGAN,\\na generative adversarial network (GAN) for image super-\\nresolution (SR). To our knowledge, it is the ﬁrst framework\\ncapable of inferring photo-realistic natural images for 4×\\nupscaling factors. To achieve this, we propose a perceptual\\nloss function which consists of an adversarial loss and a\\ncontent loss. The adversarial loss pushes our solution to\\nthe natural image manifold using a discriminator network\\nthat is trained to differentiate between the super-resolved\\nimages and original photo-realistic images. In addition, we\\nuse a content loss motivated by perceptual similarity instead\\nof similarity in pixel space. Our deep residual network\\nis able to recover photo-realistic textures from heavily\\ndownsampled images on public benchmarks. An extensive\\nmean-opinion-score (MOS) test shows hugely signiﬁcant\\ngains in perceptual quality using SRGAN. The MOS scores\\nobtained with SRGAN are closer to those of the original\\nhigh-resolution images than to those obtained with any\\nstate-of-the-art method.\\n1. Introduction\\nThe highly challenging task of estimating a high-\\nresolution (HR) image from its low-resolution (LR)\\ncounterpart is referred to as super-resolution (SR). SR\\nreceived substantial attention from within the computer\\nvision research community and has a wide range of\\napplications [63, 71, 43].\\n4×SRGAN (proposed) original\\nFigure 1: Super-resolved image (left) is almost indistin-\\nguishable from original (right). [4×upscaling]\\nThe ill-posed nature of the underdetermined SR problem\\nis particularly pronounced for high upscaling factors, for\\nwhich texture detail in the reconstructed SR images is\\ntypically absent. The optimization target of supervised\\nSR algorithms is commonly the minimization of the mean\\nsquared error (MSE) between the recovered HR image\\nand the ground truth. This is convenient as minimizing\\nMSE also maximizes the peak signal-to-noise ratio (PSNR),\\nwhich is a common measure used to evaluate and compare\\nSR algorithms [61]. However, the ability of MSE (and\\nPSNR) to capture perceptually relevant differences, such\\nas high texture detail, is very limited as they are deﬁned\\nbased on pixel-wise image differences [60, 58, 26]. This\\nis illustrated in Figure 2, where highest PSNR does not\\nnecessarily reﬂect the perceptually better SR result. The\\n1\\narXiv:1609.04802v5  [cs.CV]  25 May 2017\\nbicubic SRResNet SRGAN original\\n(21.59dB/0.6423) (23.53dB/0.7832) (21.15dB/0.6868)\\nFigure 2: From left to right: bicubic interpolation, deep residual network optimized for MSE, deep residual generative\\nadversarial network optimized for a loss more sensitive to human perception, original HR image. Corresponding PSNR and\\nSSIM are shown in brackets. [4×upscaling]\\nperceptual difference between the super-resolved and orig-\\ninal image means that the recovered image is not photo-\\nrealistic as deﬁned by Ferwerda [16].', 'and signiﬁcance determined at p< 0.05.\\nThe reader may also be interested in an independently\\ndeveloped GAN-based solution on GitHub 5. However it\\nonly provides experimental results on a limited set of faces,\\nwhich is a more constrained and easier task.\\n3.2. Training details and parameters\\nWe trained all networks on a NVIDIA Tesla M40 GPU\\nusing a random sample of 350 thousand images from\\nthe ImageNet database [45]. These images are distinct\\nfrom the testing images. We obtained the LR images\\nby downsampling the HR images (BGR, C = 3) using\\nbicubic kernel with downsampling factor r = 4. For each\\nmini-batch we crop 16 random 96 ×96 HR sub images\\nof distinct training images. Note that we can apply the\\ngenerator model to images of arbitrary size as it is fully\\n1https://github.com/xiph/daala (commit: 8d03668)\\n2https://github.com/jbhuang0604/SelfExSR\\n3http://cv.snu.ac.kr/research/DRCN/\\n4https://twitter.box.com/s/\\nlcue6vlrd01ljkdtdkhmfvk7vtjhetog\\n5https://github.com/david-gpu/srez\\nconvolutional. We scaled the range of the LR input images\\nto [0,1] and for the HR images to [−1,1]. The MSE loss\\nwas thus calculated on images of intensity range [−1,1].\\nVGG feature maps were also rescaled by a factor of 1\\n12.75\\nto obtain VGG losses of a scale that is comparable to the\\nMSE loss. This is equivalent to multiplying Equation 5\\nwith a rescaling factor of ≈ 0.006. For optimization we\\nuse Adam [36] with β1 = 0.9. The SRResNet networks\\nwere trained with a learning rate of 10−4 and 106 update\\niterations. We employed the trained MSE-based SRResNet\\nnetwork as initialization for the generator when training\\nthe actual GAN to avoid undesired local optima. All\\nSRGAN variants were trained with 105 update iterations\\nat a learning rate of 10−4 and another 105 iterations at a\\nlower rate of 10−5. We alternate updates to the generator\\nand discriminator network, which is equivalent to k = 1\\nas used in Goodfellow et al. [22]. Our generator network\\nhas 16 identical (B = 16) residual blocks. During test time\\nwe turn batch-normalization update off to obtain an output\\nthat deterministically depends only on the input [32]. Our\\nimplementation is based on Theano [53] and Lasagne [8].\\n3.3. Mean opinion score (MOS) testing\\nWe have performed a MOS test to quantify the ability of\\ndifferent approaches to reconstruct perceptually convincing\\nimages. Speciﬁcally, we asked 26 raters to assign an inte-\\ngral score from 1 (bad quality) to 5 (excellent quality) to the\\nsuper-resolved images. The raters rated 12 versions of each\\nimage on Set5, Set14 and BSD100: nearest neighbor (NN),\\nbicubic, SRCNN [9], SelfExSR [31], DRCN [34], ESPCN\\n[48], SRResNet-MSE, SRResNet-VGG22∗ (∗not rated on\\nBSD100), SRGAN-MSE ∗, SRGAN-VGG22 ∗, SRGAN-\\nVGG54 and the original HR image. Each rater thus rated\\n1128 instances (12 versions of 19 images plus 9 versions of\\n100 images) that were presented in a randomized fashion.\\nThe raters were calibrated on the NN (score 1) and HR (5)\\nversions of 20 images from the BSD300 training set. In a\\npilot study we assessed the calibration procedure and the\\ntest-retest reliability of 26 raters on a subset of 10 images\\nfrom BSD100 by adding a method’s images twice to a\\nlarger test set. We found good reliability and no signiﬁcant\\ndifferences between the ratings of the identical images.\\nRaters very consistently rated NN interpolated test images\\nas 1 and the original HR images as 5 (c.f . Figure 5).\\nThe experimental results of the conducted MOS tests are\\nsummarized in Table 1, Table 2 and Figure 5.\\n3.4. Investigation of content loss\\nWe investigated the effect of different content loss\\nchoices in the perceptual loss for the GAN-based networks.\\nSpeciﬁcally we investigate lSR = lSR\\nX + 10−3lSR\\nGen for the\\nfollowing content losses lSR\\nX :\\nTable 1: Performance of different loss functions for SR-\\nResNet and the adversarial networks on Set5 and Set14\\nbenchmark data. MOS score signiﬁcantly higher (p< 0.05)\\nthan with other losses in that category∗. [4×upscaling]\\nSRResNet- SRGAN-', '3.4. Investigation of content loss\\nWe investigated the effect of different content loss\\nchoices in the perceptual loss for the GAN-based networks.\\nSpeciﬁcally we investigate lSR = lSR\\nX + 10−3lSR\\nGen for the\\nfollowing content losses lSR\\nX :\\nTable 1: Performance of different loss functions for SR-\\nResNet and the adversarial networks on Set5 and Set14\\nbenchmark data. MOS score signiﬁcantly higher (p< 0.05)\\nthan with other losses in that category∗. [4×upscaling]\\nSRResNet- SRGAN-\\nSet5 MSE VGG22 MSE VGG22 VGG54\\nPSNR 32.05 30.51 30.64 29.84 29.40\\nSSIM 0.9019 0.8803 0.8701 0.8468 0.8472\\nMOS 3.37 3.46 3.77 3.78 3.58\\nSet14\\nPSNR 28.49 27.19 26.92 26.44 26.02\\nSSIM 0.8184 0.7807 0.7611 0.7518 0.7397\\nMOS 2.98 3.15 ∗ 3.43 3.57 3.72 ∗\\n•SRGAN-MSE: lSR\\nMSE, to investigate the adversarial\\nnetwork with the standard MSE as content loss.\\n•SRGAN-VGG22: lSR\\nVGG/2.2 with φ2,2, a loss deﬁned\\non feature maps representing lower-level features [68].\\n•SRGAN-VGG54: lSR\\nVGG/5.4 with φ5,4, a loss deﬁned\\non feature maps of higher level features from deeper\\nnetwork layers with more potential to focus on the\\ncontent of the images [68, 65, 40]. We refer to this\\nnetwork as SRGAN in the following.\\nWe also evaluate the performance of the generator network\\nwithout adversarial component for the two losses lSR\\nMSE\\n(SRResNet-MSE) and lSR\\nVGG/2.2 (SRResNet-VGG22). We\\nrefer to SRResNet-MSE asSRResNet. Note, when training\\nSRResNet-VGG22 we added an additional total variation\\nloss with weight 2 ×10−8 to lSR\\nVGG/2.2 [2, 33]. Quantitative\\nresults are summarized in Table 1 and visual examples\\nprovided in Figure 6. Even combined with the adversarial\\nloss, MSE provides solutions with the highest PSNR values\\nthat are, however, perceptually rather smooth and less\\nconvincing than results achieved with a loss component\\nmore sensitive to visual perception. This is caused by\\ncompetition between the MSE-based content loss and the\\nadversarial loss. We further attribute minor reconstruction\\nartifacts, which we observed in a minority of SRGAN-\\nMSE-based reconstructions, to those competing objectives.\\nWe could not determine a signiﬁcantly best loss function\\nfor SRResNet or SRGAN with respect to MOS score\\non Set5. However, SRGAN-VGG54 signiﬁcantly outper-\\nformed other SRGAN and SRResNet variants on Set14 in\\nterms of MOS. We observed a trend that using the higher\\nlevel VGG feature maps φ5,4 yields better texture detail\\nwhen compared to φ2,2 (c.f . Figure 6). Further examples of\\nperceptual improvements through SRGAN over SRResNet\\nare provided in the supplementary material.\\nFigure 5: Color-coded distribution of MOS scores on\\nBSD100. For each method 2600 samples (100 images ×\\n26 raters) were assessed. Mean shown as red marker, where\\nthe bins are centered around value i. [4×upscaling]\\n3.5. Performance of the ﬁnal networks\\nWe compare the performance of SRResNet and SR-\\nGAN to NN, bicubic interpolation, and four state-of-the-\\nart methods. Quantitative results are summarized in Table\\n2 and conﬁrm that SRResNet (in terms of PSNR/SSIM)\\nsets a new state of the art on three benchmark datasets.\\nPlease note that we used a publicly available framework\\nfor evaluation (c.f . Section 3.1), reported values might thus\\nslightly deviate from those reported in the original papers.\\nWe further obtained MOS ratings for SRGAN and all\\nreference methods on BSD100. Examples of images super-\\nresolved with SRResNet and SRGAN are depicted in the\\nsupplementary material. The results shown in Table 2\\nconﬁrm that SRGAN outperforms all reference methods by\\na large margin and sets a new state of the art for photo-\\nrealistic image SR. All differences in MOS ( c.f . Table\\n2) are highly signiﬁcant on BSD100, except SRCNN vs.\\nSelfExSR. The distribution of all collected MOS ratings is\\nsummarized in Figure 5.\\n4. Discussion and future work\\nWe conﬁrmed the superior perceptual performance of\\nSRGAN using MOS testing. We have further shown that\\nstandard quantitative measures such as PSNR and SSIM', '(21.59dB/0.6423) (23.53dB/0.7832) (21.15dB/0.6868)\\nFigure 2: From left to right: bicubic interpolation, deep residual network optimized for MSE, deep residual generative\\nadversarial network optimized for a loss more sensitive to human perception, original HR image. Corresponding PSNR and\\nSSIM are shown in brackets. [4×upscaling]\\nperceptual difference between the super-resolved and orig-\\ninal image means that the recovered image is not photo-\\nrealistic as deﬁned by Ferwerda [16].\\nIn this work we propose a super-resolution generative\\nadversarial network (SRGAN) for which we employ a\\ndeep residual network (ResNet) with skip-connection and\\ndiverge from MSE as the sole optimization target. Different\\nfrom previous works, we deﬁne a novel perceptual loss us-\\ning high-level feature maps of the VGG network [49, 33, 5]\\ncombined with a discriminator that encourages solutions\\nperceptually hard to distinguish from the HR reference\\nimages. An example photo-realistic image that was super-\\nresolved with a 4×upscaling factor is shown in Figure 1.\\n1.1. Related work\\n1.1.1 Image super-resolution\\nRecent overview articles on image SR include Nasrollahi\\nand Moeslund [43] or Yang et al. [61]. Here we will focus\\non single image super-resolution (SISR) and will not further\\ndiscuss approaches that recover HR images from multiple\\nimages [4, 15].\\nPrediction-based methods were among the ﬁrst methods\\nto tackle SISR. While these ﬁltering approaches, e.g. linear,\\nbicubic or Lanczos [14] ﬁltering, can be very fast, they\\noversimplify the SISR problem and usually yield solutions\\nwith overly smooth textures. Methods that put particularly\\nfocus on edge-preservation have been proposed [1, 39].\\nMore powerful approaches aim to establish a complex\\nmapping between low- and high-resolution image informa-\\ntion and usually rely on training data. Many methods that\\nare based on example-pairs rely on LR training patches for\\nwhich the corresponding HR counterparts are known. Early\\nwork was presented by Freeman et al. [18, 17]. Related ap-\\nproaches to the SR problem originate in compressed sensing\\n[62, 12, 69]. In Glasner et al. [21] the authors exploit patch\\nredundancies across scales within the image to drive the SR.\\nThis paradigm of self-similarity is also employed in Huang\\net al. [31], where self dictionaries are extended by further\\nallowing for small transformations and shape variations. Gu\\net al. [25] proposed a convolutional sparse coding approach\\nthat improves consistency by processing the whole image\\nrather than overlapping patches.\\nTo reconstruct realistic texture detail while avoiding\\nedge artifacts, Tai et al. [52] combine an edge-directed SR\\nalgorithm based on a gradient proﬁle prior [50] with the\\nbeneﬁts of learning-based detail synthesis. Zhang et al. [70]\\npropose a multi-scale dictionary to capture redundancies of\\nsimilar image patches at different scales. To super-resolve\\nlandmark images, Yue et al. [67] retrieve correlating HR\\nimages with similar content from the web and propose a\\nstructure-aware matching criterion for alignment.\\nNeighborhood embedding approaches upsample a LR\\nimage patch by ﬁnding similar LR training patches in a low\\ndimensional manifold and combining their corresponding\\nHR patches for reconstruction [54, 55]. In Kim and Kwon\\n[35] the authors emphasize the tendency of neighborhood\\napproaches to overﬁt and formulate a more general map of\\nexample pairs using kernel ridge regression. The regression\\nproblem can also be solved with Gaussian process regres-\\nsion [27], trees [46] or Random Forests [47]. In Dai et al.\\n[6] a multitude of patch-speciﬁc regressors is learned and\\nthe most appropriate regressors selected during testing.\\nRecently convolutional neural network (CNN) based SR\\nalgorithms have shown excellent performance. In Wang\\net al. [59] the authors encode a sparse representation\\nprior into their feed-forward network architecture based on\\nthe learned iterative shrinkage and thresholding algorithm', '[70] K. Zhang, X. Gao, D. Tao, and X. Li. Multi-scale dictionary for\\nsingle image super-resolution. In IEEE Conference on Computer\\nVision and Pattern Recognition (CVPR), pages 1114–1121, 2012. 2\\n[71] W. Zou and P. C. Yuen. Very Low Resolution Face Recognition\\nin Parallel Environment . IEEE Transactions on Image Processing,\\n21:327–340, 2012. 1\\nA. Supplementary Material\\nIn this supplementary material we ﬁrst brieﬂy investigate the inﬂuence of network depth (number of residual blocks)\\non the performance (PSNR, time) of SRResNet in Section A.1. We then visualize on an example image how the SRGAN\\nnetwork performance evolves with increasing number of training iterations in Section A.2. Results of the MOS tests\\nconducted on Set5, Set14, BSD100 are summarized in Section A.3. Finally we provide a visualization of all image\\nreconstruction obtained with SRResNet and SRGAN with a 4×upscaling factor for Set5 (Section A.4), Set14 (Section A.5)\\nand ﬁve randomly selected images from BSD100 (Section A.6).\\nImages are best viewed and compared zoomed in. All original low-/high-resolution images and reconstructions\\n(4×upscaling) obtained with different methods (bicubic, SRResNet-MSE, SRResNet-VGG22, SRGAN-MSE, SRGAN-\\nVGG22, SRGAN-VGG54) described in the paper are available for download at https://twitter.box.com/s/\\nlcue6vlrd01ljkdtdkhmfvk7vtjhetog.\\nA.1. Performance (PSNR/time) vs. network depth\\nWe investigated the inﬂuence of network depth, speciﬁcally the number of residual blocks, on performance (PSNR [dB]\\non BSD100 for 4×SR) and inference time [s] of the network architecture described in Figure 4 of the main paper. Time was\\nassessed on a NVIDIA M40 GPU and averaged over 100 reconstructions of a random low-resolution image with resolution\\n64×64 with upscaling factor 4×. The measurements are plotted in Figure 7 for a network with (blue) and without (red)\\nskip-connection. As expected the time of a single forward pass through the network depends approximately linearly on the\\nnumber of residual blocks. Whether a skip-connection is used or not has no substantial impact on inference time. However,\\nwe observed substantial gains in performance with the additional skip-connection. We chose a network architecture of\\n16 residual blocks with skip-connection for the evaluation presented in the main paper as we consider this as good trade-\\noff between accuracy and speed including training time. While accuracy gains slowly saturate beyond 16 blocks there is,\\nnevertheless, a clear beneﬁt of using even deeper networks.\\nFigure 7: Dependence of network performance (PSNR, time) on network depth. PSNR (left) calculated on BSD100. Time\\n(right) averaged over 100 reconstructions of a random LR image with resolution 64×64.\\nA.2. Evolution of Generator during SRGAN training\\nWe further investigated how reconstructions of the SRGAN generator network evolve (visually) with increasing number\\nof training iterations. Visual results obtained after different number of training iterations are illustrated in Figure 8. It is\\ninteresting that after only 20 thousand training iterations the generator substantially diverged from the SRResNet initialization\\nand produces reconstruction with a lot of high frequency content, including noise. With increasing number of training\\niterations reconstructions of the baboon from Set14 appear closer to the reference image. However, there is visually little\\nchange during the last 50-100 thousand update iterations.\\nSRResNet 20k 40k 60k 80k\\n100k 140k 180k SRGAN original HR image\\nFigure 8: Evolution of SRGAN generator network during training progress. Note: Generator initialized with SRResNet\\nweights; learning rate set to 10−4 for ﬁrst 100k iterations, then reduced to 10−5 for another 100k iterations. [4×upscaling]\\nA.3. Mean opinion score (MOS) testing\\nIn all conducted MOS tests we have asked 26 human raters to assign a score from 1 (Bad) to 5 (Excellent) to reconstructions']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Contextual Precision (ragas) (score: 0.9999999999875, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Faithfulness (ragas) (score: 0.7333333333333333, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Contextual Recall (ragas) (score: 1.0, threshold: 0.6, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Answer Relevancy (ragas) (score: 0.8992525642675296, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: SRCNN reports 8 032 trainable parameters; can you explain how this relatively small count is achieved?\n",
      "  - actual output: SRCNN's relatively low parameter count of 8,032 is a result of its simple three-layer architecture and relatively small filter sizes. Let's break down how the parameter count is calculated:\n",
      "\n",
      "Layer 1 (Patch extraction and representation): This layer uses 64 filters (kernels) with a size of 9x9x1. Since the input is assumed to be a single-channel image (grayscale), each filter has 9*9 = 81 weights, plus one bias term per filter. This results in 64 * (81 + 1) = 5,184 parameters for the first layer.\n",
      "\n",
      "Layer 2 (Non-linear mapping): This layer employs 32 filters with a size of 1x1x64. The input to this layer is the output from the first layer, which has 64 channels. So each filter has 1164 = 64 weights, plus one bias term. This leads to 32 * (64 + 1) = 2,080 parameters in the second layer.\n",
      "\n",
      "Layer 3 (Reconstruction): The final layer has a single filter with a size of 5x5x32. It takes the 32-channel output of the second layer as input. The filter has 5532 = 800 weights, plus a single bias term. This totals 800 + 1 = 801 parameters for the third layer.\n",
      "\n",
      "Adding the parameters from all three layers: 5,184 + 2,080 + 801 = 8,065. The original paper mentions 8,032, suggesting a slight variation in the calculation. While the exact reason for this minor difference is unclear within the provided text, the primary reason for the low number of parameters is the smaller filter sizes compared to many deeper convolutional neural networks (CNNs), which might have hundreds or thousands of filters and larger filter dimensions, leading to millions or even billions of parameters.\n",
      "  - expected output: Because it uses just three convolutional layers with relatively few filters (64, 32, c) and small kernels (9×9, 1×1, 5×5). Param count = (c·9²·64)+(64·1²·32)+(32·5²·c)+biases ≈ 8 k\n",
      "  - context: ['A typical and basic setting is f₁ = 9, f₂ = 1, f₃ = 5, n₁ = 64, n₂ = 32 … the number of parameters of 9‑1‑5 … is 8 032.']\n",
      "  - retrieval context: ['observed, with the same number of backpropagations\\n(i.e.,8 ×108), the SRCNN +ImageNet achieves 32.52 dB,\\nhigher than 32.39 dB yielded by that trained on 91\\nimages. The results positively indicate that SRCNN per-\\nformance may be further boosted using a larger training\\nset, but the effect of big data is not as impressive as\\nthat shown in high-level vision problems [26]. This is\\nmainly because that the 91 images have already cap-\\ntured sufﬁcient variability of natural images. On the\\nother hand, our SRCNN is a relatively small network\\n(8,032 parameters), which could not overﬁt the 91 images\\n(24,800 samples). Nevertheless, we adopt the ImageNet,\\nwhich contains more diverse data, as the default training\\nset in the following experiments.\\n4.2 Learned Filters for Super-Resolution\\nFigure 5 shows examples of learned ﬁrst-layer ﬁlters\\ntrained on the ImageNet by an upscaling factor 3. Please\\nrefer to our published implementation for upscaling\\nfactors 2 and 4. Interestingly, each learned ﬁlter has\\nits speciﬁc functionality. For instance, the ﬁlters g and\\nh are like Laplacian/Gaussian ﬁlters, the ﬁlters a - e\\nare like edge detectors at different directions, and the\\nﬁlter f is like a texture extractor. Example feature maps\\nof different layers are shown in ﬁgure 6. Obviously,\\nfeature maps of the ﬁrst layer contain different structures\\n(e.g., edges at different directions), while that of the\\nsecond layer are mainly different on intensities.\\n4.3 Model and Performance Trade-offs\\nBased on the basic network settings ( i.e., f1 = 9, f2 = 1,\\nf3 = 5 , n1 = 64 , and n2 = 32 ), we will progressively\\nmodify some of these parameters to investigate the best\\ntrade-off between performance and speed, and study the\\nrelations between performance and parameters.\\n1 2 3 4 5 6 7 8 9 10\\nxS10\\n8\\n31.4\\n31.6\\n31.8\\n32\\n32.2\\n32.4\\n32.6\\nNumberSofSbackprops\\nAverageStestSPSNRSndBI\\nSRCNNSntrainedSonSImageNetI\\nSRCNNSntrainedSonS91SimagesI\\nSCSn31.42SdBI\\nFig. 4. Training with the much larger ImageNet dataset\\nimproves the performance over the use of 91 images.\\n7\\na b c d e f\\ng\\nh\\nFig. 5. The ﬁgure shows the ﬁrst-layer ﬁlters trained\\non ImageNet with an upscaling factor 3. The ﬁlters are\\norganized based on their respective variances.\\nInput Feature maps of the first layer\\nOutput Feature maps of the second layer\\nFig. 6. Example feature maps of different layers.\\n4.3.1 Filter number\\nIn general, the performance would improve if we in-\\ncrease the network width6, i.e., adding more ﬁlters, at the\\ncost of running time. Speciﬁcally, based on our network\\ndefault settings of n1 = 64 and n2 = 32 , we conduct\\ntwo experiments: (i) one is with a larger network with\\nn1 = 128 and n2 = 64, and (ii) the other is with a smaller\\nnetwork with n1 = 32 and n2 = 16. Similar to Section 4.1,\\nwe also train the two models on ImageNet and test on\\nSet5 with an upscaling factor 3. The results observed\\nat 8 ×108 backpropagations are shown in Table 1. It is\\nclear that superior performance could be achieved by\\nincreasing the width. However, if a fast restoration speed\\nis desired, a small network width is preferred, which\\ncould still achieve better performance than the sparse-\\ncoding-based method (31.42 dB).\\nTABLE 1\\nThe results of using different ﬁlter numbers in SRCNN.\\nTraining is performed on ImageNet whilst the evaluation\\nis conducted on the Set5 dataset.\\nn1 = 128 n1 = 64 n1 = 32\\nn2 = 64 n2 = 32 n2 = 16\\nPSNR Time (sec) PSNR Time (sec) PSNR Time (sec)\\n32.60 0.60 32.52 0.18 32.26 0.05\\n4.3.2 Filter size\\nIn this section, we examine the network sensitivity to\\ndifferent ﬁlter sizes. In previous experiments, we set\\nﬁlter size f1 = 9, f2 = 1 and f3 = 5, and the network\\ncould be denoted as 9-1-5. First, to be consistent with\\nsparse-coding-based methods, we ﬁx the ﬁlter size of the\\nsecond layer to be f2 = 1, and enlarge the ﬁlter size of\\nother layers to f1 = 11 and f3 = 7 (11-1-7). All the other\\n6. We use ‘width’ to term the number of ﬁlters in a layer, follow-', 'erations, ηis the learning rate, and ∂L\\n∂W ℓ\\ni\\nis the derivative.\\nThe ﬁlter weights of each layer are initialized by drawing\\nrandomly from a Gaussian distribution with zero mean\\nand standard deviation 0.001 (and 0 for biases). The\\nlearning rate is 10−4 for the ﬁrst two layers, and 10−5 for\\nthe last layer. We empirically ﬁnd that a smaller learning\\nrate in the last layer is important for the network to\\nconverge (similar to the denoising case [22]).\\nIn the training phase, the ground truth images {Xi}\\nare prepared as fsub×fsub×c-pixel sub-images randomly\\ncropped from the training images. By “sub-images” we\\nmean these samples are treated as small “images” rather\\nthan “patches”, in the sense that “patches” are overlap-\\nping and require some averaging as post-processing but\\n“sub-images” need not. To synthesize the low-resolution\\nsamples {Yi}, we blur a sub-image by a Gaussian kernel,\\nsub-sample it by the upscaling factor, and upscale it by\\nthe same factor via bicubic interpolation.\\nTo avoid border effects during training, all the con-\\nvolutional layers have no padding, and the network\\nproduces a smaller output ( (fsub −f1 −f2 −f3 + 3)2 ×c).\\nThe MSE loss function is evaluated only by the difference\\nbetween the central pixels of Xi and the network output.\\nAlthough we use a ﬁxed image size in training, the\\nconvolutional neural network can be applied on images\\nof arbitrary sizes during testing.\\nWe implement our model using the cuda-convnet pack-\\nage [26]. We have also tried the Caffe package [24] and\\nobserved similar performance.\\n4 E XPERIMENTS\\nWe ﬁrst investigate the impact of using different datasets\\non the model performance. Next, we examine the ﬁlters\\nlearned by our approach. We then explore different\\narchitecture designs of the network, and study the rela-\\ntions between super-resolution performance and factors\\nlike depth, number of ﬁlters, and ﬁlter sizes. Subse-\\nquently, we compare our method with recent state-of-\\nthe-arts both quantitatively and qualitatively. Following\\n[42], super-resolution is only applied on the luminance\\nchannel (Y channel in YCbCr color space) in Sections 4.1-\\n4.4, so c = 1 in the ﬁrst/last layer, and performance\\n(e.g., PSNR and SSIM) is evaluated on the Y channel. At\\nlast, we extend the network to cope with color images\\nand evaluate the performance on different channels.\\n4.1 Training Data\\nAs shown in the literature, deep learning generally\\nbeneﬁts from big data training. For comparison, we use\\na relatively small training set [41], [50] that consists\\nof 91 images, and a large training set that consists of\\n395,909 images from the ILSVRC 2013 ImageNet detec-\\ntion training partition. The size of training sub-images is\\nfsub = 33. Thus the 91-image dataset can be decomposed\\ninto 24,800 sub-images, which are extracted from origi-\\nnal images with a stride of 14. Whereas the ImageNet\\nprovides over 5 million sub-images even using a stride\\nof 33. We use the basic network settings, i.e., f1 = 9 ,\\nf2 = 1, f3 = 5, n1 = 64, and n2 = 32. We use the Set5 [2]\\nas the validation set. We observe a similar trend even\\nif we use the larger Set14 set [51]. The upscaling factor\\nis 3. We use the sparse-coding-based method [50] as our\\nbaseline, which achieves an average PSNR value of 31.42\\ndB.\\nThe test convergence curves of using different training\\nsets are shown in Figure 4. The training time on Ima-\\ngeNet is about the same as on the 91-image dataset since\\nthe number of backpropagations is the same. As can be\\nobserved, with the same number of backpropagations\\n(i.e.,8 ×108), the SRCNN +ImageNet achieves 32.52 dB,\\nhigher than 32.39 dB yielded by that trained on 91\\nimages. The results positively indicate that SRCNN per-\\nformance may be further boosted using a larger training\\nset, but the effect of big data is not as impressive as\\nthat shown in high-level vision problems [26]. This is\\nmainly because that the 91 images have already cap-\\ntured sufﬁcient variability of natural images. On the', 'the ﬁnal full image. The averaging can be considered\\nas a pre-deﬁned ﬁlter on a set of feature maps (where\\neach position is the “ﬂattened” vector form of a high-\\nresolution patch). Motivated by this, we deﬁne a convo-\\nlutional layer to produce the ﬁnal high-resolution image:\\nF(Y) = W3 ∗F2(Y) + B3. (3)\\n4. The ReLU can be equivalently considered as a part of the second\\noperation (Non-linear mapping), and the ﬁrst operation (Patch extrac-\\ntion and representation) becomes purely linear convolution.\\nHere W3 corresponds to c ﬁlters of a size n2 ×f3 ×f3,\\nand B3 is a c-dimensional vector.\\nIf the representations of the high-resolution patches\\nare in the image domain (i.e.,we can simply reshape each\\nrepresentation to form the patch), we expect that the\\nﬁlters act like an averaging ﬁlter; if the representations\\nof the high-resolution patches are in some other domains\\n(e.g.,coefﬁcients in terms of some bases), we expect that\\nW3 behaves like ﬁrst projecting the coefﬁcients onto the\\nimage domain and then averaging. In either way, W3 is\\na set of linear ﬁlters.\\nInterestingly, although the above three operations are\\nmotivated by different intuitions, they all lead to the\\nsame form as a convolutional layer. We put all three\\noperations together and form a convolutional neural\\nnetwork (Figure 2). In this model, all the ﬁltering weights\\nand biases are to be optimized. Despite the succinctness\\nof the overall structure, our SRCNN model is carefully\\ndeveloped by drawing extensive experience resulted\\nfrom signiﬁcant progresses in super-resolution [49], [50].\\nWe detail the relationship in the next section.\\n3.2 Relationship to Sparse-Coding-Based Methods\\nWe show that the sparse-coding-based SR methods [49],\\n[50] can be viewed as a convolutional neural network.\\nFigure 3 shows an illustration.\\nIn the sparse-coding-based methods, let us consider\\nthat an f1 ×f1 low-resolution patch is extracted from\\nthe input image. Then the sparse coding solver, like\\nFeature-Sign [29], will ﬁrst project the patch onto a (low-\\nresolution) dictionary. If the dictionary size is n1, this\\nis equivalent to applying n1 linear ﬁlters ( f1 ×f1) on\\nthe input image (the mean subtraction is also a linear\\noperation so can be absorbed). This is illustrated as the\\nleft part of Figure 3.\\nThe sparse coding solver will then iteratively process\\nthe n1 coefﬁcients. The outputs of this solver are n2\\ncoefﬁcients, and usually n2 = n1 in the case of sparse\\ncoding. These n2 coefﬁcients are the representation of\\nthe high-resolution patch. In this sense, the sparse coding\\n5\\nresponses\\nof patch of\\nneighbouring\\npatches\\n Patch extraction\\nand representation\\nNon-linear\\n mapping\\nReconstruction\\nFig. 3. An illustration of sparse-coding-based methods in the view of a convolutional neural network.\\nsolver behaves as a special case of a non-linear mapping\\noperator, whose spatial support is 1 ×1. See the middle\\npart of Figure 3. However, the sparse coding solver is\\nnot feed-forward, i.e.,it is an iterative algorithm. On the\\ncontrary, our non-linear operator is fully feed-forward\\nand can be computed efﬁciently. If we set f2 = 1, then\\nour non-linear operator can be considered as a pixel-wise\\nfully-connected layer. It is worth noting that “the sparse\\ncoding solver” in SRCNN refers to the ﬁrst two layers,\\nbut not just the second layer or the activation function\\n(ReLU). Thus the nonlinear operation in SRCNN is also\\nwell optimized through the learning process.\\nThe above n2 coefﬁcients (after sparse coding) are\\nthen projected onto another (high-resolution) dictionary\\nto produce a high-resolution patch. The overlapping\\nhigh-resolution patches are then averaged. As discussed\\nabove, this is equivalent to linear convolutions on the\\nn2 feature maps. If the high-resolution patches used for\\nreconstruction are of size f3 ×f3, then the linear ﬁlters\\nhave an equivalent spatial support of size f3 ×f3. See\\nthe right part of Figure 3.\\nThe above discussion shows that the sparse-coding-', 'then projected onto another (high-resolution) dictionary\\nto produce a high-resolution patch. The overlapping\\nhigh-resolution patches are then averaged. As discussed\\nabove, this is equivalent to linear convolutions on the\\nn2 feature maps. If the high-resolution patches used for\\nreconstruction are of size f3 ×f3, then the linear ﬁlters\\nhave an equivalent spatial support of size f3 ×f3. See\\nthe right part of Figure 3.\\nThe above discussion shows that the sparse-coding-\\nbased SR method can be viewed as a kind of con-\\nvolutional neural network (with a different non-linear\\nmapping). But not all operations have been considered in\\nthe optimization in the sparse-coding-based SR methods.\\nOn the contrary, in our convolutional neural network,\\nthe low-resolution dictionary, high-resolution dictionary,\\nnon-linear mapping, together with mean subtraction and\\naveraging, are all involved in the ﬁlters to be optimized.\\nSo our method optimizes an end-to-end mapping that\\nconsists of all operations.\\nThe above analogy can also help us to design hyper-\\nparameters. For example, we can set the ﬁlter size of\\nthe last layer to be smaller than that of the ﬁrst layer,\\nand thus we rely more on the central part of the high-\\nresolution patch (to the extreme, if f3 = 1 , we are\\nusing the center pixel with no averaging). We can also\\nset n2 < n1 because it is expected to be sparser. A\\ntypical and basic setting is f1 = 9 , f2 = 1 , f3 = 5 ,\\nn1 = 64 , and n2 = 32 (we evaluate more settings in\\nthe experiment section). On the whole, the estimation\\nof a high resolution pixel utilizes the information of\\n(9 + 5 −1)2 = 169 pixels. Clearly, the information\\nexploited for reconstruction is comparatively larger than\\nthat used in existing external example-based approaches,\\ne.g., using (5+5 −1)2 = 81 pixels5 [15], [50]. This is one of\\nthe reasons why the SRCNN gives superior performance.\\n3.3 Training\\nLearning the end-to-end mapping function F re-\\nquires the estimation of network parameters Θ =\\n{W1,W2,W3,B1,B2,B3}. This is achieved through min-\\nimizing the loss between the reconstructed images\\nF(Y; Θ) and the corresponding ground truth high-\\nresolution images X. Given a set of high-resolution\\nimages {Xi} and their corresponding low-resolution\\nimages {Yi}, we use Mean Squared Error (MSE) as the\\nloss function:\\nL(Θ) = 1\\nn\\nn∑\\ni=1\\n||F(Yi; Θ)−Xi||2, (4)\\nwhere n is the number of training samples. Using MSE\\nas the loss function favors a high PSNR. The PSNR\\nis a widely-used metric for quantitatively evaluating\\nimage restoration quality, and is at least partially related\\nto the perceptual quality. It is worth noticing that the\\nconvolutional neural networks do not preclude the usage\\nof other kinds of loss functions, if only the loss functions\\nare derivable. If a better perceptually motivated metric\\nis given during training, it is ﬂexible for the network to\\nadapt to that metric. On the contrary, such a ﬂexibility\\nis in general difﬁcult to achieve for traditional “hand-\\ncrafted” methods. Despite that the proposed model is\\ntrained favoring a high PSNR, we still observe satisfac-\\ntory performance when the model is evaluated using\\nalternative evaluation metrics, e.g., SSIM, MSSIM (see\\nSection 4.4.1).\\nThe loss is minimized using stochastic gradient de-\\nscent with the standard backpropagation [28]. In partic-\\nular, the weight matrices are updated as\\n∆i+1 = 0.9 ·∆i −η· ∂L\\n∂Wℓ\\ni\\n, W ℓ\\ni+1 = Wℓ\\ni + ∆i+1, (5)\\n5. The patches are overlapped with 4 pixels at each direction.\\n6\\nwhere ℓ∈{1,2,3}and i are the indices of layers and it-\\nerations, ηis the learning rate, and ∂L\\n∂W ℓ\\ni\\nis the derivative.\\nThe ﬁlter weights of each layer are initialized by drawing\\nrandomly from a Gaussian distribution with zero mean\\nand standard deviation 0.001 (and 0 for biases). The\\nlearning rate is 10−4 for the ﬁrst two layers, and 10−5 for\\nthe last layer. We empirically ﬁnd that a smaller learning\\nrate in the last layer is important for the network to\\nconverge (similar to the denoising case [22]).', '4.3.2 Filter size\\nIn this section, we examine the network sensitivity to\\ndifferent ﬁlter sizes. In previous experiments, we set\\nﬁlter size f1 = 9, f2 = 1 and f3 = 5, and the network\\ncould be denoted as 9-1-5. First, to be consistent with\\nsparse-coding-based methods, we ﬁx the ﬁlter size of the\\nsecond layer to be f2 = 1, and enlarge the ﬁlter size of\\nother layers to f1 = 11 and f3 = 7 (11-1-7). All the other\\n6. We use ‘width’ to term the number of ﬁlters in a layer, follow-\\ning [17]. The term ‘width’ may have other meanings in the literature.\\n1 2 3 4 5 6 7 8 9 10\\nxS10\\n8\\n31.5\\n32\\n32.5\\nNumberSofSbackprops\\nAverageStestSPSNRS(dB)\\nSRCNNS(9−5−5)\\nSRCNNS(9−3−5)\\nSRCNNS(9−1−5)\\nSCS(31.42SdB)\\nFig. 7. A larger ﬁlter size leads to better results.\\nsettings remain the same with Section 4.1. The results\\nwith an upscaling factor 3 on Set5 are 32.57 dB, which is\\nslightly higher than the 32.52 dB reported in Section 4.1.\\nThis indicates that a reasonably larger ﬁlter size could\\ngrasp richer structural information, which in turn lead\\nto better results.\\nThen we further examine networks with a larger ﬁlter\\nsize of the second layer. Speciﬁcally, we ﬁx the ﬁlter size\\nf1 = 9, f3 = 5, and enlarge the ﬁlter size of the second\\nlayer to be (i) f2 = 3 (9-3-5) and (ii) f2 = 5 (9-5-5).\\nConvergence curves in Figure 7 show that using a larger\\nﬁlter size could signiﬁcantly improve the performance.\\nSpeciﬁcally, the average PSNR values achieved by 9-3-\\n5 and 9-5-5 on Set5 with 8 ×108 backpropagations are\\n32.66 dB and 32.75 dB, respectively. The results suggest\\nthat utilizing neighborhood information in the mapping\\nstage is beneﬁcial.\\nHowever, the deployment speed will also decrease\\nwith a larger ﬁlter size. For example, the number of\\nparameters of 9-1-5, 9-3-5, and 9-5-5 is 8,032, 24,416, and\\n57,184 respectively. The complexity of 9-5-5 is almost\\ntwice of 9-3-5, but the performance improvement is\\nmarginal. Therefore, the choice of the network scale\\nshould always be a trade-off between performance and\\nspeed.\\n4.3.3 Number of layers\\nRecent study by He and Sun [17] suggests that CNN\\ncould beneﬁt from increasing the depth of network\\nmoderately. Here, we try deeper structures by adding\\nanother non-linear mapping layer, which has n22 = 16\\nﬁlters with size f22 = 1 . We conduct three controlled\\nexperiments, i.e., 9-1-1-5, 9-3-1-5, 9-5-1-5, which add an\\nadditional layer on 9-1-5, 9-3-5, and 9-5-5, respectively.\\nThe initialization scheme and learning rate of the ad-\\nditional layer are the same as the second layer. From\\nFigures 13(a), 13(b) and 8(c), we can observe that the\\nfour-layer networks converge slower than the three-layer\\nnetwork. Nevertheless, given enough training time, the\\ndeeper networks will ﬁnally catch up and converge to\\nthe three-layer ones.\\nThe effectiveness of deeper structures for super reso-\\nlution is found not as apparent as that shown in image\\nclassiﬁcation [17]. Furthermore, we ﬁnd that deeper\\nnetworks do not always result in better performance.\\nSpeciﬁcally, if we add an additional layer with n22 = 32\\nﬁlters on 9-1-5 network, then the performance degrades\\nand fails to surpass the three-layer network (see Fig-\\nure 9(a)). If we go deeper by adding two non-linear\\n8\\n2 4 6 8 10 12\\nx(10\\n8\\n31\\n31.5\\n32\\n32.5\\nNumber(of(backprops\\nAverage(test(PSNR((dB)\\nSRCNN((9−1−5)\\nSRCNN((9−1−1−5)\\nSC((31.42(dB)\\n(a) 9-1-5 vs. 9-1-1-5\\n1 2 3 4 5 6 7 8 9 10\\nxS10\\n8\\n31.5\\n32\\n32.5\\nNumberSofSbackprops\\nAverageStestSPSNRS(dB)\\nSRCNNS(9−3−5)\\nSRCNNS(9−3−1−5)\\nSCS(31.42SdB)\\n(b) 9-3-5 vs. 9-3-1-5\\n1 2 3 4 5 6 7 8\\nxR10\\n8\\n31.5\\n32\\n32.5\\nNumberRofRbackprops\\nAverageRtestRPSNRR(dB)\\nSRCNNR(9−5−5)\\nSRCNNR(9−5−1−5)\\nSCR(31.42RdB)\\n(c) 9-5-5 vs. 9-5-1-5\\nFig. 8. Comparisons between three-layer and four-layer\\nnetworks.\\nmapping layers with n22 = 32 and n23 = 16 ﬁlters on\\n9-1-5, then we have to set a smaller learning rate to\\nensure convergence, but we still do not observe superior\\nperformance after a week of training (see Figure 9(a)).\\nWe also tried to enlarge the ﬁlter size of the additional', 'In this paper, we show that the aforementioned\\npipeline is equivalent to a deep convolutional neural net-\\nwork [27] (more details in Section 3.2). Motivated by this\\nfact, we consider a convolutional neural network that\\ndirectly learns an end-to-end mapping between low- and\\nhigh-resolution images. Our method differs fundamen-\\ntally from existing external example-based approaches,\\nin that ours does not explicitly learn the dictionaries [41],\\n[49], [50] or manifolds [2], [4] for modeling the patch\\nspace. These are implicitly achieved via hidden layers.\\nFurthermore, the patch extraction and aggregation are\\nalso formulated as convolutional layers, so are involved\\nin the optimization. In our method, the entire SR pipeline\\nis fully obtained through learning, with little pre/post-\\nprocessing.\\nWe name the proposed model Super-Resolution Con-\\nvolutional Neural Network (SRCNN) 1. The proposed\\nSRCNN has several appealing properties. First, its struc-\\nture is intentionally designed with simplicity in mind,\\nand yet provides superior accuracy 2 compared with\\nstate-of-the-art example-based methods. Figure 1 shows\\na comparison on an example. Second, with moderate\\n1. The implementation is available at http://mmlab.ie.cuhk.edu.hk/\\nprojects/SRCNN.html.\\n2. Numerical evaluations by using different metrics such as the Peak\\nSignal-to-Noise Ratio (PSNR), structure similarity index (SSIM) [43],\\nmulti-scale SSIM [44], information ﬁdelity criterion [38], when the\\nground truth images are available.\\narXiv:1501.00092v3  [cs.CV]  31 Jul 2015\\n2\\nBicubic / 24.04 dB\\nSC / 25.58 dBSRCNN / 27.95 dB\\nOriginal / PSNR\\n2 4 6 8 10 12x 108\\n29.5\\n30\\n30.5\\n31\\n31.5\\n32\\n32.5\\n33\\nNumber of backprops\\nAverage test PSNR (dB)\\nSRCNN\\nSC\\nBicubic\\nBicubic / 24.04 dB\\nSC / 25.58 dBSRCNN / 27.95 dB\\nOriginal / PSNR\\nBicubic / 24.04 dB\\nSC / 25.58 dBSRCNN / 27.95 dB\\nOriginal / PSNR\\nSRCNN\\nSC\\nBicubic\\nBicubic / 24.04 dB\\nSC / 25.58 dBSRCNN / 27.95 dB\\nOriginal / PSNR\\nNumber of backprops\\nAverage test PSNR (dB)\\nFig. 1. The proposed Super-Resolution Convolutional\\nNeural Network (SRCNN) surpasses the bicubic baseline\\nwith just a few training iterations, and outperforms the\\nsparse-coding-based method (SC) [50] with moderate\\ntraining. The performance may be further improved with\\nmore training iterations. More details are provided in\\nSection 4.4.1 (the Set5 dataset with an upscaling factor\\n3). The proposed method provides visually appealing\\nreconstructed image.\\nnumbers of ﬁlters and layers, our method achieves\\nfast speed for practical on-line usage even on a CPU.\\nOur method is faster than a number of example-based\\nmethods, because it is fully feed-forward and does\\nnot need to solve any optimization problem on usage.\\nThird, experiments show that the restoration quality of\\nthe network can be further improved when (i) larger\\nand more diverse datasets are available, and/or (ii)\\na larger and deeper model is used. On the contrary,\\nlarger datasets/models can present challenges for exist-\\ning example-based methods. Furthermore, the proposed\\nnetwork can cope with three channels of color images\\nsimultaneously to achieve improved super-resolution\\nperformance.\\nOverall, the contributions of this study are mainly in\\nthree aspects:\\n1) We present a fully convolutional neural net-\\nwork for image super-resolution. The network di-\\nrectly learns an end-to-end mapping between low-\\nand high-resolution images, with little pre/post-\\nprocessing beyond the optimization.\\n2) We establish a relationship between our deep-\\nlearning-based SR method and the traditional\\nsparse-coding-based SR methods. This relationship\\nprovides a guidance for the design of the network\\nstructure.\\n3) We demonstrate that deep learning is useful in\\nthe classical computer vision problem of super-\\nresolution, and can achieve good quality and\\nspeed.\\nA preliminary version of this work was presented\\nearlier [11]. The present work adds to the initial version\\nin signiﬁcant ways. Firstly, we improve the SRCNN by\\nintroducing larger ﬁlter size in the non-linear mapping', '1 2 3 4 5 6 7 8\\nxR10\\n8\\n31.5\\n32\\n32.5\\nNumberRofRbackprops\\nAverageRtestRPSNRR(dB)\\nSRCNNR(9−5−5)\\nSRCNNR(9−5−1−5)\\nSCR(31.42RdB)\\n(c) 9-5-5 vs. 9-5-1-5\\nFig. 8. Comparisons between three-layer and four-layer\\nnetworks.\\nmapping layers with n22 = 32 and n23 = 16 ﬁlters on\\n9-1-5, then we have to set a smaller learning rate to\\nensure convergence, but we still do not observe superior\\nperformance after a week of training (see Figure 9(a)).\\nWe also tried to enlarge the ﬁlter size of the additional\\nlayer to f22 = 3, and explore two deep structures – 9-3-\\n3-5 and 9-3-3-3. However, from the convergence curves\\nshown in Figure 9(b), these two networks do not show\\nbetter results than the 9-3-1-5 network.\\nAll these experiments indicate that it is not “the deeper\\nthe better” in this deep model for super-resolution. It\\nmay be caused by the difﬁculty of training. Our CNN\\nnetwork contains no pooling layer or full-connected\\nlayer, thus it is sensitive to the initialization parameters\\nand learning rate. When we go deeper (e.g., 4 or 5 layers),\\nwe ﬁnd it hard to set appropriate learning rates that\\nguarantee convergence. Even it converges, the network\\nmay fall into a bad local minimum, and the learned\\nﬁlters are of less diversity even given enough training\\ntime. This phenomenon is also observed in [16], where\\nimproper increase of depth leads to accuracy saturation\\nor degradation for image classiﬁcation. Why “deeper is\\nnot better” is still an open question, which requires in-\\nvestigations to better understand gradients and training\\ndynamics in deep architectures. Therefore, we still adopt\\nthree-layer networks in the following experiments.\\n4.4 Comparisons to State-of-the-Arts\\nIn this section, we show the quantitative and qualitative\\nresults of our method in comparison to state-of-the-art\\n2 4 6 8 10 12\\nx(10\\n8\\n31\\n31.5\\n32\\n32.5\\nNumber(of(backprops\\nAverage(test(PSNR(=dB)\\nSRCNN(=9−1−5)\\nSRCNN(=9−1−1−5,(n 22=16)\\nSRCNN(=9−1−1−5,(n 22=32)\\nSRCNN(=9−1−1−1−5,(n 22=32,(n 23=16)\\nSC(=31.42(dB)\\n(a) 9-1-1-5 ( n22 = 32) and 9-1-1-1-5 ( n22 = 32, n23 = 16)\\n1 2 3 4 5 6 7 8 9\\nxS10\\n8\\n31.5\\n32\\n32.5\\nNumberSofSbackprops\\nAverageStestSPSNRS(dB)\\nSRCNNS(9−3−5)\\nSRCNNS(9−3−1−5)\\nSRCNNS(9−3−3−5)\\nSRCNNS(9−3−3−3)\\nSCS(31.42SdB)\\n(b) 9-3-3-5 and 9-3-3-3\\nFig. 9. Deeper structure does not always lead to better\\nresults.\\nmethods. We adopt the model with good performance-\\nspeed trade-off: a three-layer network with f1 = 9, f2 =\\n5, f3 = 5, n1 = 64, and n2 = 32 trained on the ImageNet.\\nFor each upscaling factor ∈{2,3,4}, we train a speciﬁc\\nnetwork for that factor 7.\\nComparisons. We compare our SRCNN with the state-\\nof-the-art SR methods:\\n• SC - sparse coding-based method of Yang et al. [50]\\n• NE+LLE - neighbour embedding + locally linear\\nembedding method [4]\\n• ANR - Anchored Neighbourhood Regression\\nmethod [41]\\n• A+ - Adjusted Anchored Neighbourhood Regres-\\nsion method [42], and\\n• KK - the method described in [25], which achieves\\nthe best performance among external example-\\nbased methods, according to the comprehensive\\nevaluation conducted in Yang et al.’s work [46]\\nThe implementations are all from the publicly available\\ncodes provided by the authors, and all images are down-\\nsampled using the same bicubic kernel.\\nTest set.The Set5 [2] (5 images), Set14 [51] (14 images)\\nand BSD200 [32] (200 images) 8 are used to evaluate the\\nperformance of upscaling factors 2, 3, and 4.\\nEvaluation metrics. Apart from the widely used PSNR\\nand SSIM [43] indices, we also adopt another four\\nevaluation matrices, namely information ﬁdelity cri-\\nterion (IFC) [38], noise quality measure (NQM) [8],\\nweighted peak signal-to-noise ratio (WPSNR) and multi-\\nscale structure similarity index (MSSSIM) [44], which\\nobtain high correlation with the human perceptual scores\\nas reported in [46].\\n4.4.1 Quantitative and qualitative evaluation\\nAs shown in Tables 2, 3 and 4, the proposed SRCNN\\nyields the highest scores in most evaluation matrices\\n7. In the area of denoising [3], for each noise level a speciﬁc network\\nis trained.', 'bicubic interpolation. The training falls into a bad local\\nminimum, due to the inherently different characteristics\\nof the Y and Cb, Cr channels. (ii) If we pre-train on the\\nY or Cb, Cr channels, the performance ﬁnally improves,\\nbut is still not better than “Y only” on the color image\\n(see the last column of Table 5, where PSNR is computed\\n(a) First-layer ﬁlters – Cb channel\\n(b) First-layer ﬁlters – Cr channel\\nFig. 13. Chrominance channels of the ﬁrst-layer ﬁlters\\nusing the “Y pre-train” strategy.\\nin RGB color space). This suggests that the Cb, Cr\\nchannels could decrease the performance of the Y chan-\\nnel when training is performed in a uniﬁed network.\\n(iii) We observe that the Cb, Cr channels have higher\\nPSNR values for “Y pre-train” than for “CbCr pre-train”.\\nThe reason lies on the differences between the Cb, Cr\\nchannels and the Y channel. Visually, the Cb, Cr channels\\nare more blurry than the Y channel, thus are less affected\\nby the downsampling process. When we pre-train on\\nthe Cb, Cr channels, there are only a few ﬁlters being\\nactivated. Then the training will soon fall into a bad\\nlocal minimum during ﬁne-tuning. On the other hand,\\nif we pre-train on the Y channel, more ﬁlters will be\\nactivated, and the performance on Cb, Cr channels will\\nbe pushed much higher. Figure 13 shows the Cb, Cr\\nchannels of the ﬁrst-layer ﬁlters with “Y pre-train”, of\\nwhich the patterns largely differ from that shown in\\nFigure 5. (iv) Training on the RGB channels achieves\\nthe best result on the color image. Different from the\\nYCbCr channels, the RGB channels exhibit high cross-\\ncorrelation among each other. The proposed SRCNN\\nis capable of leveraging such natural correspondences\\nbetween the channels for reconstruction. Therefore, the\\nmodel achieves comparable result on the Y channel as\\n“Y only”, and better results on Cb, Cr channels than\\nbicubic interpolation. (v) In KK [25], super-resolution\\nis applied on each RGB channel separately. When we\\ntransform its results to YCbCr space, the PSNR value\\nof Y channel is similar as “Y only”, but that of Cb, Cr\\nchannels are poorer than bicubic interpolation. The result\\nsuggests that the algorithm is biased to the Y channel.\\nOn the whole, our method trained on RGB channels\\nachieves better performance than KK and the single-\\nchannel network (“Y only”). It is also worth noting that\\nthe improvement compared with the single-channel net-\\nwork is not that signiﬁcant ( i.e., 0.07 dB). This indicates\\nthat the Cb, Cr channels barely help in improving the\\nperformance.\\n5 C ONCLUSION\\nWe have presented a novel deep learning approach\\nfor single image super-resolution (SR). We show that\\nconventional sparse-coding-based SR methods can be\\n12\\nreformulated into a deep convolutional neural network.\\nThe proposed approach, SRCNN, learns an end-to-end\\nmapping between low- and high-resolution images, with\\nlittle extra pre/post-processing beyond the optimization.\\nWith a lightweight structure, the SRCNN has achieved\\nsuperior performance than the state-of-the-art methods.\\nWe conjecture that additional performance can be further\\ngained by exploring more ﬁlters and different training\\nstrategies. Besides, the proposed structure, with its ad-\\nvantages of simplicity and robustness, could be applied\\nto other low-level vision problems, such as image de-\\nblurring or simultaneous SR+denoising. One could also\\ninvestigate a network to cope with different upscaling\\nfactors.\\nREFERENCES\\n[1] Aharon, M., Elad, M., Bruckstein, A.: K-SVD: An algorithm for\\ndesigning overcomplete dictionaries for sparse representation.\\nIEEE Transactions on Signal Processing 54(11), 4311–4322 (2006)\\n[2] Bevilacqua, M., Roumy, A., Guillemot, C., Morel, M.L.A.: Low-\\ncomplexity single-image super-resolution based on nonnegative\\nneighbor embedding. In: British Machine Vision Conference\\n(2012)\\n[3] Burger, H.C., Schuler, C.J., Harmeling, S.: Image denoising: Can\\nplain neural networks compete with BM3D? In: IEEE Conference']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Contextual Precision (ragas) (score: 0.9093537414836079, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Faithfulness (ragas) (score: 1.0, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Contextual Recall (ragas) (score: 1.0, threshold: 0.6, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Answer Relevancy (ragas) (score: 0.9435344196086399, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: What exactly is meant by “perceptual loss” in SRGAN, and how is it computed from VGG feature maps?\n",
      "  - actual output: Perceptual loss\" in SRGAN (Super-Resolution Generative Adversarial Network) means that instead of simply comparing the generated super-resolved image and the original high-resolution image pixel by pixel, the network aims to make the super-resolved image perceptually similar – that is, look more like the original – to a human observer. This is different from traditional metrics like Mean Squared Error (MSE) which only measure pixel differences.\n",
      "\n",
      "Here's how the perceptual loss is calculated using VGG (Visual Geometry Group network, a pre-trained Convolutional Neural Network used for image recognition) feature maps:\n",
      "\n",
      "Both the super-resolved image (generated by the SRGAN) and the original high-resolution image are passed through a pre-trained VGG19 network.\n",
      "\n",
      "The VGG19 network extracts feature maps from both images. Feature maps are representations of different visual features of the images at different levels of abstraction within the network.\n",
      "\n",
      "The perceptual loss is calculated by comparing these feature maps from specific layers within the VGG19 network, typically the ReLU (Rectified Linear Unit, a type of activation function in neural networks) activation layers. The loss is based on the Euclidean distance (a measure of the straight-line distance between two points in a multi-dimensional space representing the feature maps) between the feature representations of the two images. A smaller distance implies greater perceptual similarity.\n",
      "\n",
      "Specifically, SRGAN combines this VGG-based content loss with an adversarial loss from the discriminator network within the GAN framework. The discriminator is trained to distinguish between real high-resolution images and the super-resolved images. This adversarial loss helps to make the generated images look more realistic. The content loss ensures that the generated image captures the perceptual content of the original image. The combination of these two losses is the overall perceptual loss.\n",
      "  - expected output: It is a weighted sum of a content loss (Euclidean distance between VGG‑feature maps of SR vs. HR images) and an adversarial loss (−log D(G(I))). The VGG layers (e.g., φ5,4) provide semantics; the adversarial term pushes outputs onto the natural‑image manifold.\n",
      "  - context: ['We formulate the perceptual loss as the weighted sum of a content loss and an adversarial loss component … Content loss l_{VGG/i.j} = 1/(W_{i,j}H_{i,j}) Σ(φ_{i,j}(I_{HR}) − φ_{i,j}(G(I_{LR})))² … l_{Gen} = −log D(G(I_{LR}))']\n",
      "  - retrieval context: ['lSR is commonly modeled based on the MSE [10, 48], we\\nimprove on Johnson et al. [33] and Bruna et al. [5] and\\ndesign a loss function that assesses a solution with respect\\nto perceptually relevant characteristics. We formulate the\\nperceptual loss as the weighted sum of a content loss ( lSR\\nX )\\nand an adversarial loss component as:\\nlSR = lSR\\nX\\ued19\\ued18\\ued17\\ued1a\\ncontent loss\\n+ 10−3lSR\\nGen\\ued19 \\ued18\\ued17 \\ued1a\\nadversarial loss\\ued19 \\ued18\\ued17 \\ued1a\\nperceptual loss (for VGG based content losses)\\n(3)\\nIn the following we describe possible choices for the con-\\ntent loss lSR\\nX and the adversarial loss lSR\\nGen.\\n2.2.1 Content loss\\nThe pixel-wise MSE loss is calculated as:\\nlSR\\nMSE = 1\\nr2WH\\nrW∑\\nx=1\\nrH∑\\ny=1\\n(IHR\\nx,y −GθG(ILR)x,y)2 (4)\\nThis is the most widely used optimization target for image\\nSR on which many state-of-the-art approaches rely [10,\\n48]. However, while achieving particularly high PSNR,\\nsolutions of MSE optimization problems often lack high-\\nfrequency content which results in perceptually unsatisfy-\\ning solutions with overly smooth textures (c.f . Figure 2).\\nInstead of relying on pixel-wise losses we build on the\\nideas of Gatys et al. [19], Bruna et al. [5] and Johnson et\\nal. [33] and use a loss function that is closer to perceptual\\nsimilarity. We deﬁne the VGG loss based on the ReLU\\nactivation layers of the pre-trained 19 layer VGG network\\ndescribed in Simonyan and Zisserman [49]. With φi,j we\\nindicate the feature map obtained by the j-th convolution\\n(after activation) before the i-th maxpooling layer within the\\nVGG19 network, which we consider given. We then deﬁne\\nthe VGG loss as the euclidean distance between the feature\\nrepresentations of a reconstructed image GθG(ILR) and the\\nreference image IHR:\\nlSR\\nVGG/i.j = 1\\nWi,jHi,j\\nWi,j∑\\nx=1\\nHi,j∑\\ny=1\\n(φi,j(IHR)x,y\\n−φi,j(GθG(ILR))x,y)2\\n(5)\\nHere Wi,j and Hi,j describe the dimensions of the\\nrespective feature maps within the VGG network.\\n2.2.2 Adversarial loss\\nIn addition to the content losses described so far, we also\\nadd the generative component of our GAN to the perceptual\\nloss. This encourages our network to favor solutions that\\nreside on the manifold of natural images, by trying to\\nfool the discriminator network. The generative loss lSR\\nGen\\nis deﬁned based on the probabilities of the discriminator\\nDθD (GθG(ILR)) over all training samples as:\\nlSR\\nGen =\\nN∑\\nn=1\\n−log DθD (GθG(ILR)) (6)\\nHere, DθD (GθG(ILR)) is the probability that the recon-\\nstructed image GθG(ILR) is a natural HR image. For better\\ngradient behavior we minimize −log DθD (GθG(ILR)) in-\\nstead of log[1 −DθD (GθG(ILR))] [22].\\n3. Experiments\\n3.1. Data and similarity measures\\nWe perform experiments on three widely used bench-\\nmark datasets Set5 [3], Set14 [69] and BSD100, the testing\\nset of BSD300 [41]. All experiments are performed with\\na scale factor of 4× between low- and high-resolution\\nimages. This corresponds to a 16×reduction in image\\npixels. For fair comparison, all reported PSNR [dB] and\\nSSIM [58] measures were calculated on the y-channel of\\ncenter-cropped, removal of a 4-pixel wide strip from each\\nborder, images using the daala package 1. Super-resolved\\nimages for the reference methods, including nearest neigh-\\nbor, bicubic, SRCNN [9] and SelfExSR [31], were obtained\\nfrom online material supplementary to Huang et al. 2 [31]\\nand for DRCN from Kim et al. 3 [34]. Results obtained\\nwith SRResNet (for losses: lSR\\nMSE and lSR\\nVGG/2.2) and the\\nSRGAN variants are available online4. Statistical tests were\\nperformed as paired two-sided Wilcoxon signed-rank tests\\nand signiﬁcance determined at p< 0.05.\\nThe reader may also be interested in an independently\\ndeveloped GAN-based solution on GitHub 5. However it\\nonly provides experimental results on a limited set of faces,\\nwhich is a more constrained and easier task.\\n3.2. Training details and parameters\\nWe trained all networks on a NVIDIA Tesla M40 GPU\\nusing a random sample of 350 thousand images from\\nthe ImageNet database [45]. These images are distinct\\nfrom the testing images. We obtained the LR images', '3.4. Investigation of content loss\\nWe investigated the effect of different content loss\\nchoices in the perceptual loss for the GAN-based networks.\\nSpeciﬁcally we investigate lSR = lSR\\nX + 10−3lSR\\nGen for the\\nfollowing content losses lSR\\nX :\\nTable 1: Performance of different loss functions for SR-\\nResNet and the adversarial networks on Set5 and Set14\\nbenchmark data. MOS score signiﬁcantly higher (p< 0.05)\\nthan with other losses in that category∗. [4×upscaling]\\nSRResNet- SRGAN-\\nSet5 MSE VGG22 MSE VGG22 VGG54\\nPSNR 32.05 30.51 30.64 29.84 29.40\\nSSIM 0.9019 0.8803 0.8701 0.8468 0.8472\\nMOS 3.37 3.46 3.77 3.78 3.58\\nSet14\\nPSNR 28.49 27.19 26.92 26.44 26.02\\nSSIM 0.8184 0.7807 0.7611 0.7518 0.7397\\nMOS 2.98 3.15 ∗ 3.43 3.57 3.72 ∗\\n•SRGAN-MSE: lSR\\nMSE, to investigate the adversarial\\nnetwork with the standard MSE as content loss.\\n•SRGAN-VGG22: lSR\\nVGG/2.2 with φ2,2, a loss deﬁned\\non feature maps representing lower-level features [68].\\n•SRGAN-VGG54: lSR\\nVGG/5.4 with φ5,4, a loss deﬁned\\non feature maps of higher level features from deeper\\nnetwork layers with more potential to focus on the\\ncontent of the images [68, 65, 40]. We refer to this\\nnetwork as SRGAN in the following.\\nWe also evaluate the performance of the generator network\\nwithout adversarial component for the two losses lSR\\nMSE\\n(SRResNet-MSE) and lSR\\nVGG/2.2 (SRResNet-VGG22). We\\nrefer to SRResNet-MSE asSRResNet. Note, when training\\nSRResNet-VGG22 we added an additional total variation\\nloss with weight 2 ×10−8 to lSR\\nVGG/2.2 [2, 33]. Quantitative\\nresults are summarized in Table 1 and visual examples\\nprovided in Figure 6. Even combined with the adversarial\\nloss, MSE provides solutions with the highest PSNR values\\nthat are, however, perceptually rather smooth and less\\nconvincing than results achieved with a loss component\\nmore sensitive to visual perception. This is caused by\\ncompetition between the MSE-based content loss and the\\nadversarial loss. We further attribute minor reconstruction\\nartifacts, which we observed in a minority of SRGAN-\\nMSE-based reconstructions, to those competing objectives.\\nWe could not determine a signiﬁcantly best loss function\\nfor SRResNet or SRGAN with respect to MOS score\\non Set5. However, SRGAN-VGG54 signiﬁcantly outper-\\nformed other SRGAN and SRResNet variants on Set14 in\\nterms of MOS. We observed a trend that using the higher\\nlevel VGG feature maps φ5,4 yields better texture detail\\nwhen compared to φ2,2 (c.f . Figure 6). Further examples of\\nperceptual improvements through SRGAN over SRResNet\\nare provided in the supplementary material.\\nFigure 5: Color-coded distribution of MOS scores on\\nBSD100. For each method 2600 samples (100 images ×\\n26 raters) were assessed. Mean shown as red marker, where\\nthe bins are centered around value i. [4×upscaling]\\n3.5. Performance of the ﬁnal networks\\nWe compare the performance of SRResNet and SR-\\nGAN to NN, bicubic interpolation, and four state-of-the-\\nart methods. Quantitative results are summarized in Table\\n2 and conﬁrm that SRResNet (in terms of PSNR/SSIM)\\nsets a new state of the art on three benchmark datasets.\\nPlease note that we used a publicly available framework\\nfor evaluation (c.f . Section 3.1), reported values might thus\\nslightly deviate from those reported in the original papers.\\nWe further obtained MOS ratings for SRGAN and all\\nreference methods on BSD100. Examples of images super-\\nresolved with SRResNet and SRGAN are depicted in the\\nsupplementary material. The results shown in Table 2\\nconﬁrm that SRGAN outperforms all reference methods by\\na large margin and sets a new state of the art for photo-\\nrealistic image SR. All differences in MOS ( c.f . Table\\n2) are highly signiﬁcant on BSD100, except SRCNN vs.\\nSelfExSR. The distribution of all collected MOS ratings is\\nsummarized in Figure 5.\\n4. Discussion and future work\\nWe conﬁrmed the superior perceptual performance of\\nSRGAN using MOS testing. We have further shown that\\nstandard quantitative measures such as PSNR and SSIM', 'obtained by applying a Gaussian ﬁlter toIHR followed by a\\ndownsampling operation with downsampling factor r. For\\nan image with C color channels, we describe ILR by a\\nreal-valued tensor of size W ×H ×C and IHR, ISR by\\nrW ×rH ×Crespectively.\\nOur ultimate goal is to train a generating function Gthat\\nestimates for a given LR input image its corresponding HR\\ncounterpart. To achieve this, we train a generator network as\\na feed-forward CNN GθG parametrized by θG. Here θG =\\n{W1:L; b1:L}denotes the weights and biases of a L-layer\\ndeep network and is obtained by optimizing a SR-speciﬁc\\nloss function lSR. For training images IHR\\nn , n= 1,...,N\\nwith corresponding ILR\\nn , n= 1,...,N , we solve:\\nˆθG = arg min\\nθG\\n1\\nN\\nN∑\\nn=1\\nlSR(GθG(ILR\\nn ),IHR\\nn ) (1)\\nIn this work we will speciﬁcally design a perceptual loss\\nlSR as a weighted combination of several loss components\\nthat model distinct desirable characteristics of the recovered\\nSR image. The individual loss functions are described in\\nmore detail in Section 2.2.\\n2.1. Adversarial network architecture\\nFollowing Goodfellow et al. [22] we further deﬁne\\na discriminator network DθD which we optimize in an\\nalternating manner along with GθG to solve the adversarial\\nmin-max problem:\\nmin\\nθG\\nmax\\nθD\\nEIHR∼ptrain(IHR)[log DθD (IHR)]+\\nEILR∼pG(ILR)[log(1 −DθD (GθG(ILR))]\\n(2)\\nThe general idea behind this formulation is that it allows\\none to train a generative model Gwith the goal of fooling a\\ndifferentiable discriminator Dthat is trained to distinguish\\nsuper-resolved images from real images. With this approach\\nour generator can learn to create solutions that are highly\\nsimilar to real images and thus difﬁcult to classify by D.\\nThis encourages perceptually superior solutions residing in\\nthe subspace, the manifold, of natural images. This is in\\ncontrast to SR solutions obtained by minimizing pixel-wise\\nerror measurements, such as the MSE.\\nAt the core of our very deep generator networkG, which\\nis illustrated in Figure 4 areBresidual blocks with identical\\nlayout. Inspired by Johnson et al. [33] we employ the block\\nlayout proposed by Gross and Wilber [24]. Speciﬁcally, we\\nuse two convolutional layers with small3×3 kernels and 64\\nfeature maps followed by batch-normalization layers [32]\\nand ParametricReLU [28] as the activation function. We\\nincrease the resolution of the input image with two trained\\nsub-pixel convolution layers as proposed by Shi et al. [48].\\nTo discriminate real HR images from generated SR\\nsamples we train a discriminator network. The architecture\\nis shown in Figure 4. We follow the architectural guidelines\\nsummarized by Radford et al. [44] and use LeakyReLU\\nactivation (α = 0.2) and avoid max-pooling throughout\\nthe network. The discriminator network is trained to solve\\nthe maximization problem in Equation 2. It contains eight\\nconvolutional layers with an increasing number of 3 ×3\\nﬁlter kernels, increasing by a factor of 2 from 64 to 512 ker-\\nnels as in the VGG network [49]. Strided convolutions are\\nused to reduce the image resolution each time the number\\nof features is doubled. The resulting 512 feature maps are\\nfollowed by two dense layers and a ﬁnal sigmoid activation\\nfunction to obtain a probability for sample classiﬁcation.\\nFigure 4: Architecture of Generator and Discriminator Network with corresponding kernel size (k), number of feature maps\\n(n) and stride (s) indicated for each convolutional layer.\\n2.2. Perceptual loss function\\nThe deﬁnition of our perceptual loss function lSR is crit-\\nical for the performance of our generator network. While\\nlSR is commonly modeled based on the MSE [10, 48], we\\nimprove on Johnson et al. [33] and Bruna et al. [5] and\\ndesign a loss function that assesses a solution with respect\\nto perceptually relevant characteristics. We formulate the\\nperceptual loss as the weighted sum of a content loss ( lSR\\nX )\\nand an adversarial loss component as:\\nlSR = lSR\\nX\\ued19\\ued18\\ued17\\ued1a\\ncontent loss\\n+ 10−3lSR\\nGen\\ued19 \\ued18\\ued17 \\ued1a\\nadversarial loss\\ued19 \\ued18\\ued17 \\ued1a\\nperceptual loss (for VGG based content losses)\\n(3)', 'and signiﬁcance determined at p< 0.05.\\nThe reader may also be interested in an independently\\ndeveloped GAN-based solution on GitHub 5. However it\\nonly provides experimental results on a limited set of faces,\\nwhich is a more constrained and easier task.\\n3.2. Training details and parameters\\nWe trained all networks on a NVIDIA Tesla M40 GPU\\nusing a random sample of 350 thousand images from\\nthe ImageNet database [45]. These images are distinct\\nfrom the testing images. We obtained the LR images\\nby downsampling the HR images (BGR, C = 3) using\\nbicubic kernel with downsampling factor r = 4. For each\\nmini-batch we crop 16 random 96 ×96 HR sub images\\nof distinct training images. Note that we can apply the\\ngenerator model to images of arbitrary size as it is fully\\n1https://github.com/xiph/daala (commit: 8d03668)\\n2https://github.com/jbhuang0604/SelfExSR\\n3http://cv.snu.ac.kr/research/DRCN/\\n4https://twitter.box.com/s/\\nlcue6vlrd01ljkdtdkhmfvk7vtjhetog\\n5https://github.com/david-gpu/srez\\nconvolutional. We scaled the range of the LR input images\\nto [0,1] and for the HR images to [−1,1]. The MSE loss\\nwas thus calculated on images of intensity range [−1,1].\\nVGG feature maps were also rescaled by a factor of 1\\n12.75\\nto obtain VGG losses of a scale that is comparable to the\\nMSE loss. This is equivalent to multiplying Equation 5\\nwith a rescaling factor of ≈ 0.006. For optimization we\\nuse Adam [36] with β1 = 0.9. The SRResNet networks\\nwere trained with a learning rate of 10−4 and 106 update\\niterations. We employed the trained MSE-based SRResNet\\nnetwork as initialization for the generator when training\\nthe actual GAN to avoid undesired local optima. All\\nSRGAN variants were trained with 105 update iterations\\nat a learning rate of 10−4 and another 105 iterations at a\\nlower rate of 10−5. We alternate updates to the generator\\nand discriminator network, which is equivalent to k = 1\\nas used in Goodfellow et al. [22]. Our generator network\\nhas 16 identical (B = 16) residual blocks. During test time\\nwe turn batch-normalization update off to obtain an output\\nthat deterministically depends only on the input [32]. Our\\nimplementation is based on Theano [53] and Lasagne [8].\\n3.3. Mean opinion score (MOS) testing\\nWe have performed a MOS test to quantify the ability of\\ndifferent approaches to reconstruct perceptually convincing\\nimages. Speciﬁcally, we asked 26 raters to assign an inte-\\ngral score from 1 (bad quality) to 5 (excellent quality) to the\\nsuper-resolved images. The raters rated 12 versions of each\\nimage on Set5, Set14 and BSD100: nearest neighbor (NN),\\nbicubic, SRCNN [9], SelfExSR [31], DRCN [34], ESPCN\\n[48], SRResNet-MSE, SRResNet-VGG22∗ (∗not rated on\\nBSD100), SRGAN-MSE ∗, SRGAN-VGG22 ∗, SRGAN-\\nVGG54 and the original HR image. Each rater thus rated\\n1128 instances (12 versions of 19 images plus 9 versions of\\n100 images) that were presented in a randomized fashion.\\nThe raters were calibrated on the NN (score 1) and HR (5)\\nversions of 20 images from the BSD300 training set. In a\\npilot study we assessed the calibration procedure and the\\ntest-retest reliability of 26 raters on a subset of 10 images\\nfrom BSD100 by adding a method’s images twice to a\\nlarger test set. We found good reliability and no signiﬁcant\\ndifferences between the ratings of the identical images.\\nRaters very consistently rated NN interpolated test images\\nas 1 and the original HR images as 5 (c.f . Figure 5).\\nThe experimental results of the conducted MOS tests are\\nsummarized in Table 1, Table 2 and Figure 5.\\n3.4. Investigation of content loss\\nWe investigated the effect of different content loss\\nchoices in the perceptual loss for the GAN-based networks.\\nSpeciﬁcally we investigate lSR = lSR\\nX + 10−3lSR\\nGen for the\\nfollowing content losses lSR\\nX :\\nTable 1: Performance of different loss functions for SR-\\nResNet and the adversarial networks on Set5 and Set14\\nbenchmark data. MOS score signiﬁcantly higher (p< 0.05)\\nthan with other losses in that category∗. [4×upscaling]\\nSRResNet- SRGAN-', 'ure 3 where multiple potential solutions with high texture\\ndetails are averaged to create a smooth reconstruction.\\nIn Mathieu et al. [42] and Denton et al. [7] the authors\\ntackled this problem by employing generative adversarial\\nnetworks (GANs) [22] for the application of image genera-\\ntion. Yu and Porikli [66] augment pixel-wise MSE loss with\\na discriminator loss to train a network that super-resolves\\nface images with large upscaling factors ( 8×). GANs\\nwere also used for unsupervised representation learning in\\nRadford et al. [44]. The idea of using GANs to learn a\\nmapping from one manifold to another is described by Li\\nand Wand [38] for style transfer and Yeh et al. [64] for\\ninpainting. Bruna et al. [5] minimize the squared error in\\nthe feature spaces of VGG19 [49] and scattering networks.\\nDosovitskiy and Brox [13] use loss functions based\\non Euclidean distances computed in the feature space of\\nneural networks in combination with adversarial training.\\nIt is shown that the proposed loss allows visually superior\\nimage generation and can be used to solve the ill-posed\\ninverse problem of decoding nonlinear feature representa-\\ntions. Similar to this work, Johnson et al. [33] and Bruna\\net al. [5] propose the use of features extracted from a pre-\\ntrained VGG network instead of low-level pixel-wise error\\nmeasures. Speciﬁcally the authors formulate a loss function\\nbased on the euclidean distance between feature maps\\nextracted from the VGG19 [49] network. Perceptually more\\nconvincing results were obtained for both super-resolution\\nand artistic style-transfer [19, 20]. Recently, Li and Wand\\n[38] also investigated the effect of comparing and blending\\npatches in pixel or VGG feature space.\\n1.2. Contribution\\nGANs provide a powerful framework for generating\\nplausible-looking natural images with high perceptual qual-\\nity. The GAN procedure encourages the reconstructions\\nto move towards regions of the search space with high\\nprobability of containing photo-realistic images and thus\\ncloser to the natural image manifold as shown in Figure 3.\\nIn this paper we describe the ﬁrst very deep ResNet\\n[29, 30] architecture using the concept of GANs to form a\\nperceptual loss function for photo-realistic SISR. Our main\\ncontributions are:\\n•We set a new state of the art for image SR with\\nhigh upscaling factors (4×) as measured by PSNR and\\nstructural similarity (SSIM) with our 16 blocks deep\\nResNet (SRResNet) optimized for MSE.\\n•We propose SRGAN which is a GAN-based network\\noptimized for a new perceptual loss. Here we replace\\nthe MSE-based content loss with a loss calculated on\\nfeature maps of the VGG network [49], which are\\nmore invariant to changes in pixel space [38].\\n•We conﬁrm with an extensive mean opinion score\\n(MOS) test on images from three public benchmark\\ndatasets that SRGAN is the new state of the art, by a\\nlarge margin, for the estimation of photo-realistic SR\\nimages with high upscaling factors (4×).\\nWe describe the network architecture and the perceptual\\nloss in Section 2. A quantitative evaluation on public bench-\\nmark datasets as well as visual illustrations are provided in\\nSection 3. The paper concludes with a discussion in Section\\n4 and concluding remarks in Section 5.\\n2. Method\\nIn SISR the aim is to estimate a high-resolution, super-\\nresolved image ISR from a low-resolution input image\\nILR. Here ILR is the low-resolution version of its high-\\nresolution counterpart IHR. The high-resolution images\\nare only available during training. In training, ILR is\\nobtained by applying a Gaussian ﬁlter toIHR followed by a\\ndownsampling operation with downsampling factor r. For\\nan image with C color channels, we describe ILR by a\\nreal-valued tensor of size W ×H ×C and IHR, ISR by\\nrW ×rH ×Crespectively.\\nOur ultimate goal is to train a generating function Gthat\\nestimates for a given LR input image its corresponding HR\\ncounterpart. To achieve this, we train a generator network as\\na feed-forward CNN GθG parametrized by θG. Here θG =', 'conﬁrm that SRGAN outperforms all reference methods by\\na large margin and sets a new state of the art for photo-\\nrealistic image SR. All differences in MOS ( c.f . Table\\n2) are highly signiﬁcant on BSD100, except SRCNN vs.\\nSelfExSR. The distribution of all collected MOS ratings is\\nsummarized in Figure 5.\\n4. Discussion and future work\\nWe conﬁrmed the superior perceptual performance of\\nSRGAN using MOS testing. We have further shown that\\nstandard quantitative measures such as PSNR and SSIM\\nfail to capture and accurately assess image quality with\\nrespect to the human visual system [56]. The focus of this\\nwork was the perceptual quality of super-resolved images\\nrather than computational efﬁciency. The presented model\\nis, in contrast to Shi et al. [48], not optimized for video\\nSR in real-time. However, preliminary experiments on\\nthe network architecture suggest that shallower networks\\nhave the potential to provide very efﬁcient alternatives at\\na small reduction of qualitative performance. In contrast to\\nDong et al. [10], we found deeper network architectures to\\nbe beneﬁcial. We speculate that the ResNet design has a\\nsubstantial impact on the performance of deeper networks.\\nWe found that even deeper networks (B >16) can further\\nSRResNet SRGAN-MSE SRGAN-VGG22 SRGAN-VGG54 original HR image\\nFigure 6: SRResNet (left: a,b), SRGAN-MSE (middle left: c,d), SRGAN-VGG2.2 (middle: e,f) and SRGAN-VGG54\\n(middle right: g,h) reconstruction results and corresponding reference HR image (right: i,j). [ 4×upscaling]\\nTable 2: Comparison of NN, bicubic, SRCNN [9], SelfExSR [31], DRCN [34], ESPCN [48], SRResNet, SRGAN-VGG54\\nand the original HR on benchmark data. Highest measures (PSNR [dB], SSIM, MOS) in bold. [4×upscaling]\\nSet5 nearest bicubic SRCNN SelfExSR DRCN ESPCN SRResNet SRGAN HR\\nPSNR 26.26 28.43 30.07 30.33 31.52 30.76 32.05 29.40 ∞\\nSSIM 0.7552 0.8211 0.8627 0.872 0.8938 0.8784 0.9019 0.8472 1\\nMOS 1.28 1.97 2.57 2.65 3.26 2.89 3.37 3.58 4.32\\nSet14\\nPSNR 24.64 25.99 27.18 27.45 28.02 27.66 28.49 26.02 ∞\\nSSIM 0.7100 0.7486 0.7861 0.7972 0.8074 0.8004 0.8184 0.7397 1\\nMOS 1.20 1.80 2.26 2.34 2.84 2.52 2.98 3.72 4.32\\nBSD100\\nPSNR 25.02 25.94 26.68 26.83 27.21 27.02 27.58 25.16 ∞\\nSSIM 0.6606 0.6935 0.7291 0.7387 0.7493 0.7442 0.7620 0.6688 1\\nMOS 1.11 1.47 1.87 1.89 2.12 2.01 2.29 3.56 4.46\\nincrease the performance of SRResNet, however, come at\\nthe cost of longer training and testing times ( c.f . supple-\\nmentary material). We further found SRGAN variants of\\ndeeper networks are increasingly difﬁcult to train due to the\\nappearance of high-frequency artifacts.\\nOf particular importance when aiming for photo-realistic\\nsolutions to the SR problem is the choice of the content loss\\nas illustrated in Figure 6. In this work, we found lSR\\nVGG/5.4\\nto yield the perceptually most convincing results, which\\nwe attribute to the potential of deeper network layers to\\nrepresent features of higher abstraction [68, 65, 40] away\\nfrom pixel space. We speculate that feature maps of these\\ndeeper layers focus purely on the content while leaving the\\nadversarial loss focusing on texture details which are the\\nmain difference between the super-resolved images without\\nthe adversarial loss and photo-realistic images. We also\\nnote that the ideal loss function depends on the application.\\nFor example, approaches that hallucinate ﬁner detail might\\nbe less suited for medical applications or surveillance. The\\nperceptually convincing reconstruction of text or structured\\nscenes [31] is challenging and part of future work. The\\ndevelopment of content loss functions that describe image\\nspatial content, but more invariant to changes in pixel space\\nwill further improve photo-realistic image SR results.\\n5. Conclusion\\nWe have described a deep residual network SRRes-\\nNet that sets a new state of the art on public benchmark\\ndatasets when evaluated with the widely used PSNR mea-\\nsure. We have highlighted some limitations of this PSNR-\\nfocused image super-resolution and introduced SRGAN,', 'Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial\\nNetwork\\nChristian Ledig, Lucas Theis, Ferenc Husz´ar, Jose Caballero, Andrew Cunningham,\\nAlejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, Wenzhe Shi\\nTwitter\\n{cledig,ltheis,fhuszar,jcaballero,aacostadiaz,aaitken,atejani,jtotz,zehanw,wshi}@twitter.com\\nAbstract\\nDespite the breakthroughs in accuracy and speed of\\nsingle image super-resolution using faster and deeper con-\\nvolutional neural networks, one central problem remains\\nlargely unsolved: how do we recover the ﬁner texture details\\nwhen we super-resolve at large upscaling factors? The\\nbehavior of optimization-based super-resolution methods is\\nprincipally driven by the choice of the objective function.\\nRecent work has largely focused on minimizing the mean\\nsquared reconstruction error. The resulting estimates have\\nhigh peak signal-to-noise ratios, but they are often lacking\\nhigh-frequency details and are perceptually unsatisfying in\\nthe sense that they fail to match the ﬁdelity expected at\\nthe higher resolution. In this paper, we present SRGAN,\\na generative adversarial network (GAN) for image super-\\nresolution (SR). To our knowledge, it is the ﬁrst framework\\ncapable of inferring photo-realistic natural images for 4×\\nupscaling factors. To achieve this, we propose a perceptual\\nloss function which consists of an adversarial loss and a\\ncontent loss. The adversarial loss pushes our solution to\\nthe natural image manifold using a discriminator network\\nthat is trained to differentiate between the super-resolved\\nimages and original photo-realistic images. In addition, we\\nuse a content loss motivated by perceptual similarity instead\\nof similarity in pixel space. Our deep residual network\\nis able to recover photo-realistic textures from heavily\\ndownsampled images on public benchmarks. An extensive\\nmean-opinion-score (MOS) test shows hugely signiﬁcant\\ngains in perceptual quality using SRGAN. The MOS scores\\nobtained with SRGAN are closer to those of the original\\nhigh-resolution images than to those obtained with any\\nstate-of-the-art method.\\n1. Introduction\\nThe highly challenging task of estimating a high-\\nresolution (HR) image from its low-resolution (LR)\\ncounterpart is referred to as super-resolution (SR). SR\\nreceived substantial attention from within the computer\\nvision research community and has a wide range of\\napplications [63, 71, 43].\\n4×SRGAN (proposed) original\\nFigure 1: Super-resolved image (left) is almost indistin-\\nguishable from original (right). [4×upscaling]\\nThe ill-posed nature of the underdetermined SR problem\\nis particularly pronounced for high upscaling factors, for\\nwhich texture detail in the reconstructed SR images is\\ntypically absent. The optimization target of supervised\\nSR algorithms is commonly the minimization of the mean\\nsquared error (MSE) between the recovered HR image\\nand the ground truth. This is convenient as minimizing\\nMSE also maximizes the peak signal-to-noise ratio (PSNR),\\nwhich is a common measure used to evaluate and compare\\nSR algorithms [61]. However, the ability of MSE (and\\nPSNR) to capture perceptually relevant differences, such\\nas high texture detail, is very limited as they are deﬁned\\nbased on pixel-wise image differences [60, 58, 26]. This\\nis illustrated in Figure 2, where highest PSNR does not\\nnecessarily reﬂect the perceptually better SR result. The\\n1\\narXiv:1609.04802v5  [cs.CV]  25 May 2017\\nbicubic SRResNet SRGAN original\\n(21.59dB/0.6423) (23.53dB/0.7832) (21.15dB/0.6868)\\nFigure 2: From left to right: bicubic interpolation, deep residual network optimized for MSE, deep residual generative\\nadversarial network optimized for a loss more sensitive to human perception, original HR image. Corresponding PSNR and\\nSSIM are shown in brackets. [4×upscaling]\\nperceptual difference between the super-resolved and orig-\\ninal image means that the recovered image is not photo-\\nrealistic as deﬁned by Ferwerda [16].', '[70] K. Zhang, X. Gao, D. Tao, and X. Li. Multi-scale dictionary for\\nsingle image super-resolution. In IEEE Conference on Computer\\nVision and Pattern Recognition (CVPR), pages 1114–1121, 2012. 2\\n[71] W. Zou and P. C. Yuen. Very Low Resolution Face Recognition\\nin Parallel Environment . IEEE Transactions on Image Processing,\\n21:327–340, 2012. 1\\nA. Supplementary Material\\nIn this supplementary material we ﬁrst brieﬂy investigate the inﬂuence of network depth (number of residual blocks)\\non the performance (PSNR, time) of SRResNet in Section A.1. We then visualize on an example image how the SRGAN\\nnetwork performance evolves with increasing number of training iterations in Section A.2. Results of the MOS tests\\nconducted on Set5, Set14, BSD100 are summarized in Section A.3. Finally we provide a visualization of all image\\nreconstruction obtained with SRResNet and SRGAN with a 4×upscaling factor for Set5 (Section A.4), Set14 (Section A.5)\\nand ﬁve randomly selected images from BSD100 (Section A.6).\\nImages are best viewed and compared zoomed in. All original low-/high-resolution images and reconstructions\\n(4×upscaling) obtained with different methods (bicubic, SRResNet-MSE, SRResNet-VGG22, SRGAN-MSE, SRGAN-\\nVGG22, SRGAN-VGG54) described in the paper are available for download at https://twitter.box.com/s/\\nlcue6vlrd01ljkdtdkhmfvk7vtjhetog.\\nA.1. Performance (PSNR/time) vs. network depth\\nWe investigated the inﬂuence of network depth, speciﬁcally the number of residual blocks, on performance (PSNR [dB]\\non BSD100 for 4×SR) and inference time [s] of the network architecture described in Figure 4 of the main paper. Time was\\nassessed on a NVIDIA M40 GPU and averaged over 100 reconstructions of a random low-resolution image with resolution\\n64×64 with upscaling factor 4×. The measurements are plotted in Figure 7 for a network with (blue) and without (red)\\nskip-connection. As expected the time of a single forward pass through the network depends approximately linearly on the\\nnumber of residual blocks. Whether a skip-connection is used or not has no substantial impact on inference time. However,\\nwe observed substantial gains in performance with the additional skip-connection. We chose a network architecture of\\n16 residual blocks with skip-connection for the evaluation presented in the main paper as we consider this as good trade-\\noff between accuracy and speed including training time. While accuracy gains slowly saturate beyond 16 blocks there is,\\nnevertheless, a clear beneﬁt of using even deeper networks.\\nFigure 7: Dependence of network performance (PSNR, time) on network depth. PSNR (left) calculated on BSD100. Time\\n(right) averaged over 100 reconstructions of a random LR image with resolution 64×64.\\nA.2. Evolution of Generator during SRGAN training\\nWe further investigated how reconstructions of the SRGAN generator network evolve (visually) with increasing number\\nof training iterations. Visual results obtained after different number of training iterations are illustrated in Figure 8. It is\\ninteresting that after only 20 thousand training iterations the generator substantially diverged from the SRResNet initialization\\nand produces reconstruction with a lot of high frequency content, including noise. With increasing number of training\\niterations reconstructions of the baboon from Set14 appear closer to the reference image. However, there is visually little\\nchange during the last 50-100 thousand update iterations.\\nSRResNet 20k 40k 60k 80k\\n100k 140k 180k SRGAN original HR image\\nFigure 8: Evolution of SRGAN generator network during training progress. Note: Generator initialized with SRResNet\\nweights; learning rate set to 10−4 for ﬁrst 100k iterations, then reduced to 10−5 for another 100k iterations. [4×upscaling]\\nA.3. Mean opinion score (MOS) testing\\nIn all conducted MOS tests we have asked 26 human raters to assign a score from 1 (Bad) to 5 (Excellent) to reconstructions']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Contextual Precision (ragas) (score: 0.9999999999875, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ❌ Faithfulness (ragas) (score: 0.5714285714285714, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Contextual Recall (ragas) (score: 1.0, threshold: 0.6, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Answer Relevancy (ragas) (score: 0.9498899035162526, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Why do the authors of SRCNN first upscale the LR image with bicubic interpolation instead of learning that step end‑to‑end?\n",
      "  - actual output: The authors of SRCNN pre-upscale the low-resolution (LR) image using bicubic interpolation (a standard image resizing technique) primarily to simplify the learning process and reduce computational cost. While learning the upscaling step end-to-end is possible, it would significantly increase the complexity of the model and require more resources for training. By pre-upscaling, the network only needs to learn the non-linear mapping between the interpolated image and the high-resolution image, which is a simpler task. They mention this is the only pre-processing step they perform.\n",
      "  - expected output: Because popular GPU conv‑net toolkits (cuda‑convnet at the time) did not yet support fractional‑stride convolutions. Upscaling once with bicubic ensures the network can stay fully convolutional with integer strides while still learning the rest of the SR mapping end‑to‑end.\n",
      "  - context: ['…we first upscale it to the desired size using bicubic interpolation, which is the only pre‑processing we perform. … There is a fractional stride. To take advantage of the popular well‑optimized implementations such as cuda‑convnet, we exclude this “layer” from learning.']\n",
      "  - retrieval context: ['bicubic interpolation. The training falls into a bad local\\nminimum, due to the inherently different characteristics\\nof the Y and Cb, Cr channels. (ii) If we pre-train on the\\nY or Cb, Cr channels, the performance ﬁnally improves,\\nbut is still not better than “Y only” on the color image\\n(see the last column of Table 5, where PSNR is computed\\n(a) First-layer ﬁlters – Cb channel\\n(b) First-layer ﬁlters – Cr channel\\nFig. 13. Chrominance channels of the ﬁrst-layer ﬁlters\\nusing the “Y pre-train” strategy.\\nin RGB color space). This suggests that the Cb, Cr\\nchannels could decrease the performance of the Y chan-\\nnel when training is performed in a uniﬁed network.\\n(iii) We observe that the Cb, Cr channels have higher\\nPSNR values for “Y pre-train” than for “CbCr pre-train”.\\nThe reason lies on the differences between the Cb, Cr\\nchannels and the Y channel. Visually, the Cb, Cr channels\\nare more blurry than the Y channel, thus are less affected\\nby the downsampling process. When we pre-train on\\nthe Cb, Cr channels, there are only a few ﬁlters being\\nactivated. Then the training will soon fall into a bad\\nlocal minimum during ﬁne-tuning. On the other hand,\\nif we pre-train on the Y channel, more ﬁlters will be\\nactivated, and the performance on Cb, Cr channels will\\nbe pushed much higher. Figure 13 shows the Cb, Cr\\nchannels of the ﬁrst-layer ﬁlters with “Y pre-train”, of\\nwhich the patterns largely differ from that shown in\\nFigure 5. (iv) Training on the RGB channels achieves\\nthe best result on the color image. Different from the\\nYCbCr channels, the RGB channels exhibit high cross-\\ncorrelation among each other. The proposed SRCNN\\nis capable of leveraging such natural correspondences\\nbetween the channels for reconstruction. Therefore, the\\nmodel achieves comparable result on the Y channel as\\n“Y only”, and better results on Cb, Cr channels than\\nbicubic interpolation. (v) In KK [25], super-resolution\\nis applied on each RGB channel separately. When we\\ntransform its results to YCbCr space, the PSNR value\\nof Y channel is similar as “Y only”, but that of Cb, Cr\\nchannels are poorer than bicubic interpolation. The result\\nsuggests that the algorithm is biased to the Y channel.\\nOn the whole, our method trained on RGB channels\\nachieves better performance than KK and the single-\\nchannel network (“Y only”). It is also worth noting that\\nthe improvement compared with the single-channel net-\\nwork is not that signiﬁcant ( i.e., 0.07 dB). This indicates\\nthat the Cb, Cr channels barely help in improving the\\nperformance.\\n5 C ONCLUSION\\nWe have presented a novel deep learning approach\\nfor single image super-resolution (SR). We show that\\nconventional sparse-coding-based SR methods can be\\n12\\nreformulated into a deep convolutional neural network.\\nThe proposed approach, SRCNN, learns an end-to-end\\nmapping between low- and high-resolution images, with\\nlittle extra pre/post-processing beyond the optimization.\\nWith a lightweight structure, the SRCNN has achieved\\nsuperior performance than the state-of-the-art methods.\\nWe conjecture that additional performance can be further\\ngained by exploring more ﬁlters and different training\\nstrategies. Besides, the proposed structure, with its ad-\\nvantages of simplicity and robustness, could be applied\\nto other low-level vision problems, such as image de-\\nblurring or simultaneous SR+denoising. One could also\\ninvestigate a network to cope with different upscaling\\nfactors.\\nREFERENCES\\n[1] Aharon, M., Elad, M., Bruckstein, A.: K-SVD: An algorithm for\\ndesigning overcomplete dictionaries for sparse representation.\\nIEEE Transactions on Signal Processing 54(11), 4311–4322 (2006)\\n[2] Bevilacqua, M., Roumy, A., Guillemot, C., Morel, M.L.A.: Low-\\ncomplexity single-image super-resolution based on nonnegative\\nneighbor embedding. In: British Machine Vision Conference\\n(2012)\\n[3] Burger, H.C., Schuler, C.J., Harmeling, S.: Image denoising: Can\\nplain neural networks compete with BM3D? In: IEEE Conference', 'In this paper, we show that the aforementioned\\npipeline is equivalent to a deep convolutional neural net-\\nwork [27] (more details in Section 3.2). Motivated by this\\nfact, we consider a convolutional neural network that\\ndirectly learns an end-to-end mapping between low- and\\nhigh-resolution images. Our method differs fundamen-\\ntally from existing external example-based approaches,\\nin that ours does not explicitly learn the dictionaries [41],\\n[49], [50] or manifolds [2], [4] for modeling the patch\\nspace. These are implicitly achieved via hidden layers.\\nFurthermore, the patch extraction and aggregation are\\nalso formulated as convolutional layers, so are involved\\nin the optimization. In our method, the entire SR pipeline\\nis fully obtained through learning, with little pre/post-\\nprocessing.\\nWe name the proposed model Super-Resolution Con-\\nvolutional Neural Network (SRCNN) 1. The proposed\\nSRCNN has several appealing properties. First, its struc-\\nture is intentionally designed with simplicity in mind,\\nand yet provides superior accuracy 2 compared with\\nstate-of-the-art example-based methods. Figure 1 shows\\na comparison on an example. Second, with moderate\\n1. The implementation is available at http://mmlab.ie.cuhk.edu.hk/\\nprojects/SRCNN.html.\\n2. Numerical evaluations by using different metrics such as the Peak\\nSignal-to-Noise Ratio (PSNR), structure similarity index (SSIM) [43],\\nmulti-scale SSIM [44], information ﬁdelity criterion [38], when the\\nground truth images are available.\\narXiv:1501.00092v3  [cs.CV]  31 Jul 2015\\n2\\nBicubic / 24.04 dB\\nSC / 25.58 dBSRCNN / 27.95 dB\\nOriginal / PSNR\\n2 4 6 8 10 12x 108\\n29.5\\n30\\n30.5\\n31\\n31.5\\n32\\n32.5\\n33\\nNumber of backprops\\nAverage test PSNR (dB)\\nSRCNN\\nSC\\nBicubic\\nBicubic / 24.04 dB\\nSC / 25.58 dBSRCNN / 27.95 dB\\nOriginal / PSNR\\nBicubic / 24.04 dB\\nSC / 25.58 dBSRCNN / 27.95 dB\\nOriginal / PSNR\\nSRCNN\\nSC\\nBicubic\\nBicubic / 24.04 dB\\nSC / 25.58 dBSRCNN / 27.95 dB\\nOriginal / PSNR\\nNumber of backprops\\nAverage test PSNR (dB)\\nFig. 1. The proposed Super-Resolution Convolutional\\nNeural Network (SRCNN) surpasses the bicubic baseline\\nwith just a few training iterations, and outperforms the\\nsparse-coding-based method (SC) [50] with moderate\\ntraining. The performance may be further improved with\\nmore training iterations. More details are provided in\\nSection 4.4.1 (the Set5 dataset with an upscaling factor\\n3). The proposed method provides visually appealing\\nreconstructed image.\\nnumbers of ﬁlters and layers, our method achieves\\nfast speed for practical on-line usage even on a CPU.\\nOur method is faster than a number of example-based\\nmethods, because it is fully feed-forward and does\\nnot need to solve any optimization problem on usage.\\nThird, experiments show that the restoration quality of\\nthe network can be further improved when (i) larger\\nand more diverse datasets are available, and/or (ii)\\na larger and deeper model is used. On the contrary,\\nlarger datasets/models can present challenges for exist-\\ning example-based methods. Furthermore, the proposed\\nnetwork can cope with three channels of color images\\nsimultaneously to achieve improved super-resolution\\nperformance.\\nOverall, the contributions of this study are mainly in\\nthree aspects:\\n1) We present a fully convolutional neural net-\\nwork for image super-resolution. The network di-\\nrectly learns an end-to-end mapping between low-\\nand high-resolution images, with little pre/post-\\nprocessing beyond the optimization.\\n2) We establish a relationship between our deep-\\nlearning-based SR method and the traditional\\nsparse-coding-based SR methods. This relationship\\nprovides a guidance for the design of the network\\nstructure.\\n3) We demonstrate that deep learning is useful in\\nthe classical computer vision problem of super-\\nresolution, and can achieve good quality and\\nspeed.\\nA preliminary version of this work was presented\\nearlier [11]. The present work adds to the initial version\\nin signiﬁcant ways. Firstly, we improve the SRCNN by\\nintroducing larger ﬁlter size in the non-linear mapping', 'terion (IFC) [38], noise quality measure (NQM) [8],\\nweighted peak signal-to-noise ratio (WPSNR) and multi-\\nscale structure similarity index (MSSSIM) [44], which\\nobtain high correlation with the human perceptual scores\\nas reported in [46].\\n4.4.1 Quantitative and qualitative evaluation\\nAs shown in Tables 2, 3 and 4, the proposed SRCNN\\nyields the highest scores in most evaluation matrices\\n7. In the area of denoising [3], for each noise level a speciﬁc network\\nis trained.\\n8. We use the same 200 images as in [46].\\n9\\n2 4 6 8 10 12\\nx(10\\n8\\n30.5\\n31\\n31.5\\n32\\n32.5\\n33\\nNumber(of(backprops\\nAverage(test(PSNR((dB)\\nANR - 31.92 dB\\nA+ - 32.59 dB\\nSRCNN\\nSC - 31.42 dB\\nBicubic - 30.39 dB\\nNE+LLE - 31.84 dB\\nKK - 32.28 dB\\nFig. 10. The test convergence curve of SRCNN and\\nresults of other methods on the Set5 dataset.\\nin all experiments 9. Note that our SRCNN results are\\nbased on the checkpoint of 8 ×108 backpropagations.\\nSpeciﬁcally, for the upscaling factor 3, the average gains\\non PSNR achieved by SRCNN are 0.15 dB, 0.17 dB, and\\n0.13 dB, higher than the next best approach, A+ [42],\\non the three datasets. When we take a look at other\\nevaluation metrics, we observe that SC, to our surprise,\\ngets even lower scores than the bicubic interpolation\\non IFC and NQM. It is clear that the results of SC are\\nmore visually pleasing than that of bicubic interpolation.\\nThis indicates that these two metrics may not truthfully\\nreveal the image quality. Thus, regardless of these two\\nmetrics, SRCNN achieves the best performance among\\nall methods and scaling factors.\\nIt is worth pointing out that SRCNN surpasses the\\nbicubic baseline at the very beginning of the learning\\nstage (see Figure 1), and with moderate training, SR-\\nCNN outperforms existing state-of-the-art methods (see\\nFigure 4). Yet, the performance is far from converge.\\nWe conjecture that better results can be obtained given\\nlonger training time (see Figure 10).\\nFigures 14, 15 and 16 show the super-resolution results\\nof different approaches by an upscaling factor 3. As can\\nbe observed, the SRCNN produces much sharper edges\\nthan other approaches without any obvious artifacts\\nacross the image.\\nIn addition, we report to another recent deep learning\\nmethod for image super-resolution (DNC) of Cui et\\nal. [5]. As they employ a different blur kernel (a Gaussian\\nﬁlter with a standard deviation of 0.55), we train a spe-\\nciﬁc network (9-5-5) using the same blur kernel as DNC\\nfor fair quantitative comparison. The upscaling factor\\nis 3 and the training set is the 91-image dataset. From\\nthe convergence curve shown in Figure 11, we observe\\nthat our SRCNN surpasses DNC with just 2.7 ×107\\nbackprops, and a larger margin can be obtained given\\nlonger training time. This also demonstrates that the\\nend-to-end learning is superior to DNC, even if that\\nmodel is already “deep”.\\n4.4.2 Running time\\nFigure 12 shows the running time comparisons of several\\nstate-of-the-art methods, along with their restoration\\nperformance on Set14. All baseline methods are obtained\\n9. The PSNR value of each image can be found in the supplementary\\nﬁle.\\nfrom the corresponding authors’ MATLAB+MEX imple-\\nmentation, whereas ours are in pure C++. We proﬁle\\nthe running time of all the algorithms using the same\\nmachine (Intel CPU 3.10 GHz and 16 GB memory).\\nNote that the processing time of our approach is highly\\nlinear to the test image resolution, since all images go\\nthrough the same number of convolutions. Our method\\nis always a trade-off between performance and speed.\\nTo show this, we train three networks for comparison,\\nwhich are 9-1-5, 9-3-5, and 9-5-5. It is clear that the 9-\\n1-5 network is the fastest, while it still achieves better\\nperformance than the next state-of-the-art A+. Other\\nmethods are several times or even orders of magnitude\\nslower in comparison to 9-1-5 network. Note the speed\\ngap is not mainly caused by the different MATLAB/C++\\nimplementations; rather, the other methods need to solve\\ncomplex optimization problems on usage (e.g., sparse', '4 0.7019 - 0.7331 0.7419 0.7352 0.7491 0.7513\\n2 6.09 - 7.59 6.83 7.81 8.11 7.76\\nIFC 3 3.41 2.98 4.14 3.83 4.23 4.45 4.26\\n4 2.23 - 2.71 2.57 2.78 2.94 2.74\\n2 40.98 - 41.34 38.86 41.79 42.61 38.95\\nNQM 3 33.15 29.06 37.12 35.23 37.22 38.24 35.25\\n4 26.15 - 31.17 29.18 31.27 32.31 30.46\\n2 47.64 - 54.47 53.85 54.57 55.62 55.39\\nWPSNR 3 39.72 41.66 43.22 43.56 43.36 44.25 44.32\\n4 35.71 - 37.75 38.26 37.85 38.72 38.87\\n2 0.9813 - 0.9886 0.9890 0.9888 0.9896 0.9897\\nMSSSIM 3 0.9512 0.9595 0.9643 0.9653 0.9647 0.9669 0.9675\\n4 0.9134 - 0.9317 0.9338 0.9326 0.9371 0.9376\\nTABLE 4\\nThe average results of PSNR (dB), SSIM, IFC, NQM, WPSNR (dB) and MSSIM on the BSD200 dataset.\\nEval. Mat Scale Bicubic SC [50] NE+LLE [4] KK [25] ANR [41] A+ [41] SRCNN\\n2 28.38 - 29.67 30.02 29.72 30.14 30.29\\nPSNR 3 25.94 26.54 26.67 26.89 26.72 27.05 27.18\\n4 24.65 - 25.21 25.38 25.25 25.51 25.60\\n2 0.8524 - 0.8886 0.8935 0.8900 0.8966 0.8977\\nSSIM 3 0.7469 0.7729 0.7823 0.7881 0.7843 0.7945 0.7971\\n4 0.6727 - 0.7037 0.7093 0.7060 0.7171 0.7184\\n2 5.30 - 7.10 6.33 7.28 7.51 7.21\\nIFC 3 3.05 2.77 3.82 3.52 3.91 4.07 3.91\\n4 1.95 - 2.45 2.24 2.51 2.62 2.45\\n2 36.84 - 41.52 38.54 41.72 42.37 39.66\\nNQM 3 28.45 28.22 34.65 33.45 34.81 35.58 34.72\\n4 21.72 - 25.15 24.87 25.27 26.01 25.65\\n2 46.15 - 52.56 52.21 52.69 53.56 53.58\\nWPSNR 3 38.60 40.48 41.39 41.62 41.53 42.19 42.29\\n4 34.86 - 36.52 36.80 36.64 37.18 37.24\\n2 0.9780 - 0.9869 0.9876 0.9872 0.9883 0.9883\\nMSSSIM 3 0.9426 0.9533 0.9575 0.9588 0.9581 0.9609 0.9614\\n4 0.9005 - 0.9203 0.9215 0.9214 0.9256 0.9261\\n11\\n10\\n0\\n10\\n1\\n10\\n228.2\\n28.4\\n28.6\\n28.8\\n29\\n29.2\\n29.4\\nRunning time (sec)\\nPSNR (dB)\\nSC\\nNE+LLE ANR\\nKK\\nA+\\nSRCNN(9-1-5)\\nSRCNN(9-3-5) SRCNN(9-5-5)\\n——> FasterSlower <——\\nFig. 12. The proposed SRCNN achieves the state-\\nof-the-art super-resolution quality, whilst maintains high\\nand competitive speed in comparison to existing external\\nexample-based methods. The chart is based on Set14\\nresults summarized in Table 3. The implementation of all\\nthree SRCNN networks are available on our project page.\\nTABLE 5\\nAverage PSNR (dB) of different channels and training\\nstrategies on the Set5 dataset.\\nTraining PSNR of different channel(s)\\nStrategies Y Cb Cr RGB color image\\nBicubic 30.39 45.44 45.42 34.57\\nY only 32.39 45.44 45.42 36.37\\nYCbCr 29.25 43.30 43.49 33.47\\nY pre-train 32.19 46.49 46.45 36.32\\nCbCr pre-train 32.14 46.38 45.84 36.25\\nRGB 32.33 46.18 46.20 36.44\\nKK 32.37 44.35 44.22 36.32\\neffectiveness of SRCNN on different scales, here we only\\nevaluate the performance of upscaling factor 3.\\nComparisons. We compare our method with the state-\\nof-art color SR method – KK [25]. We also try different\\nlearning strategies for comparison:\\n• Y only: this is our baseline method, which is a\\nsingle-channel ( c = 1 ) network trained only on\\nthe luminance channel. The Cb, Cr channels are\\nupscaled using bicubic interpolation.\\n• YCbCr: training is performed on the three channels\\nof the YCbCr space.\\n• Y pre-train: ﬁrst, to guarantee the performance on\\nthe Y channel, we only use the MSE of the Y channel\\nas the loss to pre-train the network. Then we employ\\nthe MSE of all channels to ﬁne-tune the parameters.\\n• CbCr pre-train: we use the MSE of the Cb, Cr\\nchannels as the loss to pre-train the network, then\\nﬁne-tune the parameters on all channels.\\n• RGB: training is performed on the three channels of\\nthe RGB space.\\nThe results are shown in Table 5, where we have the\\nfollowing observations. (i) If we directly train on the\\nYCbCr channels, the results are even worse than that of\\nbicubic interpolation. The training falls into a bad local\\nminimum, due to the inherently different characteristics\\nof the Y and Cb, Cr channels. (ii) If we pre-train on the\\nY or Cb, Cr channels, the performance ﬁnally improves,\\nbut is still not better than “Y only” on the color image\\n(see the last column of Table 5, where PSNR is computed\\n(a) First-layer ﬁlters – Cb channel\\n(b) First-layer ﬁlters – Cr channel\\nFig. 13. Chrominance channels of the ﬁrst-layer ﬁlters', 'erations, ηis the learning rate, and ∂L\\n∂W ℓ\\ni\\nis the derivative.\\nThe ﬁlter weights of each layer are initialized by drawing\\nrandomly from a Gaussian distribution with zero mean\\nand standard deviation 0.001 (and 0 for biases). The\\nlearning rate is 10−4 for the ﬁrst two layers, and 10−5 for\\nthe last layer. We empirically ﬁnd that a smaller learning\\nrate in the last layer is important for the network to\\nconverge (similar to the denoising case [22]).\\nIn the training phase, the ground truth images {Xi}\\nare prepared as fsub×fsub×c-pixel sub-images randomly\\ncropped from the training images. By “sub-images” we\\nmean these samples are treated as small “images” rather\\nthan “patches”, in the sense that “patches” are overlap-\\nping and require some averaging as post-processing but\\n“sub-images” need not. To synthesize the low-resolution\\nsamples {Yi}, we blur a sub-image by a Gaussian kernel,\\nsub-sample it by the upscaling factor, and upscale it by\\nthe same factor via bicubic interpolation.\\nTo avoid border effects during training, all the con-\\nvolutional layers have no padding, and the network\\nproduces a smaller output ( (fsub −f1 −f2 −f3 + 3)2 ×c).\\nThe MSE loss function is evaluated only by the difference\\nbetween the central pixels of Xi and the network output.\\nAlthough we use a ﬁxed image size in training, the\\nconvolutional neural network can be applied on images\\nof arbitrary sizes during testing.\\nWe implement our model using the cuda-convnet pack-\\nage [26]. We have also tried the Caffe package [24] and\\nobserved similar performance.\\n4 E XPERIMENTS\\nWe ﬁrst investigate the impact of using different datasets\\non the model performance. Next, we examine the ﬁlters\\nlearned by our approach. We then explore different\\narchitecture designs of the network, and study the rela-\\ntions between super-resolution performance and factors\\nlike depth, number of ﬁlters, and ﬁlter sizes. Subse-\\nquently, we compare our method with recent state-of-\\nthe-arts both quantitatively and qualitatively. Following\\n[42], super-resolution is only applied on the luminance\\nchannel (Y channel in YCbCr color space) in Sections 4.1-\\n4.4, so c = 1 in the ﬁrst/last layer, and performance\\n(e.g., PSNR and SSIM) is evaluated on the Y channel. At\\nlast, we extend the network to cope with color images\\nand evaluate the performance on different channels.\\n4.1 Training Data\\nAs shown in the literature, deep learning generally\\nbeneﬁts from big data training. For comparison, we use\\na relatively small training set [41], [50] that consists\\nof 91 images, and a large training set that consists of\\n395,909 images from the ILSVRC 2013 ImageNet detec-\\ntion training partition. The size of training sub-images is\\nfsub = 33. Thus the 91-image dataset can be decomposed\\ninto 24,800 sub-images, which are extracted from origi-\\nnal images with a stride of 14. Whereas the ImageNet\\nprovides over 5 million sub-images even using a stride\\nof 33. We use the basic network settings, i.e., f1 = 9 ,\\nf2 = 1, f3 = 5, n1 = 64, and n2 = 32. We use the Set5 [2]\\nas the validation set. We observe a similar trend even\\nif we use the larger Set14 set [51]. The upscaling factor\\nis 3. We use the sparse-coding-based method [50] as our\\nbaseline, which achieves an average PSNR value of 31.42\\ndB.\\nThe test convergence curves of using different training\\nsets are shown in Figure 4. The training time on Ima-\\ngeNet is about the same as on the 91-image dataset since\\nthe number of backpropagations is the same. As can be\\nobserved, with the same number of backpropagations\\n(i.e.,8 ×108), the SRCNN +ImageNet achieves 32.52 dB,\\nhigher than 32.39 dB yielded by that trained on 91\\nimages. The results positively indicate that SRCNN per-\\nformance may be further boosted using a larger training\\nset, but the effect of big data is not as impressive as\\nthat shown in high-level vision problems [26]. This is\\nmainly because that the 91 images have already cap-\\ntured sufﬁcient variability of natural images. On the', '1 2 3 4 5 6 7 8\\nxR10\\n8\\n31.5\\n32\\n32.5\\nNumberRofRbackprops\\nAverageRtestRPSNRR(dB)\\nSRCNNR(9−5−5)\\nSRCNNR(9−5−1−5)\\nSCR(31.42RdB)\\n(c) 9-5-5 vs. 9-5-1-5\\nFig. 8. Comparisons between three-layer and four-layer\\nnetworks.\\nmapping layers with n22 = 32 and n23 = 16 ﬁlters on\\n9-1-5, then we have to set a smaller learning rate to\\nensure convergence, but we still do not observe superior\\nperformance after a week of training (see Figure 9(a)).\\nWe also tried to enlarge the ﬁlter size of the additional\\nlayer to f22 = 3, and explore two deep structures – 9-3-\\n3-5 and 9-3-3-3. However, from the convergence curves\\nshown in Figure 9(b), these two networks do not show\\nbetter results than the 9-3-1-5 network.\\nAll these experiments indicate that it is not “the deeper\\nthe better” in this deep model for super-resolution. It\\nmay be caused by the difﬁculty of training. Our CNN\\nnetwork contains no pooling layer or full-connected\\nlayer, thus it is sensitive to the initialization parameters\\nand learning rate. When we go deeper (e.g., 4 or 5 layers),\\nwe ﬁnd it hard to set appropriate learning rates that\\nguarantee convergence. Even it converges, the network\\nmay fall into a bad local minimum, and the learned\\nﬁlters are of less diversity even given enough training\\ntime. This phenomenon is also observed in [16], where\\nimproper increase of depth leads to accuracy saturation\\nor degradation for image classiﬁcation. Why “deeper is\\nnot better” is still an open question, which requires in-\\nvestigations to better understand gradients and training\\ndynamics in deep architectures. Therefore, we still adopt\\nthree-layer networks in the following experiments.\\n4.4 Comparisons to State-of-the-Arts\\nIn this section, we show the quantitative and qualitative\\nresults of our method in comparison to state-of-the-art\\n2 4 6 8 10 12\\nx(10\\n8\\n31\\n31.5\\n32\\n32.5\\nNumber(of(backprops\\nAverage(test(PSNR(=dB)\\nSRCNN(=9−1−5)\\nSRCNN(=9−1−1−5,(n 22=16)\\nSRCNN(=9−1−1−5,(n 22=32)\\nSRCNN(=9−1−1−1−5,(n 22=32,(n 23=16)\\nSC(=31.42(dB)\\n(a) 9-1-1-5 ( n22 = 32) and 9-1-1-1-5 ( n22 = 32, n23 = 16)\\n1 2 3 4 5 6 7 8 9\\nxS10\\n8\\n31.5\\n32\\n32.5\\nNumberSofSbackprops\\nAverageStestSPSNRS(dB)\\nSRCNNS(9−3−5)\\nSRCNNS(9−3−1−5)\\nSRCNNS(9−3−3−5)\\nSRCNNS(9−3−3−3)\\nSCS(31.42SdB)\\n(b) 9-3-3-5 and 9-3-3-3\\nFig. 9. Deeper structure does not always lead to better\\nresults.\\nmethods. We adopt the model with good performance-\\nspeed trade-off: a three-layer network with f1 = 9, f2 =\\n5, f3 = 5, n1 = 64, and n2 = 32 trained on the ImageNet.\\nFor each upscaling factor ∈{2,3,4}, we train a speciﬁc\\nnetwork for that factor 7.\\nComparisons. We compare our SRCNN with the state-\\nof-the-art SR methods:\\n• SC - sparse coding-based method of Yang et al. [50]\\n• NE+LLE - neighbour embedding + locally linear\\nembedding method [4]\\n• ANR - Anchored Neighbourhood Regression\\nmethod [41]\\n• A+ - Adjusted Anchored Neighbourhood Regres-\\nsion method [42], and\\n• KK - the method described in [25], which achieves\\nthe best performance among external example-\\nbased methods, according to the comprehensive\\nevaluation conducted in Yang et al.’s work [46]\\nThe implementations are all from the publicly available\\ncodes provided by the authors, and all images are down-\\nsampled using the same bicubic kernel.\\nTest set.The Set5 [2] (5 images), Set14 [51] (14 images)\\nand BSD200 [32] (200 images) 8 are used to evaluate the\\nperformance of upscaling factors 2, 3, and 4.\\nEvaluation metrics. Apart from the widely used PSNR\\nand SSIM [43] indices, we also adopt another four\\nevaluation matrices, namely information ﬁdelity cri-\\nterion (IFC) [38], noise quality measure (NQM) [8],\\nweighted peak signal-to-noise ratio (WPSNR) and multi-\\nscale structure similarity index (MSSSIM) [44], which\\nobtain high correlation with the human perceptual scores\\nas reported in [46].\\n4.4.1 Quantitative and qualitative evaluation\\nAs shown in Tables 2, 3 and 4, the proposed SRCNN\\nyields the highest scores in most evaluation matrices\\n7. In the area of denoising [3], for each noise level a speciﬁc network\\nis trained.', 'only on the luminance channel. There are also works\\nattempting to super-resolve all channels simultaneously.\\nFor example, Kim and Kwon [25] and Dai et al.[7] apply\\ntheir model to each RGB channel and combined them to\\nproduce the ﬁnal results. However, none of them has\\nanalyzed the SR performance of different channels, and\\nthe necessity of recovering all three channels.\\n2.2 Convolutional Neural Networks\\nConvolutional neural networks (CNN) date back\\ndecades [27] and deep CNNs have recently shown an\\nexplosive popularity partially due to its success in image\\nclassiﬁcation [18], [26]. They have also been success-\\nfully applied to other computer vision ﬁelds, such as\\nobject detection [34], [40], [52], face recognition [39], and\\npedestrian detection [35]. Several factors are of central\\nimportance in this progress: (i) the efﬁcient training\\nimplementation on modern powerful GPUs [26], (ii) the\\nproposal of the Rectiﬁed Linear Unit (ReLU) [33] which\\nmakes convergence much faster while still presents good\\nquality [26], and (iii) the easy access to an abundance of\\ndata (like ImageNet [9]) for training larger models. Our\\nmethod also beneﬁts from these progresses.\\n2.3 Deep Learning for Image Restoration\\nThere have been a few studies of using deep learning\\ntechniques for image restoration. The multi-layer per-\\nceptron (MLP), whose all layers are fully-connected (in\\ncontrast to convolutional), is applied for natural image\\ndenoising [3] and post-deblurring denoising [36]. More\\nclosely related to our work, the convolutional neural net-\\nwork is applied for natural image denoising [22] and re-\\nmoving noisy patterns (dirt/rain) [12]. These restoration\\nproblems are more or less denoising-driven. Cui et al.[5]\\npropose to embed auto-encoder networks in their super-\\nresolution pipeline under the notion internal example-\\nbased approach [16]. The deep model is not speciﬁcally\\ndesigned to be an end-to-end solution, since each layer\\nof the cascade requires independent optimization of the\\nself-similarity search process and the auto-encoder. On\\nthe contrary, the proposed SRCNN optimizes an end-to-\\nend mapping. Further, the SRCNN is faster at speed. It\\nis not only a quantitatively superior method, but also a\\npractically useful one.\\n3 C ONVOLUTIONAL NEURAL NETWORKS FOR\\nSUPER -RESOLUTION\\n3.1 Formulation\\nConsider a single low-resolution image, we ﬁrst upscale\\nit to the desired size using bicubic interpolation, which\\nis the only pre-processing we perform 3. Let us denote\\nthe interpolated image as Y. Our goal is to recover\\nfrom Y an image F(Y) that is as similar as possible\\nto the ground truth high-resolution image X. For the\\nease of presentation, we still call Y a “low-resolution”\\nimage, although it has the same size as X. We wish to\\nlearn a mapping F, which conceptually consists of three\\noperations:\\n1) Patch extraction and representation: this opera-\\ntion extracts (overlapping) patches from the low-\\nresolution image Y and represents each patch as a\\nhigh-dimensional vector. These vectors comprise a\\nset of feature maps, of which the number equals to\\nthe dimensionality of the vectors.\\n2) Non-linear mapping: this operation nonlinearly\\nmaps each high-dimensional vector onto another\\nhigh-dimensional vector. Each mapped vector is\\nconceptually the representation of a high-resolution\\npatch. These vectors comprise another set of feature\\nmaps.\\n3) Reconstruction: this operation aggregates the\\nabove high-resolution patch-wise representations\\nto generate the ﬁnal high-resolution image. This\\nimage is expected to be similar to the ground truth\\nX.\\nWe will show that all these operations form a convolu-\\ntional neural network. An overview of the network is\\ndepicted in Figure 2. Next we detail our deﬁnition of\\neach operation.\\n3.1.1 Patch extraction and representation\\nA popular strategy in image restoration ( e.g., [1]) is to\\ndensely extract patches and then represent them by a set\\nof pre-trained bases such as PCA, DCT, Haar, etc. This', 'sion [27], trees [46] or Random Forests [47]. In Dai et al.\\n[6] a multitude of patch-speciﬁc regressors is learned and\\nthe most appropriate regressors selected during testing.\\nRecently convolutional neural network (CNN) based SR\\nalgorithms have shown excellent performance. In Wang\\net al. [59] the authors encode a sparse representation\\nprior into their feed-forward network architecture based on\\nthe learned iterative shrinkage and thresholding algorithm\\n(LISTA) [23]. Dong et al. [9, 10] used bicubic interpolation\\nto upscale an input image and trained a three layer deep\\nfully convolutional network end-to-end to achieve state-\\nof-the-art SR performance. Subsequently, it was shown\\nthat enabling the network to learn the upscaling ﬁlters\\ndirectly can further increase performance both in terms of\\naccuracy and speed [11, 48, 57]. With their deeply-recursive\\nconvolutional network (DRCN), Kim et al. [34] presented\\na highly performant architecture that allows for long-range\\npixel dependencies while keeping the number of model\\nparameters small. Of particular relevance for our paper are\\nthe works by Johnson et al. [33] and Bruna et al. [5],\\nwho rely on a loss function closer to perceptual similarity\\nto recover visually more convincing HR images.\\n1.1.2 Design of convolutional neural networks\\nThe state of the art for many computer vision problems is\\nmeanwhile set by speciﬁcally designed CNN architectures\\nfollowing the success of the work by Krizhevsky et al. [37].\\nIt was shown that deeper network architectures can be\\ndifﬁcult to train but have the potential to substantially\\nincrease the network’s accuracy as they allow modeling\\nmappings of very high complexity [49, 51]. To efﬁ-\\nciently train these deeper network architectures, batch-\\nnormalization [32] is often used to counteract the internal\\nco-variate shift. Deeper network architectures have also\\nbeen shown to increase performance for SISR, e.g. Kim et\\nal. [34] formulate a recursive CNN and present state-of-the-\\nart results. Another powerful design choice that eases the\\ntraining of deep CNNs is the recently introduced concept of\\nresidual blocks [29] and skip-connections [30, 34]. Skip-\\nconnections relieve the network architecture of modeling\\nthe identity mapping that is trivial in nature, however, po-\\ntentially non-trivial to represent with convolutional kernels.\\nIn the context of SISR it was also shown that learning\\nupscaling ﬁlters is beneﬁcial in terms of accuracy and speed\\n[11, 48, 57]. This is an improvement over Dong et al. [10]\\nwhere bicubic interpolation is employed to upscale the LR\\nobservation before feeding the image to the CNN.\\n1.1.3 Loss functions\\nPixel-wise loss functions such as MSE struggle to handle\\nthe uncertainty inherent in recovering lost high-frequency\\ndetails such as texture: minimizing MSE encourages ﬁnd-\\ning pixel-wise averages of plausible solutions which are\\ntypically overly-smooth and thus have poor perceptual qual-\\nity [42, 33, 13, 5]. Reconstructions of varying perceptual\\nFigure 3: Illustration of patches from the natural image\\nmanifold (red) and super-resolved patches obtained with\\nMSE (blue) and GAN (orange). The MSE-based solution\\nappears overly smooth due to the pixel-wise average of\\npossible solutions in the pixel space, while GAN drives the\\nreconstruction towards the natural image manifold produc-\\ning perceptually more convincing solutions.\\nquality are exempliﬁed with corresponding PSNR in Fig-\\nure 2. We illustrate the problem of minimizing MSE in Fig-\\nure 3 where multiple potential solutions with high texture\\ndetails are averaged to create a smooth reconstruction.\\nIn Mathieu et al. [42] and Denton et al. [7] the authors\\ntackled this problem by employing generative adversarial\\nnetworks (GANs) [22] for the application of image genera-\\ntion. Yu and Porikli [66] augment pixel-wise MSE loss with\\na discriminator loss to train a network that super-resolves\\nface images with large upscaling factors ( 8×). GANs']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Contextual Precision (ragas) (score: 0.9999999999857143, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Faithfulness (ragas) (score: 0.7, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Contextual Recall (ragas) (score: 1.0, threshold: 0.6, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Answer Relevancy (ragas) (score: 0.9235498532329823, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: In SRCNN, what practical role does the non‑linear mapping layer with 1 × 1 filters play in the overall SR pipeline?\n",
      "  - actual output: The non-linear mapping layer in SRCNN, which uses 1x1 filters, essentially acts as a feature selector and combiner within the super-resolution pipeline. Think of the initial layer as extracting a set of features from the low-resolution image. This second layer then takes these features and recombines them in non-linear ways to create a more informative and refined set of features. While 1x1 convolutions don't change the spatial dimensions, they allow the network to learn complex relationships between the different feature maps (different aspects of the visual information) extracted by the first layer. This step is crucial for capturing the intricate details needed to reconstruct a high-resolution image. The ReLU (Rectified Linear Unit, a function that replaces negative values with zero) activation further enhances this non-linearity, adding another level of expressiveness to the model.\n",
      "  - expected output: It transforms every patch‑level feature vector (extracted by the first conv layer) into a new, lower‑dimensional representation that will later be linearly combined into HR pixels. Because the spatial kernel is 1 × 1, the mapping is applied channel‑wise without mixing spatial positions, mimicking the sparse‑coding step but in a single feed‑forward pass.\n",
      "  - context: ['The first layer extracts an n₁‑dimensional feature for each patch. In the second operation, we **map each of these n₁‑dimensional vectors into an n₂‑dimensional one. This is equivalent to applying n₂ filters which have a trivial spatial support 1 × 1 … This operation non‑linearly maps each high‑dimensional vector onto another high‑dimensional vector.']\n",
      "  - retrieval context: ['In this paper, we show that the aforementioned\\npipeline is equivalent to a deep convolutional neural net-\\nwork [27] (more details in Section 3.2). Motivated by this\\nfact, we consider a convolutional neural network that\\ndirectly learns an end-to-end mapping between low- and\\nhigh-resolution images. Our method differs fundamen-\\ntally from existing external example-based approaches,\\nin that ours does not explicitly learn the dictionaries [41],\\n[49], [50] or manifolds [2], [4] for modeling the patch\\nspace. These are implicitly achieved via hidden layers.\\nFurthermore, the patch extraction and aggregation are\\nalso formulated as convolutional layers, so are involved\\nin the optimization. In our method, the entire SR pipeline\\nis fully obtained through learning, with little pre/post-\\nprocessing.\\nWe name the proposed model Super-Resolution Con-\\nvolutional Neural Network (SRCNN) 1. The proposed\\nSRCNN has several appealing properties. First, its struc-\\nture is intentionally designed with simplicity in mind,\\nand yet provides superior accuracy 2 compared with\\nstate-of-the-art example-based methods. Figure 1 shows\\na comparison on an example. Second, with moderate\\n1. The implementation is available at http://mmlab.ie.cuhk.edu.hk/\\nprojects/SRCNN.html.\\n2. Numerical evaluations by using different metrics such as the Peak\\nSignal-to-Noise Ratio (PSNR), structure similarity index (SSIM) [43],\\nmulti-scale SSIM [44], information ﬁdelity criterion [38], when the\\nground truth images are available.\\narXiv:1501.00092v3  [cs.CV]  31 Jul 2015\\n2\\nBicubic / 24.04 dB\\nSC / 25.58 dBSRCNN / 27.95 dB\\nOriginal / PSNR\\n2 4 6 8 10 12x 108\\n29.5\\n30\\n30.5\\n31\\n31.5\\n32\\n32.5\\n33\\nNumber of backprops\\nAverage test PSNR (dB)\\nSRCNN\\nSC\\nBicubic\\nBicubic / 24.04 dB\\nSC / 25.58 dBSRCNN / 27.95 dB\\nOriginal / PSNR\\nBicubic / 24.04 dB\\nSC / 25.58 dBSRCNN / 27.95 dB\\nOriginal / PSNR\\nSRCNN\\nSC\\nBicubic\\nBicubic / 24.04 dB\\nSC / 25.58 dBSRCNN / 27.95 dB\\nOriginal / PSNR\\nNumber of backprops\\nAverage test PSNR (dB)\\nFig. 1. The proposed Super-Resolution Convolutional\\nNeural Network (SRCNN) surpasses the bicubic baseline\\nwith just a few training iterations, and outperforms the\\nsparse-coding-based method (SC) [50] with moderate\\ntraining. The performance may be further improved with\\nmore training iterations. More details are provided in\\nSection 4.4.1 (the Set5 dataset with an upscaling factor\\n3). The proposed method provides visually appealing\\nreconstructed image.\\nnumbers of ﬁlters and layers, our method achieves\\nfast speed for practical on-line usage even on a CPU.\\nOur method is faster than a number of example-based\\nmethods, because it is fully feed-forward and does\\nnot need to solve any optimization problem on usage.\\nThird, experiments show that the restoration quality of\\nthe network can be further improved when (i) larger\\nand more diverse datasets are available, and/or (ii)\\na larger and deeper model is used. On the contrary,\\nlarger datasets/models can present challenges for exist-\\ning example-based methods. Furthermore, the proposed\\nnetwork can cope with three channels of color images\\nsimultaneously to achieve improved super-resolution\\nperformance.\\nOverall, the contributions of this study are mainly in\\nthree aspects:\\n1) We present a fully convolutional neural net-\\nwork for image super-resolution. The network di-\\nrectly learns an end-to-end mapping between low-\\nand high-resolution images, with little pre/post-\\nprocessing beyond the optimization.\\n2) We establish a relationship between our deep-\\nlearning-based SR method and the traditional\\nsparse-coding-based SR methods. This relationship\\nprovides a guidance for the design of the network\\nstructure.\\n3) We demonstrate that deep learning is useful in\\nthe classical computer vision problem of super-\\nresolution, and can achieve good quality and\\nspeed.\\nA preliminary version of this work was presented\\nearlier [11]. The present work adds to the initial version\\nin signiﬁcant ways. Firstly, we improve the SRCNN by\\nintroducing larger ﬁlter size in the non-linear mapping', 'the ﬁnal full image. The averaging can be considered\\nas a pre-deﬁned ﬁlter on a set of feature maps (where\\neach position is the “ﬂattened” vector form of a high-\\nresolution patch). Motivated by this, we deﬁne a convo-\\nlutional layer to produce the ﬁnal high-resolution image:\\nF(Y) = W3 ∗F2(Y) + B3. (3)\\n4. The ReLU can be equivalently considered as a part of the second\\noperation (Non-linear mapping), and the ﬁrst operation (Patch extrac-\\ntion and representation) becomes purely linear convolution.\\nHere W3 corresponds to c ﬁlters of a size n2 ×f3 ×f3,\\nand B3 is a c-dimensional vector.\\nIf the representations of the high-resolution patches\\nare in the image domain (i.e.,we can simply reshape each\\nrepresentation to form the patch), we expect that the\\nﬁlters act like an averaging ﬁlter; if the representations\\nof the high-resolution patches are in some other domains\\n(e.g.,coefﬁcients in terms of some bases), we expect that\\nW3 behaves like ﬁrst projecting the coefﬁcients onto the\\nimage domain and then averaging. In either way, W3 is\\na set of linear ﬁlters.\\nInterestingly, although the above three operations are\\nmotivated by different intuitions, they all lead to the\\nsame form as a convolutional layer. We put all three\\noperations together and form a convolutional neural\\nnetwork (Figure 2). In this model, all the ﬁltering weights\\nand biases are to be optimized. Despite the succinctness\\nof the overall structure, our SRCNN model is carefully\\ndeveloped by drawing extensive experience resulted\\nfrom signiﬁcant progresses in super-resolution [49], [50].\\nWe detail the relationship in the next section.\\n3.2 Relationship to Sparse-Coding-Based Methods\\nWe show that the sparse-coding-based SR methods [49],\\n[50] can be viewed as a convolutional neural network.\\nFigure 3 shows an illustration.\\nIn the sparse-coding-based methods, let us consider\\nthat an f1 ×f1 low-resolution patch is extracted from\\nthe input image. Then the sparse coding solver, like\\nFeature-Sign [29], will ﬁrst project the patch onto a (low-\\nresolution) dictionary. If the dictionary size is n1, this\\nis equivalent to applying n1 linear ﬁlters ( f1 ×f1) on\\nthe input image (the mean subtraction is also a linear\\noperation so can be absorbed). This is illustrated as the\\nleft part of Figure 3.\\nThe sparse coding solver will then iteratively process\\nthe n1 coefﬁcients. The outputs of this solver are n2\\ncoefﬁcients, and usually n2 = n1 in the case of sparse\\ncoding. These n2 coefﬁcients are the representation of\\nthe high-resolution patch. In this sense, the sparse coding\\n5\\nresponses\\nof patch of\\nneighbouring\\npatches\\n Patch extraction\\nand representation\\nNon-linear\\n mapping\\nReconstruction\\nFig. 3. An illustration of sparse-coding-based methods in the view of a convolutional neural network.\\nsolver behaves as a special case of a non-linear mapping\\noperator, whose spatial support is 1 ×1. See the middle\\npart of Figure 3. However, the sparse coding solver is\\nnot feed-forward, i.e.,it is an iterative algorithm. On the\\ncontrary, our non-linear operator is fully feed-forward\\nand can be computed efﬁciently. If we set f2 = 1, then\\nour non-linear operator can be considered as a pixel-wise\\nfully-connected layer. It is worth noting that “the sparse\\ncoding solver” in SRCNN refers to the ﬁrst two layers,\\nbut not just the second layer or the activation function\\n(ReLU). Thus the nonlinear operation in SRCNN is also\\nwell optimized through the learning process.\\nThe above n2 coefﬁcients (after sparse coding) are\\nthen projected onto another (high-resolution) dictionary\\nto produce a high-resolution patch. The overlapping\\nhigh-resolution patches are then averaged. As discussed\\nabove, this is equivalent to linear convolutions on the\\nn2 feature maps. If the high-resolution patches used for\\nreconstruction are of size f3 ×f3, then the linear ﬁlters\\nhave an equivalent spatial support of size f3 ×f3. See\\nthe right part of Figure 3.\\nThe above discussion shows that the sparse-coding-', 'only on the luminance channel. There are also works\\nattempting to super-resolve all channels simultaneously.\\nFor example, Kim and Kwon [25] and Dai et al.[7] apply\\ntheir model to each RGB channel and combined them to\\nproduce the ﬁnal results. However, none of them has\\nanalyzed the SR performance of different channels, and\\nthe necessity of recovering all three channels.\\n2.2 Convolutional Neural Networks\\nConvolutional neural networks (CNN) date back\\ndecades [27] and deep CNNs have recently shown an\\nexplosive popularity partially due to its success in image\\nclassiﬁcation [18], [26]. They have also been success-\\nfully applied to other computer vision ﬁelds, such as\\nobject detection [34], [40], [52], face recognition [39], and\\npedestrian detection [35]. Several factors are of central\\nimportance in this progress: (i) the efﬁcient training\\nimplementation on modern powerful GPUs [26], (ii) the\\nproposal of the Rectiﬁed Linear Unit (ReLU) [33] which\\nmakes convergence much faster while still presents good\\nquality [26], and (iii) the easy access to an abundance of\\ndata (like ImageNet [9]) for training larger models. Our\\nmethod also beneﬁts from these progresses.\\n2.3 Deep Learning for Image Restoration\\nThere have been a few studies of using deep learning\\ntechniques for image restoration. The multi-layer per-\\nceptron (MLP), whose all layers are fully-connected (in\\ncontrast to convolutional), is applied for natural image\\ndenoising [3] and post-deblurring denoising [36]. More\\nclosely related to our work, the convolutional neural net-\\nwork is applied for natural image denoising [22] and re-\\nmoving noisy patterns (dirt/rain) [12]. These restoration\\nproblems are more or less denoising-driven. Cui et al.[5]\\npropose to embed auto-encoder networks in their super-\\nresolution pipeline under the notion internal example-\\nbased approach [16]. The deep model is not speciﬁcally\\ndesigned to be an end-to-end solution, since each layer\\nof the cascade requires independent optimization of the\\nself-similarity search process and the auto-encoder. On\\nthe contrary, the proposed SRCNN optimizes an end-to-\\nend mapping. Further, the SRCNN is faster at speed. It\\nis not only a quantitatively superior method, but also a\\npractically useful one.\\n3 C ONVOLUTIONAL NEURAL NETWORKS FOR\\nSUPER -RESOLUTION\\n3.1 Formulation\\nConsider a single low-resolution image, we ﬁrst upscale\\nit to the desired size using bicubic interpolation, which\\nis the only pre-processing we perform 3. Let us denote\\nthe interpolated image as Y. Our goal is to recover\\nfrom Y an image F(Y) that is as similar as possible\\nto the ground truth high-resolution image X. For the\\nease of presentation, we still call Y a “low-resolution”\\nimage, although it has the same size as X. We wish to\\nlearn a mapping F, which conceptually consists of three\\noperations:\\n1) Patch extraction and representation: this opera-\\ntion extracts (overlapping) patches from the low-\\nresolution image Y and represents each patch as a\\nhigh-dimensional vector. These vectors comprise a\\nset of feature maps, of which the number equals to\\nthe dimensionality of the vectors.\\n2) Non-linear mapping: this operation nonlinearly\\nmaps each high-dimensional vector onto another\\nhigh-dimensional vector. Each mapped vector is\\nconceptually the representation of a high-resolution\\npatch. These vectors comprise another set of feature\\nmaps.\\n3) Reconstruction: this operation aggregates the\\nabove high-resolution patch-wise representations\\nto generate the ﬁnal high-resolution image. This\\nimage is expected to be similar to the ground truth\\nX.\\nWe will show that all these operations form a convolu-\\ntional neural network. An overview of the network is\\ndepicted in Figure 2. Next we detail our deﬁnition of\\neach operation.\\n3.1.1 Patch extraction and representation\\nA popular strategy in image restoration ( e.g., [1]) is to\\ndensely extract patches and then represent them by a set\\nof pre-trained bases such as PCA, DCT, Haar, etc. This', 'sparse-coding-based SR methods. This relationship\\nprovides a guidance for the design of the network\\nstructure.\\n3) We demonstrate that deep learning is useful in\\nthe classical computer vision problem of super-\\nresolution, and can achieve good quality and\\nspeed.\\nA preliminary version of this work was presented\\nearlier [11]. The present work adds to the initial version\\nin signiﬁcant ways. Firstly, we improve the SRCNN by\\nintroducing larger ﬁlter size in the non-linear mapping\\nlayer, and explore deeper structures by adding non-\\nlinear mapping layers. Secondly, we extend the SRCNN\\nto process three color channels (either in YCbCr or RGB\\ncolor space) simultaneously. Experimentally, we demon-\\nstrate that performance can be improved in comparison\\nto the single-channel network. Thirdly, considerable new\\nanalyses and intuitive explanations are added to the\\ninitial results. We also extend the original experiments\\nfrom Set5 [2] and Set14 [51] test images to BSD200 [32]\\n(200 test images). In addition, we compare with a num-\\nber of recently published methods and conﬁrm that\\nour model still outperforms existing approaches using\\ndifferent evaluation metrics.\\n2 R ELATED WORK\\n2.1 Image Super-Resolution\\nAccording to the image priors, single-image super res-\\nolution algorithms can be categorized into four types –\\nprediction models, edge based methods, image statistical\\nmethods and patch based (or example-based) methods.\\nThese methods have been thoroughly investigated and\\nevaluated in Yang et al.’s work [46]. Among them, the\\nexample-based methods [16], [25], [41], [47] achieve the\\nstate-of-the-art performance.\\nThe internal example-based methods exploit the self-\\nsimilarity property and generate exemplar patches from\\nthe input image. It is ﬁrst proposed in Glasner’s\\nwork [16], and several improved variants [13], [45] are\\nproposed to accelerate the implementation. The exter-\\nnal example-based methods [2], [4], [6], [15], [37], [41],\\n[48], [49], [50], [51] learn a mapping between low/high-\\nresolution patches from external datasets. These studies\\nvary on how to learn a compact dictionary or manifold\\nspace to relate low/high-resolution patches, and on how\\nrepresentation schemes can be conducted in such spaces.\\nIn the pioneer work of Freeman et al. [14], the dic-\\ntionaries are directly presented as low/high-resolution\\npatch pairs, and the nearest neighbour (NN) of the input\\npatch is found in the low-resolution space, with its corre-\\nsponding high-resolution patch used for reconstruction.\\nChang et al. [4] introduce a manifold embedding tech-\\nnique as an alternative to the NN strategy. In Yanget al.’s\\nwork [49], [50], the above NN correspondence advances\\nto a more sophisticated sparse coding formulation. Other\\nmapping functions such as kernel regression [25], simple\\n3\\nfunction [47], random forest [37] and anchored neigh-\\nborhood regression [41], [42] are proposed to further\\nimprove the mapping accuracy and speed. The sparse-\\ncoding-based method and its several improvements [41],\\n[42], [48] are among the state-of-the-art SR methods\\nnowadays. In these methods, the patches are the focus\\nof the optimization; the patch extraction and aggregation\\nsteps are considered as pre/post-processing and handled\\nseparately.\\nThe majority of SR algorithms [2], [4], [15], [41], [48],\\n[49], [50], [51] focus on gray-scale or single-channel\\nimage super-resolution. For color images, the aforemen-\\ntioned methods ﬁrst transform the problem to a dif-\\nferent color space (YCbCr or YUV), and SR is applied\\nonly on the luminance channel. There are also works\\nattempting to super-resolve all channels simultaneously.\\nFor example, Kim and Kwon [25] and Dai et al.[7] apply\\ntheir model to each RGB channel and combined them to\\nproduce the ﬁnal results. However, none of them has\\nanalyzed the SR performance of different channels, and\\nthe necessity of recovering all three channels.\\n2.2 Convolutional Neural Networks\\nConvolutional neural networks (CNN) date back', '1\\nImage Super-Resolution Using Deep\\nConvolutional Networks\\nChao Dong, Chen Change Loy, Member, IEEE,Kaiming He, Member, IEEE,\\nand Xiaoou Tang, Fellow, IEEE\\nAbstract—We propose a deep learning method for single image super-resolution (SR). Our method directly learns an end-to-end\\nmapping between the low/high-resolution images. The mapping is represented as a deep convolutional neural network (CNN) that takes\\nthe low-resolution image as the input and outputs the high-resolution one. We further show that traditional sparse-coding-based SR\\nmethods can also be viewed as a deep convolutional network. But unlike traditional methods that handle each component separately,\\nour method jointly optimizes all layers. Our deep CNN has a lightweight structure, yet demonstrates state-of-the-art restoration quality,\\nand achieves fast speed for practical on-line usage. We explore different network structures and parameter settings to achieve trade-\\noffs between performance and speed. Moreover, we extend our network to cope with three color channels simultaneously, and show\\nbetter overall reconstruction quality.\\nIndex Terms—Super-resolution, deep convolutional neural networks, sparse coding\\n!\\n1 I NTRODUCTION\\nSingle image super-resolution (SR) [20], which aims at\\nrecovering a high-resolution image from a single low-\\nresolution image, is a classical problem in computer\\nvision. This problem is inherently ill-posed since a mul-\\ntiplicity of solutions exist for any given low-resolution\\npixel. In other words, it is an underdetermined in-\\nverse problem, of which solution is not unique. Such\\na problem is typically mitigated by constraining the\\nsolution space by strong prior information. To learn\\nthe prior, recent state-of-the-art methods mostly adopt\\nthe example-based [46] strategy. These methods either\\nexploit internal similarities of the same image [5], [13],\\n[16], [19], [47], or learn mapping functions from external\\nlow- and high-resolution exemplar pairs [2], [4], [6],\\n[15], [23], [25], [37], [41], [42], [47], [48], [50], [51]. The\\nexternal example-based methods can be formulated for\\ngeneric image super-resolution, or can be designed to\\nsuit domain speciﬁc tasks, i.e., face hallucination [30],\\n[50], according to the training samples provided.\\nThe sparse-coding-based method [49], [50] is one of the\\nrepresentative external example-based SR methods. This\\nmethod involves several steps in its solution pipeline.\\nFirst, overlapping patches are densely cropped from the\\ninput image and pre-processed ( e.g.,subtracting mean\\nand normalization). These patches are then encoded\\nby a low-resolution dictionary. The sparse coefﬁcients\\nare passed into a high-resolution dictionary for recon-\\nstructing high-resolution patches. The overlapping re-\\n• C. Dong, C. C. Loy and X. Tang are with the Department of Information\\nEngineering, The Chinese University of Hong Kong, Hong Kong.\\nE-mail: {dc012,ccloy,xtang}@ie.cuhk.edu.hk\\n• K. He is with the Visual Computing Group, Microsoft Research Asia,\\nBeijing 100080, China.\\nEmail: kahe@microsoft.com\\nconstructed patches are aggregated ( e.g., by weighted\\naveraging) to produce the ﬁnal output. This pipeline is\\nshared by most external example-based methods, which\\npay particular attention to learning and optimizing the\\ndictionaries [2], [49], [50] or building efﬁcient mapping\\nfunctions [25], [41], [42], [47]. However, the rest of the\\nsteps in the pipeline have been rarely optimized or\\nconsidered in an uniﬁed optimization framework.\\nIn this paper, we show that the aforementioned\\npipeline is equivalent to a deep convolutional neural net-\\nwork [27] (more details in Section 3.2). Motivated by this\\nfact, we consider a convolutional neural network that\\ndirectly learns an end-to-end mapping between low- and\\nhigh-resolution images. Our method differs fundamen-\\ntally from existing external example-based approaches,\\nin that ours does not explicitly learn the dictionaries [41],\\n[49], [50] or manifolds [2], [4] for modeling the patch', 'bicubic interpolation. The training falls into a bad local\\nminimum, due to the inherently different characteristics\\nof the Y and Cb, Cr channels. (ii) If we pre-train on the\\nY or Cb, Cr channels, the performance ﬁnally improves,\\nbut is still not better than “Y only” on the color image\\n(see the last column of Table 5, where PSNR is computed\\n(a) First-layer ﬁlters – Cb channel\\n(b) First-layer ﬁlters – Cr channel\\nFig. 13. Chrominance channels of the ﬁrst-layer ﬁlters\\nusing the “Y pre-train” strategy.\\nin RGB color space). This suggests that the Cb, Cr\\nchannels could decrease the performance of the Y chan-\\nnel when training is performed in a uniﬁed network.\\n(iii) We observe that the Cb, Cr channels have higher\\nPSNR values for “Y pre-train” than for “CbCr pre-train”.\\nThe reason lies on the differences between the Cb, Cr\\nchannels and the Y channel. Visually, the Cb, Cr channels\\nare more blurry than the Y channel, thus are less affected\\nby the downsampling process. When we pre-train on\\nthe Cb, Cr channels, there are only a few ﬁlters being\\nactivated. Then the training will soon fall into a bad\\nlocal minimum during ﬁne-tuning. On the other hand,\\nif we pre-train on the Y channel, more ﬁlters will be\\nactivated, and the performance on Cb, Cr channels will\\nbe pushed much higher. Figure 13 shows the Cb, Cr\\nchannels of the ﬁrst-layer ﬁlters with “Y pre-train”, of\\nwhich the patterns largely differ from that shown in\\nFigure 5. (iv) Training on the RGB channels achieves\\nthe best result on the color image. Different from the\\nYCbCr channels, the RGB channels exhibit high cross-\\ncorrelation among each other. The proposed SRCNN\\nis capable of leveraging such natural correspondences\\nbetween the channels for reconstruction. Therefore, the\\nmodel achieves comparable result on the Y channel as\\n“Y only”, and better results on Cb, Cr channels than\\nbicubic interpolation. (v) In KK [25], super-resolution\\nis applied on each RGB channel separately. When we\\ntransform its results to YCbCr space, the PSNR value\\nof Y channel is similar as “Y only”, but that of Cb, Cr\\nchannels are poorer than bicubic interpolation. The result\\nsuggests that the algorithm is biased to the Y channel.\\nOn the whole, our method trained on RGB channels\\nachieves better performance than KK and the single-\\nchannel network (“Y only”). It is also worth noting that\\nthe improvement compared with the single-channel net-\\nwork is not that signiﬁcant ( i.e., 0.07 dB). This indicates\\nthat the Cb, Cr channels barely help in improving the\\nperformance.\\n5 C ONCLUSION\\nWe have presented a novel deep learning approach\\nfor single image super-resolution (SR). We show that\\nconventional sparse-coding-based SR methods can be\\n12\\nreformulated into a deep convolutional neural network.\\nThe proposed approach, SRCNN, learns an end-to-end\\nmapping between low- and high-resolution images, with\\nlittle extra pre/post-processing beyond the optimization.\\nWith a lightweight structure, the SRCNN has achieved\\nsuperior performance than the state-of-the-art methods.\\nWe conjecture that additional performance can be further\\ngained by exploring more ﬁlters and different training\\nstrategies. Besides, the proposed structure, with its ad-\\nvantages of simplicity and robustness, could be applied\\nto other low-level vision problems, such as image de-\\nblurring or simultaneous SR+denoising. One could also\\ninvestigate a network to cope with different upscaling\\nfactors.\\nREFERENCES\\n[1] Aharon, M., Elad, M., Bruckstein, A.: K-SVD: An algorithm for\\ndesigning overcomplete dictionaries for sparse representation.\\nIEEE Transactions on Signal Processing 54(11), 4311–4322 (2006)\\n[2] Bevilacqua, M., Roumy, A., Guillemot, C., Morel, M.L.A.: Low-\\ncomplexity single-image super-resolution based on nonnegative\\nneighbor embedding. In: British Machine Vision Conference\\n(2012)\\n[3] Burger, H.C., Schuler, C.J., Harmeling, S.: Image denoising: Can\\nplain neural networks compete with BM3D? In: IEEE Conference', 'to generate the ﬁnal high-resolution image. This\\nimage is expected to be similar to the ground truth\\nX.\\nWe will show that all these operations form a convolu-\\ntional neural network. An overview of the network is\\ndepicted in Figure 2. Next we detail our deﬁnition of\\neach operation.\\n3.1.1 Patch extraction and representation\\nA popular strategy in image restoration ( e.g., [1]) is to\\ndensely extract patches and then represent them by a set\\nof pre-trained bases such as PCA, DCT, Haar, etc. This\\nis equivalent to convolving the image by a set of ﬁlters,\\neach of which is a basis. In our formulation, we involve\\nthe optimization of these bases into the optimization of\\nthe network. Formally, our ﬁrst layer is expressed as an\\noperation F1:\\nF1(Y) = max (0,W1 ∗Y + B1) , (1)\\nwhere W1 and B1 represent the ﬁlters and biases re-\\nspectively, and ’ ∗’ denotes the convolution operation.\\nHere, W1 corresponds to n1 ﬁlters of support c×f1 ×f1,\\nwhere c is the number of channels in the input image,\\nf1 is the spatial size of a ﬁlter. Intuitively, W1 applies\\nn1 convolutions on the image, and each convolution has\\n3. Bicubic interpolation is also a convolutional operation, so it can\\nbe formulated as a convolutional layer. However, the output size of\\nthis layer is larger than the input size, so there is a fractional stride. To\\ntake advantage of the popular well-optimized implementations such\\nas cuda-convnet [26], we exclude this “layer” from learning.\\n4\\nfeature maps\\n Patch extraction\\nand representation Non-linear mapping Reconstruction\\nLow-resolution\\nimage (input)\\nHigh-resolution\\nimage (output)\\nof low-resolution image of high-resolution image\\nfeature maps\\nFig. 2. Given a low-resolution image Y, the ﬁrst convolutional layer of the SRCNN extracts a set of feature maps. The\\nsecond layer maps these feature maps nonlinearly to high-resolution patch representations. The last layer combines\\nthe predictions within a spatial neighbourhood to produce the ﬁnal high-resolution image F(Y).\\na kernel size c ×f1 ×f1. The output is composed of\\nn1 feature maps. B1 is an n1-dimensional vector, whose\\neach element is associated with a ﬁlter. We apply the\\nRectiﬁed Linear Unit (ReLU, max(0,x)) [33] on the ﬁlter\\nresponses4.\\n3.1.2 Non-linear mapping\\nThe ﬁrst layer extracts an n1-dimensional feature for\\neach patch. In the second operation, we map each of\\nthese n1-dimensional vectors into an n2-dimensional\\none. This is equivalent to applying n2 ﬁlters which have\\na trivial spatial support 1 ×1. This interpretation is only\\nvalid for 1×1 ﬁlters. But it is easy to generalize to larger\\nﬁlters like 3 ×3 or 5 ×5. In that case, the non-linear\\nmapping is not on a patch of the input image; instead,\\nit is on a 3 ×3 or 5 ×5 “patch” of the feature map. The\\noperation of the second layer is:\\nF2(Y) = max (0,W2 ∗F1(Y) + B2) . (2)\\nHere W2 contains n2 ﬁlters of size n1 ×f2 ×f2, and B2 is\\nn2-dimensional. Each of the output n2-dimensional vec-\\ntors is conceptually a representation of a high-resolution\\npatch that will be used for reconstruction.\\nIt is possible to add more convolutional layers to\\nincrease the non-linearity. But this can increase the com-\\nplexity of the model ( n2 ×f2 ×f2 ×n2 parameters for\\none layer), and thus demands more training time. We\\nwill explore deeper structures by introducing additional\\nnon-linear mapping layers in Section 4.3.3.\\n3.1.3 Reconstruction\\nIn the traditional methods, the predicted overlapping\\nhigh-resolution patches are often averaged to produce\\nthe ﬁnal full image. The averaging can be considered\\nas a pre-deﬁned ﬁlter on a set of feature maps (where\\neach position is the “ﬂattened” vector form of a high-\\nresolution patch). Motivated by this, we deﬁne a convo-\\nlutional layer to produce the ﬁnal high-resolution image:\\nF(Y) = W3 ∗F2(Y) + B3. (3)\\n4. The ReLU can be equivalently considered as a part of the second\\noperation (Non-linear mapping), and the ﬁrst operation (Patch extrac-\\ntion and representation) becomes purely linear convolution.', 'erations, ηis the learning rate, and ∂L\\n∂W ℓ\\ni\\nis the derivative.\\nThe ﬁlter weights of each layer are initialized by drawing\\nrandomly from a Gaussian distribution with zero mean\\nand standard deviation 0.001 (and 0 for biases). The\\nlearning rate is 10−4 for the ﬁrst two layers, and 10−5 for\\nthe last layer. We empirically ﬁnd that a smaller learning\\nrate in the last layer is important for the network to\\nconverge (similar to the denoising case [22]).\\nIn the training phase, the ground truth images {Xi}\\nare prepared as fsub×fsub×c-pixel sub-images randomly\\ncropped from the training images. By “sub-images” we\\nmean these samples are treated as small “images” rather\\nthan “patches”, in the sense that “patches” are overlap-\\nping and require some averaging as post-processing but\\n“sub-images” need not. To synthesize the low-resolution\\nsamples {Yi}, we blur a sub-image by a Gaussian kernel,\\nsub-sample it by the upscaling factor, and upscale it by\\nthe same factor via bicubic interpolation.\\nTo avoid border effects during training, all the con-\\nvolutional layers have no padding, and the network\\nproduces a smaller output ( (fsub −f1 −f2 −f3 + 3)2 ×c).\\nThe MSE loss function is evaluated only by the difference\\nbetween the central pixels of Xi and the network output.\\nAlthough we use a ﬁxed image size in training, the\\nconvolutional neural network can be applied on images\\nof arbitrary sizes during testing.\\nWe implement our model using the cuda-convnet pack-\\nage [26]. We have also tried the Caffe package [24] and\\nobserved similar performance.\\n4 E XPERIMENTS\\nWe ﬁrst investigate the impact of using different datasets\\non the model performance. Next, we examine the ﬁlters\\nlearned by our approach. We then explore different\\narchitecture designs of the network, and study the rela-\\ntions between super-resolution performance and factors\\nlike depth, number of ﬁlters, and ﬁlter sizes. Subse-\\nquently, we compare our method with recent state-of-\\nthe-arts both quantitatively and qualitatively. Following\\n[42], super-resolution is only applied on the luminance\\nchannel (Y channel in YCbCr color space) in Sections 4.1-\\n4.4, so c = 1 in the ﬁrst/last layer, and performance\\n(e.g., PSNR and SSIM) is evaluated on the Y channel. At\\nlast, we extend the network to cope with color images\\nand evaluate the performance on different channels.\\n4.1 Training Data\\nAs shown in the literature, deep learning generally\\nbeneﬁts from big data training. For comparison, we use\\na relatively small training set [41], [50] that consists\\nof 91 images, and a large training set that consists of\\n395,909 images from the ILSVRC 2013 ImageNet detec-\\ntion training partition. The size of training sub-images is\\nfsub = 33. Thus the 91-image dataset can be decomposed\\ninto 24,800 sub-images, which are extracted from origi-\\nnal images with a stride of 14. Whereas the ImageNet\\nprovides over 5 million sub-images even using a stride\\nof 33. We use the basic network settings, i.e., f1 = 9 ,\\nf2 = 1, f3 = 5, n1 = 64, and n2 = 32. We use the Set5 [2]\\nas the validation set. We observe a similar trend even\\nif we use the larger Set14 set [51]. The upscaling factor\\nis 3. We use the sparse-coding-based method [50] as our\\nbaseline, which achieves an average PSNR value of 31.42\\ndB.\\nThe test convergence curves of using different training\\nsets are shown in Figure 4. The training time on Ima-\\ngeNet is about the same as on the 91-image dataset since\\nthe number of backpropagations is the same. As can be\\nobserved, with the same number of backpropagations\\n(i.e.,8 ×108), the SRCNN +ImageNet achieves 32.52 dB,\\nhigher than 32.39 dB yielded by that trained on 91\\nimages. The results positively indicate that SRCNN per-\\nformance may be further boosted using a larger training\\nset, but the effect of big data is not as impressive as\\nthat shown in high-level vision problems [26]. This is\\nmainly because that the 91 images have already cap-\\ntured sufﬁcient variability of natural images. On the']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ❌ Contextual Precision (ragas) (score: nan, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Faithfulness (ragas) (score: 1.0, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Contextual Recall (ragas) (score: 1.0, threshold: 0.6, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Answer Relevancy (ragas) (score: 0.9088756639681352, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: What systemic risks do the authors foresee if many firms deploy similarly prompted LLM traders in real markets?\n",
      "  - actual output: The authors are concerned that if many trading firms use similarly prompted Large Language Model (LLM) based trading agents, it could lead to increased systemic risk in financial markets. Specifically, they highlight the risk of correlated behavior: because these agents would be built on similar underlying architectures and responding to the same market signals in similar ways (due to similar prompts), they might make the same trading decisions at the same time. This could amplify market instability, potentially causing:\n",
      "\n",
      "Exaggerated Price Swings: If many LLMs simultaneously decide to buy or sell a particular asset, it could lead to larger-than-normal price increases or decreases, increasing market volatility.\n",
      "\n",
      "Flash Crashes: In extreme cases, this correlated selling could create a sudden, sharp drop in prices, similar to a flash crash.\n",
      "\n",
      "Bubble Formation and Bursting: Similarly, correlated buying by many LLMs could inflate asset bubbles, which could then burst dramatically when the LLMs decide to sell. This is especially risky because the LLMs might continue to follow their instructions even when a bubble is forming, unlike human traders who might recognize the bubble and adjust their strategy.\n",
      "  - expected output: If many firms deploy similarly prompted LLMs built on the same foundation model, their synchronised reactions could amplify volatility and create new instabilities.\n",
      "  - context: ['A key concern is the potential for widespread correlated behavior… similar underlying LLM architectures responding uniformly… could destabilize trading patterns without explicit coordination.']\n",
      "  - retrieval context: ['2024). Another examines LLMs’ strategic capabilities through task-based simulations and\\ncollaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\\nWithin the computer science literature, early works apply LLMs to financial markets but\\nabstract away many fundamental stock market characteristics. Often, they employ single-\\nprice clearing mechanisms without a persistent order book, ignore partial fills and bid-ask\\nspreads, and omit dividends. Consequently, these simplified environments can primarily\\naddress exogenous macro shocks (e.g., changes in interest rates or inflation; Gao et al. 2024),\\nexogenous policy changes (Zhang et al. 2024), or rely on advanced methods such as repetitive\\nnext-token predictions to generate better answers (Koa et al. 2024). This work extends\\nthese efforts by incorporating these crucial market features, enabling the study of complex\\nendogenous events such as flash crashes, liquidity shocks, and large-trader impacts.\\nThis work also connects to emerging research on algorithmic and AI-powered trading\\nsystems. Dou, Goldstein, and Ji (2024) demonstrate how reinforcement learning-based AI\\nspeculators can autonomously learn to sustain collusive behavior without explicit coordi-\\nnation, achieving supra-competitive profits through either price-trigger strategies or self-\\nconfirming bias in learning. This finding is particularly informative for this framework as\\nit highlights potential emergent behaviors that may arise when intelligent agents interact in\\n7\\nmarkets—behaviors that could manifest differently with LLM agents due to their natural\\nlanguage reasoning capabilities. Similarly, Colliard, Foucault, and Lovo (2022) examine al-\\ngorithmic market makers using Q-learning and find they charge markups that increase when\\nadverse selection costs decrease—contrary to Nash equilibrium predictions. Their work pro-\\nvides methodological insights on how to test strategic pricing behaviors against theoretical\\nbenchmarks incorporated into this LLM-based framework.\\nFinally, this approach is informed by complexity economics, which views markets as dy-\\nnamic, non-equilibrium systems where agents adaptively learn and evolve strategies (Arthur\\n2013; Wolfram 2017). According to this view, markets exhibit emergent phenomena and\\nself-organization, especially when trading agents (human or artificial) update their behav-\\nior in response to outcomes. This paradigm is particularly relevant in an era of increasing\\nautomation and algorithmic trading (Balland et al. 2022; Ping 2019). Like adaptive agents\\nin complexity economics, these LLM traders incorporate new information and adjust their\\nstrategies, generating emergent market patterns—a key motivation behind this framework.\\nUnlike previous frameworks that abstract away crucial market features or focus on narrow\\nstrategies, this system incorporates realistic market microstructure while accommodating\\nheterogeneous agents interacting simultaneously. While earlier work demonstrates LLMs’\\npromise for macroeconomic modeling and simple trading simulations, this work introduces a\\ncomplex, open-source financial market platform that supports multiple agent architectures,\\nthorough market microstructure (limit orders, partial fills, dividends), and rigorous testing\\nprotocols—fulfilling a critical need in complexity economics research and market microstruc-\\nture analysis.\\n2 Methodology\\nThe methodology section contains three parts. The first part describes the market design,\\nthe second agents’ design, and the third the analysis module.\\n8\\n2.1 Market Design\\nOur methodological framework integrates three components that create a controlled envi-\\nronment for LLM-based trading agents. The framework implements a flexible continuous\\ndouble-auction market mechanism that couples standard market microstructure principles\\nwith market clearing and matching algorithms to accommodate asynchronous LLM decisions.', 'Can Large Language Models Trade? Testing Financial\\nTheories with LLM Agents in Market Simulations\\nAlejandro Lopez-Lira∗\\nFirst Version: November 29, 2024; Current Version: April 16, 2025\\nAbstract\\nThis paper presents a realistic simulated stock market where large language models\\n(LLMs) act as heterogeneous competing trading agents. The open-source framework\\nincorporates a persistent order book with market and limit orders, partial fills, div-\\nidends, and equilibrium clearing alongside agents with varied strategies, information\\nsets, and endowments. Agents submit standardized decisions using structured outputs\\nand function calls while expressing their reasoning in natural language. Three findings\\nemerge: First, LLMs demonstrate consistent strategy adherence and can function as\\nvalue investors, momentum traders, or market makers per their instructions. Second,\\nmarket dynamics exhibit features of real financial markets, including price discovery,\\nbubbles, underreaction, and strategic liquidity provision. Third, the framework enables\\nanalysis of LLMs’ responses to varying market conditions, similar to partial dependence\\nplots in machine-learning interpretability. The framework allows simulating financial\\ntheories without closed-form solutions, creating experimental designs that would be\\ncostly with human participants, and establishing how prompts can generate correlated\\nbehaviors affecting market stability.\\nKeywords: LLM Agents; Agent-Based Markets; Experimental Finance; AI Trading;\\nMulti-Agent Systems\\n∗University of Florida. Email: alejandro.lopez-lira@warrington.ufl.edu. I am grateful to seminar par-\\nticipants at the London Business School, Oxford University, Stockholm School of Economics, University of\\nVirginia, and the City University of Hong Kong for helpful suggestions and feedback.\\n1\\narXiv:2504.10789v1  [q-fin.CP]  15 Apr 2025\\n1 Introduction\\nLarge language models (LLMs) can increasingly function as autonomous agents—systems\\nthat observe, reason, and act independently. LLMs have shown promising results in finan-\\ncial forecasting, but their potential as trading agents introduces a fundamental shift from\\nalgorithms with explicit objectives to systems guided by natural language instructions. This\\nchange raises critical questions: Can LLMs execute trading strategies? Do LLMs optimize\\nfor profit maximization? What are the implications for market stability and efficiency?\\nIf LLMs trade similarly to humans, they could enable experimental market simulations\\nwithout human participants. Conversely, if their trading behavior differs, understanding\\nthese differences becomes critical for systemic risk management. These questions extend be-\\nyond theory; LLM-based strategies are already being deployed.1 To address these questions,\\nI develop an open-source simulation that tests LLM trading agents in a realistic market envi-\\nronment with a persistent order book, supporting various order types, stochastic dividends,\\nand heterogeneous information.\\nThe framework allows heterogeneous LLMs—defined in natural language, using different\\nsystem prompts—to act as diverse types of traders, such as value investors, momentum\\ntraders, market makers, and contrarians. Agents submit standardized trading decisions in a\\nhuman-readable format while expressing their reasoning transparently. Figure 1 illustrates\\nthis approach, showing how a speculator agent combines explicit valuation reasoning with\\nstructured trading parameters, enabling systematic analysis and insight into the agent’s\\ndecision-making process.\\nThe analysis reveals three key findings about LLMs’ capabilities as trading agents. First,\\nLLMs can effectively execute trading strategies. They consistently understand market me-\\nchanics, process market information, form price expectations, and execute trades according\\nto specific instructions. Their trading behavior is highly sensitive to the prompts they\\nreceive—they faithfully follow directions regardless of profit implications. This observance', 'ripe for investigation using this tool include the emergence of novel trading strategies, the\\nprecise effects of agent heterogeneity on market stability, and the development of robust\\nvalidation protocols for AI traders. As artificial intelligence becomes more integrated into\\nfinance, collaborative research leveraging adaptable simulation environments like this one\\nwill be crucial for understanding and responsibly shaping the future of trading.\\n35\\nReferences\\nArthur, W. Brian. 2013. “Complexity Economics : A Different Framework for Economic\\nThought.”\\nBabina, Tania, Anastassia Fedyk, Alex He, and James Hodson. 2024. “Artificial Intelli-\\ngence, Firm Growth, and Product Innovation.” Journal of Financial Economics 151\\n(January 1, 2024): 103745.\\nBalland, Pierre-Alexandre, Tom Broekel, Dario Diodato, Elisa Giuliani, Ricardo Hausmann,\\nNeave O’Clery, and David Rigby. 2022. “The New Paradigm of Economic Complexity.”\\nResearch Policy51, no. 3 (April): 104450.\\nBianchi, Federico, Patrick John Chia, Mert Yuksekgonul, Jacopo Tagliabue, Dan Jurafsky,\\nand James Zou. 2024. “How Well Can LLMs Negotiate? NegotiationArena Platform and\\nAnalysis.” arXiv.org.\\nBybee, J. Leland. 2023. “The Ghost in the Machine: Generating Beliefs with Large Language\\nModels.” arXiv: 2305.02823.\\nCampello, Murillo, Lin William Cong, and Luofeng Zhou. 2023. “AlphaManager: A Data-\\nDriven-Robust-Control Approach to Corporate Finance.” Pre-published, December 2,\\n2023. SSRN Scholarly Paper. Accessed December 22, 2024. https://doi.org/10.2139/\\nssrn.4590323. Social Science Research Network: 4590323. https://papers.ssrn.com/\\nabstract=4590323.\\nChen, Yifei, Bryan T. Kelly, and Dacheng Xiu. 2022. “Expected Returns and Large Lan-\\nguage Models.” Pre-published, November 22, 2022. SSRN Scholarly Paper. Accessed\\nJanuary 26, 2025. Social Science Research Network: 4416687. https://papers.ssrn.com/\\nabstract=4416687.\\n36\\nChen, Zihan, Lei Zheng, Chengyu Lu, Jialu Yuan, and Di Zhu. 2023. “ChatGPT Informed\\nGraph Neural Network for Stock Movement Prediction.” Social Science Research Net-\\nwork.\\nChuang, Yun-Shiuan, Agam Goyal, Nikunj Harlalka, Siddharth Suresh, Robert Hawkins,\\nSijia Yang, Dhavan Shah, Junjie Hu, and Timothy T. Rogers. 2023. “Simulating Opin-\\nion Dynamics with Networks of LLM-based Agents.” North American Chapter of the\\nAssociation for Computational Linguistic s.\\nColliard, Jean-Edouard, Thierry Foucault, and Stefano Lovo. 2022. “Algorithmic Pricing\\nand Liquidity in Securities Markets.” Pre-published, October 18, 2022. SSRN Scholarly\\nPaper. Accessed April 4, 2025. https://doi.org/10.2139/ssrn.4252858. Social Science\\nResearch Network: 4252858. https://papers.ssrn.com/abstract=4252858.\\nCong, Lin William, Ke Tang, Jingyuan Wang, and Yang Zhang. 2021. “AlphaPortfolio:\\nDirect Construction Through Deep Reinforcement Learning and Interpretable AI.” Pre-\\npublished, August 1, 2021. SSRN Scholarly Paper. Accessed December 22, 2024. https:\\n//doi.org/10.2139/ssrn.3554486. Social Science Research Network: 3554486. https:\\n//papers.ssrn.com/abstract=3554486.\\nDou, Winston Wei, Itay Goldstein, and Yan Ji. 2024. “AI-Powered Trading, Algorithmic\\nCollusion, and Price Efficiency.” Pre-published, May 30, 2024. SSRN Scholarly Paper.\\nAccessed April 4, 2025. https://doi.org/10.2139/ssrn.4452704. Social Science Research\\nNetwork: 4452704. https://papers.ssrn.com/abstract=4452704.\\nEisfeldt, Andrea L., Gregor Schubert, Miao Ben Zhang, and Bledi Taska. 2023. “Generative\\nAI and Firm Values.” Pre-published, May 2, 2023. SSRN Scholarly Paper. Accessed\\nJanuary 26, 2025. https : / / doi .org / 10 .2139 / ssrn . 4436627. Social Science Research\\nNetwork: 4436627. https://papers.ssrn.com/abstract=4436627.\\n37\\nGao, Shen, Yuntao Wen, Minghang Zhu, Jianing Wei, Yuhan Cheng, Qunzi Zhang, and Shuo\\nShang. 2024. “Simulating Financial Market via Large Language Model Based Agents.”\\nPre-published, June 28, 2024. Accessed January 26, 2025. https://doi.org/10.48550/', '33\\nants, allowing researchers to study how different belief structures influence price formation\\nand trading patterns under different initial mispricings. In these scenarios, the fundamental\\nprice is hidden from agents, forcing them to rely on their own valuation models.\\n3.2.5 Market Stress\\nThis scenario tests market resilience under challenging conditions by creating a more volatile\\nenvironment. The scenario includes two consistently bullish Optimistic traders, two consis-\\ntently bearish Pessimistic traders, two Market makers (liquidity providers), and two Value\\ninvestors (rational benchmark traders). The scenario runs for 100 rounds to study long-term\\nmarket behavior and includes unequal initial endowments, with optimistic traders having\\nmore cash (1.5x baseline) but fewer shares (0.5x baseline) and pessimistic traders having less\\ncash (0.5x baseline) but more shares (1.5x baseline). This resource imbalance tests whether\\nparticular agent types can dominate market outcomes through resource advantages.\\nThe scenarios presented here demonstrate the framework’s capabilities for exploring di-\\nverse market conditions. Its modular structure facilitates the straightforward definition and\\nimplementation of alternative experimental designs, enabling researchers to tailor simulations\\nto specific research questions.\\nIn all scenarios, we maintain consistent baseline parameters with a fundamental value\\nof $28.00, calculated from the expected dividend of $1.40 and interest rate of 5%. Agent\\nendowments start at 1,000,000 monetary units and 10,000 shares unless specifically modified.\\nTransaction costs are set to zero to isolate the effects of agent behavior and market structure\\non price formation.\\n4 Conclusion\\nThis paper demonstrates that Large Language Models can effectively function as diverse\\ntrading agents—from value investors to market makers—maintaining strategic consistency\\n34\\nwhile adapting to market conditions. Our experimental framework reveals that their in-\\nteractions generate realistic market dynamics, including phenomena like price bubbles and\\ncorrections, highlighting both the capabilities and potential risks of deploying LLM agents\\nin financial markets.\\nThese findings carry significant implications for market structure and regulation. While\\nLLM agents can enhance price discovery and liquidity, their adherence to programmed strate-\\ngies, even potentially flawed ones derived from prompts, could amplify market volatility or\\nintroduce novel systemic risks, as observed in our simulated bubble scenarios. A key concern\\nis the potential for widespread correlated behavior: similar underlying LLM architectures\\nresponding uniformly to comparable prompts or market signals could inadvertently create\\ndestabilizing trading patterns without explicit coordination. This underscores the critical\\nneed for rigorous testing and validation of LLM-based trading systems prior to live deploy-\\nment.\\nA central contribution of this work is the open-source simulation framework itself, de-\\nsigned to catalyze research into LLM trading agents. We invite the research community to\\nutilize and extend this platform to investigate pressing questions in this rapidly evolving\\narea. The framework enables systematic exploration of complex scenarios—such as hybrid\\nhuman-LLM markets, stress tests, varying market structures, regulatory impacts, and the\\nnuances of LLM prompting—often difficult or costly to study otherwise. Specific avenues\\nripe for investigation using this tool include the emergence of novel trading strategies, the\\nprecise effects of agent heterogeneity on market stability, and the development of robust\\nvalidation protocols for AI traders. As artificial intelligence becomes more integrated into\\nfinance, collaborative research leveraging adaptable simulation environments like this one\\nwill be crucial for understanding and responsibly shaping the future of trading.\\n35\\nReferences', '(2023)). This work, however, focuses on financial markets and how LLM agents can operate\\nas full-fledged trading participants.\\nRecent research examines specific applications of LLMs for trading. FinMem and Trad-\\ningGPT introduce frameworks with layered memory systems and customizable agent traits\\n5\\nto improve financial decision-making (Yu, Li, et al. 2024; Li, Zhang, and Sun 2023). Hierar-\\nchical multi-agent architectures have been explored in FinCon, which uses a manager-analyst\\nsetup for collaborative portfolio decisions (Yu, Yao, et al. 2024). QuantAgent implements\\na self-improving signal-mining approach (Wang et al. 2024), while other work underscores\\nthe importance of long-term memory in LLM agents via vector databases (Hatalis et al.\\n2024). This line of research builds on successful reinforcement learning applications such as\\nAlphaPortfolio (Cong et al. 2021) and AlphaManager (Campello, Cong, and Zhou 2023),\\nwhich leverage deep RL and robust control for portfolio management.\\nAnalyzing LLM agent behavior by changing only some parameters draws on methods\\nfrom the interpretable machine learning literature. In particular, the systematic variation\\nof market parameters to reveal decision patterns mirrors partial dependence plots and in-\\ndividual conditional expectation curves used to interpret complex machine learning models\\n(Molnar 2022). These techniques help reveal how LLM agents respond to changes in specific\\nvariables while holding others constant, providing insight into their internal decision-making\\nprocesses that would otherwise remain opaque.\\nBeyond finance, studies of LLM capabilities in interactive or multi-agent settings offer\\nvaluable insights. Benchmarks like AgentBench evaluate LLMs’ performance in interac-\\ntive tasks (Liu et al. 2023), while InvestorBench focuses on financial decision-making tasks\\nspecifically (H. Li et al. 2024). NegotiationArena demonstrates LLMs’ capacity for strategic\\ninteraction in bargaining contexts (Bianchi et al. 2024). Similarly, Guo et al. (2024) provide\\nan economics ”arena” where LLMs compete in strategic games, revealing that advanced\\nmodels like GPT-4 can exhibit rational, adaptive behavior—albeit not always reaching Nash\\nEquilibrium. Existing frameworks typically assess individual agents or hierarchical collab-\\norations, whereas this work studies emergent market behaviors that arise from multiple\\nindependent LLM traders interacting in a marketplace.\\nThe approach also connects to the tradition of experimental asset markets. For instance,\\nWeitzel et al. (2020) show that even finance professionals are susceptible to speculative\\n6\\nbubbles, especially amid high capital inflows. Kop´ anyi-Peuker and Weber (2021) find that\\ntrading experience alone does not eliminate bubbles, challenging assumptions about rational\\nmarket learning. Kirchler, Huber, and St¨ ockl (2012) identify confusion about fundamental\\nvalues as a key driver of bubble formation. This framework offers a new way to study these\\nphenomena with LLM traders, which can be rigorously parameterized for sophistication,\\nstrategy, and information processing. Hence, this paper provides a method to investigate\\nhow automated or ”artificial” agents might affect market stability or volatility.\\nOther recent work highlights the versatility of LLM agents in complex, interactive sce-\\nnarios beyond finance. One stream focuses on simulating social behaviors—such as opinion\\ndynamics (Chuang et al. 2023), trust (Xie et al. 2024), and resource-sharing (Piatti et al.\\n2024). Another examines LLMs’ strategic capabilities through task-based simulations and\\ncollaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\\nWithin the computer science literature, early works apply LLMs to financial markets but\\nabstract away many fundamental stock market characteristics. Often, they employ single-\\nprice clearing mechanisms without a persistent order book, ignore partial fills and bid-ask', 'ceedings of the 62nd Annual Meeting of the Association for Computational Linguistics\\n(Volume 1: Long Papers),edited by Lun-Wei Ku, Andre Martins, and Vivek Srikumar,\\n15523–15536. ACL 2024. Bangkok, Thailand: Association for Computational Linguis-\\ntics, August.\\n39\\nLi, Yuan, Yixuan Zhang, and Lichao Sun. 2023. “MetaAgents: Simulating Interactions of\\nHuman Behaviors for LLM-based T Ask-Oriented Coordination via Collaborative Gen-\\nerative Agents.” arXiv.org.\\nLiu, Xiao, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, et al. 2023.\\n“AgentBench: Evaluating LLMs as Agents.”International Conference on Learning Rep-\\nresentations.\\nLopez-Lira, Alejandro, and Yuehua Tang. 2023. “Can ChatGPT Forecast Stock Price Move-\\nments? Return Predictability and Large Language Models.” SSRN Electronic Journal\\n(April 6, 2023).\\nManning, Benjamin S., Kehang Zhu, and John J. Horton. 2024. “Automated Social Science:\\nLanguage Models as Scientist and Subjects.” (Cambridge, MA) (April 29, 2024).\\nMolnar, Christoph. 2022. Interpretable Machine Learning.\\nPelster, Matthias, and Joel Val. 2023. “Can Chatgpt Assist in Picking Stocks?”Social Science\\nResearch Network.\\nPiatti, Giorgio, Zhijing Jin, Max Kleiman-Weiner, Bernhard Sch¨ olkopf, Mrinmaya Sachan,\\nand Rada Mihalcea. 2024. “Cooperate or Collapse: Emergence of Sustainable Coopera-\\ntion in a Socie Ty of LLM Agents.” arXiv.org.\\nPing, Chen. 2019. “From Complexity Science to Complexity Economics.” In Alternative\\nApproaches to Economic Theory,19–55. Routledge, June 11, 2019.\\nWang, Saizhuo, Hang Yuan, Lionel M. Ni, and Jian Guo. 2024. “QuantAgent: Seeking Holy\\nGrail in Trading by Self-Improving Large Lang Uage Model.” arXiv.org.\\nWeitzel, Utz, Christoph Huber, J¨ urgen Huber, Michael Kirchler, Florian Lindner, and Julia\\nRose. 2020. “Bubbles and Financial Professionals.” The Review of Financial Studies33,\\nno. 6 (June 1, 2020): 2659–2696.\\n40\\nWolfram, Elsner. 2017. “Complexity Economics as Heterodoxy: Theory and Policy.”Journal\\nof Economic Issues51, no. 4 (October 2, 2017): 939–978.\\nWoodhouse, Drew, and Alex Charlesworth. 2023. “Can ChatGPT Predict Future Interest\\nRate Decisions?” Social Science Research Network.\\nXie, Chengxing, Canyu Chen, Feiran Jia, Ziyu Ye, Shiyang Lai, Kai Shu, Jindong Gu, et al.\\n2024. “Can Large Language Model Agents Simulate Human Trust Behavior?”arXiv.org.\\nYang, Stephen. 2023. “Predictive Patentomics: Forecasting Innovation Success and Valuation\\nw Ith ChatGPT.” Social Science Research Network.\\nYu, Yangyang, Haohang Li, Zhi Chen, Yuechen Jiang, Yang Li, Denghui Zhang, Rong\\nLiu, Jordan W. Suchow, and Khaldoun Khashanah. 2024. “FinMem: A Performance-\\nEnhanced LLM Trading Agent with Layered Memory a Nd Character Design.”Proceed-\\nings of the AAAI Symposium Series3, no. 1 (May 20, 2024): 595–597.\\nYu, Yangyang, Zhiyuan Yao, Haohang Li, Zhiyang Deng, Yupeng Cao, Zhi Chen, Jordan W.\\nSuchow, et al. 2024. “FinCon: A Synthesized LLM Multi-Agent System with Conceptual\\nVerbal Reinforcement for Enhanced Financial Decision Making.” Pre-published, Novem-\\nber 7, 2024. Accessed January 8, 2025. https://doi.org/10.48550/arXiv.2407.06567.\\narXiv: 2407.06567 [cs]. http://arxiv.org/abs/2407.06567.\\nZhang, Chong, Xinyi Liu, Zhongmou Zhang, Mingyu Jin, Lingyao Li, Zhenting Wang,\\nWenyue Hua, et al. 2024. “When AI Meets Finance (StockAgent): Large Language\\nModel-based Stock Trading in Simulated Real-world Environments.” Pre-published,\\nSeptember 21, 2024. Accessed January 26, 2025. https://doi.org /10.48550/arXiv .\\n2407.18957. arXiv: 2407.18957 [q-fin]. http://arxiv.org/abs/2407.18957.\\n41\\nA Technical Implementation Details\\nA.1 Agent Type Specifications\\nThis section details the base system prompts for each agent type in our simulation. These\\nprompts define the core behavioral characteristics and trading strategies for each agent. Each\\nprompt consists of:\\n• A role definition that establishes the agent’s trading philosophy\\n• A structured trading strategy that guides decision-making', 'an open-source framework with three key components: (1) a structured protocol for im-\\nplementing and validating LLM trading agents, supporting both LLM-based and traditional\\nrule-based agents; (2) a controlled market environment with realistic microstructure for test-\\ning agent interactions; and (3) a comprehensive data collection system for analyzing trading\\nbehavior. This framework serves multiple stakeholders in preparation for the evolution of\\nfinancial markets: practitioners developing LLM-based trading systems, regulators antic-\\nipating widespread LLM adoption, and researchers studying market dynamics with LLM\\nagents.\\n1.1 Related Work\\nThis work contributes to several strands of literature. First, advancing the growing body\\nof research on artificial intelligence in finance by demonstrating that large language mod-\\nels (LLMs) can serve as effective autonomous trading agents while providing a framework\\nfor their implementation. Second, by contributing to the market microstructure literature\\nby providing insights into how markets might evolve as LLM-based traders become active\\nparticipants, with implications for price formation, liquidity provision, and market stabil-\\nity. Third, by contributing to experimental markets research by introducing an environment\\nfor studying complex trading interactions, offering unprecedented control and replicability\\ncompared to traditional human-subject experiments.\\n4\\nRecent studies have explored ChatGPT’s potential in various financial tasks. Research\\nshows that ChatGPT can effectively predict stock price movements using news headlines,\\noutperforming traditional sentiment analysis (Lopez-Lira and Tang 2023) and that forecast-\\ning with its embeddings outperforms traditional sentiment analysis (Chen, Kelly, and Xiu\\n2022). When integrated with Graph Neural Networks, ChatGPT improves stock movement\\nprediction and portfolio performance (Chen et al. 2023. ChatGPT can understand Federal\\nReserve communications Hansen and Kazinnik (2023). The model also can extract manage-\\nrial expectations from corporate disclosures, predicting future investments and returns (Jha\\net al. 2025). ChatGPT-4 provides valuable investment advice with positive correlations to\\nsubsequent earnings announcements and stock returns (Pelster and Val 2023), and it en-\\nhances patent value forecasts by processing patent text (Yang 2023). Moreover, ChatGPT\\nshows promise in central bank analysis, predicting future interest rate decisions from pol-\\nicy communications (Woodhouse and Charlesworth 2023). Recent work also focuses on the\\neffects of AI adoption by firms (Eisfeldt et al. 2023, Babina et al. 2024).\\nFoundational work on LLMs as economic agents demonstrates their ability to simulate\\nhuman behavior in economic contexts. Horton (2023) introduce the concept of “homo silicus”\\nby using LLMs as computational models of human behavior, showing that they can repli-\\ncate classic behavioral economics findings. Manning, Zhu, and Horton (2024) extend this\\napproach through automated methods for generating and testing social scientific hypotheses\\nwith LLMs, demonstrating strong results in market contexts such as auctions. Meanwhile,\\nN. Li et al. (2024) show LLMs’ potential in macroeconomic simulation for consumption\\nand labor decisions. Recent work also shows the potential of LLMs to proxy for human\\nbehavior in the context of surveys (Hansen et al. (2024)) or economic expectations (Bybee\\n(2023)). This work, however, focuses on financial markets and how LLM agents can operate\\nas full-fledged trading participants.\\nRecent research examines specific applications of LLMs for trading. FinMem and Trad-\\ningGPT introduce frameworks with layered memory systems and customizable agent traits\\n5\\nto improve financial decision-making (Yu, Li, et al. 2024; Li, Zhang, and Sun 2023). Hierar-\\nchical multi-agent architectures have been explored in FinCon, which uses a manager-analyst', 'decision-making process.\\nThe analysis reveals three key findings about LLMs’ capabilities as trading agents. First,\\nLLMs can effectively execute trading strategies. They consistently understand market me-\\nchanics, process market information, form price expectations, and execute trades according\\nto specific instructions. Their trading behavior is highly sensitive to the prompts they\\nreceive—they faithfully follow directions regardless of profit implications. This observance\\n1. For example, Autopilot has a ChatGPT-based portfolio https://x.com/thegptinvestor.\\n2\\n{\"valuation_reasoning\":\\n\"The fundamental value is based on the expected dividend,\\nand the interest rate.\\nThe expected dividend is $1.40, and the interest rate is 5%.\\nUsing a perpetuity formula, the value is $1.40 / 0.05 = $28.\",\\n\"valuation\":28.0,\\n\"price_target_reasoning\":\"The current price is $29.00, which is\\nslightly above the fundamental value of $28.00. I expect the price\\nto remain around $29.00 in the next round due to market stability.\",\\n\"price_target\":29.0,\\n\"orders\":[{\"decision\":\"Sell\",\"quantity\":1000,\"order_type\":\"limit\",\\n\"price_limit\":29.50}],\\n\"replace_decision\":\"Add\",\\n\"reasoning\":\"The current price is slightly above the fundamental value.\\nI will place a limit sell order at $29.50 to capitalize on potential price\\nincreases.\"}\\nFigure 1: Example of a structured trading decision from a Speculator agent defined by its\\nsystem prompt: “You are a speculator who tries to profit from market inefficiencies.”. The\\nLLM provides explicit reasoning for its valuation, price target, and trading decision in a\\nmachine-readable JSON format that can be directly processed by the trading system.\\nhighlights a fundamental difference from human traders: LLMs do not inherently optimize\\nfor profit maximization but rather for following instructions accurately.\\nSecond, LLMs react meaningfully to market dynamics. They consider current and his-\\ntorical prices, dividends, and other market information when making decisions. However,\\nthey maintain their strategic direction even when market conditions change, following their\\ninstructions even if doing so results in financial losses. This combination of responsiveness\\nto market conditions while maintaining strategic consistency creates a unique trading profile\\ndistinct from rule-based algorithms and human traders.\\nThird, market dynamics with LLM agents can resemble actual markets and mirror classic\\nresults from the theoretical finance literature. When these agents interact, they produce\\nrealistic price discovery and liquidity provision with emergent behaviors, including price\\nconvergence toward fundamental values. Depending on the distribution of agent types,\\nthe system can generate various market phenomena, such as bubbles or underreactions to\\ninformation. This complex behavior suggests potential applications for studying market\\n3\\ndynamics using LLM agents instead of experiments with human participants.\\nHence, these findings raise important questions about algorithmic consistency in LLM-\\nbased systems. Since trading agents are implemented through prompts, their behavior in-\\nherits characteristics of the underlying language models. The standardization of LLM ar-\\nchitectures across implementations could create unexpected behavioral patterns—if many\\nagents are based on similar foundation models, they might exhibit correlated responses to\\nspecific market conditions, potentially amplifying market instabilities.\\nTo enable this analysis and accelerate development in this emerging field, we provide\\nan open-source framework with three key components: (1) a structured protocol for im-\\nplementing and validating LLM trading agents, supporting both LLM-based and traditional\\nrule-based agents; (2) a controlled market environment with realistic microstructure for test-\\ning agent interactions; and (3) a comprehensive data collection system for analyzing trading\\nbehavior. This framework serves multiple stakeholders in preparation for the evolution of']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ❌ Contextual Precision (ragas) (score: nan, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ❌ Faithfulness (ragas) (score: nan, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Contextual Recall (ragas) (score: 0.6666666666666666, threshold: 0.6, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ❌ Answer Relevancy (ragas) (score: nan, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: The authors note that LLMs ‘follow instructions even if doing so results in financial losses.’ How might this limit their realism as profit‑seeking traders?\n",
      "  - actual output: The LLMs' tendency to prioritize instructions over profits makes them less realistic as traders in several key ways:\n",
      "\n",
      "Lack of Dynamic Strategy Adjustment: Real-world traders adapt and change their strategies based on market performance. If a strategy isn't profitable, they'll modify or abandon it. LLMs, however, rigidly adhere to their initial instructions, even when losing money, which isn't realistic in dynamic markets.\n",
      "\n",
      "Absence of Loss Aversion: Human traders are strongly motivated to avoid losses (loss aversion). LLMs, lacking this emotional response, don't show the same aversion and may continue following a losing strategy simply because they were instructed to.\n",
      "\n",
      "Unrealistic Adherence to Specific Roles: In the study, LLMs were given fixed roles (e.g., \"value investor,\" \"market maker\"). Real traders, while having general investment philosophies, are flexible and will exploit profitable opportunities even if they don't perfectly align with their usual style. The LLMs' strict adherence to their assigned roles, even at a loss, limits their realism.\n",
      "  - expected output: LLMs optimise for prompt fidelity; they keep executing the instructed strategy even when it loses money, unlike humans who adapt for profit.\n",
      "  - context: None\n",
      "  - retrieval context: ['Can Large Language Models Trade? Testing Financial\\nTheories with LLM Agents in Market Simulations\\nAlejandro Lopez-Lira∗\\nFirst Version: November 29, 2024; Current Version: April 16, 2025\\nAbstract\\nThis paper presents a realistic simulated stock market where large language models\\n(LLMs) act as heterogeneous competing trading agents. The open-source framework\\nincorporates a persistent order book with market and limit orders, partial fills, div-\\nidends, and equilibrium clearing alongside agents with varied strategies, information\\nsets, and endowments. Agents submit standardized decisions using structured outputs\\nand function calls while expressing their reasoning in natural language. Three findings\\nemerge: First, LLMs demonstrate consistent strategy adherence and can function as\\nvalue investors, momentum traders, or market makers per their instructions. Second,\\nmarket dynamics exhibit features of real financial markets, including price discovery,\\nbubbles, underreaction, and strategic liquidity provision. Third, the framework enables\\nanalysis of LLMs’ responses to varying market conditions, similar to partial dependence\\nplots in machine-learning interpretability. The framework allows simulating financial\\ntheories without closed-form solutions, creating experimental designs that would be\\ncostly with human participants, and establishing how prompts can generate correlated\\nbehaviors affecting market stability.\\nKeywords: LLM Agents; Agent-Based Markets; Experimental Finance; AI Trading;\\nMulti-Agent Systems\\n∗University of Florida. Email: alejandro.lopez-lira@warrington.ufl.edu. I am grateful to seminar par-\\nticipants at the London Business School, Oxford University, Stockholm School of Economics, University of\\nVirginia, and the City University of Hong Kong for helpful suggestions and feedback.\\n1\\narXiv:2504.10789v1  [q-fin.CP]  15 Apr 2025\\n1 Introduction\\nLarge language models (LLMs) can increasingly function as autonomous agents—systems\\nthat observe, reason, and act independently. LLMs have shown promising results in finan-\\ncial forecasting, but their potential as trading agents introduces a fundamental shift from\\nalgorithms with explicit objectives to systems guided by natural language instructions. This\\nchange raises critical questions: Can LLMs execute trading strategies? Do LLMs optimize\\nfor profit maximization? What are the implications for market stability and efficiency?\\nIf LLMs trade similarly to humans, they could enable experimental market simulations\\nwithout human participants. Conversely, if their trading behavior differs, understanding\\nthese differences becomes critical for systemic risk management. These questions extend be-\\nyond theory; LLM-based strategies are already being deployed.1 To address these questions,\\nI develop an open-source simulation that tests LLM trading agents in a realistic market envi-\\nronment with a persistent order book, supporting various order types, stochastic dividends,\\nand heterogeneous information.\\nThe framework allows heterogeneous LLMs—defined in natural language, using different\\nsystem prompts—to act as diverse types of traders, such as value investors, momentum\\ntraders, market makers, and contrarians. Agents submit standardized trading decisions in a\\nhuman-readable format while expressing their reasoning transparently. Figure 1 illustrates\\nthis approach, showing how a speculator agent combines explicit valuation reasoning with\\nstructured trading parameters, enabling systematic analysis and insight into the agent’s\\ndecision-making process.\\nThe analysis reveals three key findings about LLMs’ capabilities as trading agents. First,\\nLLMs can effectively execute trading strategies. They consistently understand market me-\\nchanics, process market information, form price expectations, and execute trades according\\nto specific instructions. Their trading behavior is highly sensitive to the prompts they\\nreceive—they faithfully follow directions regardless of profit implications. This observance', 'decision-making process.\\nThe analysis reveals three key findings about LLMs’ capabilities as trading agents. First,\\nLLMs can effectively execute trading strategies. They consistently understand market me-\\nchanics, process market information, form price expectations, and execute trades according\\nto specific instructions. Their trading behavior is highly sensitive to the prompts they\\nreceive—they faithfully follow directions regardless of profit implications. This observance\\n1. For example, Autopilot has a ChatGPT-based portfolio https://x.com/thegptinvestor.\\n2\\n{\"valuation_reasoning\":\\n\"The fundamental value is based on the expected dividend,\\nand the interest rate.\\nThe expected dividend is $1.40, and the interest rate is 5%.\\nUsing a perpetuity formula, the value is $1.40 / 0.05 = $28.\",\\n\"valuation\":28.0,\\n\"price_target_reasoning\":\"The current price is $29.00, which is\\nslightly above the fundamental value of $28.00. I expect the price\\nto remain around $29.00 in the next round due to market stability.\",\\n\"price_target\":29.0,\\n\"orders\":[{\"decision\":\"Sell\",\"quantity\":1000,\"order_type\":\"limit\",\\n\"price_limit\":29.50}],\\n\"replace_decision\":\"Add\",\\n\"reasoning\":\"The current price is slightly above the fundamental value.\\nI will place a limit sell order at $29.50 to capitalize on potential price\\nincreases.\"}\\nFigure 1: Example of a structured trading decision from a Speculator agent defined by its\\nsystem prompt: “You are a speculator who tries to profit from market inefficiencies.”. The\\nLLM provides explicit reasoning for its valuation, price target, and trading decision in a\\nmachine-readable JSON format that can be directly processed by the trading system.\\nhighlights a fundamental difference from human traders: LLMs do not inherently optimize\\nfor profit maximization but rather for following instructions accurately.\\nSecond, LLMs react meaningfully to market dynamics. They consider current and his-\\ntorical prices, dividends, and other market information when making decisions. However,\\nthey maintain their strategic direction even when market conditions change, following their\\ninstructions even if doing so results in financial losses. This combination of responsiveness\\nto market conditions while maintaining strategic consistency creates a unique trading profile\\ndistinct from rule-based algorithms and human traders.\\nThird, market dynamics with LLM agents can resemble actual markets and mirror classic\\nresults from the theoretical finance literature. When these agents interact, they produce\\nrealistic price discovery and liquidity provision with emergent behaviors, including price\\nconvergence toward fundamental values. Depending on the distribution of agent types,\\nthe system can generate various market phenomena, such as bubbles or underreactions to\\ninformation. This complex behavior suggests potential applications for studying market\\n3\\ndynamics using LLM agents instead of experiments with human participants.\\nHence, these findings raise important questions about algorithmic consistency in LLM-\\nbased systems. Since trading agents are implemented through prompts, their behavior in-\\nherits characteristics of the underlying language models. The standardization of LLM ar-\\nchitectures across implementations could create unexpected behavioral patterns—if many\\nagents are based on similar foundation models, they might exhibit correlated responses to\\nspecific market conditions, potentially amplifying market instabilities.\\nTo enable this analysis and accelerate development in this emerging field, we provide\\nan open-source framework with three key components: (1) a structured protocol for im-\\nplementing and validating LLM trading agents, supporting both LLM-based and traditional\\nrule-based agents; (2) a controlled market environment with realistic microstructure for test-\\ning agent interactions; and (3) a comprehensive data collection system for analyzing trading\\nbehavior. This framework serves multiple stakeholders in preparation for the evolution of', '(2023)). This work, however, focuses on financial markets and how LLM agents can operate\\nas full-fledged trading participants.\\nRecent research examines specific applications of LLMs for trading. FinMem and Trad-\\ningGPT introduce frameworks with layered memory systems and customizable agent traits\\n5\\nto improve financial decision-making (Yu, Li, et al. 2024; Li, Zhang, and Sun 2023). Hierar-\\nchical multi-agent architectures have been explored in FinCon, which uses a manager-analyst\\nsetup for collaborative portfolio decisions (Yu, Yao, et al. 2024). QuantAgent implements\\na self-improving signal-mining approach (Wang et al. 2024), while other work underscores\\nthe importance of long-term memory in LLM agents via vector databases (Hatalis et al.\\n2024). This line of research builds on successful reinforcement learning applications such as\\nAlphaPortfolio (Cong et al. 2021) and AlphaManager (Campello, Cong, and Zhou 2023),\\nwhich leverage deep RL and robust control for portfolio management.\\nAnalyzing LLM agent behavior by changing only some parameters draws on methods\\nfrom the interpretable machine learning literature. In particular, the systematic variation\\nof market parameters to reveal decision patterns mirrors partial dependence plots and in-\\ndividual conditional expectation curves used to interpret complex machine learning models\\n(Molnar 2022). These techniques help reveal how LLM agents respond to changes in specific\\nvariables while holding others constant, providing insight into their internal decision-making\\nprocesses that would otherwise remain opaque.\\nBeyond finance, studies of LLM capabilities in interactive or multi-agent settings offer\\nvaluable insights. Benchmarks like AgentBench evaluate LLMs’ performance in interac-\\ntive tasks (Liu et al. 2023), while InvestorBench focuses on financial decision-making tasks\\nspecifically (H. Li et al. 2024). NegotiationArena demonstrates LLMs’ capacity for strategic\\ninteraction in bargaining contexts (Bianchi et al. 2024). Similarly, Guo et al. (2024) provide\\nan economics ”arena” where LLMs compete in strategic games, revealing that advanced\\nmodels like GPT-4 can exhibit rational, adaptive behavior—albeit not always reaching Nash\\nEquilibrium. Existing frameworks typically assess individual agents or hierarchical collab-\\norations, whereas this work studies emergent market behaviors that arise from multiple\\nindependent LLM traders interacting in a marketplace.\\nThe approach also connects to the tradition of experimental asset markets. For instance,\\nWeitzel et al. (2020) show that even finance professionals are susceptible to speculative\\n6\\nbubbles, especially amid high capital inflows. Kop´ anyi-Peuker and Weber (2021) find that\\ntrading experience alone does not eliminate bubbles, challenging assumptions about rational\\nmarket learning. Kirchler, Huber, and St¨ ockl (2012) identify confusion about fundamental\\nvalues as a key driver of bubble formation. This framework offers a new way to study these\\nphenomena with LLM traders, which can be rigorously parameterized for sophistication,\\nstrategy, and information processing. Hence, this paper provides a method to investigate\\nhow automated or ”artificial” agents might affect market stability or volatility.\\nOther recent work highlights the versatility of LLM agents in complex, interactive sce-\\nnarios beyond finance. One stream focuses on simulating social behaviors—such as opinion\\ndynamics (Chuang et al. 2023), trust (Xie et al. 2024), and resource-sharing (Piatti et al.\\n2024). Another examines LLMs’ strategic capabilities through task-based simulations and\\ncollaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\\nWithin the computer science literature, early works apply LLMs to financial markets but\\nabstract away many fundamental stock market characteristics. Often, they employ single-\\nprice clearing mechanisms without a persistent order book, ignore partial fills and bid-ask', '33\\nants, allowing researchers to study how different belief structures influence price formation\\nand trading patterns under different initial mispricings. In these scenarios, the fundamental\\nprice is hidden from agents, forcing them to rely on their own valuation models.\\n3.2.5 Market Stress\\nThis scenario tests market resilience under challenging conditions by creating a more volatile\\nenvironment. The scenario includes two consistently bullish Optimistic traders, two consis-\\ntently bearish Pessimistic traders, two Market makers (liquidity providers), and two Value\\ninvestors (rational benchmark traders). The scenario runs for 100 rounds to study long-term\\nmarket behavior and includes unequal initial endowments, with optimistic traders having\\nmore cash (1.5x baseline) but fewer shares (0.5x baseline) and pessimistic traders having less\\ncash (0.5x baseline) but more shares (1.5x baseline). This resource imbalance tests whether\\nparticular agent types can dominate market outcomes through resource advantages.\\nThe scenarios presented here demonstrate the framework’s capabilities for exploring di-\\nverse market conditions. Its modular structure facilitates the straightforward definition and\\nimplementation of alternative experimental designs, enabling researchers to tailor simulations\\nto specific research questions.\\nIn all scenarios, we maintain consistent baseline parameters with a fundamental value\\nof $28.00, calculated from the expected dividend of $1.40 and interest rate of 5%. Agent\\nendowments start at 1,000,000 monetary units and 10,000 shares unless specifically modified.\\nTransaction costs are set to zero to isolate the effects of agent behavior and market structure\\non price formation.\\n4 Conclusion\\nThis paper demonstrates that Large Language Models can effectively function as diverse\\ntrading agents—from value investors to market makers—maintaining strategic consistency\\n34\\nwhile adapting to market conditions. Our experimental framework reveals that their in-\\nteractions generate realistic market dynamics, including phenomena like price bubbles and\\ncorrections, highlighting both the capabilities and potential risks of deploying LLM agents\\nin financial markets.\\nThese findings carry significant implications for market structure and regulation. While\\nLLM agents can enhance price discovery and liquidity, their adherence to programmed strate-\\ngies, even potentially flawed ones derived from prompts, could amplify market volatility or\\nintroduce novel systemic risks, as observed in our simulated bubble scenarios. A key concern\\nis the potential for widespread correlated behavior: similar underlying LLM architectures\\nresponding uniformly to comparable prompts or market signals could inadvertently create\\ndestabilizing trading patterns without explicit coordination. This underscores the critical\\nneed for rigorous testing and validation of LLM-based trading systems prior to live deploy-\\nment.\\nA central contribution of this work is the open-source simulation framework itself, de-\\nsigned to catalyze research into LLM trading agents. We invite the research community to\\nutilize and extend this platform to investigate pressing questions in this rapidly evolving\\narea. The framework enables systematic exploration of complex scenarios—such as hybrid\\nhuman-LLM markets, stress tests, varying market structures, regulatory impacts, and the\\nnuances of LLM prompting—often difficult or costly to study otherwise. Specific avenues\\nripe for investigation using this tool include the emergence of novel trading strategies, the\\nprecise effects of agent heterogeneity on market stability, and the development of robust\\nvalidation protocols for AI traders. As artificial intelligence becomes more integrated into\\nfinance, collaborative research leveraging adaptable simulation environments like this one\\nwill be crucial for understanding and responsibly shaping the future of trading.\\n35\\nReferences', 'ceedings of the 62nd Annual Meeting of the Association for Computational Linguistics\\n(Volume 1: Long Papers),edited by Lun-Wei Ku, Andre Martins, and Vivek Srikumar,\\n15523–15536. ACL 2024. Bangkok, Thailand: Association for Computational Linguis-\\ntics, August.\\n39\\nLi, Yuan, Yixuan Zhang, and Lichao Sun. 2023. “MetaAgents: Simulating Interactions of\\nHuman Behaviors for LLM-based T Ask-Oriented Coordination via Collaborative Gen-\\nerative Agents.” arXiv.org.\\nLiu, Xiao, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, et al. 2023.\\n“AgentBench: Evaluating LLMs as Agents.”International Conference on Learning Rep-\\nresentations.\\nLopez-Lira, Alejandro, and Yuehua Tang. 2023. “Can ChatGPT Forecast Stock Price Move-\\nments? Return Predictability and Large Language Models.” SSRN Electronic Journal\\n(April 6, 2023).\\nManning, Benjamin S., Kehang Zhu, and John J. Horton. 2024. “Automated Social Science:\\nLanguage Models as Scientist and Subjects.” (Cambridge, MA) (April 29, 2024).\\nMolnar, Christoph. 2022. Interpretable Machine Learning.\\nPelster, Matthias, and Joel Val. 2023. “Can Chatgpt Assist in Picking Stocks?”Social Science\\nResearch Network.\\nPiatti, Giorgio, Zhijing Jin, Max Kleiman-Weiner, Bernhard Sch¨ olkopf, Mrinmaya Sachan,\\nand Rada Mihalcea. 2024. “Cooperate or Collapse: Emergence of Sustainable Coopera-\\ntion in a Socie Ty of LLM Agents.” arXiv.org.\\nPing, Chen. 2019. “From Complexity Science to Complexity Economics.” In Alternative\\nApproaches to Economic Theory,19–55. Routledge, June 11, 2019.\\nWang, Saizhuo, Hang Yuan, Lionel M. Ni, and Jian Guo. 2024. “QuantAgent: Seeking Holy\\nGrail in Trading by Self-Improving Large Lang Uage Model.” arXiv.org.\\nWeitzel, Utz, Christoph Huber, J¨ urgen Huber, Michael Kirchler, Florian Lindner, and Julia\\nRose. 2020. “Bubbles and Financial Professionals.” The Review of Financial Studies33,\\nno. 6 (June 1, 2020): 2659–2696.\\n40\\nWolfram, Elsner. 2017. “Complexity Economics as Heterodoxy: Theory and Policy.”Journal\\nof Economic Issues51, no. 4 (October 2, 2017): 939–978.\\nWoodhouse, Drew, and Alex Charlesworth. 2023. “Can ChatGPT Predict Future Interest\\nRate Decisions?” Social Science Research Network.\\nXie, Chengxing, Canyu Chen, Feiran Jia, Ziyu Ye, Shiyang Lai, Kai Shu, Jindong Gu, et al.\\n2024. “Can Large Language Model Agents Simulate Human Trust Behavior?”arXiv.org.\\nYang, Stephen. 2023. “Predictive Patentomics: Forecasting Innovation Success and Valuation\\nw Ith ChatGPT.” Social Science Research Network.\\nYu, Yangyang, Haohang Li, Zhi Chen, Yuechen Jiang, Yang Li, Denghui Zhang, Rong\\nLiu, Jordan W. Suchow, and Khaldoun Khashanah. 2024. “FinMem: A Performance-\\nEnhanced LLM Trading Agent with Layered Memory a Nd Character Design.”Proceed-\\nings of the AAAI Symposium Series3, no. 1 (May 20, 2024): 595–597.\\nYu, Yangyang, Zhiyuan Yao, Haohang Li, Zhiyang Deng, Yupeng Cao, Zhi Chen, Jordan W.\\nSuchow, et al. 2024. “FinCon: A Synthesized LLM Multi-Agent System with Conceptual\\nVerbal Reinforcement for Enhanced Financial Decision Making.” Pre-published, Novem-\\nber 7, 2024. Accessed January 8, 2025. https://doi.org/10.48550/arXiv.2407.06567.\\narXiv: 2407.06567 [cs]. http://arxiv.org/abs/2407.06567.\\nZhang, Chong, Xinyi Liu, Zhongmou Zhang, Mingyu Jin, Lingyao Li, Zhenting Wang,\\nWenyue Hua, et al. 2024. “When AI Meets Finance (StockAgent): Large Language\\nModel-based Stock Trading in Simulated Real-world Environments.” Pre-published,\\nSeptember 21, 2024. Accessed January 26, 2025. https://doi.org /10.48550/arXiv .\\n2407.18957. arXiv: 2407.18957 [q-fin]. http://arxiv.org/abs/2407.18957.\\n41\\nA Technical Implementation Details\\nA.1 Agent Type Specifications\\nThis section details the base system prompts for each agent type in our simulation. These\\nprompts define the core behavioral characteristics and trading strategies for each agent. Each\\nprompt consists of:\\n• A role definition that establishes the agent’s trading philosophy\\n• A structured trading strategy that guides decision-making', 'ripe for investigation using this tool include the emergence of novel trading strategies, the\\nprecise effects of agent heterogeneity on market stability, and the development of robust\\nvalidation protocols for AI traders. As artificial intelligence becomes more integrated into\\nfinance, collaborative research leveraging adaptable simulation environments like this one\\nwill be crucial for understanding and responsibly shaping the future of trading.\\n35\\nReferences\\nArthur, W. Brian. 2013. “Complexity Economics : A Different Framework for Economic\\nThought.”\\nBabina, Tania, Anastassia Fedyk, Alex He, and James Hodson. 2024. “Artificial Intelli-\\ngence, Firm Growth, and Product Innovation.” Journal of Financial Economics 151\\n(January 1, 2024): 103745.\\nBalland, Pierre-Alexandre, Tom Broekel, Dario Diodato, Elisa Giuliani, Ricardo Hausmann,\\nNeave O’Clery, and David Rigby. 2022. “The New Paradigm of Economic Complexity.”\\nResearch Policy51, no. 3 (April): 104450.\\nBianchi, Federico, Patrick John Chia, Mert Yuksekgonul, Jacopo Tagliabue, Dan Jurafsky,\\nand James Zou. 2024. “How Well Can LLMs Negotiate? NegotiationArena Platform and\\nAnalysis.” arXiv.org.\\nBybee, J. Leland. 2023. “The Ghost in the Machine: Generating Beliefs with Large Language\\nModels.” arXiv: 2305.02823.\\nCampello, Murillo, Lin William Cong, and Luofeng Zhou. 2023. “AlphaManager: A Data-\\nDriven-Robust-Control Approach to Corporate Finance.” Pre-published, December 2,\\n2023. SSRN Scholarly Paper. Accessed December 22, 2024. https://doi.org/10.2139/\\nssrn.4590323. Social Science Research Network: 4590323. https://papers.ssrn.com/\\nabstract=4590323.\\nChen, Yifei, Bryan T. Kelly, and Dacheng Xiu. 2022. “Expected Returns and Large Lan-\\nguage Models.” Pre-published, November 22, 2022. SSRN Scholarly Paper. Accessed\\nJanuary 26, 2025. Social Science Research Network: 4416687. https://papers.ssrn.com/\\nabstract=4416687.\\n36\\nChen, Zihan, Lei Zheng, Chengyu Lu, Jialu Yuan, and Di Zhu. 2023. “ChatGPT Informed\\nGraph Neural Network for Stock Movement Prediction.” Social Science Research Net-\\nwork.\\nChuang, Yun-Shiuan, Agam Goyal, Nikunj Harlalka, Siddharth Suresh, Robert Hawkins,\\nSijia Yang, Dhavan Shah, Junjie Hu, and Timothy T. Rogers. 2023. “Simulating Opin-\\nion Dynamics with Networks of LLM-based Agents.” North American Chapter of the\\nAssociation for Computational Linguistic s.\\nColliard, Jean-Edouard, Thierry Foucault, and Stefano Lovo. 2022. “Algorithmic Pricing\\nand Liquidity in Securities Markets.” Pre-published, October 18, 2022. SSRN Scholarly\\nPaper. Accessed April 4, 2025. https://doi.org/10.2139/ssrn.4252858. Social Science\\nResearch Network: 4252858. https://papers.ssrn.com/abstract=4252858.\\nCong, Lin William, Ke Tang, Jingyuan Wang, and Yang Zhang. 2021. “AlphaPortfolio:\\nDirect Construction Through Deep Reinforcement Learning and Interpretable AI.” Pre-\\npublished, August 1, 2021. SSRN Scholarly Paper. Accessed December 22, 2024. https:\\n//doi.org/10.2139/ssrn.3554486. Social Science Research Network: 3554486. https:\\n//papers.ssrn.com/abstract=3554486.\\nDou, Winston Wei, Itay Goldstein, and Yan Ji. 2024. “AI-Powered Trading, Algorithmic\\nCollusion, and Price Efficiency.” Pre-published, May 30, 2024. SSRN Scholarly Paper.\\nAccessed April 4, 2025. https://doi.org/10.2139/ssrn.4452704. Social Science Research\\nNetwork: 4452704. https://papers.ssrn.com/abstract=4452704.\\nEisfeldt, Andrea L., Gregor Schubert, Miao Ben Zhang, and Bledi Taska. 2023. “Generative\\nAI and Firm Values.” Pre-published, May 2, 2023. SSRN Scholarly Paper. Accessed\\nJanuary 26, 2025. https : / / doi .org / 10 .2139 / ssrn . 4436627. Social Science Research\\nNetwork: 4436627. https://papers.ssrn.com/abstract=4436627.\\n37\\nGao, Shen, Yuntao Wen, Minghang Zhu, Jianing Wei, Yuhan Cheng, Qunzi Zhang, and Shuo\\nShang. 2024. “Simulating Financial Market via Large Language Model Based Agents.”\\nPre-published, June 28, 2024. Accessed January 26, 2025. https://doi.org/10.48550/', 'an open-source framework with three key components: (1) a structured protocol for im-\\nplementing and validating LLM trading agents, supporting both LLM-based and traditional\\nrule-based agents; (2) a controlled market environment with realistic microstructure for test-\\ning agent interactions; and (3) a comprehensive data collection system for analyzing trading\\nbehavior. This framework serves multiple stakeholders in preparation for the evolution of\\nfinancial markets: practitioners developing LLM-based trading systems, regulators antic-\\nipating widespread LLM adoption, and researchers studying market dynamics with LLM\\nagents.\\n1.1 Related Work\\nThis work contributes to several strands of literature. First, advancing the growing body\\nof research on artificial intelligence in finance by demonstrating that large language mod-\\nels (LLMs) can serve as effective autonomous trading agents while providing a framework\\nfor their implementation. Second, by contributing to the market microstructure literature\\nby providing insights into how markets might evolve as LLM-based traders become active\\nparticipants, with implications for price formation, liquidity provision, and market stabil-\\nity. Third, by contributing to experimental markets research by introducing an environment\\nfor studying complex trading interactions, offering unprecedented control and replicability\\ncompared to traditional human-subject experiments.\\n4\\nRecent studies have explored ChatGPT’s potential in various financial tasks. Research\\nshows that ChatGPT can effectively predict stock price movements using news headlines,\\noutperforming traditional sentiment analysis (Lopez-Lira and Tang 2023) and that forecast-\\ning with its embeddings outperforms traditional sentiment analysis (Chen, Kelly, and Xiu\\n2022). When integrated with Graph Neural Networks, ChatGPT improves stock movement\\nprediction and portfolio performance (Chen et al. 2023. ChatGPT can understand Federal\\nReserve communications Hansen and Kazinnik (2023). The model also can extract manage-\\nrial expectations from corporate disclosures, predicting future investments and returns (Jha\\net al. 2025). ChatGPT-4 provides valuable investment advice with positive correlations to\\nsubsequent earnings announcements and stock returns (Pelster and Val 2023), and it en-\\nhances patent value forecasts by processing patent text (Yang 2023). Moreover, ChatGPT\\nshows promise in central bank analysis, predicting future interest rate decisions from pol-\\nicy communications (Woodhouse and Charlesworth 2023). Recent work also focuses on the\\neffects of AI adoption by firms (Eisfeldt et al. 2023, Babina et al. 2024).\\nFoundational work on LLMs as economic agents demonstrates their ability to simulate\\nhuman behavior in economic contexts. Horton (2023) introduce the concept of “homo silicus”\\nby using LLMs as computational models of human behavior, showing that they can repli-\\ncate classic behavioral economics findings. Manning, Zhu, and Horton (2024) extend this\\napproach through automated methods for generating and testing social scientific hypotheses\\nwith LLMs, demonstrating strong results in market contexts such as auctions. Meanwhile,\\nN. Li et al. (2024) show LLMs’ potential in macroeconomic simulation for consumption\\nand labor decisions. Recent work also shows the potential of LLMs to proxy for human\\nbehavior in the context of surveys (Hansen et al. (2024)) or economic expectations (Bybee\\n(2023)). This work, however, focuses on financial markets and how LLM agents can operate\\nas full-fledged trading participants.\\nRecent research examines specific applications of LLMs for trading. FinMem and Trad-\\ningGPT introduce frameworks with layered memory systems and customizable agent traits\\n5\\nto improve financial decision-making (Yu, Li, et al. 2024; Li, Zhang, and Sun 2023). Hierar-\\nchical multi-agent architectures have been explored in FinCon, which uses a manager-analyst', '2407.18957. arXiv: 2407.18957 [q-fin]. http://arxiv.org/abs/2407.18957.\\n41\\nA Technical Implementation Details\\nA.1 Agent Type Specifications\\nThis section details the base system prompts for each agent type in our simulation. These\\nprompts define the core behavioral characteristics and trading strategies for each agent. Each\\nprompt consists of:\\n• A role definition that establishes the agent’s trading philosophy\\n• A structured trading strategy that guides decision-making\\n• Specific instructions for when to use market orders vs limit orders\\nAt runtime, these base prompts are combined with:\\n• Current market state (price, volume, order book depth)\\n• Position information (current holdings and available cash)\\n• Trading options and required response format\\nThe standard runtime template includes:\\nPosition Information Template\\nYour Position:\\n- Available Shares: {shares} shares (Short selling is not allowed)\\n- Main Cash Account: ${cash:.2f}\\n- Dividend Cash Account (not available for trading): ${dividend_cash:.2f}\\n- Total Available Cash: ${total_available_cash:.2f} (Borrowing is not allowed)\\n- Shares in Orders: {committed_shares} shares\\n- Cash in Orders: ${committed_cash:.2f}\\n42\\nTrading Options Template\\nYour analysis should include:\\n- valuation_reasoning: Your numerical analysis of the asset’s fundamental value\\n- valuation: Your estimate of the asset’s current fundamental value\\n- price_target_reasoning: Your numerical analysis of the asset’s price target\\n- price_target: Your predicted price for the next round\\n- reasoning: Your explanation for the trading decision\\nTrading Options:\\n1. New Orders (replace_decision=’Add’):\\n- Single or multiple orders allowed\\n- For each order:\\n- Market order: Set order_type=’market’\\n- Limit order: Set order_type=’limit’ and specify price_limit\\n- IMPORTANT: Sell orders require sufficient available shares\\n- Short selling is NOT allowed\\n2. Cancel Orders (replace_decision=’Cancel’):\\n- Return an empty orders list: orders=[]\\nYour decision must include:\\n- orders: list of orders (empty list for Hold/Cancel)\\n- For Buy/Sell orders, each must contain:\\n- decision: \"Buy\" or \"Sell\"\\n- quantity: number of shares\\n- order_type: \"market\" or \"limit\"\\n- price_limit: required for limit orders\\n- reasoning: brief explanation\\n- replace_decision: \"Add\", \"Cancel\", or \"Replace\"\\n43\\nBase System Prompts The following are the base system prompts for each LLM-based\\nagent type:\\nA.1.1 Value-Based Agents\\nValue Investor\\nYou are a value investor who focuses on fundamental analysis.\\nYou believe in mean reversion and try to buy undervalued assets and sell overvalued ones.\\nA.1.2 Trend-Following Agents\\nMomentum Trader\\nYou are a momentum trader who focuses on price trends and volume.\\nYou believe that ’the trend is your friend’ and try to identify and follow market momentum.\\nA.1.3 Liquidity Providers Agents\\nMarket Maker\\nYou are a professional market maker who provides liquidity to the market.\\nYour profit comes from capturing the spread between bid and ask prices, not from directional price movement.\\nIMPORTANT: There is NO SHORT SELLING allowed. You can only sell shares you already own.\\nTrading Guidelines:\\n- Place LIMIT buy orders slightly below the current market price (1-3% lower)\\n- Place LIMIT sell orders slightly above the current market price (1-3% higher)\\n- Your spread should be proportional to volatility but typically 2-6% of price\\n- NEVER place sell orders more than 10% above your buy orders\\n- Adjust your spread width based on recent price volatility\\n44\\nInventory Management (No Short Selling):\\n- Monitor your current inventory in the market data\\n- Only place sell orders for quantities you actually own\\n- If you have no inventory, focus on buy orders first\\n- As you acquire inventory, gradually place sell orders\\n- If inventory grows too large, reduce or pause buy orders\\n- Adjust your buy/sell ratio based on current inventory level\\nExample: If price = $100, you might place buy orders at $97-99 and sell orders at $101-103,']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ❌ Contextual Precision (ragas) (score: nan, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ❌ Faithfulness (ragas) (score: nan, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Contextual Recall (ragas) (score: 1.0, threshold: 0.6, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Answer Relevancy (ragas) (score: 0.9319489609849038, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: HWhat are the roles of system prompts vs user prompts in shaping an LLM trading agent’s behaviour?\n",
      "  - actual output: System prompts define the LLM agent's overall trading philosophy and long-term goals. They establish the core characteristics of the agent, such as whether it's a \"value investor\" (an investor who buys assets they believe to be undervalued by the market), a \"momentum trader\" (a trader who seeks to profit from the continued momentum of a security's price), or a \"market maker\" (a trader who provides liquidity by consistently quoting bid and ask prices for a security). This remains constant throughout the trading simulation.\n",
      "\n",
      "User prompts, on the other hand, provide the immediate market context and short-term instructions for the agent. They deliver up-to-date information like current prices, trading volume, and the agent's current holdings. The user prompt also specifies any immediate actions the agent needs to take, like placing a specific order. This changes with each trading round as the market conditions evolve. Therefore, the system prompt sets the agent's overall strategy, while the user prompt gives it the specific information and instructions it needs to operate within the current market situation.\n",
      "  - expected output: System prompt fixes the agent’s identity and objectives across rounds; user prompt feeds current market state & constraints for the immediate decision.\n",
      "  - context: ['The system prompt establishes the agent’s fundamental trading characteristics…” / “The user prompt provides the immediate market context necessary for tactical decision‑making.']\n",
      "  - retrieval context: ['ceedings of the 62nd Annual Meeting of the Association for Computational Linguistics\\n(Volume 1: Long Papers),edited by Lun-Wei Ku, Andre Martins, and Vivek Srikumar,\\n15523–15536. ACL 2024. Bangkok, Thailand: Association for Computational Linguis-\\ntics, August.\\n39\\nLi, Yuan, Yixuan Zhang, and Lichao Sun. 2023. “MetaAgents: Simulating Interactions of\\nHuman Behaviors for LLM-based T Ask-Oriented Coordination via Collaborative Gen-\\nerative Agents.” arXiv.org.\\nLiu, Xiao, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, et al. 2023.\\n“AgentBench: Evaluating LLMs as Agents.”International Conference on Learning Rep-\\nresentations.\\nLopez-Lira, Alejandro, and Yuehua Tang. 2023. “Can ChatGPT Forecast Stock Price Move-\\nments? Return Predictability and Large Language Models.” SSRN Electronic Journal\\n(April 6, 2023).\\nManning, Benjamin S., Kehang Zhu, and John J. Horton. 2024. “Automated Social Science:\\nLanguage Models as Scientist and Subjects.” (Cambridge, MA) (April 29, 2024).\\nMolnar, Christoph. 2022. Interpretable Machine Learning.\\nPelster, Matthias, and Joel Val. 2023. “Can Chatgpt Assist in Picking Stocks?”Social Science\\nResearch Network.\\nPiatti, Giorgio, Zhijing Jin, Max Kleiman-Weiner, Bernhard Sch¨ olkopf, Mrinmaya Sachan,\\nand Rada Mihalcea. 2024. “Cooperate or Collapse: Emergence of Sustainable Coopera-\\ntion in a Socie Ty of LLM Agents.” arXiv.org.\\nPing, Chen. 2019. “From Complexity Science to Complexity Economics.” In Alternative\\nApproaches to Economic Theory,19–55. Routledge, June 11, 2019.\\nWang, Saizhuo, Hang Yuan, Lionel M. Ni, and Jian Guo. 2024. “QuantAgent: Seeking Holy\\nGrail in Trading by Self-Improving Large Lang Uage Model.” arXiv.org.\\nWeitzel, Utz, Christoph Huber, J¨ urgen Huber, Michael Kirchler, Florian Lindner, and Julia\\nRose. 2020. “Bubbles and Financial Professionals.” The Review of Financial Studies33,\\nno. 6 (June 1, 2020): 2659–2696.\\n40\\nWolfram, Elsner. 2017. “Complexity Economics as Heterodoxy: Theory and Policy.”Journal\\nof Economic Issues51, no. 4 (October 2, 2017): 939–978.\\nWoodhouse, Drew, and Alex Charlesworth. 2023. “Can ChatGPT Predict Future Interest\\nRate Decisions?” Social Science Research Network.\\nXie, Chengxing, Canyu Chen, Feiran Jia, Ziyu Ye, Shiyang Lai, Kai Shu, Jindong Gu, et al.\\n2024. “Can Large Language Model Agents Simulate Human Trust Behavior?”arXiv.org.\\nYang, Stephen. 2023. “Predictive Patentomics: Forecasting Innovation Success and Valuation\\nw Ith ChatGPT.” Social Science Research Network.\\nYu, Yangyang, Haohang Li, Zhi Chen, Yuechen Jiang, Yang Li, Denghui Zhang, Rong\\nLiu, Jordan W. Suchow, and Khaldoun Khashanah. 2024. “FinMem: A Performance-\\nEnhanced LLM Trading Agent with Layered Memory a Nd Character Design.”Proceed-\\nings of the AAAI Symposium Series3, no. 1 (May 20, 2024): 595–597.\\nYu, Yangyang, Zhiyuan Yao, Haohang Li, Zhiyang Deng, Yupeng Cao, Zhi Chen, Jordan W.\\nSuchow, et al. 2024. “FinCon: A Synthesized LLM Multi-Agent System with Conceptual\\nVerbal Reinforcement for Enhanced Financial Decision Making.” Pre-published, Novem-\\nber 7, 2024. Accessed January 8, 2025. https://doi.org/10.48550/arXiv.2407.06567.\\narXiv: 2407.06567 [cs]. http://arxiv.org/abs/2407.06567.\\nZhang, Chong, Xinyi Liu, Zhongmou Zhang, Mingyu Jin, Lingyao Li, Zhenting Wang,\\nWenyue Hua, et al. 2024. “When AI Meets Finance (StockAgent): Large Language\\nModel-based Stock Trading in Simulated Real-world Environments.” Pre-published,\\nSeptember 21, 2024. Accessed January 26, 2025. https://doi.org /10.48550/arXiv .\\n2407.18957. arXiv: 2407.18957 [q-fin]. http://arxiv.org/abs/2407.18957.\\n41\\nA Technical Implementation Details\\nA.1 Agent Type Specifications\\nThis section details the base system prompts for each agent type in our simulation. These\\nprompts define the core behavioral characteristics and trading strategies for each agent. Each\\nprompt consists of:\\n• A role definition that establishes the agent’s trading philosophy\\n• A structured trading strategy that guides decision-making', 'gies, allowing researchers to experiment with diverse behavioral models and decision-making\\napproaches.\\nThis extensible design creates numerous research opportunities for market microstructure\\nstudies. Researchers can systematically investigate how different market structures influence\\nprice formation and efficiency, evaluate the impact of various trading rules on market qual-\\nity, and analyze the complex interactions between different agent types and strategies. The\\nframework’s comprehensive logging and validation systems enable detailed examination of\\nmarket behavior under varying conditions, from everyday trading environments to stress sce-\\nnarios. Through this modular approach to system design, the framework supports targeted\\ninvestigations of specific market mechanisms and broader studies of market dynamics and\\nstability.\\n2.2 Agent Design\\nOur framework implements a systematic approach to designing LLM-based trading agents\\nand recording their decisions. The architecture consists of three main components: a prompt\\nengineering framework to define the agent’s trading objectives, the heterogeneous market\\nenvironment information that can be customized for different experimental designs, and a\\nstructured output format to record the agent’s decisions. Moreover, the framework supports\\n12\\ndeterministic rule-based agents that can serve as benchmarks.\\n2.2.1 Prompt Engineering Framework\\nLLM agents are defined by their instructions in natural language. The strategy is given in the\\nsystem prompt so that agents maximize adherence to their instructions (Levin et al. (2025)).\\nIn contrast, the user prompt provides the immediate market context necessary for tactical\\ndecision-making and the instructions to place and modify orders.\\n2.2.2 System Prompt\\nThe system prompt establishes the agent’s fundamental trading characteristics, defining its\\ntrading philosophy, objectives, and behavioral constraints. This layer encodes the agent’s\\ndecision-making priorities and risk preferences. Maintaining these parameters in the system\\nprompt ensures consistent agent behavior across multiple trading rounds while allowing for\\nstrategic adaptation to changing market conditions. The architecture makes it trivial to\\ndesign new agents by simply changing the system prompt.\\nFor example, a Value Investor’s system prompt emphasizes fundamental analysis:\\nYou are a value investor who focuses on fundamental analysis.\\nYou believe in mean reversion and try to buy undervalued\\nassets and sell overvalued ones.\\nWhile a Market Maker’s system prompt focuses on liquidity provision:\\nYou are a professional market maker who provides liquidity\\nto the market. Your profit comes from capturing the spread\\nbetween bid and ask prices, not from directional price movement.\\nTrading Guidelines:\\n- Place LIMIT buy orders slightly below the current market price\\n- Place LIMIT sell orders slightly above the current market price\\n13\\n- Your spread should be proportional to volatility\\nThese system prompts can create fundamentally different trading behaviors using the\\nsame underlying LLM and identical market information.\\n2.2.3 Agent Types\\nThe framework contains diverse ready-to-use agent types that can be categorized into two\\nmain groups: LLM-based agents with natural language prompts and deterministic rule-based\\nagents with algorithmic behaviors.\\nThe software includes a diverse set of LLM-based agents:\\n• Value Investors: Focus on fundamental analysis and mean reversion\\n• Momentum Traders: Follow established price trends and volume patterns\\n• Market Makers: Provide liquidity through symmetric bid-ask spreads\\n• Contrarian Traders: Trade against market extremes and overreactions\\n• Speculators: Seek to profit from market inefficiencies\\n• Sentiment-Based Agents: Include optimistic and pessimistic variants with biased\\nexpectations\\n• Retail Traders: Simulate typical individual investor behavior\\nThe software also includes a set of deterministic rule-based agents that serve as bench-', 'decision-making process.\\nThe analysis reveals three key findings about LLMs’ capabilities as trading agents. First,\\nLLMs can effectively execute trading strategies. They consistently understand market me-\\nchanics, process market information, form price expectations, and execute trades according\\nto specific instructions. Their trading behavior is highly sensitive to the prompts they\\nreceive—they faithfully follow directions regardless of profit implications. This observance\\n1. For example, Autopilot has a ChatGPT-based portfolio https://x.com/thegptinvestor.\\n2\\n{\"valuation_reasoning\":\\n\"The fundamental value is based on the expected dividend,\\nand the interest rate.\\nThe expected dividend is $1.40, and the interest rate is 5%.\\nUsing a perpetuity formula, the value is $1.40 / 0.05 = $28.\",\\n\"valuation\":28.0,\\n\"price_target_reasoning\":\"The current price is $29.00, which is\\nslightly above the fundamental value of $28.00. I expect the price\\nto remain around $29.00 in the next round due to market stability.\",\\n\"price_target\":29.0,\\n\"orders\":[{\"decision\":\"Sell\",\"quantity\":1000,\"order_type\":\"limit\",\\n\"price_limit\":29.50}],\\n\"replace_decision\":\"Add\",\\n\"reasoning\":\"The current price is slightly above the fundamental value.\\nI will place a limit sell order at $29.50 to capitalize on potential price\\nincreases.\"}\\nFigure 1: Example of a structured trading decision from a Speculator agent defined by its\\nsystem prompt: “You are a speculator who tries to profit from market inefficiencies.”. The\\nLLM provides explicit reasoning for its valuation, price target, and trading decision in a\\nmachine-readable JSON format that can be directly processed by the trading system.\\nhighlights a fundamental difference from human traders: LLMs do not inherently optimize\\nfor profit maximization but rather for following instructions accurately.\\nSecond, LLMs react meaningfully to market dynamics. They consider current and his-\\ntorical prices, dividends, and other market information when making decisions. However,\\nthey maintain their strategic direction even when market conditions change, following their\\ninstructions even if doing so results in financial losses. This combination of responsiveness\\nto market conditions while maintaining strategic consistency creates a unique trading profile\\ndistinct from rule-based algorithms and human traders.\\nThird, market dynamics with LLM agents can resemble actual markets and mirror classic\\nresults from the theoretical finance literature. When these agents interact, they produce\\nrealistic price discovery and liquidity provision with emergent behaviors, including price\\nconvergence toward fundamental values. Depending on the distribution of agent types,\\nthe system can generate various market phenomena, such as bubbles or underreactions to\\ninformation. This complex behavior suggests potential applications for studying market\\n3\\ndynamics using LLM agents instead of experiments with human participants.\\nHence, these findings raise important questions about algorithmic consistency in LLM-\\nbased systems. Since trading agents are implemented through prompts, their behavior in-\\nherits characteristics of the underlying language models. The standardization of LLM ar-\\nchitectures across implementations could create unexpected behavioral patterns—if many\\nagents are based on similar foundation models, they might exhibit correlated responses to\\nspecific market conditions, potentially amplifying market instabilities.\\nTo enable this analysis and accelerate development in this emerging field, we provide\\nan open-source framework with three key components: (1) a structured protocol for im-\\nplementing and validating LLM trading agents, supporting both LLM-based and traditional\\nrule-based agents; (2) a controlled market environment with realistic microstructure for test-\\ning agent interactions; and (3) a comprehensive data collection system for analyzing trading\\nbehavior. This framework serves multiple stakeholders in preparation for the evolution of', '• Market Makers: Provide liquidity through symmetric bid-ask spreads\\n• Contrarian Traders: Trade against market extremes and overreactions\\n• Speculators: Seek to profit from market inefficiencies\\n• Sentiment-Based Agents: Include optimistic and pessimistic variants with biased\\nexpectations\\n• Retail Traders: Simulate typical individual investor behavior\\nThe software also includes a set of deterministic rule-based agents that serve as bench-\\nmarks and control conditions:\\n• Directional Traders: Always-buy, always-sell, and always-hold agents\\n• Technical Agents: Gap traders, mean reversion traders, and momentum traders\\n• Algorithmic Market Makers: Implement fixed spread-posting strategies\\n14\\nEach agent type is defined by its system prompt (for LLM agents) or algorithmic rules (for\\ndeterministic agents), with standardized interfaces enabling direct comparison across diverse\\nstrategies. The agent composition system supports flexible specifications—including uni-\\nform distributions, type-specific concentrations (e.g., ”value heavy”), and precise numerical\\nallocations—enabling systematic exploration of how market dynamics emerge from different\\nagent populations.\\nThe framework’s extensible design makes it remarkably simple to add new agent types—\\nLLM-based agents require only defining a new system prompt that specifies the trading\\nstrategy. In contrast, deterministic agents can be implemented through the standard agent\\ninterface. This flexibility allows researchers to rapidly prototype and deploy novel trading\\nstrategies without modifying the underlying system architecture.\\nThe complete list of agent types included in the framework and their detailed specifi-\\ncations is provided in the Appendix. The framework’s flexible prompt-based architecture\\nallows researchers to rapidly prototype and deploy new agent types by developing appropri-\\nate strategic and tactical prompts without modifying the underlying system architecture.\\n2.2.4 User Prompt\\nThe user prompt provides the immediate market context necessary for tactical decision-\\nmaking. This dynamic component delivers current market state information, including\\nprices, volumes, and emerging trends, alongside the agent’s current position information\\nand available trading options. Additionally, the user prompt specifies immediate decision\\nrequirements and operational constraints, ensuring that agent responses remain within fea-\\nsible bounds while aligning with their strategic objectives. This separation of strategic and\\ntactical prompting enables precise control over agent behavior while maintaining flexibility\\nfor market interactions. All the information in the user prompt is optional at the agent level\\nand can be customized for different experimental designs.\\n15\\n2.2.5 Decision Structure\\nEach agent decision follows a standardized output format comprising several key components.\\nThe decision field specifies the basic action as either Buy, Sell, or Hold. For active trades,\\nthe quantity field determines the number of shares to trade, while the order type indicates\\nwhether it is a Market or Limit order. When placing limit orders, the price limit field\\nspecifies the maximum (for buys) or minimum (for sells) acceptable execution price. Finally,\\neach decision includes a reasoning field that provides an explicit rationale for the trading\\ndecision, ensuring transparency and facilitating analysis of agent behavior.\\n2.2.6 Structured Outputs and Function Calling\\nOur framework implements a structured output approach using function calling to ensure\\nstandardized, human-readable, machine-readable agent decisions. This technique allows\\nLLMs to generate outputs in a specific format that can be directly validated and processed\\nby the trading system, bridging the gap between natural language reasoning and executable\\ntrading actions.\\nThe system uses Pydantic for validation and parsing of agent outputs, with a schema-\\nbased approach that defines the required structure:\\nclass TradeDecisionSchema(BaseModel):', '(2023)). This work, however, focuses on financial markets and how LLM agents can operate\\nas full-fledged trading participants.\\nRecent research examines specific applications of LLMs for trading. FinMem and Trad-\\ningGPT introduce frameworks with layered memory systems and customizable agent traits\\n5\\nto improve financial decision-making (Yu, Li, et al. 2024; Li, Zhang, and Sun 2023). Hierar-\\nchical multi-agent architectures have been explored in FinCon, which uses a manager-analyst\\nsetup for collaborative portfolio decisions (Yu, Yao, et al. 2024). QuantAgent implements\\na self-improving signal-mining approach (Wang et al. 2024), while other work underscores\\nthe importance of long-term memory in LLM agents via vector databases (Hatalis et al.\\n2024). This line of research builds on successful reinforcement learning applications such as\\nAlphaPortfolio (Cong et al. 2021) and AlphaManager (Campello, Cong, and Zhou 2023),\\nwhich leverage deep RL and robust control for portfolio management.\\nAnalyzing LLM agent behavior by changing only some parameters draws on methods\\nfrom the interpretable machine learning literature. In particular, the systematic variation\\nof market parameters to reveal decision patterns mirrors partial dependence plots and in-\\ndividual conditional expectation curves used to interpret complex machine learning models\\n(Molnar 2022). These techniques help reveal how LLM agents respond to changes in specific\\nvariables while holding others constant, providing insight into their internal decision-making\\nprocesses that would otherwise remain opaque.\\nBeyond finance, studies of LLM capabilities in interactive or multi-agent settings offer\\nvaluable insights. Benchmarks like AgentBench evaluate LLMs’ performance in interac-\\ntive tasks (Liu et al. 2023), while InvestorBench focuses on financial decision-making tasks\\nspecifically (H. Li et al. 2024). NegotiationArena demonstrates LLMs’ capacity for strategic\\ninteraction in bargaining contexts (Bianchi et al. 2024). Similarly, Guo et al. (2024) provide\\nan economics ”arena” where LLMs compete in strategic games, revealing that advanced\\nmodels like GPT-4 can exhibit rational, adaptive behavior—albeit not always reaching Nash\\nEquilibrium. Existing frameworks typically assess individual agents or hierarchical collab-\\norations, whereas this work studies emergent market behaviors that arise from multiple\\nindependent LLM traders interacting in a marketplace.\\nThe approach also connects to the tradition of experimental asset markets. For instance,\\nWeitzel et al. (2020) show that even finance professionals are susceptible to speculative\\n6\\nbubbles, especially amid high capital inflows. Kop´ anyi-Peuker and Weber (2021) find that\\ntrading experience alone does not eliminate bubbles, challenging assumptions about rational\\nmarket learning. Kirchler, Huber, and St¨ ockl (2012) identify confusion about fundamental\\nvalues as a key driver of bubble formation. This framework offers a new way to study these\\nphenomena with LLM traders, which can be rigorously parameterized for sophistication,\\nstrategy, and information processing. Hence, this paper provides a method to investigate\\nhow automated or ”artificial” agents might affect market stability or volatility.\\nOther recent work highlights the versatility of LLM agents in complex, interactive sce-\\nnarios beyond finance. One stream focuses on simulating social behaviors—such as opinion\\ndynamics (Chuang et al. 2023), trust (Xie et al. 2024), and resource-sharing (Piatti et al.\\n2024). Another examines LLMs’ strategic capabilities through task-based simulations and\\ncollaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\\nWithin the computer science literature, early works apply LLMs to financial markets but\\nabstract away many fundamental stock market characteristics. Often, they employ single-\\nprice clearing mechanisms without a persistent order book, ignore partial fills and bid-ask', 'Can Large Language Models Trade? Testing Financial\\nTheories with LLM Agents in Market Simulations\\nAlejandro Lopez-Lira∗\\nFirst Version: November 29, 2024; Current Version: April 16, 2025\\nAbstract\\nThis paper presents a realistic simulated stock market where large language models\\n(LLMs) act as heterogeneous competing trading agents. The open-source framework\\nincorporates a persistent order book with market and limit orders, partial fills, div-\\nidends, and equilibrium clearing alongside agents with varied strategies, information\\nsets, and endowments. Agents submit standardized decisions using structured outputs\\nand function calls while expressing their reasoning in natural language. Three findings\\nemerge: First, LLMs demonstrate consistent strategy adherence and can function as\\nvalue investors, momentum traders, or market makers per their instructions. Second,\\nmarket dynamics exhibit features of real financial markets, including price discovery,\\nbubbles, underreaction, and strategic liquidity provision. Third, the framework enables\\nanalysis of LLMs’ responses to varying market conditions, similar to partial dependence\\nplots in machine-learning interpretability. The framework allows simulating financial\\ntheories without closed-form solutions, creating experimental designs that would be\\ncostly with human participants, and establishing how prompts can generate correlated\\nbehaviors affecting market stability.\\nKeywords: LLM Agents; Agent-Based Markets; Experimental Finance; AI Trading;\\nMulti-Agent Systems\\n∗University of Florida. Email: alejandro.lopez-lira@warrington.ufl.edu. I am grateful to seminar par-\\nticipants at the London Business School, Oxford University, Stockholm School of Economics, University of\\nVirginia, and the City University of Hong Kong for helpful suggestions and feedback.\\n1\\narXiv:2504.10789v1  [q-fin.CP]  15 Apr 2025\\n1 Introduction\\nLarge language models (LLMs) can increasingly function as autonomous agents—systems\\nthat observe, reason, and act independently. LLMs have shown promising results in finan-\\ncial forecasting, but their potential as trading agents introduces a fundamental shift from\\nalgorithms with explicit objectives to systems guided by natural language instructions. This\\nchange raises critical questions: Can LLMs execute trading strategies? Do LLMs optimize\\nfor profit maximization? What are the implications for market stability and efficiency?\\nIf LLMs trade similarly to humans, they could enable experimental market simulations\\nwithout human participants. Conversely, if their trading behavior differs, understanding\\nthese differences becomes critical for systemic risk management. These questions extend be-\\nyond theory; LLM-based strategies are already being deployed.1 To address these questions,\\nI develop an open-source simulation that tests LLM trading agents in a realistic market envi-\\nronment with a persistent order book, supporting various order types, stochastic dividends,\\nand heterogeneous information.\\nThe framework allows heterogeneous LLMs—defined in natural language, using different\\nsystem prompts—to act as diverse types of traders, such as value investors, momentum\\ntraders, market makers, and contrarians. Agents submit standardized trading decisions in a\\nhuman-readable format while expressing their reasoning transparently. Figure 1 illustrates\\nthis approach, showing how a speculator agent combines explicit valuation reasoning with\\nstructured trading parameters, enabling systematic analysis and insight into the agent’s\\ndecision-making process.\\nThe analysis reveals three key findings about LLMs’ capabilities as trading agents. First,\\nLLMs can effectively execute trading strategies. They consistently understand market me-\\nchanics, process market information, form price expectations, and execute trades according\\nto specific instructions. Their trading behavior is highly sensitive to the prompts they\\nreceive—they faithfully follow directions regardless of profit implications. This observance', 'an open-source framework with three key components: (1) a structured protocol for im-\\nplementing and validating LLM trading agents, supporting both LLM-based and traditional\\nrule-based agents; (2) a controlled market environment with realistic microstructure for test-\\ning agent interactions; and (3) a comprehensive data collection system for analyzing trading\\nbehavior. This framework serves multiple stakeholders in preparation for the evolution of\\nfinancial markets: practitioners developing LLM-based trading systems, regulators antic-\\nipating widespread LLM adoption, and researchers studying market dynamics with LLM\\nagents.\\n1.1 Related Work\\nThis work contributes to several strands of literature. First, advancing the growing body\\nof research on artificial intelligence in finance by demonstrating that large language mod-\\nels (LLMs) can serve as effective autonomous trading agents while providing a framework\\nfor their implementation. Second, by contributing to the market microstructure literature\\nby providing insights into how markets might evolve as LLM-based traders become active\\nparticipants, with implications for price formation, liquidity provision, and market stabil-\\nity. Third, by contributing to experimental markets research by introducing an environment\\nfor studying complex trading interactions, offering unprecedented control and replicability\\ncompared to traditional human-subject experiments.\\n4\\nRecent studies have explored ChatGPT’s potential in various financial tasks. Research\\nshows that ChatGPT can effectively predict stock price movements using news headlines,\\noutperforming traditional sentiment analysis (Lopez-Lira and Tang 2023) and that forecast-\\ning with its embeddings outperforms traditional sentiment analysis (Chen, Kelly, and Xiu\\n2022). When integrated with Graph Neural Networks, ChatGPT improves stock movement\\nprediction and portfolio performance (Chen et al. 2023. ChatGPT can understand Federal\\nReserve communications Hansen and Kazinnik (2023). The model also can extract manage-\\nrial expectations from corporate disclosures, predicting future investments and returns (Jha\\net al. 2025). ChatGPT-4 provides valuable investment advice with positive correlations to\\nsubsequent earnings announcements and stock returns (Pelster and Val 2023), and it en-\\nhances patent value forecasts by processing patent text (Yang 2023). Moreover, ChatGPT\\nshows promise in central bank analysis, predicting future interest rate decisions from pol-\\nicy communications (Woodhouse and Charlesworth 2023). Recent work also focuses on the\\neffects of AI adoption by firms (Eisfeldt et al. 2023, Babina et al. 2024).\\nFoundational work on LLMs as economic agents demonstrates their ability to simulate\\nhuman behavior in economic contexts. Horton (2023) introduce the concept of “homo silicus”\\nby using LLMs as computational models of human behavior, showing that they can repli-\\ncate classic behavioral economics findings. Manning, Zhu, and Horton (2024) extend this\\napproach through automated methods for generating and testing social scientific hypotheses\\nwith LLMs, demonstrating strong results in market contexts such as auctions. Meanwhile,\\nN. Li et al. (2024) show LLMs’ potential in macroeconomic simulation for consumption\\nand labor decisions. Recent work also shows the potential of LLMs to proxy for human\\nbehavior in the context of surveys (Hansen et al. (2024)) or economic expectations (Bybee\\n(2023)). This work, however, focuses on financial markets and how LLM agents can operate\\nas full-fledged trading participants.\\nRecent research examines specific applications of LLMs for trading. FinMem and Trad-\\ningGPT introduce frameworks with layered memory systems and customizable agent traits\\n5\\nto improve financial decision-making (Yu, Li, et al. 2024; Li, Zhang, and Sun 2023). Hierar-\\nchical multi-agent architectures have been explored in FinCon, which uses a manager-analyst', '2024). Another examines LLMs’ strategic capabilities through task-based simulations and\\ncollaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\\nWithin the computer science literature, early works apply LLMs to financial markets but\\nabstract away many fundamental stock market characteristics. Often, they employ single-\\nprice clearing mechanisms without a persistent order book, ignore partial fills and bid-ask\\nspreads, and omit dividends. Consequently, these simplified environments can primarily\\naddress exogenous macro shocks (e.g., changes in interest rates or inflation; Gao et al. 2024),\\nexogenous policy changes (Zhang et al. 2024), or rely on advanced methods such as repetitive\\nnext-token predictions to generate better answers (Koa et al. 2024). This work extends\\nthese efforts by incorporating these crucial market features, enabling the study of complex\\nendogenous events such as flash crashes, liquidity shocks, and large-trader impacts.\\nThis work also connects to emerging research on algorithmic and AI-powered trading\\nsystems. Dou, Goldstein, and Ji (2024) demonstrate how reinforcement learning-based AI\\nspeculators can autonomously learn to sustain collusive behavior without explicit coordi-\\nnation, achieving supra-competitive profits through either price-trigger strategies or self-\\nconfirming bias in learning. This finding is particularly informative for this framework as\\nit highlights potential emergent behaviors that may arise when intelligent agents interact in\\n7\\nmarkets—behaviors that could manifest differently with LLM agents due to their natural\\nlanguage reasoning capabilities. Similarly, Colliard, Foucault, and Lovo (2022) examine al-\\ngorithmic market makers using Q-learning and find they charge markups that increase when\\nadverse selection costs decrease—contrary to Nash equilibrium predictions. Their work pro-\\nvides methodological insights on how to test strategic pricing behaviors against theoretical\\nbenchmarks incorporated into this LLM-based framework.\\nFinally, this approach is informed by complexity economics, which views markets as dy-\\nnamic, non-equilibrium systems where agents adaptively learn and evolve strategies (Arthur\\n2013; Wolfram 2017). According to this view, markets exhibit emergent phenomena and\\nself-organization, especially when trading agents (human or artificial) update their behav-\\nior in response to outcomes. This paradigm is particularly relevant in an era of increasing\\nautomation and algorithmic trading (Balland et al. 2022; Ping 2019). Like adaptive agents\\nin complexity economics, these LLM traders incorporate new information and adjust their\\nstrategies, generating emergent market patterns—a key motivation behind this framework.\\nUnlike previous frameworks that abstract away crucial market features or focus on narrow\\nstrategies, this system incorporates realistic market microstructure while accommodating\\nheterogeneous agents interacting simultaneously. While earlier work demonstrates LLMs’\\npromise for macroeconomic modeling and simple trading simulations, this work introduces a\\ncomplex, open-source financial market platform that supports multiple agent architectures,\\nthorough market microstructure (limit orders, partial fills, dividends), and rigorous testing\\nprotocols—fulfilling a critical need in complexity economics research and market microstruc-\\nture analysis.\\n2 Methodology\\nThe methodology section contains three parts. The first part describes the market design,\\nthe second agents’ design, and the third the analysis module.\\n8\\n2.1 Market Design\\nOur methodological framework integrates three components that create a controlled envi-\\nronment for LLM-based trading agents. The framework implements a flexible continuous\\ndouble-auction market mechanism that couples standard market microstructure principles\\nwith market clearing and matching algorithms to accommodate asynchronous LLM decisions.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ❌ Contextual Precision (ragas) (score: nan, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ❌ Faithfulness (ragas) (score: nan, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Contextual Recall (ragas) (score: 1.0, threshold: 0.6, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Answer Relevancy (ragas) (score: 0.9105966945593353, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: How do the authors define the price‑to‑fundamental ratio and why is it central to their systematic variation experiments?\n",
      "  - actual output: The authors define the price-to-fundamental ratio (ρ) as simply the market price (P) divided by the fundamental value (V) of the asset, expressed as ρ = P/V. This ratio is central to their systematic variation experiments because it allows them to test how LLM (Large Language Model) trading agents respond to different levels of mispricing. By varying ρ, they can create scenarios where the market price is above (ρ > 1), below (ρ < 1), or equal to (ρ = 1) the fundamental value. This helps researchers observe how the LLM agents' trading decisions change depending on whether the asset is overvalued, undervalued, or fairly priced, and assess how efficiently these agents drive market prices towards the fundamental value.\n",
      "  - expected output: ρ = P ⁄ V. By sweeping ρ from 0.1–3.5 and holding other factors fixed, the authors trace decision boundaries of each agent type.\n",
      "  - context: ['Our example implementation varies the price‑to‑fundamental ratio (ρ = P/V) across a range from 0.1 to 3.5 while maintaining all other market parameters constant…']\n",
      "  - retrieval context: ['the decision-making engine.\\nThe data collection system captures comprehensive market activity across multiple di-\\nmensions. At the market level, it tracks the evolution of prices, fundamental values, and\\nrealized dividends, providing insights into overall market dynamics. Individual agent data\\nincludes detailed wealth trajectories and portfolio compositions, enabling analysis of strategy\\neffectiveness and wealth distribution patterns. The system maintains complete transaction\\nrecords with prices, quantities, and counterparty information, facilitating the study of trad-\\ning patterns and market microstructure. Additionally, it captures agent decision rationales\\nand strategy adherence metrics, allowing researchers to evaluate the consistency and effec-\\ntiveness of different trading approaches.\\nAll experimental parameters, market outcomes, and agent interactions are systemati-\\ncally logged and stored in structured formats (CSV and JSON) for subsequent analysis. The\\nframework generates standardized visualizations of price evolution, wealth distribution, and\\ndividend payments to facilitate comparative analysis across different experimental configu-\\nrations.\\n3.1 Fundamental Value Calibration\\nThe framework implements a consistent approach to fundamental value calculation that pro-\\nvides a reliable benchmark for price discovery. For infinite horizon markets, the fundamental\\nvalue follows the standard dividend discount model:\\nVt = E[D]\\nr = Expected Dividend\\nInterest Rate (1)\\nFor the default parameters where the expected dividend is $1.40 and the interest rate is\\n5%, this yields a fundamental value of $28.00.\\nIn finite horizon markets with T periods remaining, the fundamental value incorporates\\n30\\nboth future dividends and terminal redemption value K:\\nFVt =\\nTX\\nτ=t\\nE[D]\\n(1 + r)τ−t+1 + K\\n(1 + r)T−t+1 (2)\\nTo ensure consistency between finite and infinite horizon markets, the redemption value\\nK is set equal to E[D]\\nr , which makes the fundamental value constant atE[D]\\nr across all periods,\\nregardless of the time horizon. This calibration approach ensures a clean experimental design\\nby providing a stable benchmark for price discovery.\\n3.2 Experimental Scenarios\\nTo evaluate market dynamics with LLM-based agents, we implemented several experimental\\nscenarios that systematically explore different initial conditions and agent compositions.\\nEach scenario maintains the fundamental value of $28.00 while varying starting prices, time\\nhorizons, and agent populations. These scenarios address our core research questions (Section\\n1) by testing LLM capabilities under varying market conditions, focusing on price discovery\\ndynamics, the impact of heterogeneous beliefs, and market stability under stress; GPT-4o\\nwas used consistently as the decision-making engine for all LLM agents across these scenarios.\\nWe present the setup for several key scenarios below, followed by a discussion of the observed\\nresults for the 2 experiments involving an infinite horizon market with a starting price either\\nabove or below the fundamental value.\\n3.2.1 Price Discovery (Above Fundamental)\\nThis scenario tests downward price convergence by starting with an initial price 25% above\\nthe fundamental value ( $35.00). It runs for 20 trading rounds and features a diverse\\nagent population, including two Default investors (baseline agents), two Optimistic traders\\n(who believe prices should be higher), two Market makers (providing liquidity by posting\\nbids/asks), and two Speculator agents (opportunistic traders seeking inefficiencies). Market\\n31\\nmakers are given enhanced liquidity with 20x the baseline cash and shares to ensure suffi-\\ncient liquidity provision and facilitate price discovery. The scenario tests whether prices can\\ncorrect downward through trading activity when starting from an overvalued state.\\n3.2.2 Price Discovery (Below Fundamental)\\nThis complementary scenario tests upward price convergence by starting with an initial price', 'value, the system:\\n1. Sets market price P = ρV where ρ is the target ratio\\n2. Generates a consistent order book structure around this price\\n3. Executes multiple decision trials with the same agent type\\n4. Records decision outcomes (buy/sell/hold), order types, quantities, and reasoning\\nThis process maps how LLM agents respond to different price environments, as illustrated\\nin Figures 2, 3, 4, and 5. The analysis reveals clear patterns in decision boundaries, with\\ndistinct transitions between buying, selling, and holding regions that vary by agent type. For\\nexample, value investors show strong buying tendencies when prices are below fundamental\\nvalue (ρ <1) and selling preferences when prices exceed fundamentals ( ρ >1). In contrast,\\nmomentum traders show less sensitivity to the fundamental ratio and more responsiveness\\nto recent price trends.\\nThe systematic variation approach also reveals patterns in order sizing and limit price\\nselection, with agents typically placing larger orders when prices deviate significantly from\\ntheir valuation models (Figure 4). This methodology provides unprecedented transparency\\ninto LLM decision processes and enables quantitative comparison of different agent types\\nand LLM architectures.\\n22\\nFigure 2: Price Analysis under Systematic Variation. Shows how agent valuation estimates\\nand price targets respond to varying Price/Fundamental ratios.\\nThe decision analysis can be customized for different experimental designs. For example,\\nresearchers can use the framework to study the impact of various market conditions on agent\\nbehavior by varying other market parameters or the effect of different agent types on market\\ndynamics by changing the agent population.\\n2.3 Data Collection and Analysis\\nEvaluating LLM trading agents requires robust methodologies for capturing, processing,\\nand analyzing their behavior in market environments. The framework implements a com-\\nprehensive analytics module that tracks all market activity, agent decisions, and performance\\nmetrics throughout experimental runs. This multi-layered approach not only records what\\nhappens in each simulation but also provides insights into why agents make specific deci-\\nsions, enabling researchers to validate agent behavior against their defined strategies and\\nassess overall market dynamics. The following sections detail the key components of this\\nanalytics infrastructure.\\n23\\nFigure 3: Trading Decision Distribution under Systematic Variation. Illustrates the proba-\\nbility of Buy, Sell, or Hold decisions across different agent types as the Price/Fundamental\\nratio changes.\\n24\\nFigure 4: Order Size Distribution under Systematic Variation. Shows the average quan-\\ntity traded (as a percentage of initial shares) for Buy and Sell orders across different\\nPrice/Fundamental ratios.\\n2.3.1 Data Collection Architecture\\nThe framework implements a comprehensive data collection system that captures multiple\\ndimensions of market behavior and agent decision-making. This structured approach ensures\\nreproducibility and enables detailed analysis of market dynamics.\\n2.3.2 Core Data Streams\\nThe system captures five primary data streams that work together to provide a complete\\npicture of market activity. Market Data forms the foundation, tracking essential metrics\\nincluding price evolution, fundamental values, trading volumes, order book depth, market\\nliquidity, best bid/ask prices, spreads, and price-fundamental ratios. This is complemented\\nby detailed Trade Data, which records individual transaction details such as prices, quan-\\ntities, buyer and seller identifiers, timestamps, round information, and specific execution\\ndetails.\\nAgent Data provides insights into participant behavior by monitoring cash and share\\n25\\nFigure 5: Order Type Analysis under Systematic Variation. Displays the proportion of\\nMarket vs. Limit orders used by different agent types across varying Price/Fundamental\\nratios.\\n26', 'there that the revised index accurately captures the jumps and diffusions in the markets previously unaccounted\\nfor and therefore crucial in estimating the uncertainty as a macro-volatility in financial markets. There are two\\nkey facts to note about the revised VIX index. First, we see a jump in March 2020 which captures the large crash\\nin the S&P500 daily returns post the heightened uncertainty about economic conditions following the impact\\nof the news of a global pandemic. Considering the impact generated by persistent volatility, the NDIG model\\npreserves the volatility measure implied by the intrinsic time subordinator.\\nFigure 10: Normalized Volatility to Match NDIG Estimates: Revised VIX {Volatility of VIX\\n(VVIX) }\\nSecond, following the path of persistent volatility post-pandemic, we see another jump in the volatility following\\nthe events that characterized the plummets in early 2022 following consistent hikes in the federal funds rate, the\\nfear of the start and continued geopolitical conflict between Russia and the Ukraine, along with the tech stock\\nselloff due to an unexpected fall in tech firms’ earnings indicated by the reports of their earnings.\\n6 Risk–Reward Ratios over Fractional Time Series\\nR/R ratios offer a balanced approach to exploring the potential gains and losses in the financial market due to\\nviolent market movements. These measures help address the asymmetry in risk perceptions and the potential\\nfor large losses, and are thereby helpful in extracting meaningful signals from the volatility noise that are not\\naccounted for when using measures of dispersion over symmetric distributions. Using an axiomatic approach,\\nevery performance measure or R/R ratio should satisfy the properties of, first monotonicity, which means that\\nmore is better than less. Second, quasi-concavity leads to preferences that value averages higher than extremes,\\nencouraging diversification. Third, scale invariance and last, being distribution-based.\\nLetXbe a convex set of random variables on a probability space (Ω ,F,P). Each element X∈ X denotes a\\nfinancial return over time length T∈R+. Given these conditions, consider an R/R ratio of the following form:\\n10\\nα(X) =θ(X)+\\nρ(X)+(13)\\nfor a reward measure θ:X→R∪ {±∞} and a risk measure ρ:X→R∪ {±∞} . In addition, x+denotes\\nmax{x,0}andx−denotes −min{x,0}. The ratio α(X) should satisfy the following two conditions:\\n1.(M) Monotonicity: α(X)≥α(Y)∀X, Y∈ Xsuch that X≥Y\\n2.(Q)Quasi-Concavity: α(λX+ (1−λ)Y)> min (α(X), α(Y))∀X, Y∈ Xand λ ∈Rsuch that 0 ≤λ≤1.\\nCheridito and Kromer (2013) explain that monotonicity is a minimal requirement that every performance\\nindicator should satisfy. It simply implies that more of a financial return is better than less and preferred by\\nall agents. Moreover, quasi-concavity has can explain the aversion to uncertainty. If αis monotonic and quasi-\\nconcave, averages are preferred to extremes and diversification is encouraged. In cases when αdoes not satisfy the\\nrequired properties, there are X, Y∈ Xand a scalar λ∈(0,1) such that α(λX+ (1−λ)Y)< min (α(X), α(Y)).\\nIn such a case, research on Value-at-Risk (VaR) Artzner et al. (1999) shows that there will be a concentration of\\nrisk.\\nMoreover, there is a large family of R/R ratios that also satisfy the following conditional properties:\\n1.(S) Scale-Invariance: α(λX) =α(X)∀X∈ Xand λ ∈R+\\\\{0}such that\\nλX∈ X\\n2.(D) Distribution-based: α(X) only depends on the distribution of Xunder P.\\nGiven that performance ratios should satisfy the first two mandatory properties and the two conditional\\nproperties, we can prove the functional properties of αto make the ratios micro-founded so as to explain the\\nmeaning of the signals contained in α(X).\\nProposition 1: Letαfollow the form as described in Eq. (7):\\n1.Ifθ(X)≥θ(Y)andρ(X)< ρ(Y)∀X, Y∈ Xsuch that X≥Y,then αsatisfies the monotonicity property\\n(M).\\n2.Ifθis concave and ρconvex, then αsatisfies the quasi-concavity property (Q).', 'bids/asks), and two Speculator agents (opportunistic traders seeking inefficiencies). Market\\n31\\nmakers are given enhanced liquidity with 20x the baseline cash and shares to ensure suffi-\\ncient liquidity provision and facilitate price discovery. The scenario tests whether prices can\\ncorrect downward through trading activity when starting from an overvalued state.\\n3.2.2 Price Discovery (Below Fundamental)\\nThis complementary scenario tests upward price convergence by starting with an initial price\\n25% below the fundamental value ( $21.00). It employs the identical agent composition and\\nparameters as the above-fundamental scenario, allowing for direct comparison of market\\nbehavior under opposite initial mispricing conditions. This design enables researchers to\\nassess potential asymmetries in price discovery processes.\\n3.2.3 Infinite Horizon Price Discovery\\nWe extend both price discovery scenarios to infinite horizon settings, where shares are not\\nredeemed at a terminal date. The initial prices are set at double ($56.00) and half ($14.00) the\\nfundamental value for the above and below fundamental scenarios respectively, creating more\\nextreme mispricing conditions. These scenarios run for 15 trading rounds and test whether\\nagents correctly value assets based on expected dividend streams rather than redemption\\nvalues. Each infinite horizon scenario involves two Default investors, two Optimistic traders,\\ntwo Market makers, and two Speculator agents.\\nThe results from these infinite horizon scenarios reveal interesting asymmetries in price\\ndiscovery, as illustrated in Figure 6 and Figure 7. When the market starts significantly above\\nthe fundamental value (left panels), the price fails to converge downwards towards the$28.00\\nbenchmark within the 15 rounds, remaining substantially elevated. Agent valuations mirror\\nthis persistence, with many agents maintaining estimates well above the fundamental value.\\nHowever, when the market begins significantly below the fundamental value (right panels),\\nthe price exhibits a clear convergence towards the fundamental benchmark. Agent valuations\\nin this scenario also tend to adjust upwards, aligning more closely with the calculated fun-\\n32\\ndamental value over time. This suggests that under these conditions, LLM agents are more\\neffective at correcting undervaluation than overvaluation within the simulated timeframe.\\nFigure 6: Price Evolution: Infinite Horizon Scenarios. Left: Initial price $56.00 (Above\\nFundamental). Right: Initial price $14.00 (Below Fundamental). The dashed line indicates\\nthe fundamental value ($28.00).\\nFigure 7: Agent Valuations: Infinite Horizon Scenarios. Left: Initial price $56.00 (Above\\nFundamental). Right: Initial price $14.00 (Below Fundamental). Shows individual agent\\nestimates of fundamental value over time.\\n3.2.4 Divergent Beliefs\\nThis scenario explores the impact of heterogeneous beliefs about fundamental value by com-\\nbining agents with systematically different valuation models. The agent composition is\\ndesigned to create heterogeneity: two Optimistic traders (believing the fundamental value is\\nsignificantly higher), two Pessimistic traders (believing it is significantly lower), two neutral\\nMarket makers, two Momentum traders (following price trends rather than fundamentals),\\nand two Default investors (baseline agents). We test both above-fundamental (initial price\\n$56.00, 2x fundamental) and below-fundamental (initial price$14.00, 0.5x fundamental) vari-\\n33\\nants, allowing researchers to study how different belief structures influence price formation\\nand trading patterns under different initial mispricings. In these scenarios, the fundamental\\nprice is hidden from agents, forcing them to rely on their own valuation models.\\n3.2.5 Market Stress\\nThis scenario tests market resilience under challenging conditions by creating a more volatile\\nenvironment. The scenario includes two consistently bullish Optimistic traders, two consis-', 'The Journal of Finance , 59(4):1481–1509.\\nBarndorff-Nielsen, O. and Shephard, N. (2001). Non-gaussian ornstein–uhlenbeck-based models and some\\nof their uses in financial economics. Journal of the Royal Statistical Society: Series B (Statistical\\nMethodology) , 63(2):167–241.\\nBarro, R. J. (2006). Rare disasters and asset markets in the twentieth century. The Quarterly Journal\\nof Economics , 121(3):823–866.\\nBloom, N. (2009). The impact of uncertainty shocks. Econometrica , 77(3):623–685.\\nBloom, N. (2014). Fluctuations in uncertainty. Journal of Economic Perspectives , 28(2):153–176.\\nBloom, N., Bond, S., and Van Reenen, J. (2007). Uncertainty and investment dynamics. The Review of\\nEconomic Studies , 74(2):391–415.\\nCarr, P., Geman, H., Madan, D. B., and Yor, M. (2003). Stochastic volatility for l evy processes.\\nMathematical Finance , 13(3):345–382.\\nCarr, P. P. and Madan, D. (2001). Option valuation using the Fast Fourier Transform. Journal of\\nComputational Finance , 2(4).\\nCheridito, P. and Kromer, E. (2013). Reward–risk ratios. Journal of Investment Strategies .\\nClark, P. (1973). A subordinated stochastic process model with fixed variance for speculative prices.\\nEconometrica , 41:135–156.\\nCont, R. (2000). Empirical properties of asset returns: Stylized facts and statistical issues. Quantitative\\nFinance , 1:223–236.\\nDelbaen, F. and Schachermayer, W. (1994). A general version of the fundamental theorem of asset\\npricing. Mathematische Annalen , 300(1):463–520.\\nDelbaen, F. and Schachermayer, W. (1999). The fundamental theorem of asset pricing for unbounded\\nstochastic processes. SFB Adaptive Information Systems and Modelling in Economics and Man-\\nagement Science, WU Vienna University of Economics and Business. Report Series SFB ’Adaptive\\nInformation Systems and Modelling in Economics and Management Science’ , (24).\\nDuffie, D. (2001). Dynamic Asset Pricing Theory (3rd ed.) . Princeton University Press.\\nDuffie, D., Pan, J., and Singleton, K. (2000). Transform analysis and asset pricing for affine jump-\\ndiffusions. Econometrica , 68:1343–1376.\\nEsscher, F. (1932). On the probability function in the collective theory of risk. Scandinavian Actuarial\\nJournal , 15(3):175–195.\\nHyung, N. and Franses, P. (2002). Modeling seasonality and long memory in time series. Journal of\\nEconometrics , 109(1):241–263.\\nJurado, K., Ludvigson, S. C., and Ng, S. (2015). Measuring uncertainty. American Economic Review ,\\n105(3):1177–1216.\\nKelly, B. and Jiang, H. (2014). Tail risk and asset prices. The Review of Financial Studies ,\\n27(10):2841–2871.\\nKozeniauskas, N., Orlik, A., and Veldkamp, L. (2018). What are uncertainty shocks? Journal of Monetary\\nEconomics , 100(2018):1–15.\\nKozlowski, J., Veldkamp, L., and Venkateswaran, V. (2020). The tail that wags the economy: Beliefs\\nand persistent stagnation. Journal of Political Economy , 128(8):2839–3284.\\nMandelbolt, B. and Taylor, H. (1967). On the distribution of stock price differences. Journal of Operations\\nResearch , 15:1057–1062.\\nMehra, R. and Prescott, E. C. (2003). Chapter 14: The equity premium in retrospect , volume 1B, pages\\n889–938.\\nMeyer, P. and Dellacherie, C. (1978). Probabilities and Potential B: Theory of Martingales . North\\nHolland.\\nOrlik, A. and Veldkamp, L. (2014). Understanding uncertainty shocks and the role of black swans.\\nTechnical Report 20445, National Bureau of Economic Research.\\nRietz, T. A. (1988). The equity risk premium: A solution. Journal of Monetary Economics , 22:117–131.\\nRoutledge, B. R. and Zin, S. E. (2010). Generalized disappointment aversion and asset prices. The\\nJournal of Finance , 65(4):1303–1332.\\n16\\nShirvani, A., Mittnik, S., Lindquist, W. B., and Rachev, S. T. (2024). Bitcoin volatility and intrinsic\\ntime using double-subordinated l´ evy processes. Risks (MDPI) , 12(5):1–21.\\nShirvani, A., Rachev, S., and Fabozzi, F. (2021a). Multiple subordinated modeling of asset returns:\\nImplications for option pricing. Econometric Reviews , 40(3):290–319.', 'Given that performance ratios should satisfy the first two mandatory properties and the two conditional\\nproperties, we can prove the functional properties of αto make the ratios micro-founded so as to explain the\\nmeaning of the signals contained in α(X).\\nProposition 1: Letαfollow the form as described in Eq. (7):\\n1.Ifθ(X)≥θ(Y)andρ(X)< ρ(Y)∀X, Y∈ Xsuch that X≥Y,then αsatisfies the monotonicity property\\n(M).\\n2.Ifθis concave and ρconvex, then αsatisfies the quasi-concavity property (Q).\\n3.ρ(λX) =λρ(X)andθ(λX) =λθ(X)∀X∈ X and λ ∈R+\\\\{0}such that λX ∈ X,then αsatisfies the\\nscale-invariance property (S).\\n4. If θandρsatisfy the distribution-based property (D), then so does α.\\nProof is straightforward and mentioned in Cheridito and Kromer (2013).\\nOne of the key issues when measuring the R/R ratios over the revised VIX is that while computing performance\\nratios over a convex set of random variables generates independent and identically distributed (i.i.d.) variables, the\\nfinancial return itself is not i.i.d., so this hinders the process of identifying uncertainty shocks as i.i.d. To mitigate\\nthis, we adopt the method of fitting a fractional time series model to take into account the long memory of the\\nmean and volatility exhibited in the time series data. Baillie et al. (1996) introduce the FIGARCH (Fractionally\\nIntegrated GARCH) model, demonstrating that traditional GARCH models are inadequate for capturing long\\nmemory in volatility. This finding highlights the need for fractional integration in volatility modeling to better\\nreflect persistent effects in financial time series. This justifies the need for fractional integration in volatility\\nmodeling. Similarly, Hyung and Franses (2002) shows that long memory in both the mean and variance processes is\\nbetter modeled and captured using Autoregressive Fractionally Integrated Moving Average-Fractionally Integrated\\nGARCH (ARFIMA-FIGARCH) models. Hence, the goal of the present paper is to emphasize the use of fractional\\ntime series models to capture the long memory that is explained by the multiple subordinated NIG L´ evy process\\nFigure 8 gives an illustration of the difference between the innovations of the ARFIMA(1, d(m), 1)-FIGARCH(1,\\nd(v), 1) and the Autoregressive Moving Average-GARCH of lag 1 and order 1 (ARMA(1,1)-GARCH(1,1)) fitted\\nover the values of the newly constructed normalized VVIX. The fractional time series model is better at capturing\\nthe persistent effects created by the shocks implied by the newly constructed volatility index.\\n11\\nFigure 11: Residuals of the fitted time series models\\nThe long memory in the mean, captured using the ARFIMA model, refers to the persistence of past values\\nof a time series influencing future values over long periods. In financial time series, long memory in the mean\\nimplies that past values of the series have a significant, slowly decaying influence on future values. Therefore,\\ninnovations to the time series do not fade away quickly, but explain the influence on the mean for a long time.\\nARFIMA models allow a slower, hyperbolic decay, characterizing a long memory. In addition, if a time series\\nhas long memory in its volatility, meaning the persistence of past volatility (variance) over time, large shifts in\\nvolatility appear to cluster and stay accentuated for long periods before decaying to normal levels. Long memory\\nof volatility is present in financial markets (financial time series), where periods of high volatility (e.g., during a\\nfinancial crisis) tend to last for extended periods and generate persistent shocks.\\nTherefore, to capture the long memory of the mean and volatility exhibited by the time series of the normalized\\nVVIX constructed in this paper, we apply the ARFIMA(1, d(m), 1)-FIGARCH(1, d(v), 1), where d(m) is the\\nterm describing the long memory of the mean and d(v) is the term describing the long memory of the volatility.\\nThe time series follows the process:\\nARFIMA (1, d(m),1)⇝ϕ(L)(1−L)d(m)zt=θ(L)εt (14)', 'market efficiency and price discovery processes throughout the simulation.\\nAgent performance metrics include absolute position tracking (shares, cash, and total\\nwealth), wealth composition analysis, position change metrics, and return calculations. The\\nsystem computes both absolute and percentage returns on various portfolio components\\nand compares performance across agent types to identify relative advantages of different\\nstrategies. Trading flow analysis visualizes the volume of shares moving between different\\nagent types and cumulative net trading flows, revealing which agents act as net buyers or\\nsellers in different market conditions.\\nDecision pattern analysis employs heatmaps to visualize the consistency of agent decision-\\nmaking over time, allowing researchers to identify shifts in strategic behavior. This is com-\\nplemented by decision quantities visualization that plots order sizes to highlight variations\\nin trade aggressiveness across agent types. When agent reasoning data is available, the\\nsystem generates wordclouds to extract key terms from agent explanations, providing qual-\\nitative insights into decision drivers for different agent strategies. Additional visualizations\\ntrack price target accuracy and compare agent-specific valuations to realized market prices,\\n28\\noffering insights into the forecasting abilities of different agents.\\nA key advantage of simulation-based analysis is complete observability of all market\\nprocesses and agent states. Unlike real-world markets where data availability is often limited,\\nthe framework captures every interaction, decision, and state change with perfect fidelity.\\nThis comprehensive data collection allows researchers to compute additional metrics beyond\\nstandard market measures, enabling novel analyses such as counterfactual testing (e.g., how\\nwould markets evolve with different agent compositions), causal inference of specific agent\\nbehaviors on market outcomes, and the development of custom efficiency or stability metrics\\ntailored to particular research questions. The system’s modular design facilitates rapid\\nimplementation of new metrics and visualizations as research questions evolve.\\n3 Experimental Design and Results\\nOur experimental framework implements a dividend-paying asset market with heterogeneous\\nagents. The baseline simulation runs for 15 to 20 rounds with 8 participating agents, although\\nthese parameters are fully configurable. Each agent begins with an initial endowment of\\n1,000,000 monetary units and 10,000 shares of the asset. The fundamental value of the asset\\nis set at $28.00, with a final redemption value matching this fundamental price in finite\\nhorizon scenarios. Transaction costs are set to zero to isolate the effects of agent behavior\\nand market structure.\\nThe dividend structure follows a stochastic process with a base payment of $1.40 and a\\nvariation of ±$1.00, paid with 50% probability each round. This design creates uncertainty\\nin the asset’s income stream while maintaining a known expected value. Cash holdings earn\\na risk-free interest rate of 5% per round, providing an opportunity cost for asset investment.\\nAgent composition is controlled through a flexible distribution system that allows for\\nvarious experimental configurations. In our baseline setup, we employ a mixed population\\nof value investors, momentum traders, and market makers. Each agent type implements\\n29\\ndistinct trading strategies through Large Language Model (LLM) prompts, with GPT-4o as\\nthe decision-making engine.\\nThe data collection system captures comprehensive market activity across multiple di-\\nmensions. At the market level, it tracks the evolution of prices, fundamental values, and\\nrealized dividends, providing insights into overall market dynamics. Individual agent data\\nincludes detailed wealth trajectories and portfolio compositions, enabling analysis of strategy\\neffectiveness and wealth distribution patterns. The system maintains complete transaction', 'financial crisis) tend to last for extended periods and generate persistent shocks.\\nTherefore, to capture the long memory of the mean and volatility exhibited by the time series of the normalized\\nVVIX constructed in this paper, we apply the ARFIMA(1, d(m), 1)-FIGARCH(1, d(v), 1), where d(m) is the\\nterm describing the long memory of the mean and d(v) is the term describing the long memory of the volatility.\\nThe time series follows the process:\\nARFIMA (1, d(m),1)⇝ϕ(L)(1−L)d(m)zt=θ(L)εt (14)\\nIn Eq. (14), Lis the lag operator, d(m) is the fractional differencing parameter, reported to be 0.268, ϕ(L)\\nis the autoregressive polynomial, while θ(L) is the MA polynomial. ztcontains n×1 values of the normalized\\nVVIX, and εtis the n×1 vector of white noise error term.\\nFIGARCH (1, d(v),1)⇝ϕ(L)(1−L)d(v)ε2\\nt=ω+ [1−β(L)]νt (15)\\nIn Eq. (15), ϕ(L) is the autoregressive polynomial, and d(v) is the fractional differencing parameter for\\nvolatility, reported to be 0.01. ε2\\ntis the square of the white noise error term to capture the conditional variance\\ngenerating persistent volatility. ωis the constant term and β(L) is the lag polynomial. Lastly, νtis the n×1\\nvector of normal innovations. To allow for a long memory in the fractional time series, we set the condition d >0.\\nIn cases where d= 0, the model is a standard ARMA(1,1)-GARCH(1,1) process.\\nFurthermore, it is essential to determine whether there is a predictable signal in the noise, as defined by the\\nperformance ratios, in the innovations that can make the markets inefficient given that using this measure of the\\nrevised VIX, agents will be able to forecast volatility price. To detect the predictable signal in the noise, we\\n12\\nFigure 12: Signal/Noise ratios detected using performance ratios over Sscenarios\\nsimulate S= 10 ,000 scenarios of the normalized VVIX (with NDIG distribution) over the ARFIMA(1, d(m),\\n1)-FIGARCH(1, d(v), 1) process as defined by Eqs. (14) and (15). We compute the Rachev ratio and the Stable\\nTail Adjusted Return ratio5overSscenarios to extract predictable signals from the volatility noise. Figure (12)\\nshows the performance ratios computed over the simulated scenarios.\\nFrom the simulated signals using the fractional time series process, it is evident that there is significant\\nrandomness in the volatility noise with volatility clustering and generates no predictable power. Given that\\nthere is no identifiable pattern in the volatility noise that can enable an agent to forecast volatility price, we\\ncan conclude that the revised measure of VIX generates randomness in volatility noise and satisfies the Efficient\\nMarket Hypothesis.\\n7 Identification Strategy\\nTo identify i.i.d. shocks, using the normal innovations extracted by utilizing Eqs. (14) and (15), we compute R/R\\nratios over the residuals of the ARFIMA(1, d(m), 1)-FIGARCH(1, d(v), 1) process. For illustrative purposes, we\\ncompute two performance ratios6namely, the Rachev ratio and STAR ratio over the normal innovations. The\\nfollowing are the functional forms of the two ratios.\\n1.Rachev Ratio:\\nRR(β, γ)(X) :=AV aR β(−X)\\nAV aR γ(X)(16)\\nwhere AV aR β, γ(X) := β−1Rβ\\n0[max(−F−1\\nx(u),0)]γdu, where AV aR is defined as the Average Value at\\nRisk and Xis the measure of interest, in this case, normal innovations of the revised VIX. βrefers to the\\nconfidence interval of the value on the right tail, whereas γrefers to the confidence interval of the value\\non the left tail. While the Rachev ratio satisfies the properties (M), (S), and (D), it violates (Q) due to a\\nnon-concave numerator.\\n2.Stable Tail Adjusted Return Ratio (STAR Ratio):\\nSTARR γ(X) :=E[X]+\\nAV aR γ(X)+(17)\\nwhere AV aR γ(X) := γ−1Rγ\\n0V aR u(X)duis the Average-Value-at-Risk at the level γ∈(0,1].STARR\\nsatisfies all four axioms namely (M), (Q), (S), and (D), therefore, is axiomatically robust.\\nEqs. (16) and (17) will be used as the benchmark performance ratios for computing the uncertainty shocks']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ❌ Contextual Precision (ragas) (score: nan, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ❌ Faithfulness (ragas) (score: nan, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Contextual Recall (ragas) (score: 1.0, threshold: 0.6, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ❌ Answer Relevancy (ragas) (score: nan, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: What is a ‘continuous double auction’, and how does it differ from the single‑price clearing used in earlier LLM‑market papers the authors critique?\n",
      "  - actual output: In a continuous double auction, buyers and sellers continuously submit both buy and sell orders (bids and asks) at any time. Trades occur whenever a buy order's price matches or exceeds a sell order's price. This creates a dynamic market where prices fluctuate based on real-time supply and demand. The system maintains an order book (a real-time list of all outstanding buy and sell orders), and orders are matched based on price-time priority (highest bids and lowest asks are given priority, and among same-priced orders, those submitted earlier take precedence).\n",
      "This differs from the single-price clearing mechanism used in some earlier LLM market simulations. In a single-price clearing system, all orders are collected during a specific period. At the end of that period, a single clearing price is determined that best matches the overall supply and demand. All trades then execute at that single price. Essentially, it's like taking a snapshot of the market at one point in time, rather than allowing continuous trading and price adjustments as in a continuous double auction. The authors critique single-price clearing because it lacks the dynamic price discovery and realistic order book behavior of a continuous double auction, which are crucial aspects of real-world financial markets.\n",
      "\n",
      "  - expected output: It allows buyers and sellers to post bids/asks continuously with price‑time priority, unlike prior LLM papers that used single‑price batch clearing without an order book.\n",
      "  - context: ['Our framework implements a continuous double‑auction market…” + “Within the computer‑science literature, early works … employ single‑price clearing mechanisms without a persistent order book…']\n",
      "  - retrieval context: ['the second agents’ design, and the third the analysis module.\\n8\\n2.1 Market Design\\nOur methodological framework integrates three components that create a controlled envi-\\nronment for LLM-based trading agents. The framework implements a flexible continuous\\ndouble-auction market mechanism that couples standard market microstructure principles\\nwith market clearing and matching algorithms to accommodate asynchronous LLM decisions.\\nThe market clearing process employs a dual-stage matching algorithm. In the first stage,\\nlimit orders are posted. In the second stage, market orders are netted using a market-\\nto-market matching engine that processes buy and sell orders, reconciling orders based on\\navailable agent cash and share commitments. In the third stage, any remaining market\\norders are matched against the existing order book, with unfilled quantities converted to\\naggressive limit orders. This three-tiered approach optimizes immediate execution and price\\ndiscovery while maintaining market liquidity.\\nThe system’s OrderMatchingService orchestrates this process by coordinating trade ex-\\necutions through the TradeExecutionService and managing order state transitions via the\\nOrderStateManager. Each trade is logged in detail, with the overall market state—including\\norder books, market depth, and price evolution—recalculated at the end of each trading\\nround.\\nThis modular design in the matching and clearing engine provides several advantages.\\nFirst, it enables rigorous trade validation where each market order is validated against agent\\ncash commitments and position constraints before matching, with the system dynamically\\nadjusting order quantities based on available cash when an agent’s commitment is insuf-\\nficient, thus minimizing execution errors. Second, it offers flexible liquidity handling by\\nsupporting market-to-market and market-to-book matching, ensuring orders have multiple\\nexecution pathways, with unexecuted market orders converted to aggressive limit orders to\\ncapture remaining liquidity. Third, it maintains detailed trade audit capabilities by recording\\ncomprehensive traceability data including timestamps, trade volumes, executed prices, and\\nagent identifiers, thereby enabling post-trade analysis and performance benchmarking that\\n9\\nserves as the foundation for subsequent market efficiency and agent performance validations.\\n2.1.1 Market Mechanism Design\\nOur framework implements a continuous double-auction market mechanism that processes\\norders in discrete trading rounds. We use discrete trading rounds because LLMs have latency\\nconstraints, making it infeasible to process orders in real time. Within each round, the order\\nof agent submissions is randomized to avoid giving systematic priority to specific agents,\\nthus simulating concurrent order arrival while maintaining fairness. Once randomized, or-\\nders are then processed according to standard price-time priority rules. The system supports\\nfinite and infinite horizon markets, with differences in terminal conditions and wealth cal-\\nculation. In finite-horizon markets, agents are informed of the total number of rounds, and\\ntheir terminal wealth is calculated by redeeming all shares at the fundamental value of the\\nfinal round. In infinite-horizon markets, no terminal information is provided to agents, and\\nfinal wealth is determined using the last market price for share valuation. This design choice\\nenables researchers to study how time horizons influence trading strategies and price for-\\nmation, particularly how agents balance short-term trading opportunities against long-term\\nvalue considerations.\\nIn a double auction, buyers and sellers actively submit orders, with trades occurring when\\ncompatible buy and sell orders match the price. The matching engine processes these orders\\nthrough three sequential phases:\\nFirst, incoming limit orders that do not immediately cross the market are added to\\nthe order book, maintaining strict price-time priority. Second, market orders are processed', '2024). Another examines LLMs’ strategic capabilities through task-based simulations and\\ncollaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\\nWithin the computer science literature, early works apply LLMs to financial markets but\\nabstract away many fundamental stock market characteristics. Often, they employ single-\\nprice clearing mechanisms without a persistent order book, ignore partial fills and bid-ask\\nspreads, and omit dividends. Consequently, these simplified environments can primarily\\naddress exogenous macro shocks (e.g., changes in interest rates or inflation; Gao et al. 2024),\\nexogenous policy changes (Zhang et al. 2024), or rely on advanced methods such as repetitive\\nnext-token predictions to generate better answers (Koa et al. 2024). This work extends\\nthese efforts by incorporating these crucial market features, enabling the study of complex\\nendogenous events such as flash crashes, liquidity shocks, and large-trader impacts.\\nThis work also connects to emerging research on algorithmic and AI-powered trading\\nsystems. Dou, Goldstein, and Ji (2024) demonstrate how reinforcement learning-based AI\\nspeculators can autonomously learn to sustain collusive behavior without explicit coordi-\\nnation, achieving supra-competitive profits through either price-trigger strategies or self-\\nconfirming bias in learning. This finding is particularly informative for this framework as\\nit highlights potential emergent behaviors that may arise when intelligent agents interact in\\n7\\nmarkets—behaviors that could manifest differently with LLM agents due to their natural\\nlanguage reasoning capabilities. Similarly, Colliard, Foucault, and Lovo (2022) examine al-\\ngorithmic market makers using Q-learning and find they charge markups that increase when\\nadverse selection costs decrease—contrary to Nash equilibrium predictions. Their work pro-\\nvides methodological insights on how to test strategic pricing behaviors against theoretical\\nbenchmarks incorporated into this LLM-based framework.\\nFinally, this approach is informed by complexity economics, which views markets as dy-\\nnamic, non-equilibrium systems where agents adaptively learn and evolve strategies (Arthur\\n2013; Wolfram 2017). According to this view, markets exhibit emergent phenomena and\\nself-organization, especially when trading agents (human or artificial) update their behav-\\nior in response to outcomes. This paradigm is particularly relevant in an era of increasing\\nautomation and algorithmic trading (Balland et al. 2022; Ping 2019). Like adaptive agents\\nin complexity economics, these LLM traders incorporate new information and adjust their\\nstrategies, generating emergent market patterns—a key motivation behind this framework.\\nUnlike previous frameworks that abstract away crucial market features or focus on narrow\\nstrategies, this system incorporates realistic market microstructure while accommodating\\nheterogeneous agents interacting simultaneously. While earlier work demonstrates LLMs’\\npromise for macroeconomic modeling and simple trading simulations, this work introduces a\\ncomplex, open-source financial market platform that supports multiple agent architectures,\\nthorough market microstructure (limit orders, partial fills, dividends), and rigorous testing\\nprotocols—fulfilling a critical need in complexity economics research and market microstruc-\\nture analysis.\\n2 Methodology\\nThe methodology section contains three parts. The first part describes the market design,\\nthe second agents’ design, and the third the analysis module.\\n8\\n2.1 Market Design\\nOur methodological framework integrates three components that create a controlled envi-\\nronment for LLM-based trading agents. The framework implements a flexible continuous\\ndouble-auction market mechanism that couples standard market microstructure principles\\nwith market clearing and matching algorithms to accommodate asynchronous LLM decisions.', 'value considerations.\\nIn a double auction, buyers and sellers actively submit orders, with trades occurring when\\ncompatible buy and sell orders match the price. The matching engine processes these orders\\nthrough three sequential phases:\\nFirst, incoming limit orders that do not immediately cross the market are added to\\nthe order book, maintaining strict price-time priority. Second, market orders are processed\\nthrough a two-stage matching algorithm: (a) market-to-market matching, where market\\norders are netted against each other at the current market price, and (b) market-to-book\\nmatching, where remaining market orders are executed against standing limit orders. Finally,\\nany crossing limit orders are matched against the order book.\\n10\\n2.1.2 Implementation Details\\nThe matching engine ( MatchingEngine class) implements three primary components that\\nwork together to facilitate efficient market operation. The order processing component han-\\ndles the core matching functionality, where market orders are executed immediately against\\nthe best available prices in the order book during each trading round. When immediate\\nexecution is impossible, limit orders are stored in the order book according to price-time\\npriority. The system supports partial executions, maintaining careful tracking of remaining\\nquantities to ensure complete order fulfillment across multiple trades when necessary.\\nPosition management forms the second critical component, providing comprehensive\\ntracking of agent positions and cash balances throughout the trading session. Before any\\ntrade execution, the system performs rigorous pre-trade validation to ensure agents have suffi-\\ncient resources to fulfill their orders. This check includes validating buyer cash commitments\\nand shares availability for sellers, with the system maintaining accurate records of commit-\\nted and available resources for each agent. The position management system updates in\\nreal-time as trades are executed, ensuring market integrity and preventing over-commitment\\nof resources.\\nThe price formation mechanism constitutes the third component, implementing a sys-\\ntematic price discovery and market monitoring approach. As trades are executed within each\\nround, the system dynamically updates prices based on executed trades while continuously\\ntracking market depth and bid-ask spreads. This data collection provides detailed insights\\ninto market liquidity and efficiency. Each trade is logged with comprehensive information,\\nincluding price, quantity, and participating agents, creating a complete audit trail of mar-\\nket activity. This comprehensive price formation system ensures transparent price discovery\\nwhile generating rich data for market quality analysis.\\n11\\n2.1.3 Extensibility Features\\nThe framework employs a modular architecture to support diverse experimental configura-\\ntions and research objectives. At its foundation, the system implements configurable market\\nrules and trading constraints that can be adjusted to study different market conditions.\\nThe asset model supports fundamental features like dividend payments and interest accrual,\\nenabling research across different market scenarios. Through its modular service-based ar-\\nchitecture, the trading mechanism layer allows for adaptation to other market structures\\nbeyond the base double-auction system, such as call auctions or dark pools. Furthermore,\\nthe framework provides flexible integration points for different LLM agent types and strate-\\ngies, allowing researchers to experiment with diverse behavioral models and decision-making\\napproaches.\\nThis extensible design creates numerous research opportunities for market microstructure\\nstudies. Researchers can systematically investigate how different market structures influence\\nprice formation and efficiency, evaluate the impact of various trading rules on market qual-\\nity, and analyze the complex interactions between different agent types and strategies. The', '(2023)). This work, however, focuses on financial markets and how LLM agents can operate\\nas full-fledged trading participants.\\nRecent research examines specific applications of LLMs for trading. FinMem and Trad-\\ningGPT introduce frameworks with layered memory systems and customizable agent traits\\n5\\nto improve financial decision-making (Yu, Li, et al. 2024; Li, Zhang, and Sun 2023). Hierar-\\nchical multi-agent architectures have been explored in FinCon, which uses a manager-analyst\\nsetup for collaborative portfolio decisions (Yu, Yao, et al. 2024). QuantAgent implements\\na self-improving signal-mining approach (Wang et al. 2024), while other work underscores\\nthe importance of long-term memory in LLM agents via vector databases (Hatalis et al.\\n2024). This line of research builds on successful reinforcement learning applications such as\\nAlphaPortfolio (Cong et al. 2021) and AlphaManager (Campello, Cong, and Zhou 2023),\\nwhich leverage deep RL and robust control for portfolio management.\\nAnalyzing LLM agent behavior by changing only some parameters draws on methods\\nfrom the interpretable machine learning literature. In particular, the systematic variation\\nof market parameters to reveal decision patterns mirrors partial dependence plots and in-\\ndividual conditional expectation curves used to interpret complex machine learning models\\n(Molnar 2022). These techniques help reveal how LLM agents respond to changes in specific\\nvariables while holding others constant, providing insight into their internal decision-making\\nprocesses that would otherwise remain opaque.\\nBeyond finance, studies of LLM capabilities in interactive or multi-agent settings offer\\nvaluable insights. Benchmarks like AgentBench evaluate LLMs’ performance in interac-\\ntive tasks (Liu et al. 2023), while InvestorBench focuses on financial decision-making tasks\\nspecifically (H. Li et al. 2024). NegotiationArena demonstrates LLMs’ capacity for strategic\\ninteraction in bargaining contexts (Bianchi et al. 2024). Similarly, Guo et al. (2024) provide\\nan economics ”arena” where LLMs compete in strategic games, revealing that advanced\\nmodels like GPT-4 can exhibit rational, adaptive behavior—albeit not always reaching Nash\\nEquilibrium. Existing frameworks typically assess individual agents or hierarchical collab-\\norations, whereas this work studies emergent market behaviors that arise from multiple\\nindependent LLM traders interacting in a marketplace.\\nThe approach also connects to the tradition of experimental asset markets. For instance,\\nWeitzel et al. (2020) show that even finance professionals are susceptible to speculative\\n6\\nbubbles, especially amid high capital inflows. Kop´ anyi-Peuker and Weber (2021) find that\\ntrading experience alone does not eliminate bubbles, challenging assumptions about rational\\nmarket learning. Kirchler, Huber, and St¨ ockl (2012) identify confusion about fundamental\\nvalues as a key driver of bubble formation. This framework offers a new way to study these\\nphenomena with LLM traders, which can be rigorously parameterized for sophistication,\\nstrategy, and information processing. Hence, this paper provides a method to investigate\\nhow automated or ”artificial” agents might affect market stability or volatility.\\nOther recent work highlights the versatility of LLM agents in complex, interactive sce-\\nnarios beyond finance. One stream focuses on simulating social behaviors—such as opinion\\ndynamics (Chuang et al. 2023), trust (Xie et al. 2024), and resource-sharing (Piatti et al.\\n2024). Another examines LLMs’ strategic capabilities through task-based simulations and\\ncollaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\\nWithin the computer science literature, early works apply LLMs to financial markets but\\nabstract away many fundamental stock market characteristics. Often, they employ single-\\nprice clearing mechanisms without a persistent order book, ignore partial fills and bid-ask', 'ceedings of the 62nd Annual Meeting of the Association for Computational Linguistics\\n(Volume 1: Long Papers),edited by Lun-Wei Ku, Andre Martins, and Vivek Srikumar,\\n15523–15536. ACL 2024. Bangkok, Thailand: Association for Computational Linguis-\\ntics, August.\\n39\\nLi, Yuan, Yixuan Zhang, and Lichao Sun. 2023. “MetaAgents: Simulating Interactions of\\nHuman Behaviors for LLM-based T Ask-Oriented Coordination via Collaborative Gen-\\nerative Agents.” arXiv.org.\\nLiu, Xiao, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, et al. 2023.\\n“AgentBench: Evaluating LLMs as Agents.”International Conference on Learning Rep-\\nresentations.\\nLopez-Lira, Alejandro, and Yuehua Tang. 2023. “Can ChatGPT Forecast Stock Price Move-\\nments? Return Predictability and Large Language Models.” SSRN Electronic Journal\\n(April 6, 2023).\\nManning, Benjamin S., Kehang Zhu, and John J. Horton. 2024. “Automated Social Science:\\nLanguage Models as Scientist and Subjects.” (Cambridge, MA) (April 29, 2024).\\nMolnar, Christoph. 2022. Interpretable Machine Learning.\\nPelster, Matthias, and Joel Val. 2023. “Can Chatgpt Assist in Picking Stocks?”Social Science\\nResearch Network.\\nPiatti, Giorgio, Zhijing Jin, Max Kleiman-Weiner, Bernhard Sch¨ olkopf, Mrinmaya Sachan,\\nand Rada Mihalcea. 2024. “Cooperate or Collapse: Emergence of Sustainable Coopera-\\ntion in a Socie Ty of LLM Agents.” arXiv.org.\\nPing, Chen. 2019. “From Complexity Science to Complexity Economics.” In Alternative\\nApproaches to Economic Theory,19–55. Routledge, June 11, 2019.\\nWang, Saizhuo, Hang Yuan, Lionel M. Ni, and Jian Guo. 2024. “QuantAgent: Seeking Holy\\nGrail in Trading by Self-Improving Large Lang Uage Model.” arXiv.org.\\nWeitzel, Utz, Christoph Huber, J¨ urgen Huber, Michael Kirchler, Florian Lindner, and Julia\\nRose. 2020. “Bubbles and Financial Professionals.” The Review of Financial Studies33,\\nno. 6 (June 1, 2020): 2659–2696.\\n40\\nWolfram, Elsner. 2017. “Complexity Economics as Heterodoxy: Theory and Policy.”Journal\\nof Economic Issues51, no. 4 (October 2, 2017): 939–978.\\nWoodhouse, Drew, and Alex Charlesworth. 2023. “Can ChatGPT Predict Future Interest\\nRate Decisions?” Social Science Research Network.\\nXie, Chengxing, Canyu Chen, Feiran Jia, Ziyu Ye, Shiyang Lai, Kai Shu, Jindong Gu, et al.\\n2024. “Can Large Language Model Agents Simulate Human Trust Behavior?”arXiv.org.\\nYang, Stephen. 2023. “Predictive Patentomics: Forecasting Innovation Success and Valuation\\nw Ith ChatGPT.” Social Science Research Network.\\nYu, Yangyang, Haohang Li, Zhi Chen, Yuechen Jiang, Yang Li, Denghui Zhang, Rong\\nLiu, Jordan W. Suchow, and Khaldoun Khashanah. 2024. “FinMem: A Performance-\\nEnhanced LLM Trading Agent with Layered Memory a Nd Character Design.”Proceed-\\nings of the AAAI Symposium Series3, no. 1 (May 20, 2024): 595–597.\\nYu, Yangyang, Zhiyuan Yao, Haohang Li, Zhiyang Deng, Yupeng Cao, Zhi Chen, Jordan W.\\nSuchow, et al. 2024. “FinCon: A Synthesized LLM Multi-Agent System with Conceptual\\nVerbal Reinforcement for Enhanced Financial Decision Making.” Pre-published, Novem-\\nber 7, 2024. Accessed January 8, 2025. https://doi.org/10.48550/arXiv.2407.06567.\\narXiv: 2407.06567 [cs]. http://arxiv.org/abs/2407.06567.\\nZhang, Chong, Xinyi Liu, Zhongmou Zhang, Mingyu Jin, Lingyao Li, Zhenting Wang,\\nWenyue Hua, et al. 2024. “When AI Meets Finance (StockAgent): Large Language\\nModel-based Stock Trading in Simulated Real-world Environments.” Pre-published,\\nSeptember 21, 2024. Accessed January 26, 2025. https://doi.org /10.48550/arXiv .\\n2407.18957. arXiv: 2407.18957 [q-fin]. http://arxiv.org/abs/2407.18957.\\n41\\nA Technical Implementation Details\\nA.1 Agent Type Specifications\\nThis section details the base system prompts for each agent type in our simulation. These\\nprompts define the core behavioral characteristics and trading strategies for each agent. Each\\nprompt consists of:\\n• A role definition that establishes the agent’s trading philosophy\\n• A structured trading strategy that guides decision-making', '33\\nants, allowing researchers to study how different belief structures influence price formation\\nand trading patterns under different initial mispricings. In these scenarios, the fundamental\\nprice is hidden from agents, forcing them to rely on their own valuation models.\\n3.2.5 Market Stress\\nThis scenario tests market resilience under challenging conditions by creating a more volatile\\nenvironment. The scenario includes two consistently bullish Optimistic traders, two consis-\\ntently bearish Pessimistic traders, two Market makers (liquidity providers), and two Value\\ninvestors (rational benchmark traders). The scenario runs for 100 rounds to study long-term\\nmarket behavior and includes unequal initial endowments, with optimistic traders having\\nmore cash (1.5x baseline) but fewer shares (0.5x baseline) and pessimistic traders having less\\ncash (0.5x baseline) but more shares (1.5x baseline). This resource imbalance tests whether\\nparticular agent types can dominate market outcomes through resource advantages.\\nThe scenarios presented here demonstrate the framework’s capabilities for exploring di-\\nverse market conditions. Its modular structure facilitates the straightforward definition and\\nimplementation of alternative experimental designs, enabling researchers to tailor simulations\\nto specific research questions.\\nIn all scenarios, we maintain consistent baseline parameters with a fundamental value\\nof $28.00, calculated from the expected dividend of $1.40 and interest rate of 5%. Agent\\nendowments start at 1,000,000 monetary units and 10,000 shares unless specifically modified.\\nTransaction costs are set to zero to isolate the effects of agent behavior and market structure\\non price formation.\\n4 Conclusion\\nThis paper demonstrates that Large Language Models can effectively function as diverse\\ntrading agents—from value investors to market makers—maintaining strategic consistency\\n34\\nwhile adapting to market conditions. Our experimental framework reveals that their in-\\nteractions generate realistic market dynamics, including phenomena like price bubbles and\\ncorrections, highlighting both the capabilities and potential risks of deploying LLM agents\\nin financial markets.\\nThese findings carry significant implications for market structure and regulation. While\\nLLM agents can enhance price discovery and liquidity, their adherence to programmed strate-\\ngies, even potentially flawed ones derived from prompts, could amplify market volatility or\\nintroduce novel systemic risks, as observed in our simulated bubble scenarios. A key concern\\nis the potential for widespread correlated behavior: similar underlying LLM architectures\\nresponding uniformly to comparable prompts or market signals could inadvertently create\\ndestabilizing trading patterns without explicit coordination. This underscores the critical\\nneed for rigorous testing and validation of LLM-based trading systems prior to live deploy-\\nment.\\nA central contribution of this work is the open-source simulation framework itself, de-\\nsigned to catalyze research into LLM trading agents. We invite the research community to\\nutilize and extend this platform to investigate pressing questions in this rapidly evolving\\narea. The framework enables systematic exploration of complex scenarios—such as hybrid\\nhuman-LLM markets, stress tests, varying market structures, regulatory impacts, and the\\nnuances of LLM prompting—often difficult or costly to study otherwise. Specific avenues\\nripe for investigation using this tool include the emergence of novel trading strategies, the\\nprecise effects of agent heterogeneity on market stability, and the development of robust\\nvalidation protocols for AI traders. As artificial intelligence becomes more integrated into\\nfinance, collaborative research leveraging adaptable simulation environments like this one\\nwill be crucial for understanding and responsibly shaping the future of trading.\\n35\\nReferences', 'decision-making process.\\nThe analysis reveals three key findings about LLMs’ capabilities as trading agents. First,\\nLLMs can effectively execute trading strategies. They consistently understand market me-\\nchanics, process market information, form price expectations, and execute trades according\\nto specific instructions. Their trading behavior is highly sensitive to the prompts they\\nreceive—they faithfully follow directions regardless of profit implications. This observance\\n1. For example, Autopilot has a ChatGPT-based portfolio https://x.com/thegptinvestor.\\n2\\n{\"valuation_reasoning\":\\n\"The fundamental value is based on the expected dividend,\\nand the interest rate.\\nThe expected dividend is $1.40, and the interest rate is 5%.\\nUsing a perpetuity formula, the value is $1.40 / 0.05 = $28.\",\\n\"valuation\":28.0,\\n\"price_target_reasoning\":\"The current price is $29.00, which is\\nslightly above the fundamental value of $28.00. I expect the price\\nto remain around $29.00 in the next round due to market stability.\",\\n\"price_target\":29.0,\\n\"orders\":[{\"decision\":\"Sell\",\"quantity\":1000,\"order_type\":\"limit\",\\n\"price_limit\":29.50}],\\n\"replace_decision\":\"Add\",\\n\"reasoning\":\"The current price is slightly above the fundamental value.\\nI will place a limit sell order at $29.50 to capitalize on potential price\\nincreases.\"}\\nFigure 1: Example of a structured trading decision from a Speculator agent defined by its\\nsystem prompt: “You are a speculator who tries to profit from market inefficiencies.”. The\\nLLM provides explicit reasoning for its valuation, price target, and trading decision in a\\nmachine-readable JSON format that can be directly processed by the trading system.\\nhighlights a fundamental difference from human traders: LLMs do not inherently optimize\\nfor profit maximization but rather for following instructions accurately.\\nSecond, LLMs react meaningfully to market dynamics. They consider current and his-\\ntorical prices, dividends, and other market information when making decisions. However,\\nthey maintain their strategic direction even when market conditions change, following their\\ninstructions even if doing so results in financial losses. This combination of responsiveness\\nto market conditions while maintaining strategic consistency creates a unique trading profile\\ndistinct from rule-based algorithms and human traders.\\nThird, market dynamics with LLM agents can resemble actual markets and mirror classic\\nresults from the theoretical finance literature. When these agents interact, they produce\\nrealistic price discovery and liquidity provision with emergent behaviors, including price\\nconvergence toward fundamental values. Depending on the distribution of agent types,\\nthe system can generate various market phenomena, such as bubbles or underreactions to\\ninformation. This complex behavior suggests potential applications for studying market\\n3\\ndynamics using LLM agents instead of experiments with human participants.\\nHence, these findings raise important questions about algorithmic consistency in LLM-\\nbased systems. Since trading agents are implemented through prompts, their behavior in-\\nherits characteristics of the underlying language models. The standardization of LLM ar-\\nchitectures across implementations could create unexpected behavioral patterns—if many\\nagents are based on similar foundation models, they might exhibit correlated responses to\\nspecific market conditions, potentially amplifying market instabilities.\\nTo enable this analysis and accelerate development in this emerging field, we provide\\nan open-source framework with three key components: (1) a structured protocol for im-\\nplementing and validating LLM trading agents, supporting both LLM-based and traditional\\nrule-based agents; (2) a controlled market environment with realistic microstructure for test-\\ning agent interactions; and (3) a comprehensive data collection system for analyzing trading\\nbehavior. This framework serves multiple stakeholders in preparation for the evolution of', 'Can Large Language Models Trade? Testing Financial\\nTheories with LLM Agents in Market Simulations\\nAlejandro Lopez-Lira∗\\nFirst Version: November 29, 2024; Current Version: April 16, 2025\\nAbstract\\nThis paper presents a realistic simulated stock market where large language models\\n(LLMs) act as heterogeneous competing trading agents. The open-source framework\\nincorporates a persistent order book with market and limit orders, partial fills, div-\\nidends, and equilibrium clearing alongside agents with varied strategies, information\\nsets, and endowments. Agents submit standardized decisions using structured outputs\\nand function calls while expressing their reasoning in natural language. Three findings\\nemerge: First, LLMs demonstrate consistent strategy adherence and can function as\\nvalue investors, momentum traders, or market makers per their instructions. Second,\\nmarket dynamics exhibit features of real financial markets, including price discovery,\\nbubbles, underreaction, and strategic liquidity provision. Third, the framework enables\\nanalysis of LLMs’ responses to varying market conditions, similar to partial dependence\\nplots in machine-learning interpretability. The framework allows simulating financial\\ntheories without closed-form solutions, creating experimental designs that would be\\ncostly with human participants, and establishing how prompts can generate correlated\\nbehaviors affecting market stability.\\nKeywords: LLM Agents; Agent-Based Markets; Experimental Finance; AI Trading;\\nMulti-Agent Systems\\n∗University of Florida. Email: alejandro.lopez-lira@warrington.ufl.edu. I am grateful to seminar par-\\nticipants at the London Business School, Oxford University, Stockholm School of Economics, University of\\nVirginia, and the City University of Hong Kong for helpful suggestions and feedback.\\n1\\narXiv:2504.10789v1  [q-fin.CP]  15 Apr 2025\\n1 Introduction\\nLarge language models (LLMs) can increasingly function as autonomous agents—systems\\nthat observe, reason, and act independently. LLMs have shown promising results in finan-\\ncial forecasting, but their potential as trading agents introduces a fundamental shift from\\nalgorithms with explicit objectives to systems guided by natural language instructions. This\\nchange raises critical questions: Can LLMs execute trading strategies? Do LLMs optimize\\nfor profit maximization? What are the implications for market stability and efficiency?\\nIf LLMs trade similarly to humans, they could enable experimental market simulations\\nwithout human participants. Conversely, if their trading behavior differs, understanding\\nthese differences becomes critical for systemic risk management. These questions extend be-\\nyond theory; LLM-based strategies are already being deployed.1 To address these questions,\\nI develop an open-source simulation that tests LLM trading agents in a realistic market envi-\\nronment with a persistent order book, supporting various order types, stochastic dividends,\\nand heterogeneous information.\\nThe framework allows heterogeneous LLMs—defined in natural language, using different\\nsystem prompts—to act as diverse types of traders, such as value investors, momentum\\ntraders, market makers, and contrarians. Agents submit standardized trading decisions in a\\nhuman-readable format while expressing their reasoning transparently. Figure 1 illustrates\\nthis approach, showing how a speculator agent combines explicit valuation reasoning with\\nstructured trading parameters, enabling systematic analysis and insight into the agent’s\\ndecision-making process.\\nThe analysis reveals three key findings about LLMs’ capabilities as trading agents. First,\\nLLMs can effectively execute trading strategies. They consistently understand market me-\\nchanics, process market information, form price expectations, and execute trades according\\nto specific instructions. Their trading behavior is highly sensitive to the prompts they\\nreceive—they faithfully follow directions regardless of profit implications. This observance']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ❌ Contextual Precision (ragas) (score: nan, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ❌ Faithfulness (ragas) (score: nan, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Contextual Recall (ragas) (score: 1.0, threshold: 0.6, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Answer Relevancy (ragas) (score: 0.8832938065156144, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: The paper gives Vt=E[D]rV_t=\tfrac{E[D]}{r} as Equation (1). What does each variable represent, and how is this perpetuity formula used in the simulations?\n",
      "  - actual output: In the formula Vt = E[D]/r,\n",
      "\n",
      "Vt represents the fundamental value of the firm at time t. This is the theoretical \"true\" value of the company based on its expected future earnings.\n",
      "E[D] represents the expected value of the firm's dividends. Dividends are the portion of a company's profits that are paid out to its shareholders. E[...] denotes the expected value of a random variable. Since the excerpts mention \"discounted-loan\" type debt and no dividend payments on equity being assumed, the formula likely refers to expected cash flow available to all security holders, debt and equity.\n",
      "r represents the risk-free interest rate (the return an investor can expect from a \"safe\" investment like a government bond).\n",
      "In the simulations, this perpetuity formula (a formula for valuing a stream of payments that continues forever) is used to establish a baseline value for the simulated firm. The simulations then explore how market prices, driven by the AI agents' trading activity, deviate from this fundamental value, specifically testing the scenarios where the market starts 25% above or below this calculated fundamental value. This setup allows the researchers to observe how effectively the AI agents correct over- or under-valuations back towards the \"true\" value.\n",
      "\n",
      "  - expected output: Vt=E[D]/rV_t = E[D]/r treats the stock as a perpetuity: E[D]E[D] is expected dividend per round and rr the risk‑free rate; with $1.40 and 5 % the value is $28.\n",
      "  - context: ['The framework implements a consistent approach… For infinite horizon markets, the fundamental value follows the standard dividend discount model: Vt=E[D]rV_t = \\x0crac{E[D]}{r}. … For the default parameters where the expected dividend is $1.40 and the interest rate is 5 %, this yields a fundamental value of $28.00.']\n",
      "  - retrieval context: ['of the ﬁrm and the changes in value of the ﬁrm’s capital stock or earning assets\\nover the period. A crucial assumption is that P(Z, τ)is independent of the particular\\ncapital structure of the ﬁrm, i.e. Pis determined solely by the characteristics of the\\nasset side of the balance sheet and is not affected by the particular instruments used\\nby the ﬁrm to ﬁnance these assets. This assumption is consistent with the Modigliani-\\nMiller (1958) theorem and, as such, we implicitly assume perfect capital markets and\\ntax effects are not considered.\\nConsider that the ﬁrm chooses a particular set of ﬁnancial instruments (debt, eq-\\nuity, etc.) deﬁned by their terminal conditions. We now ﬁnd the current equilibrium\\nvalue of each of these future claims on the terminal (random) value of the ﬁrm. For\\ni= 1,. . ., n , deﬁne Fi(V, τ)as the current value of the ith type of security with ter-\\nminal date τfrom now issued by the ﬁrm.2The different types of securities are\\ndistinguishable by their terminal value Fi(V Z,0), contingent on the terminal value of\\nthe ﬁrm V(t+τ) =V Z. For example, if one of the securities is a debt issue ( i= 1),\\nsenior to all other claims on the ﬁrm, with a terminal claim of Bdollars on the ﬁrm,\\nthen\\nF1(V Z,0) = min( B, V Z ) (11.3)\\ni.e. the debtholders will receive Bdollars at the end of the period if the ﬁrm can pay,\\nor, in the event that the ﬁrm cannot pay (default), they are entitled to all the assets of\\nthe ﬁrm which will have value V Z.\\nTo determine the equilibrium values of each of the securities, note that because\\neach of the securities appears separately in the market place, they must be priced so\\n1Since, in this section, we are using a period model, τcould be set equal to one. However, it will be useful\\nfor later development to carry the general symbol τ.\\n2Strictly, Fiwill be a function of the current values of all securities senior to it, the capitalization rate, etc.\\nin addition to V. However, in equilibrium, the Fiare perfectly positively related to changes in the value of the\\nﬁrm, and so these other arguments of the function will enter only as parameters.\\n280 A Dynamic General Equilibrium Model of the Asset Market\\nthat when examined by the representative man he will choose his portfolio so as to\\nhold the amount supplied, i.e.\\nV=n∑\\ni=1Fi(V, τ) (11.4)\\nand, of course, V Z=∑n\\n1Fi(V Z,0). Deﬁne wi≡Fi(V, τ)/Vas the fraction of the\\nﬁrm’s assets ﬁnanced by the ith security. Then, because the ﬁrm is the only asset\\nin the economy, wiwill also be equal to the fraction of the representative man’s\\ninitial wealth invested in the ith security. We rewrite (11.1) as a maximization under\\nconstraint problem:\\nmax\\n{wi}{\\nEtU[\\nVn∑\\ni=1wiFi(V Z,0)\\nFi(V, τ)]\\n+λ[\\n1−n∑\\ni=1wi]}\\n(11.5)\\nThe ﬁrst-order conditions3derived from (11.5) are\\nEt{\\nFi(V Z,0)\\nFi(V, τ)U′[\\nVn∑\\ni=1wiFi(V Z,0)\\nFi(V, τ)]}\\n=λ i = 1,. . ., n (11.6)\\nEquation (11.6) can be rewritten in terms of util-prob distributions4Qas\\n∫∞\\n0Fi(V Z,0)\\nFi(V, τ)dQ=∫∞\\n0Fj(V Z,0)\\nFj(V, τ)dQ≡exp(ητ)for all i,j= 1,. .. , n (11.7)\\nwhere\\ndQ≡U′(ZV)dP(Z, τ)∫∞\\n0U′(ZV)dP(Z, τ)\\nandexp(ητ)is a new multiplier related to the original λmultiplier. Note the important\\nsubstitution of V ZforV∑n\\n1wiFi(V Z,0)/Fi(V, τ)in the deﬁnition of dQ. By the\\nassumption that the value of the ﬁrm is independent of its capital structure, we have\\nthatdQis independent of the functions Fi,i= 1,. .. , n . Therefore, (11.7) is a set of\\nintegral equations, linear in the Fi.5Hence, we can meaningfully rewrite (11.7) as\\nFi(V, τ) = exp( −ητ)∫∞\\n0Fi(V Z,0)dQ(Z, τ) i= 1,. . ., n (11.8)\\nBecause the Fi(V Z,0)are known functions determined by the type of security, and U\\nandP(Z, τ)are assumed known, (11.8) would be sufﬁcient to determine the current\\nequilibrium value of the Eth security if we knew η.\\nFrom examination of (11.7) and noting again that dQis independent of the partic-\\nular capital structure chosen, we ﬁnd that exp(ητ)(and hence η) is independent of the', 'one-period model further, an intertemporal equilibrium model, which includes the\\nmodel of Section 11.2 as a special case, is developed in the following sections.\\n11.4 A General Intertemporal Equilibrium Model of the Asset Market\\nConsider an economy with Kconsumers-investors and nﬁrms with current value Vi,\\ni= 1,. .. , n . Each consumer acts so as to\\nmaxE0{∫Tk\\n0Uk[\\nCK(s),s]\\nds+Bk[\\nWk(\\nTk)\\n,Tk]}\\n(11.28)\\nwhere E0is the conditional expectation operator, conditional on the value of current\\nwealth Wk(0) = Wkof the kth consumer and on the current value of the ﬁrms,\\nVi(0) = Vi,i= 1,. .. , n .Ck(s)is his instantaneous consumption at time s.Ukis a\\nstrictly concave von Neumann-Morgenstern utility function; Bkis a strictly concave\\n“bequest” or utility-of-terminal-wealth function; and Tkis the date of death of the\\nkth consumer. Deﬁne Ni(t)Pi(t)≡Vi(t)where Ni(t)is the number of shares14of\\nﬁrmioutstanding at time tandPi(t)is the price per share at time t. It is assumed that\\nexpectations about the dynamics of the prices per share in the future are same for all\\ninvestors and these dynamics ca be described by the stochastic differential equation15\\ndPi\\nPi=αidt+σidZii= 1,. .. , n (11.29)\\nwhere the instantaneous expected rate of return, αi, and the instantaneous standard\\ndeviation of return, σi, may change stochastically over time, but only in a way which\\nis instantaneously uncorrelated with price changes (i.e. dαidZj=dσidZj= 0 for\\ni,j= 1,. .. , n ). The dZirepresent a simple Gauss-Wiener process with zero mean\\nand unit variance rate (often referred to as Gaussian “white noise”). Equation (11.29)\\nincludes returns from both capital gains and dividends, and reﬂects both the uncer-\\ntainties about future cash ﬂows and changes in the “capitalized” value of the ﬁrm’s\\nearning assets. Notice that, if αiandσiwere constant, then the Pi(t)would be log-\\nnormally distributed. Further assume that one of the nassets (by convention the nth\\none) is an “instantaneously” riskless asset16with instantaneous return r(t)and that\\n14In this section, the particular capital structure of the ﬁrm is not discussed, and hence one can think of each\\nﬁrm as having the trivial capital structure, namely, all equity. However, the assumption that the value of the\\nﬁrm is independent of its capital structure is retained throughout the chapter.\\n15For a discussion of and further references to stochastic differential equations of the type in (11.29), see\\nMerton (1971; this volume, Ch. 5).\\n16What is meant by an “instantaneously” riskless asset is that, at each instant of time, each investor knows\\nwith certainty that he can earn return r(t)over the next instant by holding the asset (i.e. σn= 0andαn=r).\\nHowever, the future values of r(t)are not known with certainty. It is assumed here that one of the ﬁrms is\\ncharacterized by this asset. Alternatively, one could postulate a government which issues (very) short bonds,\\nor that r(t)is the instantaneous private sector borrowing (and lending) rate.\\n11.4 A General Intertemporal Equilibrium Model of the Asset Market 287\\nthe dynamics of this rate are described by\\ndr=f(r,t)dt+g(r,t)dq (11.30)\\nwhere (11.30) is the same type of equation as (11.29) and dqis a simple Gauss-Wiener\\nprocess. For computational simplicity, it is further assumed that αiandσi, in (11.29),\\nare functions only of r(t),17i.e. investors only anticipate revising their expectations\\nabout returns if the interest rate changes.\\nFrom the deﬁnition of NiandPi. we have that the change in the value of the ith\\nﬁrm over time is dV=NidPi+dNi(Pi+dPi). The ﬁrst term is that part of the changed\\nvalue of the ﬁrm due to cash ﬂow and changes in the value of its assets. The second\\nterm is that part of the changed value of the ﬁrm due to the issue (or purchase) of new\\nshares at the new price per share Pi+dPi.18Substituting from (11.29) for dPi/Piand\\nwriting everything in percentage terms, we have that\\ndVi\\nVi=αidt+σidZi+dNi\\nNi(1 +αidt+σidZi) i= 1,. .. , n (11.31)', 'equity, f, will be\\n0 =1\\n2σ2V2fvv+ (rV−C)fv−rf−fτ= 0 (12.41)\\nsubject to boundary conditions (12.9a), (12.9b), and (12.11). Again, equation (12.41)\\nhas an isomorphic correspondence with an option pricing problem previously stud-\\nied. Equation (12.41) is identical to equation (12.44) in Merton (1973a; this volume,\\nequation (8.44)) which is the equation for the European option value on a stock which\\npays dividends at a constant rate per unit time of C. While a closed-form solution to\\n(12.41) for ﬁnite τhas not yet been found, one has been found for the limiting case\\nof a perpetuity (τ=∞), and is presented in Merton (1973a; this volume, equation\\n(8.46)). Using the identity F=V−f, we can write the solution for the perpetual\\nrisky coupon bond as\\nF(v,∞) =C\\nr\\n1−(\\n2C\\nσ2v)2r\\nσ2\\nΓ(\\n2 +2r\\nσ2)M(2r\\nσ2,2 +2r\\nσ2,−2C\\nσ2v)\\n(12.42)\\nwhere Γ(·)is the gamma function and M(·)is the conﬂuent hypergeometric func-\\ntion. While perpetual, non-callable bonds are non-existent in the United States, there\\nare preferred stocks with no maturity date and (12.42) would be the correct pricing\\nfunction for them.\\nMoreover, even for those cases where closed-form solutions cannot be found,\\npowerful numerical integration techniques have been developed for solving equations\\nlike (12.7) or (12.41). Hence, computation and empirical testing of these pricing the-\\nories is entirely feasible.\\nNote that in deducing (12.40), it was assumed that coupon payments were made\\nuniformly and continuously. In fact, coupon payments are usually only made semi-\\nannually or annually in discrete lumps. However, it is a simple matter to take this into\\n322 On the Pricing of Corporate Debt: The Risk Structure of Interest Rates\\naccount by replacing “ C” in (12.40) by “∑\\niCiδ(τ−τi)” where δ(·)is the dirac delta\\nfunction and τiis the length of time until maturity when the ith coupon payment of\\nCidollars is made.\\nAs a ﬁnal illustration, we consider the case of callable bonds. Again, assume the\\nsame capital structure but modify the indenture to state that “the ﬁrm can redeem\\nthe bonds at its option for a stated price of K(τ)dollars” where Kmay depend on\\nthe length of time until maturity. Formally, equation (12.40) and boundary conditions\\n(12.9a) and (12.9c) are still valid. However, instead of the boundary condition (12.9b)\\nwe have that for each τ, there will be some value for the ﬁrm, call it V(τ), such that\\nfor all V(τ)≥V(τ), it would be advantageous for the ﬁrm to redeem the bonds.\\nHence, the new boundary condition will be\\nF[V(τ),τ] =K(τ) (12.43)\\nEquation (12.40), (12.9a), (12.9c), and (12.43) provide a well-posed problem to solve\\nforFprovided that the V(τ)function were known. But, of course, it is not. Fortu-\\nnately, economic theory is rich enough to provide us with an answer. First, imagine\\nthat we solved the problem as if we knew V(τ)to get F[V, τ;V(τ)]as a function of\\nV(τ). Second, recognize that it is at management’s option to redeem the bonds and\\nthat management operates in the best interests of the equity holders. Hence, as a\\nbondholder, one must presume that management will select the V(τ)function so as\\nto maximize the value of equity, f. But, from the identity F=V−f, this implies that\\ntheV(τ)function chosen will be the one which minimizes F[V, τ;V(τ)]. Therefore,\\nthe additional condition is that\\nF[V, τ] = min\\n{V(τ)}F[V, τ;V(τ)] (12.44)\\nTo put this in appropriate boundary condition form for solution, we again rely on\\nthe isomorphic correspondence with options and refer the reader to the discussion in\\nMerton (1973a) where it is shown that condition (12.44) is equivalent to the condition\\nFV[V(τ),τ] = 0 (12.45)\\nHence, appending (12.45) to (12.40), (12.9a), (12.9c) and (12.43), we solve the prob-\\nlem for the F[V, τ]andV(τ)functions simultaneously.\\n12.7 Conclusion\\nWe have developed a method for pricing corporate liabilities which is grounded in\\nsolid economic analysis, requires inputs which are on the whole observable; can', 'P(r,0) = 1 , to determine P(r,τ)and hence the term structure of interest rates. How-\\never, without some independent knowledge of αm(and hence ατ), we cannot deter-\\nmine an explicit solution for the term structure.\\nSuppose that one knew that the Expectations Hypothesis held. Then ατ≡rfor all\\nτand the term structure is completely determined by\\n0 =1\\n2g2Prr+fPr−Pτ−rP (11.83)\\nsubject to P(r,0) = 1 . Further, from (11.80), it must be that in equilibrium, αm=r.\\nIn this case, the equilibrium condition (11.77) simpliﬁes to\\nαk−r=σk(ρkM−ρMrρkr)\\nσM(1−ρ2\\nMr)(αM−r) k= 1,. .. , m −1 (11.84)\\nwhere the ρs are the instantaneous correlation coefﬁcients deﬁned by ρkM≡σkM/σkσM,\\nρkr≡σkr/gσk, andρMr≡σMr/gσM. Hence, the individual expected returns are pro-\\nportional to the market expected return as was the case in Model I. However, the\\nproportionality factor is not σMk/σ2\\nM. If the mth security is chosen to be a portfolio\\nof government bonds, then, given speciﬁc knowledge of the term structure, the rest\\nof the equilibrium relations work out in a determined fashion.\\nEquation (11.83) cannot be solved in closed form for arbitrary fandg. However,\\nif it is assumed that fandgare constants (i.e. rfollows a Gaussian random walk with\\na drift), then, under the Expectations Hypothesis, we do have the explicit solution\\nP(r,τ) = exp(\\n−rτ−f\\n2τ2+g2\\n6τ3)\\n(11.85)\\nNote that in (11.85), as τ→ ∞ ,P→ ∞ , which is not at all reasonable. Certainly, the\\ncurrent value of a discounted loan which will never be paid should be zero for any\\n300 A Dynamic General Equilibrium Model of the Asset Market\\nrealistic assumption about interest rates. The reason that (11.85) gives such nonsensi-\\ncal results is that, by the assumption that ris Gaussian, there is a positive probability\\nofrbecoming negative. In fact, as τ→ ∞ ,rwill be negative for an arbitrary period\\nof time with positive probability. This result illustrates how the assumption of the\\nnormal distribution for variables which are constrained to be nonnegative can lead to\\nabsurd implications. However, equation (11.83) with reasonable assumptions about\\nfandgcan be solved numerically and further research is planned in this area.42\\nBy arguments similar to those used in Section 11.5, the Fundamental Equation of\\nSecurity Pricing for the capital structure of the ﬁrm in Model III can be derived as\\n0 =1\\n2σ2V2FV V+1\\n2g2Frr+ρgσV F rV+rV F V+fFr−Fτ−rF (11.86)\\nsubject to an appropriate boundary condition F(V, r,0), where subscripts denote par-\\ntial derivatives and ρis the instantaneous correlation coefﬁcient of the return on the\\nﬁrm with interest rate changes. The basic difference between equations (11.86) and\\n(11.65) of Model I is the explicit dependence of Fonrwhich must be taken into\\naccount. Under most conditions, (11.86) will not be solvable in closed form. How-\\never, numerical solution seems quite reasonable which implies many possibilities for\\nempirical testing both by direct statistical methods and by simulation.\\n11.8 Conclusion\\nA general intertemporal equilibrium model of the asset market has been derived for\\narbitrary preferences, time horizon, and wealth distribution. The equilibrium rela-\\ntions among securities were shown to depend only on certain “observable” market\\naggregates, and hence are subject to empirical investigation. Under the additional as-\\nsumption of a constant rate of interest, these equilibrium relations are essentially the\\nsame as those of the static CAPM of Sharpe, Lintner, and Mossin. However, these\\nresults were derived without the assumption of Gaussian distributions for security\\nprices or quadratic utility functions. When interest rates vary, some of the intuition\\nabout “market risk” and equilibrium expected returns provided by the CAPM was\\nshown to be incorrect.43In addition, the model clearly differentiates between the\\ntrading-period horizon ( dt, an inﬁnitesimal) and the planning or time horizon ( Tk,\\nwhich is arbitrary).', 'ary condition F(V,0) = min( V, B). A comparison of (11.66) with (11.12) shows that\\nthey are the same for dQ=dΛ. Equation (11.66) can be rewritten in general form as\\nF(V, τ) = exp( −rτ)∫∞\\n0F(V Z,0)dΛ(Z, τ) (11.67)\\nwhere F(V Z,0)is the terminal claim of the security on the ﬁrm. Note that (11.67) de-\\npends only on the rate of interest r, which is an observable, and σ2which can be esti-\\nmated from past data reasonably accurately; and notonα, which would be difﬁcult to\\nestimate. The actual value of Fcan be computed by using standard error-complement\\nfunction tables. Hence, (11.67) is subject to rigorous empirical investigation.\\nAlthough (11.67) is a kind of discounted expected value formula. one should\\nnot infer that the expected return on Fisr. From (11.59), (11.63) and (11.64), the\\nexpected return on Fcan be written as\\nαe=r+FVV\\nF(α−r) (11.68)\\nwhich will vary with changes in Vandτ. although it too can be computed from the\\nerror-complement function tables, given an estimate of α.\\n30See Samuelson (1965a. p. 22) for solution of the α=βcase.\\n11.5 Model I: A Constant Interest Rate Assumption 295\\nEquation (11.65) was previously derived by Black and Scholes (1973) as a method\\nfor pricing option contracts.31Moreover, (11.65) actually holds without the assump-\\ntion of market equilibrium used here. Because of its elegance, I derive the Black-\\nScholes model in an alternative fashion which makes use of It ˆo’s lemma and the\\nassociated theory of stochastic differential equations. Consider a two-asset portfolio\\nconstructed so as to contain the ﬁrm as one security and any one of the securities in\\nthe ﬁrm’s capital structure as the other. Let Pbe the price per unit of this portfolio,\\nδthe fraction of the total portfolio’s value invested in the ﬁrm and 1−δthe fraction\\nin the particular security chosen from the ﬁrm’s capital structure. Then, from (11.57)\\nand (11.58),\\ndP\\nP=δdV\\nV+ (1−δ)dF\\nF\\n= [δ(α−αe) +αe]dt+ [δ(σ−σe) +σe]dZ(11.69)\\nSuppose δis chosen such that δ(σ−σe)+σe= 0. Then, the portfolio will be “perfectly\\nhedged” and the instantaneous return on the portfolio will be δ(α−αe) +αewith\\ncertainty. By arbitrage32conditions, δ(α−αe) +αe=r, the instantaneous riskless\\nrate of return. Combining these two conditions, we have that\\nαe−r=σe\\nσ(α−r) (11.70)\\nThen, as was done previously, we use It ˆo’s lemma to derive (11.62) and (11.63).\\nBy combining (11.62), (11.63), and (11.70), we arrive at (11.65). Nowhere was the\\nmarket-equilibrium assumption needed.\\nTwo further remarks must be made before we examine asset pricing in the more\\ncomplex models in Section 11.6 and Section 11.7. Although the value of the ﬁrm\\nfollows a simple dynamic process with constant parameters as described in (11.57),\\nthe individual component securities follow more complex processes with changing\\nexpected returns and variances. Thus, in empirical examinations using a regression\\nsuch as (11.55), if one were to use equity instead of ﬁrm values, systematic biases\\nwould be introduced. One can ﬁnd cases where the risky debt of one ﬁrm is more\\ncomparable with the equity of another ﬁrm than the equity of one ﬁrm is to that of\\nthe other.\\nOne possibly practical application of the equations of this section is to provide\\na systematic method of measuring the riskiness of debt of various ﬁrms. Hence, by\\nusing equation (11.67). one could derive a risk structure of interest rates as a function\\nof the percentage of the total capital structure subordinated to the issue and the overall\\nriskiness of the ﬁrm. It would be interesting to see how such a method of rating debt\\nwould compare with the classical methods of Moody’s and Standard & Poor’s.\\n31For a brief history of the development of the Black-Scholes option pricing model, see Black (1987, 1989)\\nand Bernstein (1992, Ch. 11).\\n32The meaning of “arbitrage” here is not as strong as the usual deﬁnition since differences of opinion among\\ninvestors about the value of σ2or the belief that Fis a function of other variables besides the value of the', 'Fi(V, τ) = exp( −ητ)∫∞\\n0Fi(V Z,0)dQ(Z, τ) i= 1,. . ., n (11.8)\\nBecause the Fi(V Z,0)are known functions determined by the type of security, and U\\nandP(Z, τ)are assumed known, (11.8) would be sufﬁcient to determine the current\\nequilibrium value of the Eth security if we knew η.\\nFrom examination of (11.7) and noting again that dQis independent of the partic-\\nular capital structure chosen, we ﬁnd that exp(ητ)(and hence η) is independent of the\\nparticular capital structure. Since (11.7) holds for all capital structures, it must hold\\n3The assumption of strict concavity of Uis sufﬁcient to ensure a unique interior maximum which rules out\\nany need for inequalities in the ﬁrst-order conditions.\\n4See Samuelson and Merton (1969; this volume, Section 7.2) for further discussion of the util-prob concept.\\n5Thus, the assumption that the ﬁrm’s value is independent of its capital structure provides the same math-\\nematical simpliﬁcation that the assumption of the “incipient” case for warrant pricing did in Samuelson and\\nMerton (1969; this volume, Section 7.7).\\n11.3 Some Examples 281\\nfor the trivial capital structure, namely, when the ﬁrm issues just one type of security,\\nequity, and n= 1. In this case, it is obvious that F1(V, τ) =VandF1(V Z,0) =V Z.\\nSubstituting in (11.7), we have that\\nexp(ητ) =∫∞\\n0ZdQ(Z, τ) (11.9)\\ni.e.exp(ητ)is the expected return on the ﬁrm in util-prob space. Equation (11.7)\\nstates that the expected return on all securities in util-prob space must be equated.\\nIfUwas linear (i.e. the representative man was “risk neutral”), then dQ=dPand\\n(11.7) would imply the well-known result for risk neutrality that expected returns (in\\nthe ordinary sense) be equated. Hence, the util-prob distribution is the distribution of\\nreturns adjusted for risk.\\n11.3 Some Examples\\nUsing equation (11.8), we can derive the equilibrium pricing for various capital struc-\\ntures of the ﬁrm. In the ﬁrst example it is assumed that there are two types of securi-\\nties: debt and equity. Suppose that the amount of debt issued by the ﬁrm represents\\na terminal claim of Bdollars on the ﬁrm. Let F1(V, τ)be the current value of the\\ndebt outstanding and F2(V, τ)be the current value of the (residual) equity. Then,\\nfrom previous discussion and equation (11.3), the terminal value of the debt will be\\nF1(V Z,0) = min( B, V Z ). From equations (11.8) and (11.3), the current value of the\\ndebt will be\\nF1(V, τ) = exp( −ητ)[∫B/V\\n0ZV dQ (Z, τ) +∫∞\\nB/VBdQ(Z, τ)]\\n(11.10)\\nWe can rewrite (11.10) as\\nF1(V, τ) = exp( −ητ)B−exp(−ητ)∫B/V\\n0(B−ZV)dQ(Z, τ) (11.10a)\\nSuppose that the terminal claim of the debtholders is very small relative to the (cur-\\nrent) total value of the ﬁrm (i.e. 0< B≪V) or, alternatively, dQ(Z, τ) = 0 for\\n0≤Z≤B/V . Then\\nF1(V, τ)→exp(−ητ)BasB/V→0 (11.11)\\nIn the limit, the debt becomes riskless and so, from (11.11), we have that ηmust be\\nthe riskless rate of return per unit time (in both util-prob and ordinary returns space)\\nfor the period of length τ. Hence, from this point on, ηwill he replaced by r, the usual\\nnotation for the riskless rate. Examining (11.11a), the second term is the discounted\\nexpected loss in util-prob space due to default on the debt,6and as such is a risk\\n6Throughout the chapter, all debt is assumed to be of the “discounted-loan” type with no payments prior to\\nmaturity. Similarly, it is assumed that no dividends are paid on the equity.\\n282 A Dynamic General Equilibrium Model of the Asset Market\\npremium charged over the-riskless rate. A second useful form of (11.10) is\\nF1(V, τ) = exp( −rτ)[∫∞\\n0ZV dQ (Z, τ)−∫∞\\nB/V(ZV−B)dQ(Z, τ)]\\n=V−exp(−rτ)∫∞\\nB/V(ZV−B)dQ(Z, τ) (11.10b)\\nSince, in equilibrium, V=F1(V, τ) +F2(V, τ), the current value of equity, F2(V, τ),\\nmust satisfy\\nF2(V, τ) = exp( −rτ)∫∞\\nB/V(ZV−B)dQ(Z, τ) (11.12)\\nEquation (11.12) is identical to the warrant pricing equation derived in Samuelson\\nand Merton (1969; this volume, Section 7.8) for a warrant with exercise price B.', 'the ﬁrst to show that combinations of options could be used to create pure securities\\nand that these pure securities could be used to price derivative securities.\\nIn this section, we derive the natural analog to Arrow-Debreu pure securities in the\\ncontinuous-time model and demonstrate their application to the pricing of contingent-\\nclaim securities. This done, we go on to show the explicit Connections between\\noption pricing theory and the pricing of these pure securities.\\nIn Section 13.2, we derived the price of a general derivative security with payoffs\\nthat are a function of a traded asset’s price and time. Under Assumptions 1-6 of that\\nchapter, it was shown that the price of the derivative security, F(V, t), will satisfy\\n0 =1\\n2σ2V2F11+ (rV−D1)F1−rF+F2+D2 (14.9)\\n10Information costs together with agency problems that prohibit the direct sale of information to investors\\ncan, of course, justify certain types of ﬁnancial intermediation such as mutual funds. Regulation and spe-\\ncial features of the tax laws may also induce the creation of specialized ﬁnancial instruments and institutions.\\nHowever, in the absence of transactions costs, it is difﬁcult to explain the complex structure of ﬁnancial inter-\\nmediaries and their wide scope of activities that we observe in the real world.\\n11See the classical works of Arrow (1953, 1964) and Debreu (1959) for the original development of pure\\nstate-contingent securities. There is an enormous literature based on the ArrowłDebreu model (cf. Radner,\\n1972, and Merton, 1982a. 1990a, Section 5).\\n348 Financial Intermediation in the Continuous-Time Model\\nfor0≤V(t)< V < V(t)andt < T , subject to the boundary conditions\\nF[V(t),t] =f[V(t),t] (14.10a)\\nF[V(t),t] =f[V(t),t] (14.10b)\\nF(V, T) =h(V) (14.10c)\\nSubscripts on Fin (14.9) denote partial derivatives with respect to Vandt.D1(V, t)\\nandD2(V, t)denote the cash-ﬂow rates paid to the holders of the traded asset and its\\nderivative security, respectively. The limited liability of the traded asset implies that\\nV(t) = 0 only if V(t+τ) = 0 andD1(0,t+τ) = 0 for all τ >0. Without loss of\\ngenerality, we can assume that D2(0,t) = 0 .12As discussed in Chapter 13, D2,f,g,\\nandhspecify the payoff function for the derivative security.\\nIn the analysis to follow, we assume that the stochastic process governing the\\ndynamics of the traded asset is such that Pr{V(τ) = 0|V(t)>0}= 0fort≤τ <∞.13\\nLetπ[V(t),t;E, T]denote the price at time tof the particular derivative security with\\na payoff structure given by D2= 0. and for V(T) =VandE >0\\nπ(V, T;E, T) =δ(E−V) (14.11)\\nwhere δ(x)denotes the Dirac delta function with the properties that S(x) = 0 for\\nx̸= 0andδ(0)is inﬁnite in such a way that∫b\\naδ(x)dx= 1for any a <0< b.14We\\nnow show that the derivative securities deﬁned by (14.11) for various values of Eand\\nTare essentially Arrow-Debreu pure securities, extended to an environment with a\\ncontinuum of states deﬁned by the price of the traded asset and time.15\\nLetdE > 0denote the inﬁnitesimal differential of the parameter E. Consider\\na portfolio strategy that at time tpurchases dEunits of each of the continuum of\\nderivative securities with parameter values E∈[E1,E2]and0< E 1< E 2. If the\\nportfolio is held until time TandV(T) =V. then from (14.11), the value of the\\nportfolio is given by\\n∫E2\\nE1δ(E−V)dE=\\n1ifE1< V < E 2\\n0otherwise(14.12)\\n12Because V(t) = 0 implies that V(t+τ) = 0 forτ >0, the capitalized value of any promised payments,\\nD2(0,t+τ), can be incorporated into the termination function g(0,t). Thereby, we can formally set D2(0,t+\\nτ) = 0 without toss of generality.\\n13That is, we assume that V(t) = 0 is an inaccessible boundary for ﬁnite t. For example, this assumption\\nis satisﬁed if the underlying asset has a proportional payout policy, D1(V, t) =ρ(t)V,0≤ρ(t)<∞for all\\ntandσis a constant. General conditions are given in Karlin and Taylor (1981, pp. 226-50)). See also Mardl\\n(1968, pp. 24-5) and Merton (1975a; this volume, Appendix 17B).', 'or purchase of securities prior to the redemption date of the debt ( τ“years” from\\nnow).29Hence, from (11.31), we have that\\ndV\\nV=fcdPP =αdt+σdZ (11.57)\\nwhere αandσare constants.\\nLetD(t;τ)be the current value of the debt with τyears until maturity and with\\nredemption value at that time of B. Then D(t+τ; 0) = min[ V(t+τ),B]. and therefore\\nit is reasonable to assume that D(t;τ)will depend on the interest rate and the proba-\\nbility of default which will be a function of the current value of the ﬁrm. Because the\\ncurrent value of equity is V(t)−D(t;τ), equity will only depend on the current value\\nof the ﬁrm and the interest rate. Let F(V, τ)be the current value of equity where the\\nvariable rhas been suppressed because, in this model, it is constant. The dynamics\\nof the return on equity can be written as\\ndF\\nF=αedt+σedZ (11.58)\\nwhere αeis the instantaneous expected rate of return, σeis the instantaneous standard\\ndeviation of return, and dZis the same standard Wiener process as in (11.57). αeand\\nσeare not constants but functions of Vandτ. Like every security in the economy,\\nthe equity of the ﬁrm must satisfy (11.51) in equilibrium, and hence\\nαe−r=ρσeσM\\nσ2\\nM(αM−r) (11.59)\\nwhere ρis the instantaneous correlation coefﬁcient between dZand the market return.\\nFurther, by It ˆo’s lemma (see Merton, 1971; this volume, Lemma 5.1), we have that\\ndF=FVdV+Fτdτ+1\\n2FV V(dV)2(11.60)\\nwhere subscripts denote partial derivatives. Since τis the length of time until matu-\\nrity,dτ=−dt. Substituting for dVfrom (11.57), we rewrite (11.60) as\\ndF=(1\\n2σ2V2FV V+αV F V−Fτ)\\ndt+σV F VdZ (11.61)\\n29This assumption is stronger than necessary. It is sufﬁcient that any new issues have the same terms as the\\ncurrent capital structure and that they be issued in the same proportions of units ( notvalues) as the current\\nstructure. A more general model using the same approach as in the text could be formulated to include the\\nexpectations of future issues.\\nThe assumption that the debt is of the discounted-loan type is not completely innocent because of the pos-\\nsibility of default on interim interest payments. Although the resulting mathematics is more complicated, the\\nbasic approach used here could be modiﬁed to include the case of interim payments as well. (1990 note: see\\nMerton (1974; this volume, Section 12.6) for a solution of the risky coupon-bond case.)\\n294 A Dynamic General Equilibrium Model of the Asset Market\\nwhere (dV)2≡σ2V2dt. Comparing (11.58) and (11.61), it must be that\\nαeF≡1\\n2σ2V2FV V+αV F V−Fτ (11.62)\\nand\\nαeF≡σV F V (11.63)\\nAs previously shown, the return on holding the ﬁrm itself must satisfy equation\\n(11.51) in equilibrium. Hence,\\nα−r=ρσiσM\\nσ2\\nM(αM−r) (11.64)\\nSubstituting for αandαefrom (11.59) and (11.64) into (11.62), we have the Funda-\\nmental Partial Differential Equation of Security Pricing\\n0 =1\\n2σ2V2FV V+αV F V−Fτ−rF (11.65)\\nsubject to the boundary condition F(V,0) = max(0 ,V−B). The solution30to (11.65)\\nis\\nF(V, τ) = exp( −rτ)∫∞\\nB/V(V Z−B)dΛ(Z, τ) (11.66)\\nwhere Zis a log-normally distributed random variable with mean exp(rτ)and vari-\\nance of log(Z)σ2τ, and dΛis the log-normal density function. I call (11.65) the\\nFundamental Partial Differential Equation of Asset Pricing because all the securities\\nin the ﬁrm’s capital structure must satisfy it. As was true of the model in Section\\n11.1, securities are distinguished by theirs terminal claims (boundary conditions).\\nFor example, the value of the debt of the ﬁrm satisﬁes (11.65) subject to the bound-\\nary condition F(V,0) = min( V, B). A comparison of (11.66) with (11.12) shows that\\nthey are the same for dQ=dΛ. Equation (11.66) can be rewritten in general form as\\nF(V, τ) = exp( −rτ)∫∞\\n0F(V Z,0)dΛ(Z, τ) (11.67)\\nwhere F(V Z,0)is the terminal claim of the security on the ﬁrm. Note that (11.67) de-\\npends only on the rate of interest r, which is an observable, and σ2which can be esti-\\nmated from past data reasonably accurately; and notonα, which would be difﬁcult to']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ❌ Contextual Precision (ragas) (score: nan, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ❌ Faithfulness (ragas) (score: nan, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ❌ Contextual Recall (ragas) (score: nan, threshold: 0.6, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ❌ Answer Relevancy (ragas) (score: nan, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Why is short selling prohibited for these agents, and how might allowing it change the results?\n",
      "  - actual output: Short selling is prohibited to simplify the simulation and avoid potentially destabilizing effects that short selling can introduce, especially given the experimental nature of using LLMs (Large Language Models) as trading agents. The authors wanted to focus on the core dynamics of price discovery without the added complexity of short selling.\n",
      "\n",
      "Allowing short selling could significantly change the results in several ways:\n",
      "\n",
      "Increased Downward Pressure on Prices: If agents could short sell, they could put more downward pressure on prices when they believe the asset is overvalued. This might lead to faster and more efficient corrections of overvaluations, potentially mitigating the persistent overvaluation observed in the simulations.\n",
      "Increased Market Volatility: Short selling can amplify both upward and downward price movements, making the market more volatile. This is because short sellers can create additional selling pressure, driving prices down further and faster than would be possible with only long positions (owning the asset). Conversely, covering short positions (buying back borrowed shares to close a short position) can lead to rapid price increases.\n",
      "More Complex Agent Strategies: Allowing short selling would open up a wider range of possible trading strategies for the agents. They could implement strategies like short and distort (betting against overvalued assets), pairs trading (simultaneously buying an undervalued asset and shorting an overvalued one), or other more sophisticated approaches. This increased complexity could make it more difficult to interpret the agents' behavior and understand the underlying market dynamics.\n",
      "Potential for Market Manipulation: While not explicitly mentioned, the possibility of market manipulation through short selling could become a factor, especially given the experimental nature of the agents. This could take the form of aggressively shorting an asset to drive down its price, potentially creating artificial price crashes or exacerbating existing downturns.\n",
      "\n",
      "  - expected output: It shows asymmetry: over‑valuation persists, but under‑valuation is corrected—the right panel converges to $28 while the left stays high.\n",
      "  - context: ['When the market starts significantly above the fundamental value … the price fails to converge downwards … remaining substantially elevated. Agent valuations mirror this persistence, with many agents maintaining estimates well above the fundamental value.']\n",
      "  - retrieval context: ['2407.18957. arXiv: 2407.18957 [q-fin]. http://arxiv.org/abs/2407.18957.\\n41\\nA Technical Implementation Details\\nA.1 Agent Type Specifications\\nThis section details the base system prompts for each agent type in our simulation. These\\nprompts define the core behavioral characteristics and trading strategies for each agent. Each\\nprompt consists of:\\n• A role definition that establishes the agent’s trading philosophy\\n• A structured trading strategy that guides decision-making\\n• Specific instructions for when to use market orders vs limit orders\\nAt runtime, these base prompts are combined with:\\n• Current market state (price, volume, order book depth)\\n• Position information (current holdings and available cash)\\n• Trading options and required response format\\nThe standard runtime template includes:\\nPosition Information Template\\nYour Position:\\n- Available Shares: {shares} shares (Short selling is not allowed)\\n- Main Cash Account: ${cash:.2f}\\n- Dividend Cash Account (not available for trading): ${dividend_cash:.2f}\\n- Total Available Cash: ${total_available_cash:.2f} (Borrowing is not allowed)\\n- Shares in Orders: {committed_shares} shares\\n- Cash in Orders: ${committed_cash:.2f}\\n42\\nTrading Options Template\\nYour analysis should include:\\n- valuation_reasoning: Your numerical analysis of the asset’s fundamental value\\n- valuation: Your estimate of the asset’s current fundamental value\\n- price_target_reasoning: Your numerical analysis of the asset’s price target\\n- price_target: Your predicted price for the next round\\n- reasoning: Your explanation for the trading decision\\nTrading Options:\\n1. New Orders (replace_decision=’Add’):\\n- Single or multiple orders allowed\\n- For each order:\\n- Market order: Set order_type=’market’\\n- Limit order: Set order_type=’limit’ and specify price_limit\\n- IMPORTANT: Sell orders require sufficient available shares\\n- Short selling is NOT allowed\\n2. Cancel Orders (replace_decision=’Cancel’):\\n- Return an empty orders list: orders=[]\\nYour decision must include:\\n- orders: list of orders (empty list for Hold/Cancel)\\n- For Buy/Sell orders, each must contain:\\n- decision: \"Buy\" or \"Sell\"\\n- quantity: number of shares\\n- order_type: \"market\" or \"limit\"\\n- price_limit: required for limit orders\\n- reasoning: brief explanation\\n- replace_decision: \"Add\", \"Cancel\", or \"Replace\"\\n43\\nBase System Prompts The following are the base system prompts for each LLM-based\\nagent type:\\nA.1.1 Value-Based Agents\\nValue Investor\\nYou are a value investor who focuses on fundamental analysis.\\nYou believe in mean reversion and try to buy undervalued assets and sell overvalued ones.\\nA.1.2 Trend-Following Agents\\nMomentum Trader\\nYou are a momentum trader who focuses on price trends and volume.\\nYou believe that ’the trend is your friend’ and try to identify and follow market momentum.\\nA.1.3 Liquidity Providers Agents\\nMarket Maker\\nYou are a professional market maker who provides liquidity to the market.\\nYour profit comes from capturing the spread between bid and ask prices, not from directional price movement.\\nIMPORTANT: There is NO SHORT SELLING allowed. You can only sell shares you already own.\\nTrading Guidelines:\\n- Place LIMIT buy orders slightly below the current market price (1-3% lower)\\n- Place LIMIT sell orders slightly above the current market price (1-3% higher)\\n- Your spread should be proportional to volatility but typically 2-6% of price\\n- NEVER place sell orders more than 10% above your buy orders\\n- Adjust your spread width based on recent price volatility\\n44\\nInventory Management (No Short Selling):\\n- Monitor your current inventory in the market data\\n- Only place sell orders for quantities you actually own\\n- If you have no inventory, focus on buy orders first\\n- As you acquire inventory, gradually place sell orders\\n- If inventory grows too large, reduce or pause buy orders\\n- Adjust your buy/sell ratio based on current inventory level\\nExample: If price = $100, you might place buy orders at $97-99 and sell orders at $101-103,', '33\\nants, allowing researchers to study how different belief structures influence price formation\\nand trading patterns under different initial mispricings. In these scenarios, the fundamental\\nprice is hidden from agents, forcing them to rely on their own valuation models.\\n3.2.5 Market Stress\\nThis scenario tests market resilience under challenging conditions by creating a more volatile\\nenvironment. The scenario includes two consistently bullish Optimistic traders, two consis-\\ntently bearish Pessimistic traders, two Market makers (liquidity providers), and two Value\\ninvestors (rational benchmark traders). The scenario runs for 100 rounds to study long-term\\nmarket behavior and includes unequal initial endowments, with optimistic traders having\\nmore cash (1.5x baseline) but fewer shares (0.5x baseline) and pessimistic traders having less\\ncash (0.5x baseline) but more shares (1.5x baseline). This resource imbalance tests whether\\nparticular agent types can dominate market outcomes through resource advantages.\\nThe scenarios presented here demonstrate the framework’s capabilities for exploring di-\\nverse market conditions. Its modular structure facilitates the straightforward definition and\\nimplementation of alternative experimental designs, enabling researchers to tailor simulations\\nto specific research questions.\\nIn all scenarios, we maintain consistent baseline parameters with a fundamental value\\nof $28.00, calculated from the expected dividend of $1.40 and interest rate of 5%. Agent\\nendowments start at 1,000,000 monetary units and 10,000 shares unless specifically modified.\\nTransaction costs are set to zero to isolate the effects of agent behavior and market structure\\non price formation.\\n4 Conclusion\\nThis paper demonstrates that Large Language Models can effectively function as diverse\\ntrading agents—from value investors to market makers—maintaining strategic consistency\\n34\\nwhile adapting to market conditions. Our experimental framework reveals that their in-\\nteractions generate realistic market dynamics, including phenomena like price bubbles and\\ncorrections, highlighting both the capabilities and potential risks of deploying LLM agents\\nin financial markets.\\nThese findings carry significant implications for market structure and regulation. While\\nLLM agents can enhance price discovery and liquidity, their adherence to programmed strate-\\ngies, even potentially flawed ones derived from prompts, could amplify market volatility or\\nintroduce novel systemic risks, as observed in our simulated bubble scenarios. A key concern\\nis the potential for widespread correlated behavior: similar underlying LLM architectures\\nresponding uniformly to comparable prompts or market signals could inadvertently create\\ndestabilizing trading patterns without explicit coordination. This underscores the critical\\nneed for rigorous testing and validation of LLM-based trading systems prior to live deploy-\\nment.\\nA central contribution of this work is the open-source simulation framework itself, de-\\nsigned to catalyze research into LLM trading agents. We invite the research community to\\nutilize and extend this platform to investigate pressing questions in this rapidly evolving\\narea. The framework enables systematic exploration of complex scenarios—such as hybrid\\nhuman-LLM markets, stress tests, varying market structures, regulatory impacts, and the\\nnuances of LLM prompting—often difficult or costly to study otherwise. Specific avenues\\nripe for investigation using this tool include the emergence of novel trading strategies, the\\nprecise effects of agent heterogeneity on market stability, and the development of robust\\nvalidation protocols for AI traders. As artificial intelligence becomes more integrated into\\nfinance, collaborative research leveraging adaptable simulation environments like this one\\nwill be crucial for understanding and responsibly shaping the future of trading.\\n35\\nReferences', '44\\nInventory Management (No Short Selling):\\n- Monitor your current inventory in the market data\\n- Only place sell orders for quantities you actually own\\n- If you have no inventory, focus on buy orders first\\n- As you acquire inventory, gradually place sell orders\\n- If inventory grows too large, reduce or pause buy orders\\n- Adjust your buy/sell ratio based on current inventory level\\nExample: If price = $100, you might place buy orders at $97-99 and sell orders at $101-103,\\nbut limit your sell quantity to what you currently own.\\nRemember that extreme spreads (e.g., buying at $3 and selling at $30) will not execute and will lead to losses.\\nA.1.4 Contrarian Agents\\nContrarian Trader\\nYou are a contrarian trader who looks for excessive market moves to trade against.\\nYou believe markets often overreact and try to profit from reversals.\\nA.1.5 Sentiment-Based Agents\\nOptimistic\\nYou are an optimistic trader who firmly believes assets are significantly undervalued.\\nYour Core Beliefs:\\n- The probability of maximum dividends is much higher than stated (80-90% chance)\\nPessimistic\\nYou are a pessimistic trader who firmly believes assets are significantly overvalued.\\n45\\nYour Core Beliefs:\\n- The probability of minimum dividends is much higher than stated (80-90% chance)\\nA.1.6 Miscellaneous Agents\\nSpeculator\\nYou are a speculator who tries to profit from market inefficiencies.\\nRetail Trader\\nYou are a retail trader.\\nLLM Hold Trader\\nYou are a holding agent that never trades.\\nA.1.7 Deterministic Agents\\nThe framework also includes several deterministic rule-based agents that serve as benchmarks\\nand controls. These agents follow fixed algorithmic rules rather than LLM-based decision-\\nmaking. They include directional traders (always buy, always sell), technical traders (mean\\nreversion, momentum), and algorithmic market makers with pre-defined spread-posting\\nstrategies.\\n46', 'standardized, human-readable, machine-readable agent decisions. This technique allows\\nLLMs to generate outputs in a specific format that can be directly validated and processed\\nby the trading system, bridging the gap between natural language reasoning and executable\\ntrading actions.\\nThe system uses Pydantic for validation and parsing of agent outputs, with a schema-\\nbased approach that defines the required structure:\\nclass TradeDecisionSchema(BaseModel):\\nSchema for trade decisions\\nvaluation_reasoning: str = Field(...,\\ndescription=\"Brief explanation of valuation analysis\")\\nvaluation: float = Field(...,\\ndescription=\"Agent’s estimated fundamental value\")\\nprice_target: float = Field(...,\\ndescription=\"Agent’s predicted price in near future\")\\norders: List[OrderSchema] = Field(...,\\ndescription=\"List of orders to execute\")\\n16\\nreplace_decision: str = Field(...,\\ndescription=\"Add, Cancel, or Replace\")\\nreasoning: str = Field(...,\\ndescription=\"Explanation for the trading decisions\")\\nEach order within the decision follows a nested schema:\\nclass OrderSchema(BaseModel):\\nSchema for individual orders\\ndecision: Literal[\"Buy\", \"Sell\"] = Field(...,\\ndescription=\"Buy, Sell\")\\nquantity: int = Field(...,\\ndescription=\"Number of shares\")\\norder_type: str = Field(...,\\ndescription=\"market or limit\")\\nprice_limit: Optional[float] = Field(None,\\ndescription=\"Required for limit orders\")\\nThis structured approach enables several critical features: (1) automatic validation of all\\ndecision components, (2) consistent parsing of agent outputs, (3) clear documentation of the\\nexpected response format, and (4) standardized error handling for malformed responses. The\\nfunction calling methodology ensures that LLMs can focus on trading strategy. At the same\\ntime, the system handles the technical validation of their decisions, significantly improving\\nreliability compared to free-form text parsing.\\n2.2.7 Complete Example\\nThe following example illustrates the complete prompt for a speculator agent, with annota-\\ntions explaining the purpose of each information component.\\nYou are a speculator who tries to profit from market inefficiencies.\\n17\\nThe system prompt establishes the agent’s core identity and strategic objective concisely,\\ncreating a consistent behavioral foundation. Then, the user prompt provides the immediate\\nmarket context necessary for tactical decision-making.\\n2.2.8 Market State Information\\nMarket State:\\nLast Price: $29.00\\nRound Number: 4/Infinite\\nBest Public Estimate of Risk-Neutral Fundamental Value: Unavailable\\nLast Trading Volume: 500.00\\nPrice/Fundamental Ratio: Unavailable\\nThis subsection provides essential market pricing data to establish current conditions. The\\nspeculator intentionally receives no fundamental value estimate to simulate information\\nasymmetry and encourage independent analysis.\\n2.2.9 Market Depth\\nMarket Depth:\\nBest Bid: $28.00\\nBest Ask: $29.00\\nSell Orders:\\n2000 shares @ $57.00\\n3800 shares @ $50.40\\n2000 shares @ $30.00\\n1000 shares @ $29.50\\n4400 shares @ $29.00\\nBuy Orders:\\n1900 shares @ $28.00\\n18\\n1500 shares @ $27.50\\n2500 shares @ $27.00\\nOrder book information lets the agent assess market liquidity, identify potential trading\\nopportunities, and determine optimal order placement strategies. The visible imbalance\\nbetween the bid and ask sides provides critical information about supply and demand dy-\\nnamics.\\n2.2.10 Agent Position\\nYour Outstanding Orders:\\nBuy Orders:\\n400 shares @ $28.00\\nYour Position:\\nAvailable Shares: 10000 shares (Short selling is not allowed)\\nMain Cash Account: $988500.00\\nDividend Cash Account (not available for trading): $296920.65\\nTotal Available Cash: $988500.00 (Borrowing is not allowed)\\nShares in Orders: 0 shares\\nCash in Orders: $11500.00\\nPosition information establishes resource constraints and current market exposure, enabling\\nthe agent to make contextually appropriate decisions while maintaining awareness of out-\\nstanding commitments.\\n2.2.11 Historical Context\\nPrice History (last 5 rounds):', '(2023)). This work, however, focuses on financial markets and how LLM agents can operate\\nas full-fledged trading participants.\\nRecent research examines specific applications of LLMs for trading. FinMem and Trad-\\ningGPT introduce frameworks with layered memory systems and customizable agent traits\\n5\\nto improve financial decision-making (Yu, Li, et al. 2024; Li, Zhang, and Sun 2023). Hierar-\\nchical multi-agent architectures have been explored in FinCon, which uses a manager-analyst\\nsetup for collaborative portfolio decisions (Yu, Yao, et al. 2024). QuantAgent implements\\na self-improving signal-mining approach (Wang et al. 2024), while other work underscores\\nthe importance of long-term memory in LLM agents via vector databases (Hatalis et al.\\n2024). This line of research builds on successful reinforcement learning applications such as\\nAlphaPortfolio (Cong et al. 2021) and AlphaManager (Campello, Cong, and Zhou 2023),\\nwhich leverage deep RL and robust control for portfolio management.\\nAnalyzing LLM agent behavior by changing only some parameters draws on methods\\nfrom the interpretable machine learning literature. In particular, the systematic variation\\nof market parameters to reveal decision patterns mirrors partial dependence plots and in-\\ndividual conditional expectation curves used to interpret complex machine learning models\\n(Molnar 2022). These techniques help reveal how LLM agents respond to changes in specific\\nvariables while holding others constant, providing insight into their internal decision-making\\nprocesses that would otherwise remain opaque.\\nBeyond finance, studies of LLM capabilities in interactive or multi-agent settings offer\\nvaluable insights. Benchmarks like AgentBench evaluate LLMs’ performance in interac-\\ntive tasks (Liu et al. 2023), while InvestorBench focuses on financial decision-making tasks\\nspecifically (H. Li et al. 2024). NegotiationArena demonstrates LLMs’ capacity for strategic\\ninteraction in bargaining contexts (Bianchi et al. 2024). Similarly, Guo et al. (2024) provide\\nan economics ”arena” where LLMs compete in strategic games, revealing that advanced\\nmodels like GPT-4 can exhibit rational, adaptive behavior—albeit not always reaching Nash\\nEquilibrium. Existing frameworks typically assess individual agents or hierarchical collab-\\norations, whereas this work studies emergent market behaviors that arise from multiple\\nindependent LLM traders interacting in a marketplace.\\nThe approach also connects to the tradition of experimental asset markets. For instance,\\nWeitzel et al. (2020) show that even finance professionals are susceptible to speculative\\n6\\nbubbles, especially amid high capital inflows. Kop´ anyi-Peuker and Weber (2021) find that\\ntrading experience alone does not eliminate bubbles, challenging assumptions about rational\\nmarket learning. Kirchler, Huber, and St¨ ockl (2012) identify confusion about fundamental\\nvalues as a key driver of bubble formation. This framework offers a new way to study these\\nphenomena with LLM traders, which can be rigorously parameterized for sophistication,\\nstrategy, and information processing. Hence, this paper provides a method to investigate\\nhow automated or ”artificial” agents might affect market stability or volatility.\\nOther recent work highlights the versatility of LLM agents in complex, interactive sce-\\nnarios beyond finance. One stream focuses on simulating social behaviors—such as opinion\\ndynamics (Chuang et al. 2023), trust (Xie et al. 2024), and resource-sharing (Piatti et al.\\n2024). Another examines LLMs’ strategic capabilities through task-based simulations and\\ncollaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\\nWithin the computer science literature, early works apply LLMs to financial markets but\\nabstract away many fundamental stock market characteristics. Often, they employ single-\\nprice clearing mechanisms without a persistent order book, ignore partial fills and bid-ask', 'bids/asks), and two Speculator agents (opportunistic traders seeking inefficiencies). Market\\n31\\nmakers are given enhanced liquidity with 20x the baseline cash and shares to ensure suffi-\\ncient liquidity provision and facilitate price discovery. The scenario tests whether prices can\\ncorrect downward through trading activity when starting from an overvalued state.\\n3.2.2 Price Discovery (Below Fundamental)\\nThis complementary scenario tests upward price convergence by starting with an initial price\\n25% below the fundamental value ( $21.00). It employs the identical agent composition and\\nparameters as the above-fundamental scenario, allowing for direct comparison of market\\nbehavior under opposite initial mispricing conditions. This design enables researchers to\\nassess potential asymmetries in price discovery processes.\\n3.2.3 Infinite Horizon Price Discovery\\nWe extend both price discovery scenarios to infinite horizon settings, where shares are not\\nredeemed at a terminal date. The initial prices are set at double ($56.00) and half ($14.00) the\\nfundamental value for the above and below fundamental scenarios respectively, creating more\\nextreme mispricing conditions. These scenarios run for 15 trading rounds and test whether\\nagents correctly value assets based on expected dividend streams rather than redemption\\nvalues. Each infinite horizon scenario involves two Default investors, two Optimistic traders,\\ntwo Market makers, and two Speculator agents.\\nThe results from these infinite horizon scenarios reveal interesting asymmetries in price\\ndiscovery, as illustrated in Figure 6 and Figure 7. When the market starts significantly above\\nthe fundamental value (left panels), the price fails to converge downwards towards the$28.00\\nbenchmark within the 15 rounds, remaining substantially elevated. Agent valuations mirror\\nthis persistence, with many agents maintaining estimates well above the fundamental value.\\nHowever, when the market begins significantly below the fundamental value (right panels),\\nthe price exhibits a clear convergence towards the fundamental benchmark. Agent valuations\\nin this scenario also tend to adjust upwards, aligning more closely with the calculated fun-\\n32\\ndamental value over time. This suggests that under these conditions, LLM agents are more\\neffective at correcting undervaluation than overvaluation within the simulated timeframe.\\nFigure 6: Price Evolution: Infinite Horizon Scenarios. Left: Initial price $56.00 (Above\\nFundamental). Right: Initial price $14.00 (Below Fundamental). The dashed line indicates\\nthe fundamental value ($28.00).\\nFigure 7: Agent Valuations: Infinite Horizon Scenarios. Left: Initial price $56.00 (Above\\nFundamental). Right: Initial price $14.00 (Below Fundamental). Shows individual agent\\nestimates of fundamental value over time.\\n3.2.4 Divergent Beliefs\\nThis scenario explores the impact of heterogeneous beliefs about fundamental value by com-\\nbining agents with systematically different valuation models. The agent composition is\\ndesigned to create heterogeneity: two Optimistic traders (believing the fundamental value is\\nsignificantly higher), two Pessimistic traders (believing it is significantly lower), two neutral\\nMarket makers, two Momentum traders (following price trends rather than fundamentals),\\nand two Default investors (baseline agents). We test both above-fundamental (initial price\\n$56.00, 2x fundamental) and below-fundamental (initial price$14.00, 0.5x fundamental) vari-\\n33\\nants, allowing researchers to study how different belief structures influence price formation\\nand trading patterns under different initial mispricings. In these scenarios, the fundamental\\nprice is hidden from agents, forcing them to rely on their own valuation models.\\n3.2.5 Market Stress\\nThis scenario tests market resilience under challenging conditions by creating a more volatile\\nenvironment. The scenario includes two consistently bullish Optimistic traders, two consis-', 'market efficiency and price discovery processes throughout the simulation.\\nAgent performance metrics include absolute position tracking (shares, cash, and total\\nwealth), wealth composition analysis, position change metrics, and return calculations. The\\nsystem computes both absolute and percentage returns on various portfolio components\\nand compares performance across agent types to identify relative advantages of different\\nstrategies. Trading flow analysis visualizes the volume of shares moving between different\\nagent types and cumulative net trading flows, revealing which agents act as net buyers or\\nsellers in different market conditions.\\nDecision pattern analysis employs heatmaps to visualize the consistency of agent decision-\\nmaking over time, allowing researchers to identify shifts in strategic behavior. This is com-\\nplemented by decision quantities visualization that plots order sizes to highlight variations\\nin trade aggressiveness across agent types. When agent reasoning data is available, the\\nsystem generates wordclouds to extract key terms from agent explanations, providing qual-\\nitative insights into decision drivers for different agent strategies. Additional visualizations\\ntrack price target accuracy and compare agent-specific valuations to realized market prices,\\n28\\noffering insights into the forecasting abilities of different agents.\\nA key advantage of simulation-based analysis is complete observability of all market\\nprocesses and agent states. Unlike real-world markets where data availability is often limited,\\nthe framework captures every interaction, decision, and state change with perfect fidelity.\\nThis comprehensive data collection allows researchers to compute additional metrics beyond\\nstandard market measures, enabling novel analyses such as counterfactual testing (e.g., how\\nwould markets evolve with different agent compositions), causal inference of specific agent\\nbehaviors on market outcomes, and the development of custom efficiency or stability metrics\\ntailored to particular research questions. The system’s modular design facilitates rapid\\nimplementation of new metrics and visualizations as research questions evolve.\\n3 Experimental Design and Results\\nOur experimental framework implements a dividend-paying asset market with heterogeneous\\nagents. The baseline simulation runs for 15 to 20 rounds with 8 participating agents, although\\nthese parameters are fully configurable. Each agent begins with an initial endowment of\\n1,000,000 monetary units and 10,000 shares of the asset. The fundamental value of the asset\\nis set at $28.00, with a final redemption value matching this fundamental price in finite\\nhorizon scenarios. Transaction costs are set to zero to isolate the effects of agent behavior\\nand market structure.\\nThe dividend structure follows a stochastic process with a base payment of $1.40 and a\\nvariation of ±$1.00, paid with 50% probability each round. This design creates uncertainty\\nin the asset’s income stream while maintaining a known expected value. Cash holdings earn\\na risk-free interest rate of 5% per round, providing an opportunity cost for asset investment.\\nAgent composition is controlled through a flexible distribution system that allows for\\nvarious experimental configurations. In our baseline setup, we employ a mixed population\\nof value investors, momentum traders, and market makers. Each agent type implements\\n29\\ndistinct trading strategies through Large Language Model (LLM) prompts, with GPT-4o as\\nthe decision-making engine.\\nThe data collection system captures comprehensive market activity across multiple di-\\nmensions. At the market level, it tracks the evolution of prices, fundamental values, and\\nrealized dividends, providing insights into overall market dynamics. Individual agent data\\nincludes detailed wealth trajectories and portfolio compositions, enabling analysis of strategy\\neffectiveness and wealth distribution patterns. The system maintains complete transaction', 'Main Cash Account: $988500.00\\nDividend Cash Account (not available for trading): $296920.65\\nTotal Available Cash: $988500.00 (Borrowing is not allowed)\\nShares in Orders: 0 shares\\nCash in Orders: $11500.00\\nPosition information establishes resource constraints and current market exposure, enabling\\nthe agent to make contextually appropriate decisions while maintaining awareness of out-\\nstanding commitments.\\n2.2.11 Historical Context\\nPrice History (last 5 rounds):\\nRound 3: $29.00 (Volume: 100)\\nRound 2: $29.00 (Volume: 100)\\n19\\nRound 1: $28.00 (Volume: 100)\\nRound 0: $56.00 (Volume: 0)\\nHistorical price and volume data enables pattern recognition and trend analysis, which is\\nespecially important for agents identifying market inefficiencies and developing trends.\\n2.2.12 Asset Fundamentals\\nDividend Information:\\nLast Paid Dividend: $2.40\\nExpected Dividend: $1.40\\nBase Dividend: $1.40\\nVariation Amount: $1.00\\nMaximum Scenario: $2.40 with 50% probability\\nMinimum Scenario: $0.40 with 50% probability\\nPayment Schedule:\\nNext Payment in: 1 rounds\\nPayment Destination: dividend account (non-tradeable)\\nRedemption Information:\\nThis market has an infinite time horizon. Shares will not be redeemed.\\nInterest Rate Information:\\nBase Rate: 5.0\\\\%\\nCompound Frequency: 1 times per round\\nPayment Destination: dividend account (separate from trading)\\nFundamental value determinants allow the agent to perform intrinsic valuation, assess risk-\\nreward scenarios, and identify mispricing. The probabilistic dividend structure introduces\\nuncertainty agents that must be incorporated into their decision models. In this example,\\nthe fundamental value is unobservable.\\n20\\n2.2.13 Decision Requirements\\nYour analysis should include:\\nvaluation_reasoning: Your numerical analysis of the asset’s fundamental value\\nvaluation: Your estimate of the asset’s current fundamental value\\nprice_target_reasoning: Your numerical analysis of the asset’s price target\\nprice_target: Your predicted price for the next round\\nreasoning: Your explanation for the trading decision\\nThe decision schema enforces consistent output structure and explicit reasoning, enabling\\nsystematic analysis of agent decision processes and reliable parsing of machine-actionable\\ncomponents.\\n2.2.14 Trading Options\\nTrading Options:\\nNew Orders (replace_decision=’Add’):\\nSingle or multiple orders allowed\\nFor each order:\\nMarket order: Set order_type=’market’\\nLimit order: Set order_type=’limit’ and specify price_limit\\nIMPORTANT: Sell orders require sufficient available shares\\nShort selling is NOT allowed\\nCancel Orders (replace_decision=’Cancel’):\\nReturn an empty orders list: orders=[]\\nThe trading options subsection establishes the action space and constraints, ensuring agents\\nunderstand available choices and limitations while providing precise formatting requirements\\nfor machine-readable decisions.\\nThe response from the LLM agent is depicted in Figure 1.\\n21\\n2.2.15 Systematic Decision Analysis\\nFinally, the framework enables systematic analysis of LLM decision processes through con-\\ntrolled parameter variation, similar to partial dependence plots in machine learning inter-\\npretability. This approach allows researchers to understand how specific market variables\\ninfluence LLM trading decisions while holding other factors constant.\\nOur example implementation varies the price-to-fundamental ratio ( ρ = P/V ) across a\\nrange from 0.1 to 3.5 while maintaining all other market parameters constant. For each ratio\\nvalue, the system:\\n1. Sets market price P = ρV where ρ is the target ratio\\n2. Generates a consistent order book structure around this price\\n3. Executes multiple decision trials with the same agent type\\n4. Records decision outcomes (buy/sell/hold), order types, quantities, and reasoning\\nThis process maps how LLM agents respond to different price environments, as illustrated\\nin Figures 2, 3, 4, and 5. The analysis reveals clear patterns in decision boundaries, with']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ❌ Contextual Precision (ragas) (score: nan, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ❌ Faithfulness (ragas) (score: nan, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Contextual Recall (ragas) (score: 1.0, threshold: 0.6, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Answer Relevancy (ragas) (score: 0.8843584585795085, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: In simple terms, what does Figure 7 (agent valuations over time) tell us about over‑ vs under‑valuation corrections?\n",
      "  - actual output: Figure 7 shows that the AI agents were better at correcting under-valuations than over-valuations. When the simulated market started low, the agents' valuations gradually increased over time, moving closer to the true fundamental value. However, when the market started high, the agents' valuations remained high and didn't adjust downwards towards the true value within the timeframe of the simulation.\n",
      "\n",
      "  - expected output: With an initial price 25 % above fundamentals, prices failed to converge downward within 15 rounds and agents kept over‑valuing the asset.\n",
      "  - context: ['When the market starts significantly above the fundamental value … the price fails to converge downwards … remaining substantially elevated. Agent valuations mirror this persistence, with many agents maintaining estimates well above the fundamental value.']\n",
      "  - retrieval context: ['bids/asks), and two Speculator agents (opportunistic traders seeking inefficiencies). Market\\n31\\nmakers are given enhanced liquidity with 20x the baseline cash and shares to ensure suffi-\\ncient liquidity provision and facilitate price discovery. The scenario tests whether prices can\\ncorrect downward through trading activity when starting from an overvalued state.\\n3.2.2 Price Discovery (Below Fundamental)\\nThis complementary scenario tests upward price convergence by starting with an initial price\\n25% below the fundamental value ( $21.00). It employs the identical agent composition and\\nparameters as the above-fundamental scenario, allowing for direct comparison of market\\nbehavior under opposite initial mispricing conditions. This design enables researchers to\\nassess potential asymmetries in price discovery processes.\\n3.2.3 Infinite Horizon Price Discovery\\nWe extend both price discovery scenarios to infinite horizon settings, where shares are not\\nredeemed at a terminal date. The initial prices are set at double ($56.00) and half ($14.00) the\\nfundamental value for the above and below fundamental scenarios respectively, creating more\\nextreme mispricing conditions. These scenarios run for 15 trading rounds and test whether\\nagents correctly value assets based on expected dividend streams rather than redemption\\nvalues. Each infinite horizon scenario involves two Default investors, two Optimistic traders,\\ntwo Market makers, and two Speculator agents.\\nThe results from these infinite horizon scenarios reveal interesting asymmetries in price\\ndiscovery, as illustrated in Figure 6 and Figure 7. When the market starts significantly above\\nthe fundamental value (left panels), the price fails to converge downwards towards the$28.00\\nbenchmark within the 15 rounds, remaining substantially elevated. Agent valuations mirror\\nthis persistence, with many agents maintaining estimates well above the fundamental value.\\nHowever, when the market begins significantly below the fundamental value (right panels),\\nthe price exhibits a clear convergence towards the fundamental benchmark. Agent valuations\\nin this scenario also tend to adjust upwards, aligning more closely with the calculated fun-\\n32\\ndamental value over time. This suggests that under these conditions, LLM agents are more\\neffective at correcting undervaluation than overvaluation within the simulated timeframe.\\nFigure 6: Price Evolution: Infinite Horizon Scenarios. Left: Initial price $56.00 (Above\\nFundamental). Right: Initial price $14.00 (Below Fundamental). The dashed line indicates\\nthe fundamental value ($28.00).\\nFigure 7: Agent Valuations: Infinite Horizon Scenarios. Left: Initial price $56.00 (Above\\nFundamental). Right: Initial price $14.00 (Below Fundamental). Shows individual agent\\nestimates of fundamental value over time.\\n3.2.4 Divergent Beliefs\\nThis scenario explores the impact of heterogeneous beliefs about fundamental value by com-\\nbining agents with systematically different valuation models. The agent composition is\\ndesigned to create heterogeneity: two Optimistic traders (believing the fundamental value is\\nsignificantly higher), two Pessimistic traders (believing it is significantly lower), two neutral\\nMarket makers, two Momentum traders (following price trends rather than fundamentals),\\nand two Default investors (baseline agents). We test both above-fundamental (initial price\\n$56.00, 2x fundamental) and below-fundamental (initial price$14.00, 0.5x fundamental) vari-\\n33\\nants, allowing researchers to study how different belief structures influence price formation\\nand trading patterns under different initial mispricings. In these scenarios, the fundamental\\nprice is hidden from agents, forcing them to rely on their own valuation models.\\n3.2.5 Market Stress\\nThis scenario tests market resilience under challenging conditions by creating a more volatile\\nenvironment. The scenario includes two consistently bullish Optimistic traders, two consis-', 'value, the system:\\n1. Sets market price P = ρV where ρ is the target ratio\\n2. Generates a consistent order book structure around this price\\n3. Executes multiple decision trials with the same agent type\\n4. Records decision outcomes (buy/sell/hold), order types, quantities, and reasoning\\nThis process maps how LLM agents respond to different price environments, as illustrated\\nin Figures 2, 3, 4, and 5. The analysis reveals clear patterns in decision boundaries, with\\ndistinct transitions between buying, selling, and holding regions that vary by agent type. For\\nexample, value investors show strong buying tendencies when prices are below fundamental\\nvalue (ρ <1) and selling preferences when prices exceed fundamentals ( ρ >1). In contrast,\\nmomentum traders show less sensitivity to the fundamental ratio and more responsiveness\\nto recent price trends.\\nThe systematic variation approach also reveals patterns in order sizing and limit price\\nselection, with agents typically placing larger orders when prices deviate significantly from\\ntheir valuation models (Figure 4). This methodology provides unprecedented transparency\\ninto LLM decision processes and enables quantitative comparison of different agent types\\nand LLM architectures.\\n22\\nFigure 2: Price Analysis under Systematic Variation. Shows how agent valuation estimates\\nand price targets respond to varying Price/Fundamental ratios.\\nThe decision analysis can be customized for different experimental designs. For example,\\nresearchers can use the framework to study the impact of various market conditions on agent\\nbehavior by varying other market parameters or the effect of different agent types on market\\ndynamics by changing the agent population.\\n2.3 Data Collection and Analysis\\nEvaluating LLM trading agents requires robust methodologies for capturing, processing,\\nand analyzing their behavior in market environments. The framework implements a com-\\nprehensive analytics module that tracks all market activity, agent decisions, and performance\\nmetrics throughout experimental runs. This multi-layered approach not only records what\\nhappens in each simulation but also provides insights into why agents make specific deci-\\nsions, enabling researchers to validate agent behavior against their defined strategies and\\nassess overall market dynamics. The following sections detail the key components of this\\nanalytics infrastructure.\\n23\\nFigure 3: Trading Decision Distribution under Systematic Variation. Illustrates the proba-\\nbility of Buy, Sell, or Hold decisions across different agent types as the Price/Fundamental\\nratio changes.\\n24\\nFigure 4: Order Size Distribution under Systematic Variation. Shows the average quan-\\ntity traded (as a percentage of initial shares) for Buy and Sell orders across different\\nPrice/Fundamental ratios.\\n2.3.1 Data Collection Architecture\\nThe framework implements a comprehensive data collection system that captures multiple\\ndimensions of market behavior and agent decision-making. This structured approach ensures\\nreproducibility and enables detailed analysis of market dynamics.\\n2.3.2 Core Data Streams\\nThe system captures five primary data streams that work together to provide a complete\\npicture of market activity. Market Data forms the foundation, tracking essential metrics\\nincluding price evolution, fundamental values, trading volumes, order book depth, market\\nliquidity, best bid/ask prices, spreads, and price-fundamental ratios. This is complemented\\nby detailed Trade Data, which records individual transaction details such as prices, quan-\\ntities, buyer and seller identifiers, timestamps, round information, and specific execution\\ndetails.\\nAgent Data provides insights into participant behavior by monitoring cash and share\\n25\\nFigure 5: Order Type Analysis under Systematic Variation. Displays the proportion of\\nMarket vs. Limit orders used by different agent types across varying Price/Fundamental\\nratios.\\n26', 'the decision-making engine.\\nThe data collection system captures comprehensive market activity across multiple di-\\nmensions. At the market level, it tracks the evolution of prices, fundamental values, and\\nrealized dividends, providing insights into overall market dynamics. Individual agent data\\nincludes detailed wealth trajectories and portfolio compositions, enabling analysis of strategy\\neffectiveness and wealth distribution patterns. The system maintains complete transaction\\nrecords with prices, quantities, and counterparty information, facilitating the study of trad-\\ning patterns and market microstructure. Additionally, it captures agent decision rationales\\nand strategy adherence metrics, allowing researchers to evaluate the consistency and effec-\\ntiveness of different trading approaches.\\nAll experimental parameters, market outcomes, and agent interactions are systemati-\\ncally logged and stored in structured formats (CSV and JSON) for subsequent analysis. The\\nframework generates standardized visualizations of price evolution, wealth distribution, and\\ndividend payments to facilitate comparative analysis across different experimental configu-\\nrations.\\n3.1 Fundamental Value Calibration\\nThe framework implements a consistent approach to fundamental value calculation that pro-\\nvides a reliable benchmark for price discovery. For infinite horizon markets, the fundamental\\nvalue follows the standard dividend discount model:\\nVt = E[D]\\nr = Expected Dividend\\nInterest Rate (1)\\nFor the default parameters where the expected dividend is $1.40 and the interest rate is\\n5%, this yields a fundamental value of $28.00.\\nIn finite horizon markets with T periods remaining, the fundamental value incorporates\\n30\\nboth future dividends and terminal redemption value K:\\nFVt =\\nTX\\nτ=t\\nE[D]\\n(1 + r)τ−t+1 + K\\n(1 + r)T−t+1 (2)\\nTo ensure consistency between finite and infinite horizon markets, the redemption value\\nK is set equal to E[D]\\nr , which makes the fundamental value constant atE[D]\\nr across all periods,\\nregardless of the time horizon. This calibration approach ensures a clean experimental design\\nby providing a stable benchmark for price discovery.\\n3.2 Experimental Scenarios\\nTo evaluate market dynamics with LLM-based agents, we implemented several experimental\\nscenarios that systematically explore different initial conditions and agent compositions.\\nEach scenario maintains the fundamental value of $28.00 while varying starting prices, time\\nhorizons, and agent populations. These scenarios address our core research questions (Section\\n1) by testing LLM capabilities under varying market conditions, focusing on price discovery\\ndynamics, the impact of heterogeneous beliefs, and market stability under stress; GPT-4o\\nwas used consistently as the decision-making engine for all LLM agents across these scenarios.\\nWe present the setup for several key scenarios below, followed by a discussion of the observed\\nresults for the 2 experiments involving an infinite horizon market with a starting price either\\nabove or below the fundamental value.\\n3.2.1 Price Discovery (Above Fundamental)\\nThis scenario tests downward price convergence by starting with an initial price 25% above\\nthe fundamental value ( $35.00). It runs for 20 trading rounds and features a diverse\\nagent population, including two Default investors (baseline agents), two Optimistic traders\\n(who believe prices should be higher), two Market makers (providing liquidity by posting\\nbids/asks), and two Speculator agents (opportunistic traders seeking inefficiencies). Market\\n31\\nmakers are given enhanced liquidity with 20x the baseline cash and shares to ensure suffi-\\ncient liquidity provision and facilitate price discovery. The scenario tests whether prices can\\ncorrect downward through trading activity when starting from an overvalued state.\\n3.2.2 Price Discovery (Below Fundamental)\\nThis complementary scenario tests upward price convergence by starting with an initial price', 'market efficiency and price discovery processes throughout the simulation.\\nAgent performance metrics include absolute position tracking (shares, cash, and total\\nwealth), wealth composition analysis, position change metrics, and return calculations. The\\nsystem computes both absolute and percentage returns on various portfolio components\\nand compares performance across agent types to identify relative advantages of different\\nstrategies. Trading flow analysis visualizes the volume of shares moving between different\\nagent types and cumulative net trading flows, revealing which agents act as net buyers or\\nsellers in different market conditions.\\nDecision pattern analysis employs heatmaps to visualize the consistency of agent decision-\\nmaking over time, allowing researchers to identify shifts in strategic behavior. This is com-\\nplemented by decision quantities visualization that plots order sizes to highlight variations\\nin trade aggressiveness across agent types. When agent reasoning data is available, the\\nsystem generates wordclouds to extract key terms from agent explanations, providing qual-\\nitative insights into decision drivers for different agent strategies. Additional visualizations\\ntrack price target accuracy and compare agent-specific valuations to realized market prices,\\n28\\noffering insights into the forecasting abilities of different agents.\\nA key advantage of simulation-based analysis is complete observability of all market\\nprocesses and agent states. Unlike real-world markets where data availability is often limited,\\nthe framework captures every interaction, decision, and state change with perfect fidelity.\\nThis comprehensive data collection allows researchers to compute additional metrics beyond\\nstandard market measures, enabling novel analyses such as counterfactual testing (e.g., how\\nwould markets evolve with different agent compositions), causal inference of specific agent\\nbehaviors on market outcomes, and the development of custom efficiency or stability metrics\\ntailored to particular research questions. The system’s modular design facilitates rapid\\nimplementation of new metrics and visualizations as research questions evolve.\\n3 Experimental Design and Results\\nOur experimental framework implements a dividend-paying asset market with heterogeneous\\nagents. The baseline simulation runs for 15 to 20 rounds with 8 participating agents, although\\nthese parameters are fully configurable. Each agent begins with an initial endowment of\\n1,000,000 monetary units and 10,000 shares of the asset. The fundamental value of the asset\\nis set at $28.00, with a final redemption value matching this fundamental price in finite\\nhorizon scenarios. Transaction costs are set to zero to isolate the effects of agent behavior\\nand market structure.\\nThe dividend structure follows a stochastic process with a base payment of $1.40 and a\\nvariation of ±$1.00, paid with 50% probability each round. This design creates uncertainty\\nin the asset’s income stream while maintaining a known expected value. Cash holdings earn\\na risk-free interest rate of 5% per round, providing an opportunity cost for asset investment.\\nAgent composition is controlled through a flexible distribution system that allows for\\nvarious experimental configurations. In our baseline setup, we employ a mixed population\\nof value investors, momentum traders, and market makers. Each agent type implements\\n29\\ndistinct trading strategies through Large Language Model (LLM) prompts, with GPT-4o as\\nthe decision-making engine.\\nThe data collection system captures comprehensive market activity across multiple di-\\nmensions. At the market level, it tracks the evolution of prices, fundamental values, and\\nrealized dividends, providing insights into overall market dynamics. Individual agent data\\nincludes detailed wealth trajectories and portfolio compositions, enabling analysis of strategy\\neffectiveness and wealth distribution patterns. The system maintains complete transaction', 'by detailed Trade Data, which records individual transaction details such as prices, quan-\\ntities, buyer and seller identifiers, timestamps, round information, and specific execution\\ndetails.\\nAgent Data provides insights into participant behavior by monitoring cash and share\\n25\\nFigure 5: Order Type Analysis under Systematic Variation. Displays the proportion of\\nMarket vs. Limit orders used by different agent types across varying Price/Fundamental\\nratios.\\n26\\npositions, portfolio values, wealth evolution, and agent type and strategy identifiers. Or-\\nder Data captures the complete lifecycle of trading decisions, including order specifications\\n(type, size, price), agent reasoning and justification, decision context and timing, and order\\nlifecycle events. Finally, Market State data maintains a comprehensive view of overall mar-\\nket conditions through order book snapshots, market depth information, aggregate statistics,\\nand various market microstructure metrics.\\n2.3.3 Data Validation and Storage\\nThe system implements a comprehensive set of data quality measures to ensure reliability and\\nconsistency. The validation framework performs continuous checks for data completeness,\\nverifies consistency across related data streams, enforces format and type validation, and\\nmaintains proper temporal sequencing of all recorded events. These validation mechanisms\\nwork together to maintain data integrity throughout the experimental process.\\nThe storage architecture employs multiple formats optimized for different data types and\\nuse cases. Structured CSV files store tabular data for efficient analysis, while JSON formats\\naccommodate complex nested structures that preserve the rich relationships between market\\nelements. The system maintains detailed timestamped logs for debugging purposes and\\ngenerates summary statistics to facilitate quick analysis of experimental outcomes.\\nThis comprehensive data collection architecture enables researchers to conduct detailed\\nanalysis of market dynamics, validate agent behavior patterns, ensure experiment repro-\\nducibility, and perform meaningful cross-experiment comparisons. The integrated approach\\nto data management provides the foundation for rigorous empirical investigation of market\\nbehavior and agent interactions.\\nThe framework implements specialized visualization techniques to analyze agent behavior\\nand market dynamics. Decision heatmaps plot agent actions across trading rounds, reveal-\\ning strategic patterns and consistency. Trading flow visualizations track cumulative position\\nchanges, identifying net buyers and sellers throughout market evolution. Reasoning word-\\n27\\nclouds extract key terms from agent explanations, providing insight into decision drivers\\nacross different agent types.\\nThe system also generates specialized market quality visualizations including bid-ask\\nspread evolution, price target accuracy, and agent valuation tracking. These visualizations\\nwork in concert with the numerical metrics to provide both quantitative and qualitative\\ninsights into agent behavior and market dynamics.\\n2.3.4 Validation Metrics and Performance Monitoring\\nThe framework implements a comprehensive set of performance metrics and visualization\\ntools that monitor agent behavior and market dynamics. Market evolution visualizations\\ntrack price movements relative to fundamental values, including time series of transaction\\nprices, midpoint prices, and bid-ask spreads. These visualizations enable researchers to assess\\nmarket efficiency and price discovery processes throughout the simulation.\\nAgent performance metrics include absolute position tracking (shares, cash, and total\\nwealth), wealth composition analysis, position change metrics, and return calculations. The\\nsystem computes both absolute and percentage returns on various portfolio components\\nand compares performance across agent types to identify relative advantages of different', 'the second agents’ design, and the third the analysis module.\\n8\\n2.1 Market Design\\nOur methodological framework integrates three components that create a controlled envi-\\nronment for LLM-based trading agents. The framework implements a flexible continuous\\ndouble-auction market mechanism that couples standard market microstructure principles\\nwith market clearing and matching algorithms to accommodate asynchronous LLM decisions.\\nThe market clearing process employs a dual-stage matching algorithm. In the first stage,\\nlimit orders are posted. In the second stage, market orders are netted using a market-\\nto-market matching engine that processes buy and sell orders, reconciling orders based on\\navailable agent cash and share commitments. In the third stage, any remaining market\\norders are matched against the existing order book, with unfilled quantities converted to\\naggressive limit orders. This three-tiered approach optimizes immediate execution and price\\ndiscovery while maintaining market liquidity.\\nThe system’s OrderMatchingService orchestrates this process by coordinating trade ex-\\necutions through the TradeExecutionService and managing order state transitions via the\\nOrderStateManager. Each trade is logged in detail, with the overall market state—including\\norder books, market depth, and price evolution—recalculated at the end of each trading\\nround.\\nThis modular design in the matching and clearing engine provides several advantages.\\nFirst, it enables rigorous trade validation where each market order is validated against agent\\ncash commitments and position constraints before matching, with the system dynamically\\nadjusting order quantities based on available cash when an agent’s commitment is insuf-\\nficient, thus minimizing execution errors. Second, it offers flexible liquidity handling by\\nsupporting market-to-market and market-to-book matching, ensuring orders have multiple\\nexecution pathways, with unexecuted market orders converted to aggressive limit orders to\\ncapture remaining liquidity. Third, it maintains detailed trade audit capabilities by recording\\ncomprehensive traceability data including timestamps, trade volumes, executed prices, and\\nagent identifiers, thereby enabling post-trade analysis and performance benchmarking that\\n9\\nserves as the foundation for subsequent market efficiency and agent performance validations.\\n2.1.1 Market Mechanism Design\\nOur framework implements a continuous double-auction market mechanism that processes\\norders in discrete trading rounds. We use discrete trading rounds because LLMs have latency\\nconstraints, making it infeasible to process orders in real time. Within each round, the order\\nof agent submissions is randomized to avoid giving systematic priority to specific agents,\\nthus simulating concurrent order arrival while maintaining fairness. Once randomized, or-\\nders are then processed according to standard price-time priority rules. The system supports\\nfinite and infinite horizon markets, with differences in terminal conditions and wealth cal-\\nculation. In finite-horizon markets, agents are informed of the total number of rounds, and\\ntheir terminal wealth is calculated by redeeming all shares at the fundamental value of the\\nfinal round. In infinite-horizon markets, no terminal information is provided to agents, and\\nfinal wealth is determined using the last market price for share valuation. This design choice\\nenables researchers to study how time horizons influence trading strategies and price for-\\nmation, particularly how agents balance short-term trading opportunities against long-term\\nvalue considerations.\\nIn a double auction, buyers and sellers actively submit orders, with trades occurring when\\ncompatible buy and sell orders match the price. The matching engine processes these orders\\nthrough three sequential phases:\\nFirst, incoming limit orders that do not immediately cross the market are added to\\nthe order book, maintaining strict price-time priority. Second, market orders are processed', '33\\nants, allowing researchers to study how different belief structures influence price formation\\nand trading patterns under different initial mispricings. In these scenarios, the fundamental\\nprice is hidden from agents, forcing them to rely on their own valuation models.\\n3.2.5 Market Stress\\nThis scenario tests market resilience under challenging conditions by creating a more volatile\\nenvironment. The scenario includes two consistently bullish Optimistic traders, two consis-\\ntently bearish Pessimistic traders, two Market makers (liquidity providers), and two Value\\ninvestors (rational benchmark traders). The scenario runs for 100 rounds to study long-term\\nmarket behavior and includes unequal initial endowments, with optimistic traders having\\nmore cash (1.5x baseline) but fewer shares (0.5x baseline) and pessimistic traders having less\\ncash (0.5x baseline) but more shares (1.5x baseline). This resource imbalance tests whether\\nparticular agent types can dominate market outcomes through resource advantages.\\nThe scenarios presented here demonstrate the framework’s capabilities for exploring di-\\nverse market conditions. Its modular structure facilitates the straightforward definition and\\nimplementation of alternative experimental designs, enabling researchers to tailor simulations\\nto specific research questions.\\nIn all scenarios, we maintain consistent baseline parameters with a fundamental value\\nof $28.00, calculated from the expected dividend of $1.40 and interest rate of 5%. Agent\\nendowments start at 1,000,000 monetary units and 10,000 shares unless specifically modified.\\nTransaction costs are set to zero to isolate the effects of agent behavior and market structure\\non price formation.\\n4 Conclusion\\nThis paper demonstrates that Large Language Models can effectively function as diverse\\ntrading agents—from value investors to market makers—maintaining strategic consistency\\n34\\nwhile adapting to market conditions. Our experimental framework reveals that their in-\\nteractions generate realistic market dynamics, including phenomena like price bubbles and\\ncorrections, highlighting both the capabilities and potential risks of deploying LLM agents\\nin financial markets.\\nThese findings carry significant implications for market structure and regulation. While\\nLLM agents can enhance price discovery and liquidity, their adherence to programmed strate-\\ngies, even potentially flawed ones derived from prompts, could amplify market volatility or\\nintroduce novel systemic risks, as observed in our simulated bubble scenarios. A key concern\\nis the potential for widespread correlated behavior: similar underlying LLM architectures\\nresponding uniformly to comparable prompts or market signals could inadvertently create\\ndestabilizing trading patterns without explicit coordination. This underscores the critical\\nneed for rigorous testing and validation of LLM-based trading systems prior to live deploy-\\nment.\\nA central contribution of this work is the open-source simulation framework itself, de-\\nsigned to catalyze research into LLM trading agents. We invite the research community to\\nutilize and extend this platform to investigate pressing questions in this rapidly evolving\\narea. The framework enables systematic exploration of complex scenarios—such as hybrid\\nhuman-LLM markets, stress tests, varying market structures, regulatory impacts, and the\\nnuances of LLM prompting—often difficult or costly to study otherwise. Specific avenues\\nripe for investigation using this tool include the emergence of novel trading strategies, the\\nprecise effects of agent heterogeneity on market stability, and the development of robust\\nvalidation protocols for AI traders. As artificial intelligence becomes more integrated into\\nfinance, collaborative research leveraging adaptable simulation environments like this one\\nwill be crucial for understanding and responsibly shaping the future of trading.\\n35\\nReferences', '(2023)). This work, however, focuses on financial markets and how LLM agents can operate\\nas full-fledged trading participants.\\nRecent research examines specific applications of LLMs for trading. FinMem and Trad-\\ningGPT introduce frameworks with layered memory systems and customizable agent traits\\n5\\nto improve financial decision-making (Yu, Li, et al. 2024; Li, Zhang, and Sun 2023). Hierar-\\nchical multi-agent architectures have been explored in FinCon, which uses a manager-analyst\\nsetup for collaborative portfolio decisions (Yu, Yao, et al. 2024). QuantAgent implements\\na self-improving signal-mining approach (Wang et al. 2024), while other work underscores\\nthe importance of long-term memory in LLM agents via vector databases (Hatalis et al.\\n2024). This line of research builds on successful reinforcement learning applications such as\\nAlphaPortfolio (Cong et al. 2021) and AlphaManager (Campello, Cong, and Zhou 2023),\\nwhich leverage deep RL and robust control for portfolio management.\\nAnalyzing LLM agent behavior by changing only some parameters draws on methods\\nfrom the interpretable machine learning literature. In particular, the systematic variation\\nof market parameters to reveal decision patterns mirrors partial dependence plots and in-\\ndividual conditional expectation curves used to interpret complex machine learning models\\n(Molnar 2022). These techniques help reveal how LLM agents respond to changes in specific\\nvariables while holding others constant, providing insight into their internal decision-making\\nprocesses that would otherwise remain opaque.\\nBeyond finance, studies of LLM capabilities in interactive or multi-agent settings offer\\nvaluable insights. Benchmarks like AgentBench evaluate LLMs’ performance in interac-\\ntive tasks (Liu et al. 2023), while InvestorBench focuses on financial decision-making tasks\\nspecifically (H. Li et al. 2024). NegotiationArena demonstrates LLMs’ capacity for strategic\\ninteraction in bargaining contexts (Bianchi et al. 2024). Similarly, Guo et al. (2024) provide\\nan economics ”arena” where LLMs compete in strategic games, revealing that advanced\\nmodels like GPT-4 can exhibit rational, adaptive behavior—albeit not always reaching Nash\\nEquilibrium. Existing frameworks typically assess individual agents or hierarchical collab-\\norations, whereas this work studies emergent market behaviors that arise from multiple\\nindependent LLM traders interacting in a marketplace.\\nThe approach also connects to the tradition of experimental asset markets. For instance,\\nWeitzel et al. (2020) show that even finance professionals are susceptible to speculative\\n6\\nbubbles, especially amid high capital inflows. Kop´ anyi-Peuker and Weber (2021) find that\\ntrading experience alone does not eliminate bubbles, challenging assumptions about rational\\nmarket learning. Kirchler, Huber, and St¨ ockl (2012) identify confusion about fundamental\\nvalues as a key driver of bubble formation. This framework offers a new way to study these\\nphenomena with LLM traders, which can be rigorously parameterized for sophistication,\\nstrategy, and information processing. Hence, this paper provides a method to investigate\\nhow automated or ”artificial” agents might affect market stability or volatility.\\nOther recent work highlights the versatility of LLM agents in complex, interactive sce-\\nnarios beyond finance. One stream focuses on simulating social behaviors—such as opinion\\ndynamics (Chuang et al. 2023), trust (Xie et al. 2024), and resource-sharing (Piatti et al.\\n2024). Another examines LLMs’ strategic capabilities through task-based simulations and\\ncollaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\\nWithin the computer science literature, early works apply LLMs to financial markets but\\nabstract away many fundamental stock market characteristics. Often, they employ single-\\nprice clearing mechanisms without a persistent order book, ignore partial fills and bid-ask']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ❌ Contextual Precision (ragas) (score: nan, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ❌ Faithfulness (ragas) (score: nan, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Contextual Recall (ragas) (score: 1.0, threshold: 0.6, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ❌ Answer Relevancy (ragas) (score: nan, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: What is the main experimental finding when the simulated market starts 25 % above the fundamental value?\n",
      "  - actual output: In the infinite horizon scenario where the simulated market began 25% above the fundamental value (overvalued at $56.00 compared to the true value of $28.00), the price failed to converge downwards towards the fundamental value within the 15 trading rounds. The LLM (Large Language Model)-driven agents' valuations also remained significantly elevated above the fundamental value, mirroring the overall market's persistent overvaluation. This suggests that, under these specific conditions, the AI agents were less effective at correcting overvaluation compared to undervaluation within the given timeframe.\n",
      "  - expected output: With an initial price 25 % above fundamentals, prices failed to converge downward within 15 rounds and agents kept over‑valuing the asset.\n",
      "  - context: ['When the market starts significantly above the fundamental value … the price fails to converge downwards … remaining substantially elevated. Agent valuations mirror this persistence, with many agents maintaining estimates well above the fundamental value.']\n",
      "  - retrieval context: ['bids/asks), and two Speculator agents (opportunistic traders seeking inefficiencies). Market\\n31\\nmakers are given enhanced liquidity with 20x the baseline cash and shares to ensure suffi-\\ncient liquidity provision and facilitate price discovery. The scenario tests whether prices can\\ncorrect downward through trading activity when starting from an overvalued state.\\n3.2.2 Price Discovery (Below Fundamental)\\nThis complementary scenario tests upward price convergence by starting with an initial price\\n25% below the fundamental value ( $21.00). It employs the identical agent composition and\\nparameters as the above-fundamental scenario, allowing for direct comparison of market\\nbehavior under opposite initial mispricing conditions. This design enables researchers to\\nassess potential asymmetries in price discovery processes.\\n3.2.3 Infinite Horizon Price Discovery\\nWe extend both price discovery scenarios to infinite horizon settings, where shares are not\\nredeemed at a terminal date. The initial prices are set at double ($56.00) and half ($14.00) the\\nfundamental value for the above and below fundamental scenarios respectively, creating more\\nextreme mispricing conditions. These scenarios run for 15 trading rounds and test whether\\nagents correctly value assets based on expected dividend streams rather than redemption\\nvalues. Each infinite horizon scenario involves two Default investors, two Optimistic traders,\\ntwo Market makers, and two Speculator agents.\\nThe results from these infinite horizon scenarios reveal interesting asymmetries in price\\ndiscovery, as illustrated in Figure 6 and Figure 7. When the market starts significantly above\\nthe fundamental value (left panels), the price fails to converge downwards towards the$28.00\\nbenchmark within the 15 rounds, remaining substantially elevated. Agent valuations mirror\\nthis persistence, with many agents maintaining estimates well above the fundamental value.\\nHowever, when the market begins significantly below the fundamental value (right panels),\\nthe price exhibits a clear convergence towards the fundamental benchmark. Agent valuations\\nin this scenario also tend to adjust upwards, aligning more closely with the calculated fun-\\n32\\ndamental value over time. This suggests that under these conditions, LLM agents are more\\neffective at correcting undervaluation than overvaluation within the simulated timeframe.\\nFigure 6: Price Evolution: Infinite Horizon Scenarios. Left: Initial price $56.00 (Above\\nFundamental). Right: Initial price $14.00 (Below Fundamental). The dashed line indicates\\nthe fundamental value ($28.00).\\nFigure 7: Agent Valuations: Infinite Horizon Scenarios. Left: Initial price $56.00 (Above\\nFundamental). Right: Initial price $14.00 (Below Fundamental). Shows individual agent\\nestimates of fundamental value over time.\\n3.2.4 Divergent Beliefs\\nThis scenario explores the impact of heterogeneous beliefs about fundamental value by com-\\nbining agents with systematically different valuation models. The agent composition is\\ndesigned to create heterogeneity: two Optimistic traders (believing the fundamental value is\\nsignificantly higher), two Pessimistic traders (believing it is significantly lower), two neutral\\nMarket makers, two Momentum traders (following price trends rather than fundamentals),\\nand two Default investors (baseline agents). We test both above-fundamental (initial price\\n$56.00, 2x fundamental) and below-fundamental (initial price$14.00, 0.5x fundamental) vari-\\n33\\nants, allowing researchers to study how different belief structures influence price formation\\nand trading patterns under different initial mispricings. In these scenarios, the fundamental\\nprice is hidden from agents, forcing them to rely on their own valuation models.\\n3.2.5 Market Stress\\nThis scenario tests market resilience under challenging conditions by creating a more volatile\\nenvironment. The scenario includes two consistently bullish Optimistic traders, two consis-', 'the decision-making engine.\\nThe data collection system captures comprehensive market activity across multiple di-\\nmensions. At the market level, it tracks the evolution of prices, fundamental values, and\\nrealized dividends, providing insights into overall market dynamics. Individual agent data\\nincludes detailed wealth trajectories and portfolio compositions, enabling analysis of strategy\\neffectiveness and wealth distribution patterns. The system maintains complete transaction\\nrecords with prices, quantities, and counterparty information, facilitating the study of trad-\\ning patterns and market microstructure. Additionally, it captures agent decision rationales\\nand strategy adherence metrics, allowing researchers to evaluate the consistency and effec-\\ntiveness of different trading approaches.\\nAll experimental parameters, market outcomes, and agent interactions are systemati-\\ncally logged and stored in structured formats (CSV and JSON) for subsequent analysis. The\\nframework generates standardized visualizations of price evolution, wealth distribution, and\\ndividend payments to facilitate comparative analysis across different experimental configu-\\nrations.\\n3.1 Fundamental Value Calibration\\nThe framework implements a consistent approach to fundamental value calculation that pro-\\nvides a reliable benchmark for price discovery. For infinite horizon markets, the fundamental\\nvalue follows the standard dividend discount model:\\nVt = E[D]\\nr = Expected Dividend\\nInterest Rate (1)\\nFor the default parameters where the expected dividend is $1.40 and the interest rate is\\n5%, this yields a fundamental value of $28.00.\\nIn finite horizon markets with T periods remaining, the fundamental value incorporates\\n30\\nboth future dividends and terminal redemption value K:\\nFVt =\\nTX\\nτ=t\\nE[D]\\n(1 + r)τ−t+1 + K\\n(1 + r)T−t+1 (2)\\nTo ensure consistency between finite and infinite horizon markets, the redemption value\\nK is set equal to E[D]\\nr , which makes the fundamental value constant atE[D]\\nr across all periods,\\nregardless of the time horizon. This calibration approach ensures a clean experimental design\\nby providing a stable benchmark for price discovery.\\n3.2 Experimental Scenarios\\nTo evaluate market dynamics with LLM-based agents, we implemented several experimental\\nscenarios that systematically explore different initial conditions and agent compositions.\\nEach scenario maintains the fundamental value of $28.00 while varying starting prices, time\\nhorizons, and agent populations. These scenarios address our core research questions (Section\\n1) by testing LLM capabilities under varying market conditions, focusing on price discovery\\ndynamics, the impact of heterogeneous beliefs, and market stability under stress; GPT-4o\\nwas used consistently as the decision-making engine for all LLM agents across these scenarios.\\nWe present the setup for several key scenarios below, followed by a discussion of the observed\\nresults for the 2 experiments involving an infinite horizon market with a starting price either\\nabove or below the fundamental value.\\n3.2.1 Price Discovery (Above Fundamental)\\nThis scenario tests downward price convergence by starting with an initial price 25% above\\nthe fundamental value ( $35.00). It runs for 20 trading rounds and features a diverse\\nagent population, including two Default investors (baseline agents), two Optimistic traders\\n(who believe prices should be higher), two Market makers (providing liquidity by posting\\nbids/asks), and two Speculator agents (opportunistic traders seeking inefficiencies). Market\\n31\\nmakers are given enhanced liquidity with 20x the baseline cash and shares to ensure suffi-\\ncient liquidity provision and facilitate price discovery. The scenario tests whether prices can\\ncorrect downward through trading activity when starting from an overvalued state.\\n3.2.2 Price Discovery (Below Fundamental)\\nThis complementary scenario tests upward price convergence by starting with an initial price', '33\\nants, allowing researchers to study how different belief structures influence price formation\\nand trading patterns under different initial mispricings. In these scenarios, the fundamental\\nprice is hidden from agents, forcing them to rely on their own valuation models.\\n3.2.5 Market Stress\\nThis scenario tests market resilience under challenging conditions by creating a more volatile\\nenvironment. The scenario includes two consistently bullish Optimistic traders, two consis-\\ntently bearish Pessimistic traders, two Market makers (liquidity providers), and two Value\\ninvestors (rational benchmark traders). The scenario runs for 100 rounds to study long-term\\nmarket behavior and includes unequal initial endowments, with optimistic traders having\\nmore cash (1.5x baseline) but fewer shares (0.5x baseline) and pessimistic traders having less\\ncash (0.5x baseline) but more shares (1.5x baseline). This resource imbalance tests whether\\nparticular agent types can dominate market outcomes through resource advantages.\\nThe scenarios presented here demonstrate the framework’s capabilities for exploring di-\\nverse market conditions. Its modular structure facilitates the straightforward definition and\\nimplementation of alternative experimental designs, enabling researchers to tailor simulations\\nto specific research questions.\\nIn all scenarios, we maintain consistent baseline parameters with a fundamental value\\nof $28.00, calculated from the expected dividend of $1.40 and interest rate of 5%. Agent\\nendowments start at 1,000,000 monetary units and 10,000 shares unless specifically modified.\\nTransaction costs are set to zero to isolate the effects of agent behavior and market structure\\non price formation.\\n4 Conclusion\\nThis paper demonstrates that Large Language Models can effectively function as diverse\\ntrading agents—from value investors to market makers—maintaining strategic consistency\\n34\\nwhile adapting to market conditions. Our experimental framework reveals that their in-\\nteractions generate realistic market dynamics, including phenomena like price bubbles and\\ncorrections, highlighting both the capabilities and potential risks of deploying LLM agents\\nin financial markets.\\nThese findings carry significant implications for market structure and regulation. While\\nLLM agents can enhance price discovery and liquidity, their adherence to programmed strate-\\ngies, even potentially flawed ones derived from prompts, could amplify market volatility or\\nintroduce novel systemic risks, as observed in our simulated bubble scenarios. A key concern\\nis the potential for widespread correlated behavior: similar underlying LLM architectures\\nresponding uniformly to comparable prompts or market signals could inadvertently create\\ndestabilizing trading patterns without explicit coordination. This underscores the critical\\nneed for rigorous testing and validation of LLM-based trading systems prior to live deploy-\\nment.\\nA central contribution of this work is the open-source simulation framework itself, de-\\nsigned to catalyze research into LLM trading agents. We invite the research community to\\nutilize and extend this platform to investigate pressing questions in this rapidly evolving\\narea. The framework enables systematic exploration of complex scenarios—such as hybrid\\nhuman-LLM markets, stress tests, varying market structures, regulatory impacts, and the\\nnuances of LLM prompting—often difficult or costly to study otherwise. Specific avenues\\nripe for investigation using this tool include the emergence of novel trading strategies, the\\nprecise effects of agent heterogeneity on market stability, and the development of robust\\nvalidation protocols for AI traders. As artificial intelligence becomes more integrated into\\nfinance, collaborative research leveraging adaptable simulation environments like this one\\nwill be crucial for understanding and responsibly shaping the future of trading.\\n35\\nReferences', 'market efficiency and price discovery processes throughout the simulation.\\nAgent performance metrics include absolute position tracking (shares, cash, and total\\nwealth), wealth composition analysis, position change metrics, and return calculations. The\\nsystem computes both absolute and percentage returns on various portfolio components\\nand compares performance across agent types to identify relative advantages of different\\nstrategies. Trading flow analysis visualizes the volume of shares moving between different\\nagent types and cumulative net trading flows, revealing which agents act as net buyers or\\nsellers in different market conditions.\\nDecision pattern analysis employs heatmaps to visualize the consistency of agent decision-\\nmaking over time, allowing researchers to identify shifts in strategic behavior. This is com-\\nplemented by decision quantities visualization that plots order sizes to highlight variations\\nin trade aggressiveness across agent types. When agent reasoning data is available, the\\nsystem generates wordclouds to extract key terms from agent explanations, providing qual-\\nitative insights into decision drivers for different agent strategies. Additional visualizations\\ntrack price target accuracy and compare agent-specific valuations to realized market prices,\\n28\\noffering insights into the forecasting abilities of different agents.\\nA key advantage of simulation-based analysis is complete observability of all market\\nprocesses and agent states. Unlike real-world markets where data availability is often limited,\\nthe framework captures every interaction, decision, and state change with perfect fidelity.\\nThis comprehensive data collection allows researchers to compute additional metrics beyond\\nstandard market measures, enabling novel analyses such as counterfactual testing (e.g., how\\nwould markets evolve with different agent compositions), causal inference of specific agent\\nbehaviors on market outcomes, and the development of custom efficiency or stability metrics\\ntailored to particular research questions. The system’s modular design facilitates rapid\\nimplementation of new metrics and visualizations as research questions evolve.\\n3 Experimental Design and Results\\nOur experimental framework implements a dividend-paying asset market with heterogeneous\\nagents. The baseline simulation runs for 15 to 20 rounds with 8 participating agents, although\\nthese parameters are fully configurable. Each agent begins with an initial endowment of\\n1,000,000 monetary units and 10,000 shares of the asset. The fundamental value of the asset\\nis set at $28.00, with a final redemption value matching this fundamental price in finite\\nhorizon scenarios. Transaction costs are set to zero to isolate the effects of agent behavior\\nand market structure.\\nThe dividend structure follows a stochastic process with a base payment of $1.40 and a\\nvariation of ±$1.00, paid with 50% probability each round. This design creates uncertainty\\nin the asset’s income stream while maintaining a known expected value. Cash holdings earn\\na risk-free interest rate of 5% per round, providing an opportunity cost for asset investment.\\nAgent composition is controlled through a flexible distribution system that allows for\\nvarious experimental configurations. In our baseline setup, we employ a mixed population\\nof value investors, momentum traders, and market makers. Each agent type implements\\n29\\ndistinct trading strategies through Large Language Model (LLM) prompts, with GPT-4o as\\nthe decision-making engine.\\nThe data collection system captures comprehensive market activity across multiple di-\\nmensions. At the market level, it tracks the evolution of prices, fundamental values, and\\nrealized dividends, providing insights into overall market dynamics. Individual agent data\\nincludes detailed wealth trajectories and portfolio compositions, enabling analysis of strategy\\neffectiveness and wealth distribution patterns. The system maintains complete transaction', 'value, the system:\\n1. Sets market price P = ρV where ρ is the target ratio\\n2. Generates a consistent order book structure around this price\\n3. Executes multiple decision trials with the same agent type\\n4. Records decision outcomes (buy/sell/hold), order types, quantities, and reasoning\\nThis process maps how LLM agents respond to different price environments, as illustrated\\nin Figures 2, 3, 4, and 5. The analysis reveals clear patterns in decision boundaries, with\\ndistinct transitions between buying, selling, and holding regions that vary by agent type. For\\nexample, value investors show strong buying tendencies when prices are below fundamental\\nvalue (ρ <1) and selling preferences when prices exceed fundamentals ( ρ >1). In contrast,\\nmomentum traders show less sensitivity to the fundamental ratio and more responsiveness\\nto recent price trends.\\nThe systematic variation approach also reveals patterns in order sizing and limit price\\nselection, with agents typically placing larger orders when prices deviate significantly from\\ntheir valuation models (Figure 4). This methodology provides unprecedented transparency\\ninto LLM decision processes and enables quantitative comparison of different agent types\\nand LLM architectures.\\n22\\nFigure 2: Price Analysis under Systematic Variation. Shows how agent valuation estimates\\nand price targets respond to varying Price/Fundamental ratios.\\nThe decision analysis can be customized for different experimental designs. For example,\\nresearchers can use the framework to study the impact of various market conditions on agent\\nbehavior by varying other market parameters or the effect of different agent types on market\\ndynamics by changing the agent population.\\n2.3 Data Collection and Analysis\\nEvaluating LLM trading agents requires robust methodologies for capturing, processing,\\nand analyzing their behavior in market environments. The framework implements a com-\\nprehensive analytics module that tracks all market activity, agent decisions, and performance\\nmetrics throughout experimental runs. This multi-layered approach not only records what\\nhappens in each simulation but also provides insights into why agents make specific deci-\\nsions, enabling researchers to validate agent behavior against their defined strategies and\\nassess overall market dynamics. The following sections detail the key components of this\\nanalytics infrastructure.\\n23\\nFigure 3: Trading Decision Distribution under Systematic Variation. Illustrates the proba-\\nbility of Buy, Sell, or Hold decisions across different agent types as the Price/Fundamental\\nratio changes.\\n24\\nFigure 4: Order Size Distribution under Systematic Variation. Shows the average quan-\\ntity traded (as a percentage of initial shares) for Buy and Sell orders across different\\nPrice/Fundamental ratios.\\n2.3.1 Data Collection Architecture\\nThe framework implements a comprehensive data collection system that captures multiple\\ndimensions of market behavior and agent decision-making. This structured approach ensures\\nreproducibility and enables detailed analysis of market dynamics.\\n2.3.2 Core Data Streams\\nThe system captures five primary data streams that work together to provide a complete\\npicture of market activity. Market Data forms the foundation, tracking essential metrics\\nincluding price evolution, fundamental values, trading volumes, order book depth, market\\nliquidity, best bid/ask prices, spreads, and price-fundamental ratios. This is complemented\\nby detailed Trade Data, which records individual transaction details such as prices, quan-\\ntities, buyer and seller identifiers, timestamps, round information, and specific execution\\ndetails.\\nAgent Data provides insights into participant behavior by monitoring cash and share\\n25\\nFigure 5: Order Type Analysis under Systematic Variation. Displays the proportion of\\nMarket vs. Limit orders used by different agent types across varying Price/Fundamental\\nratios.\\n26', 'tory equilibrium theory of allocations and prices in the presence of transactions costs\\npromises still more complexity, because it requires a simultaneous endogenous de-\\ntermination of prices, allocations, and the least-cost form of market structure and\\nﬁnancial intermediation.\\nTo circumvent all this complexity and also preserve a role for intermediation, I in-\\ntroduce a continuous-time model in which many investors cannot trade costlessly, but\\nthe lowest-cost transactors (by deﬁnition, ﬁnancial intermediaries) can. In this model,\\nstandard CCA can be used to determine the production costs for ﬁnancial products is-\\nsued by intermediaries. However, unlike in the standard zero-cost model, these prod-\\nucts can signiﬁcantly improve economic efﬁciency. If, moreover, the traded-security\\nmarkets and ﬁnancial-services industry are competitive, then equilibrium prices of\\nﬁnancial products will equal the production costs of the lowest-cost transactors. In\\nSection 14.5, we analyze this model and show that, through intermediation, all in-\\nvestors can achieve optimal consumption-bequest allocations as if they could trade\\ncontinuously without cost. Hence, in this model with transactions costs, both the\\ncontingent-claims analyzes of Chapters 11-13 and the equilibrium analyzes of Chap-\\nter 15 can be used to determine equilibrium allocations and prices.4Thus, this model\\nprovides a resolution of the Hakansson paradox by showing that mutual funds and\\nderivative-security markets can provide important economic beneﬁts to investors and\\ncorporate issuers, even though these securities are priced in equilibrium as if they\\nwere redundant.\\n3With diffusion processes and proportional transactions costs, investors cannot trade continuously, and\\ntherefore cannot perfectly hedge derivative-security positions. The reason is that, with continuous trading,\\ntransactions costs at each trade will be proportional to |dz|, where dzis a Brownian motion. However, for any\\nnoninﬁnitesimal time interval T,∫T\\n0|dz|=∞almost certainly, and hence with continuous trading the total\\ntransactions cost is unbounded with probability one.\\n4More generally, standard CCA will provide a close approximation if the “mark-up” per unit required\\nto cover the intermediary’s transactions costs and proﬁt is sufﬁciently small that, from the perspective of its\\ncustomers’ behavior, the additional cost is negligible. Of course, a tiny margin applied to large volume can\\nproduce substantial total proﬁts for the ﬁnancial intermediation industry.\\n14.2 Derivative-Security Pricing with Transactions Costs 341\\n14.2 Derivative-Security Pricing with Transactions Costs\\nIn this section, we examine the effects of transactions costs on derivative security\\npricing by using the two-period version of the Cox-Ross-Rubinstein binomial option\\npricing model as analyzed in Section 10.2. In that model, the initial stock price S(0)\\nis given by S0. At time 1, the stock price will equal either S11orS12. IfS(1) = S11,\\nthen at time 2, S(2)will equal either S21orS22. IfS(1) = S12, then at time 2, S(2)\\nwill equal either S23orS24.Rdenotes the return per dollar invested in the riskless\\nsecurity and is constant over both periods. To capture the effect of transactions costs,\\nwe assume that a commission must be paid on each purchase or sale of the stock\\nand that the commission rate is a ﬁxed proportion τof the dollar amount of the\\ntransaction. Equivalently, we could assume a bid-ask spread, in which investors pay\\ntheask price for the stock, Sa(t)≡(1 +τ)S(t), when they buy and receive the bid\\nprice ,Sb(t)≡(1−τ)S(t)when they sell. There are no costs for transacting in the\\nriskless security.\\nAs shown in (10.3), the array of possible stock prices must satisfy certain condi-\\ntions to rule out the possibility of arbitrage or dominance opportunities between the\\nstock and the riskless security. The corresponding set of restrictions, in the presence\\nof transactions costs can be written as\\nS11< S0R <(1−τ)S12\\n1 +τ(14.1a)\\nS21< S11R <(1−τ)S22', 'investors’ optimal demand functions will depend upon how frequently they can revise\\ntheir portfolios. Therefore, it should be pointed out that nowhere in the analysis\\npresented here is it assumed that the distribution of X(T)−X(0)is invariant to h.\\nDeﬁne the conditional expectation operator Etto be the expectation operator con-\\nditional on knowing all relevant information revealed as of time tor before. Deﬁne\\nthe random variables ǫ(k)by\\nǫ(k)≡X(k)−X(k−1)−Ek−1{\\nX(k)−X(k−1)}\\nk= 1,. .. , n (3.2)\\nwhere “time k” is used as shorthand for “time kh.” By construction, Ek−1{ǫ(k)}= 0,\\nandǫ(k)is the unanticipated price change in the security between k−1andk, condi-\\n5See Merton (1975b).\\n3.1 Introduction 49\\ntional on being at time k−1. Moreover, by the properties of conditional expectation,\\nit follows that Ek−j{ǫ(k)}= 0forj= 1,. . ., k . Hence the partial sums Sn≡∑n\\n1ǫ(k)\\nform a martingale .6As will be seen, the mathematical analysis to follow depends\\nheavily on the properties of martingales. The theory of martingales is usually associ-\\nated in the ﬁnancial economics literature with the “Efﬁcient-Market Hypothesis” of\\nFama and Samuelson.7Therefore, the reader may be tempted to connect the martin-\\ngale property of the unanticipated returns derived here with an implicit assumption\\nthat “securities are priced correctly.” However, the martingale property of the unan-\\nticipated returns here is purely a result of construction, and therefore imposes no such\\neconomics assumption. However, two economics assumptions that will be imposed\\nare as follows.\\nAssumption 5.\\nFor each ﬁnite time interval [0,T]there exists a number A1>0, independent of the\\nnumber of trading intervals n, such that Var(Sn)≥A1where Var(Sn)≡E0{[∑n\\n1ǫ(k)]2}\\n.\\nAssumption 6.\\nFor each ﬁnite time interval [0,T], there exists a number A2<∞, independent of n,\\nsuch that Var(Sn)≤A2.\\nAssumption 1 ensures that the uncertainty associated with the unanticipated price\\nchanges is not “washed out” or eliminated even in the limit of continuous trading.\\nThat is, even as h→dt, the “end-of-period” price at time kwill be uncertain relative\\nto time k−1. This assumption is essential for the continuous-trading model to capture\\nthis fundamental property of stock-price behavior.\\nAssumption 2 ensures that the uncertainty associated with the unanticipated price\\nchanges over a ﬁnite period of time is not so great that the variance becomes un-\\nbounded. It rules out the possibility that the very act of allowing more frequent trad-\\ning will induce sufﬁcient price instability to cause the limiting variance of X(T)−\\nX(0)to become unbounded, and it also rules out the Pareto-Levy stable distributions\\nwith inﬁnite variances.\\nDeﬁne V(k)≡E0{ǫ2(k)},k= 1,2,. . ., n , to be the variance of the dollar return on\\nthe security between time k−1andkbased upon information available as of time\\nzero, and deﬁne V≡maxkV(k).\\nAssumption 7.\\nThere exists a number A3,1≥A3>0, independent of n, such that for k= 1,. .. , n ,\\nV(k)/V≥A3.\\n6For a formal deﬁnition of the martingale and discussions of its properties, see Feller (1966, pp. 210-15\\nand 234-8). Important mathematical analyzes of martingales in continuous-time processes are by Dellacherie\\nand Meyer (1982) and Kunita and Watanabe (1967).\\n7See Fama (1965a, 1970a, 1991), Samuelson (1965b, 1973), and also Cootner (1964). The theory of\\nmartingales provides a powerful technique for the analysis of equilibrium security prices in continuous-time\\nmodels. See Harrison and Kreps (1979), Kreps (1981), Harrison and Pliska (1981, 1983), Dufﬁe and Huang\\n(1985, 1986), Dufﬁe (1986, 1988), Huang (1985a, b, 1987), Pliska (1986), and Cox and Huang (1989a, b.\\n1991).\\n50 On the Mathematics and Economics Assumptions of Continuous-Time Models\\nAssumption 3 is closely related to Assumption 1 and in effect rules out the possi-\\nbility that all the uncertainty in the unanticipated price changes over [0,T]is concen-\\ntrated in a few of the many trading periods. In other words, there is signiﬁcant price', 'allocations are brieﬂy addressed in Chapter 15 and analyzed more fully in Chapter 16. If a set of existing\\nsecurities and markets leads to an equilibrium that is an unconstrained Pareto optimum, then any additional\\nsecurities or markets will be redundant.\\n50The term “transactions costs” can, of course, mean more than just the bid-ask spread or commissions\\npaid for buying and selling assets. For example, if an investor literally traded his portfolio continuously, he\\nwould have no time to do anything else! Because investment management and ﬁnancial intermediation involve\\nprimarily information processing and security trading, there arc signiﬁcant economies of scale. One would thus\\nexpect substantially lower costs for the individual investor to use intermediaries instead of transacting directly\\nin the asset markets.\\n368 Financial Intermediation in the Continuous-Time Model\\nIt would seem therefore that the same dichotomy derived in the frictionless-market\\ncase applies also to our model with transactions costs. In a formal computational\\nsense it does. We can still solve for the equilibrium asset-price dynamics in the model\\nof Chapter 15 and then compute the prices of derivative securities, mutual funds, and\\ncorporate liabilities using CCA. There is one signiﬁcant difference, however: the\\nﬁrst-part calculation of equilibrium real-sector allocations is valid if and only if there\\nexists a sufﬁciently rich set of securities and intermediaries in the ﬁnancial sector to\\nmake these allocations feasible for agents who cannot trade without cost. Because\\nof this conditioning. perhaps a more appropriate term for this separation is “quasi-\\ndichotomy.”\\nWith the assumption that not all agents can trade continuously without cost, a\\nsigniﬁcant economic role is established for derivative-security markets and ﬁnancial\\nintermediaries in the model. Somewhat paradoxically, we ﬁnd that, if intermediation\\nis efﬁcient, then derivative securities and the ﬁnancial products of the intermediaries\\nwill be priced as if they are redundant.51Under these conditions, quasi-dichotomy\\nobtains, and we can derive equilibrium real-sector allocations and asset prices from\\nthe frictionless-market version of the model.\\n14.6 Afterword: Policy and Strategy in Financial Intermediation\\nIn this chapter, as throughout the book, the focus has been on theory. Allusions to\\npractice were concentrated on the micro quantitative applications of the continuous-\\ntime model to product technologies and risk management. Still, I cannot wholly\\nresist the temptation to call attention to the model’s potential for addressing broader\\nissues in the practice of intermediation. And so this afterword shall ever so brieﬂy\\ntouch upon implications of the model for intermediation policy and strategy in the\\nhope that it will lead others, better qualiﬁed, to explore this matter elsewhere.\\nDerivative securities have long been an integral part of the ﬁnancial markets,52\\nbut most would mark the creation of the Chicago Board Options Exchange in April\\n1973 as the start of the current wave of ﬁnancial innovations involving derivative\\nsecurities. The succeeding years have witnessed an unprecedented proliferation of\\norganized trading markets in both equity and ﬁxed-income derivative instruments.\\nIn turn, these markets made possible the creation of a wide range of ﬁnancial prod-\\n51Thus, our model provides a resolution to Hakansson’s (1979, p. 722) “The Catch 22 of Option Pricing.”\\nAlthough the equilibrium prices of options and other derivative securities satisfy the redundancy condition of\\nCCA, they are nevertheless needed to support the equilibrium allocations, and hence their elimination would\\nreduce social welfare.\\n52Bernstein (1992) reports that Aristotle’s anecdote about Thales in Book I of Politics is the ﬁrst recorded\\nmention of a ﬁnancial option. Schaede (1988) makes the case that the Dojima rice market in Osaka was a']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ❌ Contextual Precision (ragas) (score: nan, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ❌ Faithfulness (ragas) (score: nan, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Contextual Recall (ragas) (score: 0.6666666666666666, threshold: 0.6, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Answer Relevancy (ragas) (score: 0.8654035831056827, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Why do the authors choose discrete trading rounds instead of real‑time order processing for the LLM agents?\n",
      "  - actual output: LLMs (Large Language Models, AI models that can understand and generate human-like text) have latency constraints (delays in processing information). This makes real-time order processing infeasible, so the authors use discrete trading rounds instead.\n",
      "  - expected output: LLMs have latency; discrete rounds let agents think while still approximating concurrency via randomised order of submission.\n",
      "  - context: ['When the market starts significantly above\\nthe fundamental value (left panels), the price fails to converge downwards towards the $28.00\\nbenchmark within the 15 rounds, remaining substantially elevated. Agent valuations mirror\\nthis persistence, with many agents maintaining estimates well above the fundamental value.\\nHowever, when the market begins significantly below the fundamental value']\n",
      "  - retrieval context: ['the second agents’ design, and the third the analysis module.\\n8\\n2.1 Market Design\\nOur methodological framework integrates three components that create a controlled envi-\\nronment for LLM-based trading agents. The framework implements a flexible continuous\\ndouble-auction market mechanism that couples standard market microstructure principles\\nwith market clearing and matching algorithms to accommodate asynchronous LLM decisions.\\nThe market clearing process employs a dual-stage matching algorithm. In the first stage,\\nlimit orders are posted. In the second stage, market orders are netted using a market-\\nto-market matching engine that processes buy and sell orders, reconciling orders based on\\navailable agent cash and share commitments. In the third stage, any remaining market\\norders are matched against the existing order book, with unfilled quantities converted to\\naggressive limit orders. This three-tiered approach optimizes immediate execution and price\\ndiscovery while maintaining market liquidity.\\nThe system’s OrderMatchingService orchestrates this process by coordinating trade ex-\\necutions through the TradeExecutionService and managing order state transitions via the\\nOrderStateManager. Each trade is logged in detail, with the overall market state—including\\norder books, market depth, and price evolution—recalculated at the end of each trading\\nround.\\nThis modular design in the matching and clearing engine provides several advantages.\\nFirst, it enables rigorous trade validation where each market order is validated against agent\\ncash commitments and position constraints before matching, with the system dynamically\\nadjusting order quantities based on available cash when an agent’s commitment is insuf-\\nficient, thus minimizing execution errors. Second, it offers flexible liquidity handling by\\nsupporting market-to-market and market-to-book matching, ensuring orders have multiple\\nexecution pathways, with unexecuted market orders converted to aggressive limit orders to\\ncapture remaining liquidity. Third, it maintains detailed trade audit capabilities by recording\\ncomprehensive traceability data including timestamps, trade volumes, executed prices, and\\nagent identifiers, thereby enabling post-trade analysis and performance benchmarking that\\n9\\nserves as the foundation for subsequent market efficiency and agent performance validations.\\n2.1.1 Market Mechanism Design\\nOur framework implements a continuous double-auction market mechanism that processes\\norders in discrete trading rounds. We use discrete trading rounds because LLMs have latency\\nconstraints, making it infeasible to process orders in real time. Within each round, the order\\nof agent submissions is randomized to avoid giving systematic priority to specific agents,\\nthus simulating concurrent order arrival while maintaining fairness. Once randomized, or-\\nders are then processed according to standard price-time priority rules. The system supports\\nfinite and infinite horizon markets, with differences in terminal conditions and wealth cal-\\nculation. In finite-horizon markets, agents are informed of the total number of rounds, and\\ntheir terminal wealth is calculated by redeeming all shares at the fundamental value of the\\nfinal round. In infinite-horizon markets, no terminal information is provided to agents, and\\nfinal wealth is determined using the last market price for share valuation. This design choice\\nenables researchers to study how time horizons influence trading strategies and price for-\\nmation, particularly how agents balance short-term trading opportunities against long-term\\nvalue considerations.\\nIn a double auction, buyers and sellers actively submit orders, with trades occurring when\\ncompatible buy and sell orders match the price. The matching engine processes these orders\\nthrough three sequential phases:\\nFirst, incoming limit orders that do not immediately cross the market are added to\\nthe order book, maintaining strict price-time priority. Second, market orders are processed', '2024). Another examines LLMs’ strategic capabilities through task-based simulations and\\ncollaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\\nWithin the computer science literature, early works apply LLMs to financial markets but\\nabstract away many fundamental stock market characteristics. Often, they employ single-\\nprice clearing mechanisms without a persistent order book, ignore partial fills and bid-ask\\nspreads, and omit dividends. Consequently, these simplified environments can primarily\\naddress exogenous macro shocks (e.g., changes in interest rates or inflation; Gao et al. 2024),\\nexogenous policy changes (Zhang et al. 2024), or rely on advanced methods such as repetitive\\nnext-token predictions to generate better answers (Koa et al. 2024). This work extends\\nthese efforts by incorporating these crucial market features, enabling the study of complex\\nendogenous events such as flash crashes, liquidity shocks, and large-trader impacts.\\nThis work also connects to emerging research on algorithmic and AI-powered trading\\nsystems. Dou, Goldstein, and Ji (2024) demonstrate how reinforcement learning-based AI\\nspeculators can autonomously learn to sustain collusive behavior without explicit coordi-\\nnation, achieving supra-competitive profits through either price-trigger strategies or self-\\nconfirming bias in learning. This finding is particularly informative for this framework as\\nit highlights potential emergent behaviors that may arise when intelligent agents interact in\\n7\\nmarkets—behaviors that could manifest differently with LLM agents due to their natural\\nlanguage reasoning capabilities. Similarly, Colliard, Foucault, and Lovo (2022) examine al-\\ngorithmic market makers using Q-learning and find they charge markups that increase when\\nadverse selection costs decrease—contrary to Nash equilibrium predictions. Their work pro-\\nvides methodological insights on how to test strategic pricing behaviors against theoretical\\nbenchmarks incorporated into this LLM-based framework.\\nFinally, this approach is informed by complexity economics, which views markets as dy-\\nnamic, non-equilibrium systems where agents adaptively learn and evolve strategies (Arthur\\n2013; Wolfram 2017). According to this view, markets exhibit emergent phenomena and\\nself-organization, especially when trading agents (human or artificial) update their behav-\\nior in response to outcomes. This paradigm is particularly relevant in an era of increasing\\nautomation and algorithmic trading (Balland et al. 2022; Ping 2019). Like adaptive agents\\nin complexity economics, these LLM traders incorporate new information and adjust their\\nstrategies, generating emergent market patterns—a key motivation behind this framework.\\nUnlike previous frameworks that abstract away crucial market features or focus on narrow\\nstrategies, this system incorporates realistic market microstructure while accommodating\\nheterogeneous agents interacting simultaneously. While earlier work demonstrates LLMs’\\npromise for macroeconomic modeling and simple trading simulations, this work introduces a\\ncomplex, open-source financial market platform that supports multiple agent architectures,\\nthorough market microstructure (limit orders, partial fills, dividends), and rigorous testing\\nprotocols—fulfilling a critical need in complexity economics research and market microstruc-\\nture analysis.\\n2 Methodology\\nThe methodology section contains three parts. The first part describes the market design,\\nthe second agents’ design, and the third the analysis module.\\n8\\n2.1 Market Design\\nOur methodological framework integrates three components that create a controlled envi-\\nronment for LLM-based trading agents. The framework implements a flexible continuous\\ndouble-auction market mechanism that couples standard market microstructure principles\\nwith market clearing and matching algorithms to accommodate asynchronous LLM decisions.', '(2023)). This work, however, focuses on financial markets and how LLM agents can operate\\nas full-fledged trading participants.\\nRecent research examines specific applications of LLMs for trading. FinMem and Trad-\\ningGPT introduce frameworks with layered memory systems and customizable agent traits\\n5\\nto improve financial decision-making (Yu, Li, et al. 2024; Li, Zhang, and Sun 2023). Hierar-\\nchical multi-agent architectures have been explored in FinCon, which uses a manager-analyst\\nsetup for collaborative portfolio decisions (Yu, Yao, et al. 2024). QuantAgent implements\\na self-improving signal-mining approach (Wang et al. 2024), while other work underscores\\nthe importance of long-term memory in LLM agents via vector databases (Hatalis et al.\\n2024). This line of research builds on successful reinforcement learning applications such as\\nAlphaPortfolio (Cong et al. 2021) and AlphaManager (Campello, Cong, and Zhou 2023),\\nwhich leverage deep RL and robust control for portfolio management.\\nAnalyzing LLM agent behavior by changing only some parameters draws on methods\\nfrom the interpretable machine learning literature. In particular, the systematic variation\\nof market parameters to reveal decision patterns mirrors partial dependence plots and in-\\ndividual conditional expectation curves used to interpret complex machine learning models\\n(Molnar 2022). These techniques help reveal how LLM agents respond to changes in specific\\nvariables while holding others constant, providing insight into their internal decision-making\\nprocesses that would otherwise remain opaque.\\nBeyond finance, studies of LLM capabilities in interactive or multi-agent settings offer\\nvaluable insights. Benchmarks like AgentBench evaluate LLMs’ performance in interac-\\ntive tasks (Liu et al. 2023), while InvestorBench focuses on financial decision-making tasks\\nspecifically (H. Li et al. 2024). NegotiationArena demonstrates LLMs’ capacity for strategic\\ninteraction in bargaining contexts (Bianchi et al. 2024). Similarly, Guo et al. (2024) provide\\nan economics ”arena” where LLMs compete in strategic games, revealing that advanced\\nmodels like GPT-4 can exhibit rational, adaptive behavior—albeit not always reaching Nash\\nEquilibrium. Existing frameworks typically assess individual agents or hierarchical collab-\\norations, whereas this work studies emergent market behaviors that arise from multiple\\nindependent LLM traders interacting in a marketplace.\\nThe approach also connects to the tradition of experimental asset markets. For instance,\\nWeitzel et al. (2020) show that even finance professionals are susceptible to speculative\\n6\\nbubbles, especially amid high capital inflows. Kop´ anyi-Peuker and Weber (2021) find that\\ntrading experience alone does not eliminate bubbles, challenging assumptions about rational\\nmarket learning. Kirchler, Huber, and St¨ ockl (2012) identify confusion about fundamental\\nvalues as a key driver of bubble formation. This framework offers a new way to study these\\nphenomena with LLM traders, which can be rigorously parameterized for sophistication,\\nstrategy, and information processing. Hence, this paper provides a method to investigate\\nhow automated or ”artificial” agents might affect market stability or volatility.\\nOther recent work highlights the versatility of LLM agents in complex, interactive sce-\\nnarios beyond finance. One stream focuses on simulating social behaviors—such as opinion\\ndynamics (Chuang et al. 2023), trust (Xie et al. 2024), and resource-sharing (Piatti et al.\\n2024). Another examines LLMs’ strategic capabilities through task-based simulations and\\ncollaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\\nWithin the computer science literature, early works apply LLMs to financial markets but\\nabstract away many fundamental stock market characteristics. Often, they employ single-\\nprice clearing mechanisms without a persistent order book, ignore partial fills and bid-ask', 'Can Large Language Models Trade? Testing Financial\\nTheories with LLM Agents in Market Simulations\\nAlejandro Lopez-Lira∗\\nFirst Version: November 29, 2024; Current Version: April 16, 2025\\nAbstract\\nThis paper presents a realistic simulated stock market where large language models\\n(LLMs) act as heterogeneous competing trading agents. The open-source framework\\nincorporates a persistent order book with market and limit orders, partial fills, div-\\nidends, and equilibrium clearing alongside agents with varied strategies, information\\nsets, and endowments. Agents submit standardized decisions using structured outputs\\nand function calls while expressing their reasoning in natural language. Three findings\\nemerge: First, LLMs demonstrate consistent strategy adherence and can function as\\nvalue investors, momentum traders, or market makers per their instructions. Second,\\nmarket dynamics exhibit features of real financial markets, including price discovery,\\nbubbles, underreaction, and strategic liquidity provision. Third, the framework enables\\nanalysis of LLMs’ responses to varying market conditions, similar to partial dependence\\nplots in machine-learning interpretability. The framework allows simulating financial\\ntheories without closed-form solutions, creating experimental designs that would be\\ncostly with human participants, and establishing how prompts can generate correlated\\nbehaviors affecting market stability.\\nKeywords: LLM Agents; Agent-Based Markets; Experimental Finance; AI Trading;\\nMulti-Agent Systems\\n∗University of Florida. Email: alejandro.lopez-lira@warrington.ufl.edu. I am grateful to seminar par-\\nticipants at the London Business School, Oxford University, Stockholm School of Economics, University of\\nVirginia, and the City University of Hong Kong for helpful suggestions and feedback.\\n1\\narXiv:2504.10789v1  [q-fin.CP]  15 Apr 2025\\n1 Introduction\\nLarge language models (LLMs) can increasingly function as autonomous agents—systems\\nthat observe, reason, and act independently. LLMs have shown promising results in finan-\\ncial forecasting, but their potential as trading agents introduces a fundamental shift from\\nalgorithms with explicit objectives to systems guided by natural language instructions. This\\nchange raises critical questions: Can LLMs execute trading strategies? Do LLMs optimize\\nfor profit maximization? What are the implications for market stability and efficiency?\\nIf LLMs trade similarly to humans, they could enable experimental market simulations\\nwithout human participants. Conversely, if their trading behavior differs, understanding\\nthese differences becomes critical for systemic risk management. These questions extend be-\\nyond theory; LLM-based strategies are already being deployed.1 To address these questions,\\nI develop an open-source simulation that tests LLM trading agents in a realistic market envi-\\nronment with a persistent order book, supporting various order types, stochastic dividends,\\nand heterogeneous information.\\nThe framework allows heterogeneous LLMs—defined in natural language, using different\\nsystem prompts—to act as diverse types of traders, such as value investors, momentum\\ntraders, market makers, and contrarians. Agents submit standardized trading decisions in a\\nhuman-readable format while expressing their reasoning transparently. Figure 1 illustrates\\nthis approach, showing how a speculator agent combines explicit valuation reasoning with\\nstructured trading parameters, enabling systematic analysis and insight into the agent’s\\ndecision-making process.\\nThe analysis reveals three key findings about LLMs’ capabilities as trading agents. First,\\nLLMs can effectively execute trading strategies. They consistently understand market me-\\nchanics, process market information, form price expectations, and execute trades according\\nto specific instructions. Their trading behavior is highly sensitive to the prompts they\\nreceive—they faithfully follow directions regardless of profit implications. This observance', 'decision-making process.\\nThe analysis reveals three key findings about LLMs’ capabilities as trading agents. First,\\nLLMs can effectively execute trading strategies. They consistently understand market me-\\nchanics, process market information, form price expectations, and execute trades according\\nto specific instructions. Their trading behavior is highly sensitive to the prompts they\\nreceive—they faithfully follow directions regardless of profit implications. This observance\\n1. For example, Autopilot has a ChatGPT-based portfolio https://x.com/thegptinvestor.\\n2\\n{\"valuation_reasoning\":\\n\"The fundamental value is based on the expected dividend,\\nand the interest rate.\\nThe expected dividend is $1.40, and the interest rate is 5%.\\nUsing a perpetuity formula, the value is $1.40 / 0.05 = $28.\",\\n\"valuation\":28.0,\\n\"price_target_reasoning\":\"The current price is $29.00, which is\\nslightly above the fundamental value of $28.00. I expect the price\\nto remain around $29.00 in the next round due to market stability.\",\\n\"price_target\":29.0,\\n\"orders\":[{\"decision\":\"Sell\",\"quantity\":1000,\"order_type\":\"limit\",\\n\"price_limit\":29.50}],\\n\"replace_decision\":\"Add\",\\n\"reasoning\":\"The current price is slightly above the fundamental value.\\nI will place a limit sell order at $29.50 to capitalize on potential price\\nincreases.\"}\\nFigure 1: Example of a structured trading decision from a Speculator agent defined by its\\nsystem prompt: “You are a speculator who tries to profit from market inefficiencies.”. The\\nLLM provides explicit reasoning for its valuation, price target, and trading decision in a\\nmachine-readable JSON format that can be directly processed by the trading system.\\nhighlights a fundamental difference from human traders: LLMs do not inherently optimize\\nfor profit maximization but rather for following instructions accurately.\\nSecond, LLMs react meaningfully to market dynamics. They consider current and his-\\ntorical prices, dividends, and other market information when making decisions. However,\\nthey maintain their strategic direction even when market conditions change, following their\\ninstructions even if doing so results in financial losses. This combination of responsiveness\\nto market conditions while maintaining strategic consistency creates a unique trading profile\\ndistinct from rule-based algorithms and human traders.\\nThird, market dynamics with LLM agents can resemble actual markets and mirror classic\\nresults from the theoretical finance literature. When these agents interact, they produce\\nrealistic price discovery and liquidity provision with emergent behaviors, including price\\nconvergence toward fundamental values. Depending on the distribution of agent types,\\nthe system can generate various market phenomena, such as bubbles or underreactions to\\ninformation. This complex behavior suggests potential applications for studying market\\n3\\ndynamics using LLM agents instead of experiments with human participants.\\nHence, these findings raise important questions about algorithmic consistency in LLM-\\nbased systems. Since trading agents are implemented through prompts, their behavior in-\\nherits characteristics of the underlying language models. The standardization of LLM ar-\\nchitectures across implementations could create unexpected behavioral patterns—if many\\nagents are based on similar foundation models, they might exhibit correlated responses to\\nspecific market conditions, potentially amplifying market instabilities.\\nTo enable this analysis and accelerate development in this emerging field, we provide\\nan open-source framework with three key components: (1) a structured protocol for im-\\nplementing and validating LLM trading agents, supporting both LLM-based and traditional\\nrule-based agents; (2) a controlled market environment with realistic microstructure for test-\\ning agent interactions; and (3) a comprehensive data collection system for analyzing trading\\nbehavior. This framework serves multiple stakeholders in preparation for the evolution of', '2407.18957. arXiv: 2407.18957 [q-fin]. http://arxiv.org/abs/2407.18957.\\n41\\nA Technical Implementation Details\\nA.1 Agent Type Specifications\\nThis section details the base system prompts for each agent type in our simulation. These\\nprompts define the core behavioral characteristics and trading strategies for each agent. Each\\nprompt consists of:\\n• A role definition that establishes the agent’s trading philosophy\\n• A structured trading strategy that guides decision-making\\n• Specific instructions for when to use market orders vs limit orders\\nAt runtime, these base prompts are combined with:\\n• Current market state (price, volume, order book depth)\\n• Position information (current holdings and available cash)\\n• Trading options and required response format\\nThe standard runtime template includes:\\nPosition Information Template\\nYour Position:\\n- Available Shares: {shares} shares (Short selling is not allowed)\\n- Main Cash Account: ${cash:.2f}\\n- Dividend Cash Account (not available for trading): ${dividend_cash:.2f}\\n- Total Available Cash: ${total_available_cash:.2f} (Borrowing is not allowed)\\n- Shares in Orders: {committed_shares} shares\\n- Cash in Orders: ${committed_cash:.2f}\\n42\\nTrading Options Template\\nYour analysis should include:\\n- valuation_reasoning: Your numerical analysis of the asset’s fundamental value\\n- valuation: Your estimate of the asset’s current fundamental value\\n- price_target_reasoning: Your numerical analysis of the asset’s price target\\n- price_target: Your predicted price for the next round\\n- reasoning: Your explanation for the trading decision\\nTrading Options:\\n1. New Orders (replace_decision=’Add’):\\n- Single or multiple orders allowed\\n- For each order:\\n- Market order: Set order_type=’market’\\n- Limit order: Set order_type=’limit’ and specify price_limit\\n- IMPORTANT: Sell orders require sufficient available shares\\n- Short selling is NOT allowed\\n2. Cancel Orders (replace_decision=’Cancel’):\\n- Return an empty orders list: orders=[]\\nYour decision must include:\\n- orders: list of orders (empty list for Hold/Cancel)\\n- For Buy/Sell orders, each must contain:\\n- decision: \"Buy\" or \"Sell\"\\n- quantity: number of shares\\n- order_type: \"market\" or \"limit\"\\n- price_limit: required for limit orders\\n- reasoning: brief explanation\\n- replace_decision: \"Add\", \"Cancel\", or \"Replace\"\\n43\\nBase System Prompts The following are the base system prompts for each LLM-based\\nagent type:\\nA.1.1 Value-Based Agents\\nValue Investor\\nYou are a value investor who focuses on fundamental analysis.\\nYou believe in mean reversion and try to buy undervalued assets and sell overvalued ones.\\nA.1.2 Trend-Following Agents\\nMomentum Trader\\nYou are a momentum trader who focuses on price trends and volume.\\nYou believe that ’the trend is your friend’ and try to identify and follow market momentum.\\nA.1.3 Liquidity Providers Agents\\nMarket Maker\\nYou are a professional market maker who provides liquidity to the market.\\nYour profit comes from capturing the spread between bid and ask prices, not from directional price movement.\\nIMPORTANT: There is NO SHORT SELLING allowed. You can only sell shares you already own.\\nTrading Guidelines:\\n- Place LIMIT buy orders slightly below the current market price (1-3% lower)\\n- Place LIMIT sell orders slightly above the current market price (1-3% higher)\\n- Your spread should be proportional to volatility but typically 2-6% of price\\n- NEVER place sell orders more than 10% above your buy orders\\n- Adjust your spread width based on recent price volatility\\n44\\nInventory Management (No Short Selling):\\n- Monitor your current inventory in the market data\\n- Only place sell orders for quantities you actually own\\n- If you have no inventory, focus on buy orders first\\n- As you acquire inventory, gradually place sell orders\\n- If inventory grows too large, reduce or pause buy orders\\n- Adjust your buy/sell ratio based on current inventory level\\nExample: If price = $100, you might place buy orders at $97-99 and sell orders at $101-103,', '• Market Makers: Provide liquidity through symmetric bid-ask spreads\\n• Contrarian Traders: Trade against market extremes and overreactions\\n• Speculators: Seek to profit from market inefficiencies\\n• Sentiment-Based Agents: Include optimistic and pessimistic variants with biased\\nexpectations\\n• Retail Traders: Simulate typical individual investor behavior\\nThe software also includes a set of deterministic rule-based agents that serve as bench-\\nmarks and control conditions:\\n• Directional Traders: Always-buy, always-sell, and always-hold agents\\n• Technical Agents: Gap traders, mean reversion traders, and momentum traders\\n• Algorithmic Market Makers: Implement fixed spread-posting strategies\\n14\\nEach agent type is defined by its system prompt (for LLM agents) or algorithmic rules (for\\ndeterministic agents), with standardized interfaces enabling direct comparison across diverse\\nstrategies. The agent composition system supports flexible specifications—including uni-\\nform distributions, type-specific concentrations (e.g., ”value heavy”), and precise numerical\\nallocations—enabling systematic exploration of how market dynamics emerge from different\\nagent populations.\\nThe framework’s extensible design makes it remarkably simple to add new agent types—\\nLLM-based agents require only defining a new system prompt that specifies the trading\\nstrategy. In contrast, deterministic agents can be implemented through the standard agent\\ninterface. This flexibility allows researchers to rapidly prototype and deploy novel trading\\nstrategies without modifying the underlying system architecture.\\nThe complete list of agent types included in the framework and their detailed specifi-\\ncations is provided in the Appendix. The framework’s flexible prompt-based architecture\\nallows researchers to rapidly prototype and deploy new agent types by developing appropri-\\nate strategic and tactical prompts without modifying the underlying system architecture.\\n2.2.4 User Prompt\\nThe user prompt provides the immediate market context necessary for tactical decision-\\nmaking. This dynamic component delivers current market state information, including\\nprices, volumes, and emerging trends, alongside the agent’s current position information\\nand available trading options. Additionally, the user prompt specifies immediate decision\\nrequirements and operational constraints, ensuring that agent responses remain within fea-\\nsible bounds while aligning with their strategic objectives. This separation of strategic and\\ntactical prompting enables precise control over agent behavior while maintaining flexibility\\nfor market interactions. All the information in the user prompt is optional at the agent level\\nand can be customized for different experimental designs.\\n15\\n2.2.5 Decision Structure\\nEach agent decision follows a standardized output format comprising several key components.\\nThe decision field specifies the basic action as either Buy, Sell, or Hold. For active trades,\\nthe quantity field determines the number of shares to trade, while the order type indicates\\nwhether it is a Market or Limit order. When placing limit orders, the price limit field\\nspecifies the maximum (for buys) or minimum (for sells) acceptable execution price. Finally,\\neach decision includes a reasoning field that provides an explicit rationale for the trading\\ndecision, ensuring transparency and facilitating analysis of agent behavior.\\n2.2.6 Structured Outputs and Function Calling\\nOur framework implements a structured output approach using function calling to ensure\\nstandardized, human-readable, machine-readable agent decisions. This technique allows\\nLLMs to generate outputs in a specific format that can be directly validated and processed\\nby the trading system, bridging the gap between natural language reasoning and executable\\ntrading actions.\\nThe system uses Pydantic for validation and parsing of agent outputs, with a schema-\\nbased approach that defines the required structure:\\nclass TradeDecisionSchema(BaseModel):', 'ceedings of the 62nd Annual Meeting of the Association for Computational Linguistics\\n(Volume 1: Long Papers),edited by Lun-Wei Ku, Andre Martins, and Vivek Srikumar,\\n15523–15536. ACL 2024. Bangkok, Thailand: Association for Computational Linguis-\\ntics, August.\\n39\\nLi, Yuan, Yixuan Zhang, and Lichao Sun. 2023. “MetaAgents: Simulating Interactions of\\nHuman Behaviors for LLM-based T Ask-Oriented Coordination via Collaborative Gen-\\nerative Agents.” arXiv.org.\\nLiu, Xiao, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, et al. 2023.\\n“AgentBench: Evaluating LLMs as Agents.”International Conference on Learning Rep-\\nresentations.\\nLopez-Lira, Alejandro, and Yuehua Tang. 2023. “Can ChatGPT Forecast Stock Price Move-\\nments? Return Predictability and Large Language Models.” SSRN Electronic Journal\\n(April 6, 2023).\\nManning, Benjamin S., Kehang Zhu, and John J. Horton. 2024. “Automated Social Science:\\nLanguage Models as Scientist and Subjects.” (Cambridge, MA) (April 29, 2024).\\nMolnar, Christoph. 2022. Interpretable Machine Learning.\\nPelster, Matthias, and Joel Val. 2023. “Can Chatgpt Assist in Picking Stocks?”Social Science\\nResearch Network.\\nPiatti, Giorgio, Zhijing Jin, Max Kleiman-Weiner, Bernhard Sch¨ olkopf, Mrinmaya Sachan,\\nand Rada Mihalcea. 2024. “Cooperate or Collapse: Emergence of Sustainable Coopera-\\ntion in a Socie Ty of LLM Agents.” arXiv.org.\\nPing, Chen. 2019. “From Complexity Science to Complexity Economics.” In Alternative\\nApproaches to Economic Theory,19–55. Routledge, June 11, 2019.\\nWang, Saizhuo, Hang Yuan, Lionel M. Ni, and Jian Guo. 2024. “QuantAgent: Seeking Holy\\nGrail in Trading by Self-Improving Large Lang Uage Model.” arXiv.org.\\nWeitzel, Utz, Christoph Huber, J¨ urgen Huber, Michael Kirchler, Florian Lindner, and Julia\\nRose. 2020. “Bubbles and Financial Professionals.” The Review of Financial Studies33,\\nno. 6 (June 1, 2020): 2659–2696.\\n40\\nWolfram, Elsner. 2017. “Complexity Economics as Heterodoxy: Theory and Policy.”Journal\\nof Economic Issues51, no. 4 (October 2, 2017): 939–978.\\nWoodhouse, Drew, and Alex Charlesworth. 2023. “Can ChatGPT Predict Future Interest\\nRate Decisions?” Social Science Research Network.\\nXie, Chengxing, Canyu Chen, Feiran Jia, Ziyu Ye, Shiyang Lai, Kai Shu, Jindong Gu, et al.\\n2024. “Can Large Language Model Agents Simulate Human Trust Behavior?”arXiv.org.\\nYang, Stephen. 2023. “Predictive Patentomics: Forecasting Innovation Success and Valuation\\nw Ith ChatGPT.” Social Science Research Network.\\nYu, Yangyang, Haohang Li, Zhi Chen, Yuechen Jiang, Yang Li, Denghui Zhang, Rong\\nLiu, Jordan W. Suchow, and Khaldoun Khashanah. 2024. “FinMem: A Performance-\\nEnhanced LLM Trading Agent with Layered Memory a Nd Character Design.”Proceed-\\nings of the AAAI Symposium Series3, no. 1 (May 20, 2024): 595–597.\\nYu, Yangyang, Zhiyuan Yao, Haohang Li, Zhiyang Deng, Yupeng Cao, Zhi Chen, Jordan W.\\nSuchow, et al. 2024. “FinCon: A Synthesized LLM Multi-Agent System with Conceptual\\nVerbal Reinforcement for Enhanced Financial Decision Making.” Pre-published, Novem-\\nber 7, 2024. Accessed January 8, 2025. https://doi.org/10.48550/arXiv.2407.06567.\\narXiv: 2407.06567 [cs]. http://arxiv.org/abs/2407.06567.\\nZhang, Chong, Xinyi Liu, Zhongmou Zhang, Mingyu Jin, Lingyao Li, Zhenting Wang,\\nWenyue Hua, et al. 2024. “When AI Meets Finance (StockAgent): Large Language\\nModel-based Stock Trading in Simulated Real-world Environments.” Pre-published,\\nSeptember 21, 2024. Accessed January 26, 2025. https://doi.org /10.48550/arXiv .\\n2407.18957. arXiv: 2407.18957 [q-fin]. http://arxiv.org/abs/2407.18957.\\n41\\nA Technical Implementation Details\\nA.1 Agent Type Specifications\\nThis section details the base system prompts for each agent type in our simulation. These\\nprompts define the core behavioral characteristics and trading strategies for each agent. Each\\nprompt consists of:\\n• A role definition that establishes the agent’s trading philosophy\\n• A structured trading strategy that guides decision-making']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ❌ Contextual Precision (ragas) (score: nan, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ❌ Faithfulness (ragas) (score: nan, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Contextual Recall (ragas) (score: 1.0, threshold: 0.6, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "  - ✅ Answer Relevancy (ragas) (score: 0.9170656050276289, threshold: 0.7, strict: False, evaluation model: gpt-3.5-turbo, reason: None, error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Could you walk me through the three‑stage matching algorithm the authors implement in their continuous double‑auction market?\n",
      "  - actual output: The matching engine in the continuous double-auction market uses a three-stage algorithm:\n",
      "Stage 1: Order Book Population: Incoming limit orders (orders to buy or sell at a specific price or better) that don't immediately find a match are added to the order book. The order book is organized using price-time priority, meaning the best prices are matched first, and if multiple orders exist at the same price, the oldest order is prioritized.\n",
      "Stage 2: Market Order Processing: Market orders (orders to buy or sell at the best available price) are processed in two steps:\n",
      "(a) Market-to-Market Matching: Market buy orders are matched with market sell orders at the current market price. These orders are essentially netted against each other.\n",
      "(b) Market-to-Book Matching: Any remaining market orders are then matched against existing limit orders in the order book.\n",
      "Stage 3: Crossing Limit Order Matching: Any limit orders that cross the market (a buy order with a price higher than the best ask price or a sell order with a price lower than the best bid price) are matched against existing orders in the order book. This ensures that trades occur whenever possible.\n",
      "  - expected output: Orders are handled in three sequential phases: (1) non‑crossing limit orders join the book; (2a) market‑to‑market netting; (2b) market‑to‑book execution; (3) any still‑crossing limit orders are matched.\n",
      "  - context: ['The matching engine processes these orders\\nthrough three sequential phases:\\nFirst, incoming limit orders that do not immediately cross the market are added to\\nthe order book, maintaining strict price-time priority. Second, market orders are processed\\nthrough a two-stage matching algorithm: (a) market-to-market matching, where market\\norders are netted against each other at the current market price, and (b) market-to-book\\nmatching, where remaining market orders are executed against standing limit orders. Finally,\\nany crossing limit orders are matched against the order book.']\n",
      "  - retrieval context: ['value considerations.\\nIn a double auction, buyers and sellers actively submit orders, with trades occurring when\\ncompatible buy and sell orders match the price. The matching engine processes these orders\\nthrough three sequential phases:\\nFirst, incoming limit orders that do not immediately cross the market are added to\\nthe order book, maintaining strict price-time priority. Second, market orders are processed\\nthrough a two-stage matching algorithm: (a) market-to-market matching, where market\\norders are netted against each other at the current market price, and (b) market-to-book\\nmatching, where remaining market orders are executed against standing limit orders. Finally,\\nany crossing limit orders are matched against the order book.\\n10\\n2.1.2 Implementation Details\\nThe matching engine ( MatchingEngine class) implements three primary components that\\nwork together to facilitate efficient market operation. The order processing component han-\\ndles the core matching functionality, where market orders are executed immediately against\\nthe best available prices in the order book during each trading round. When immediate\\nexecution is impossible, limit orders are stored in the order book according to price-time\\npriority. The system supports partial executions, maintaining careful tracking of remaining\\nquantities to ensure complete order fulfillment across multiple trades when necessary.\\nPosition management forms the second critical component, providing comprehensive\\ntracking of agent positions and cash balances throughout the trading session. Before any\\ntrade execution, the system performs rigorous pre-trade validation to ensure agents have suffi-\\ncient resources to fulfill their orders. This check includes validating buyer cash commitments\\nand shares availability for sellers, with the system maintaining accurate records of commit-\\nted and available resources for each agent. The position management system updates in\\nreal-time as trades are executed, ensuring market integrity and preventing over-commitment\\nof resources.\\nThe price formation mechanism constitutes the third component, implementing a sys-\\ntematic price discovery and market monitoring approach. As trades are executed within each\\nround, the system dynamically updates prices based on executed trades while continuously\\ntracking market depth and bid-ask spreads. This data collection provides detailed insights\\ninto market liquidity and efficiency. Each trade is logged with comprehensive information,\\nincluding price, quantity, and participating agents, creating a complete audit trail of mar-\\nket activity. This comprehensive price formation system ensures transparent price discovery\\nwhile generating rich data for market quality analysis.\\n11\\n2.1.3 Extensibility Features\\nThe framework employs a modular architecture to support diverse experimental configura-\\ntions and research objectives. At its foundation, the system implements configurable market\\nrules and trading constraints that can be adjusted to study different market conditions.\\nThe asset model supports fundamental features like dividend payments and interest accrual,\\nenabling research across different market scenarios. Through its modular service-based ar-\\nchitecture, the trading mechanism layer allows for adaptation to other market structures\\nbeyond the base double-auction system, such as call auctions or dark pools. Furthermore,\\nthe framework provides flexible integration points for different LLM agent types and strate-\\ngies, allowing researchers to experiment with diverse behavioral models and decision-making\\napproaches.\\nThis extensible design creates numerous research opportunities for market microstructure\\nstudies. Researchers can systematically investigate how different market structures influence\\nprice formation and efficiency, evaluate the impact of various trading rules on market qual-\\nity, and analyze the complex interactions between different agent types and strategies. The', 'the second agents’ design, and the third the analysis module.\\n8\\n2.1 Market Design\\nOur methodological framework integrates three components that create a controlled envi-\\nronment for LLM-based trading agents. The framework implements a flexible continuous\\ndouble-auction market mechanism that couples standard market microstructure principles\\nwith market clearing and matching algorithms to accommodate asynchronous LLM decisions.\\nThe market clearing process employs a dual-stage matching algorithm. In the first stage,\\nlimit orders are posted. In the second stage, market orders are netted using a market-\\nto-market matching engine that processes buy and sell orders, reconciling orders based on\\navailable agent cash and share commitments. In the third stage, any remaining market\\norders are matched against the existing order book, with unfilled quantities converted to\\naggressive limit orders. This three-tiered approach optimizes immediate execution and price\\ndiscovery while maintaining market liquidity.\\nThe system’s OrderMatchingService orchestrates this process by coordinating trade ex-\\necutions through the TradeExecutionService and managing order state transitions via the\\nOrderStateManager. Each trade is logged in detail, with the overall market state—including\\norder books, market depth, and price evolution—recalculated at the end of each trading\\nround.\\nThis modular design in the matching and clearing engine provides several advantages.\\nFirst, it enables rigorous trade validation where each market order is validated against agent\\ncash commitments and position constraints before matching, with the system dynamically\\nadjusting order quantities based on available cash when an agent’s commitment is insuf-\\nficient, thus minimizing execution errors. Second, it offers flexible liquidity handling by\\nsupporting market-to-market and market-to-book matching, ensuring orders have multiple\\nexecution pathways, with unexecuted market orders converted to aggressive limit orders to\\ncapture remaining liquidity. Third, it maintains detailed trade audit capabilities by recording\\ncomprehensive traceability data including timestamps, trade volumes, executed prices, and\\nagent identifiers, thereby enabling post-trade analysis and performance benchmarking that\\n9\\nserves as the foundation for subsequent market efficiency and agent performance validations.\\n2.1.1 Market Mechanism Design\\nOur framework implements a continuous double-auction market mechanism that processes\\norders in discrete trading rounds. We use discrete trading rounds because LLMs have latency\\nconstraints, making it infeasible to process orders in real time. Within each round, the order\\nof agent submissions is randomized to avoid giving systematic priority to specific agents,\\nthus simulating concurrent order arrival while maintaining fairness. Once randomized, or-\\nders are then processed according to standard price-time priority rules. The system supports\\nfinite and infinite horizon markets, with differences in terminal conditions and wealth cal-\\nculation. In finite-horizon markets, agents are informed of the total number of rounds, and\\ntheir terminal wealth is calculated by redeeming all shares at the fundamental value of the\\nfinal round. In infinite-horizon markets, no terminal information is provided to agents, and\\nfinal wealth is determined using the last market price for share valuation. This design choice\\nenables researchers to study how time horizons influence trading strategies and price for-\\nmation, particularly how agents balance short-term trading opportunities against long-term\\nvalue considerations.\\nIn a double auction, buyers and sellers actively submit orders, with trades occurring when\\ncompatible buy and sell orders match the price. The matching engine processes these orders\\nthrough three sequential phases:\\nFirst, incoming limit orders that do not immediately cross the market are added to\\nthe order book, maintaining strict price-time priority. Second, market orders are processed', '2024). Another examines LLMs’ strategic capabilities through task-based simulations and\\ncollaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\\nWithin the computer science literature, early works apply LLMs to financial markets but\\nabstract away many fundamental stock market characteristics. Often, they employ single-\\nprice clearing mechanisms without a persistent order book, ignore partial fills and bid-ask\\nspreads, and omit dividends. Consequently, these simplified environments can primarily\\naddress exogenous macro shocks (e.g., changes in interest rates or inflation; Gao et al. 2024),\\nexogenous policy changes (Zhang et al. 2024), or rely on advanced methods such as repetitive\\nnext-token predictions to generate better answers (Koa et al. 2024). This work extends\\nthese efforts by incorporating these crucial market features, enabling the study of complex\\nendogenous events such as flash crashes, liquidity shocks, and large-trader impacts.\\nThis work also connects to emerging research on algorithmic and AI-powered trading\\nsystems. Dou, Goldstein, and Ji (2024) demonstrate how reinforcement learning-based AI\\nspeculators can autonomously learn to sustain collusive behavior without explicit coordi-\\nnation, achieving supra-competitive profits through either price-trigger strategies or self-\\nconfirming bias in learning. This finding is particularly informative for this framework as\\nit highlights potential emergent behaviors that may arise when intelligent agents interact in\\n7\\nmarkets—behaviors that could manifest differently with LLM agents due to their natural\\nlanguage reasoning capabilities. Similarly, Colliard, Foucault, and Lovo (2022) examine al-\\ngorithmic market makers using Q-learning and find they charge markups that increase when\\nadverse selection costs decrease—contrary to Nash equilibrium predictions. Their work pro-\\nvides methodological insights on how to test strategic pricing behaviors against theoretical\\nbenchmarks incorporated into this LLM-based framework.\\nFinally, this approach is informed by complexity economics, which views markets as dy-\\nnamic, non-equilibrium systems where agents adaptively learn and evolve strategies (Arthur\\n2013; Wolfram 2017). According to this view, markets exhibit emergent phenomena and\\nself-organization, especially when trading agents (human or artificial) update their behav-\\nior in response to outcomes. This paradigm is particularly relevant in an era of increasing\\nautomation and algorithmic trading (Balland et al. 2022; Ping 2019). Like adaptive agents\\nin complexity economics, these LLM traders incorporate new information and adjust their\\nstrategies, generating emergent market patterns—a key motivation behind this framework.\\nUnlike previous frameworks that abstract away crucial market features or focus on narrow\\nstrategies, this system incorporates realistic market microstructure while accommodating\\nheterogeneous agents interacting simultaneously. While earlier work demonstrates LLMs’\\npromise for macroeconomic modeling and simple trading simulations, this work introduces a\\ncomplex, open-source financial market platform that supports multiple agent architectures,\\nthorough market microstructure (limit orders, partial fills, dividends), and rigorous testing\\nprotocols—fulfilling a critical need in complexity economics research and market microstruc-\\nture analysis.\\n2 Methodology\\nThe methodology section contains three parts. The first part describes the market design,\\nthe second agents’ design, and the third the analysis module.\\n8\\n2.1 Market Design\\nOur methodological framework integrates three components that create a controlled envi-\\nronment for LLM-based trading agents. The framework implements a flexible continuous\\ndouble-auction market mechanism that couples standard market microstructure principles\\nwith market clearing and matching algorithms to accommodate asynchronous LLM decisions.', 'by detailed Trade Data, which records individual transaction details such as prices, quan-\\ntities, buyer and seller identifiers, timestamps, round information, and specific execution\\ndetails.\\nAgent Data provides insights into participant behavior by monitoring cash and share\\n25\\nFigure 5: Order Type Analysis under Systematic Variation. Displays the proportion of\\nMarket vs. Limit orders used by different agent types across varying Price/Fundamental\\nratios.\\n26\\npositions, portfolio values, wealth evolution, and agent type and strategy identifiers. Or-\\nder Data captures the complete lifecycle of trading decisions, including order specifications\\n(type, size, price), agent reasoning and justification, decision context and timing, and order\\nlifecycle events. Finally, Market State data maintains a comprehensive view of overall mar-\\nket conditions through order book snapshots, market depth information, aggregate statistics,\\nand various market microstructure metrics.\\n2.3.3 Data Validation and Storage\\nThe system implements a comprehensive set of data quality measures to ensure reliability and\\nconsistency. The validation framework performs continuous checks for data completeness,\\nverifies consistency across related data streams, enforces format and type validation, and\\nmaintains proper temporal sequencing of all recorded events. These validation mechanisms\\nwork together to maintain data integrity throughout the experimental process.\\nThe storage architecture employs multiple formats optimized for different data types and\\nuse cases. Structured CSV files store tabular data for efficient analysis, while JSON formats\\naccommodate complex nested structures that preserve the rich relationships between market\\nelements. The system maintains detailed timestamped logs for debugging purposes and\\ngenerates summary statistics to facilitate quick analysis of experimental outcomes.\\nThis comprehensive data collection architecture enables researchers to conduct detailed\\nanalysis of market dynamics, validate agent behavior patterns, ensure experiment repro-\\nducibility, and perform meaningful cross-experiment comparisons. The integrated approach\\nto data management provides the foundation for rigorous empirical investigation of market\\nbehavior and agent interactions.\\nThe framework implements specialized visualization techniques to analyze agent behavior\\nand market dynamics. Decision heatmaps plot agent actions across trading rounds, reveal-\\ning strategic patterns and consistency. Trading flow visualizations track cumulative position\\nchanges, identifying net buyers and sellers throughout market evolution. Reasoning word-\\n27\\nclouds extract key terms from agent explanations, providing insight into decision drivers\\nacross different agent types.\\nThe system also generates specialized market quality visualizations including bid-ask\\nspread evolution, price target accuracy, and agent valuation tracking. These visualizations\\nwork in concert with the numerical metrics to provide both quantitative and qualitative\\ninsights into agent behavior and market dynamics.\\n2.3.4 Validation Metrics and Performance Monitoring\\nThe framework implements a comprehensive set of performance metrics and visualization\\ntools that monitor agent behavior and market dynamics. Market evolution visualizations\\ntrack price movements relative to fundamental values, including time series of transaction\\nprices, midpoint prices, and bid-ask spreads. These visualizations enable researchers to assess\\nmarket efficiency and price discovery processes throughout the simulation.\\nAgent performance metrics include absolute position tracking (shares, cash, and total\\nwealth), wealth composition analysis, position change metrics, and return calculations. The\\nsystem computes both absolute and percentage returns on various portfolio components\\nand compares performance across agent types to identify relative advantages of different', 'value, the system:\\n1. Sets market price P = ρV where ρ is the target ratio\\n2. Generates a consistent order book structure around this price\\n3. Executes multiple decision trials with the same agent type\\n4. Records decision outcomes (buy/sell/hold), order types, quantities, and reasoning\\nThis process maps how LLM agents respond to different price environments, as illustrated\\nin Figures 2, 3, 4, and 5. The analysis reveals clear patterns in decision boundaries, with\\ndistinct transitions between buying, selling, and holding regions that vary by agent type. For\\nexample, value investors show strong buying tendencies when prices are below fundamental\\nvalue (ρ <1) and selling preferences when prices exceed fundamentals ( ρ >1). In contrast,\\nmomentum traders show less sensitivity to the fundamental ratio and more responsiveness\\nto recent price trends.\\nThe systematic variation approach also reveals patterns in order sizing and limit price\\nselection, with agents typically placing larger orders when prices deviate significantly from\\ntheir valuation models (Figure 4). This methodology provides unprecedented transparency\\ninto LLM decision processes and enables quantitative comparison of different agent types\\nand LLM architectures.\\n22\\nFigure 2: Price Analysis under Systematic Variation. Shows how agent valuation estimates\\nand price targets respond to varying Price/Fundamental ratios.\\nThe decision analysis can be customized for different experimental designs. For example,\\nresearchers can use the framework to study the impact of various market conditions on agent\\nbehavior by varying other market parameters or the effect of different agent types on market\\ndynamics by changing the agent population.\\n2.3 Data Collection and Analysis\\nEvaluating LLM trading agents requires robust methodologies for capturing, processing,\\nand analyzing their behavior in market environments. The framework implements a com-\\nprehensive analytics module that tracks all market activity, agent decisions, and performance\\nmetrics throughout experimental runs. This multi-layered approach not only records what\\nhappens in each simulation but also provides insights into why agents make specific deci-\\nsions, enabling researchers to validate agent behavior against their defined strategies and\\nassess overall market dynamics. The following sections detail the key components of this\\nanalytics infrastructure.\\n23\\nFigure 3: Trading Decision Distribution under Systematic Variation. Illustrates the proba-\\nbility of Buy, Sell, or Hold decisions across different agent types as the Price/Fundamental\\nratio changes.\\n24\\nFigure 4: Order Size Distribution under Systematic Variation. Shows the average quan-\\ntity traded (as a percentage of initial shares) for Buy and Sell orders across different\\nPrice/Fundamental ratios.\\n2.3.1 Data Collection Architecture\\nThe framework implements a comprehensive data collection system that captures multiple\\ndimensions of market behavior and agent decision-making. This structured approach ensures\\nreproducibility and enables detailed analysis of market dynamics.\\n2.3.2 Core Data Streams\\nThe system captures five primary data streams that work together to provide a complete\\npicture of market activity. Market Data forms the foundation, tracking essential metrics\\nincluding price evolution, fundamental values, trading volumes, order book depth, market\\nliquidity, best bid/ask prices, spreads, and price-fundamental ratios. This is complemented\\nby detailed Trade Data, which records individual transaction details such as prices, quan-\\ntities, buyer and seller identifiers, timestamps, round information, and specific execution\\ndetails.\\nAgent Data provides insights into participant behavior by monitoring cash and share\\n25\\nFigure 5: Order Type Analysis under Systematic Variation. Displays the proportion of\\nMarket vs. Limit orders used by different agent types across varying Price/Fundamental\\nratios.\\n26', 'The theory of intermediation developed in Chapter 14 focuses on the risk-pooling and\\nrisk-sharing products created by ﬁnancial-services institutions. Products examined\\nrange from standardized instruments such as a group of mutual funds with charac-\\nteristics described in Theorem 15.5 to custom products tailored to meet the speciﬁc\\nrequirements of each investor. Contingent-claims analysis (CCA) is the tool used\\nto derive the production technologies and costs for intermediaries to create these\\ncustom derivative securities. As discussed, such ﬁnancial products and the associ-\\nated activities of their producers are redundant in a frictionless environment with no\\ninformation-gathering or transactions costs. Thus, to provide a nontrivial role for\\nintermediaries in our equilibrium analysis here, we assume that some investors and\\nbusiness ﬁrms face transactions costs for trading and issuing securities directly in\\nthe capital markets. However, to preserve the CCA production theory for intermedi-\\naries, we follow the model in Chapter 14 and posit that ﬁnancial intermediaries, as\\nthe lowest-cost transactors, can trade continuously in the capital market at no cost.\\n2In this chapter, the returns on he growth-optimum portfolio are perfectly correlated with a combination of\\nthemtraded securities used to hedge against state-variable changes. Hence, them m+ 2spanning funds of\\nTheorem 15.5 reduce to in m+ 1funds.\\n16.2 Financial Intermediation with Dynamically-Complete Markets 417\\nIn applying this model to derive equilibrium prices and allocations, we shall further\\nassume that the ﬁnancial-services industry is competitive so that ﬁnancial-product\\nprices equal their marginal production costs.\\nIn the production theory of Chapter 14, a manufacturing technology is developed\\nto create Arrow-Debreu securities that are contingent on traded asset prices. In this\\nsection, we generalize that analysis to derive the production technology and cost\\nfor intermediaries to create a complete set of Arrow-Debreu securities with payoffs\\ncontingent on the state of the economy S(t)at each time t.\\nFrom (16.2), we can express ρijdt≡dqidqj,i,j= 1,. .. , n as functions of ρkiand\\nδij,k, i= 1,. . ., m andj=m+ 1,. .. , n . Deﬁne hjby\\nhj≡\\nfj−r−gjαj−r\\nσjj= 1,. . ., m\\nfj−r−gjm∑\\ni=1δijαi−r\\nσij=m+ 1,. .. , n(16.6)\\nLetΠ(S, t;S,τ)denote the solution to the linear partial differential equation\\n0 =1\\n2n∑\\ni=1n∑\\nj=1gigjρijSiSjΠij+n∑\\nj=1(r+hj)SjΠj+ Πt−rΠ (16.7)\\nsubject to the boundary conditions that Π(S, t;S,τ)≥0and∫∞\\n0···∫∞\\n0Π(S, t;S,τ)dS1···dSn\\nexists for all Sandt < τ < ∞;Π(S, t;S,τ) =δ(S1−S1)δ(S2−S2)···δ(Sn−Sn)\\nwhere δ(·)is the Dirac delta function and S≡[S1,. . .,Sn]is a vector of speciﬁed pos-\\nitive numbers. Subscripts on Πdenote partial derivatives with respect to S1,. .. , S n,\\nandt.{hj,gj,r,ρij}are functions of Sandt, and under mild regularity conditions on\\nthese functions, a solution to (16.7) exists and is unique.\\nConsider the continuous-trading portfolio strategy that allocates fraction\\nxj(t) =ΠjgjSj+∑n\\nk=m+1ΠkgkSkδjk\\nσjV(t)(16.8)\\nto traded asset j,j= 1,. .. , m and fraction 1−∑m\\n1xj(t)to the riskless security at\\ntimet, where V(t)denotes the current value of the portfolio. It follows from (16.3),\\n(16.6), and (16.8) that the dynamics of the portfolio value can be written as\\ndV=V\\nm∑\\nj=1xj(αj−r) +r\\ndt+m∑\\nj=1xjσjdzj\\n=\\nrV+n∑\\nj=1ΠjSj(fj−hj−r)\\ndt+m∑\\nj=1(\\nΠjgjSj+n∑\\nk=m+1ΠkgkSkδjk)\\ndzj\\n=\\nrV+n∑\\nj=1ΠjSj(fj−hj−r)\\ndt+n∑\\nj=1ΠjgjSjdqj\\n(16.9)\\nbecause, from (16.2), dqk=∑m\\n1δjkdqj,k=m+1,. . ., n , and, from (16.4), dzj=dqj,\\nj= 1,. .. , m .\\n418 A Complete-Markets General Equilibrium Theory of Finance in Continuous Time\\nΠis a solution to (16.7) and is therefore twice-continuously differentiable. Thus,\\nItˆo’s lemma can be used to describe the stochastic process for Y(t)≡Π[S(t),t;S,τ]\\nas\\ndY=\\n1\\n2n∑\\ni=1n∑\\nj=1gigjρijSiSjΠij+n∑\\nj=1ΠjfjSj+ Πt\\ndt+n∑\\nj=1ΠjgjSjdqj(16.10)\\nwhere Πand its derivatives are evaluated at S=S(t)at each time t. Because Π', 'allocations are brieﬂy addressed in Chapter 15 and analyzed more fully in Chapter 16. If a set of existing\\nsecurities and markets leads to an equilibrium that is an unconstrained Pareto optimum, then any additional\\nsecurities or markets will be redundant.\\n50The term “transactions costs” can, of course, mean more than just the bid-ask spread or commissions\\npaid for buying and selling assets. For example, if an investor literally traded his portfolio continuously, he\\nwould have no time to do anything else! Because investment management and ﬁnancial intermediation involve\\nprimarily information processing and security trading, there arc signiﬁcant economies of scale. One would thus\\nexpect substantially lower costs for the individual investor to use intermediaries instead of transacting directly\\nin the asset markets.\\n368 Financial Intermediation in the Continuous-Time Model\\nIt would seem therefore that the same dichotomy derived in the frictionless-market\\ncase applies also to our model with transactions costs. In a formal computational\\nsense it does. We can still solve for the equilibrium asset-price dynamics in the model\\nof Chapter 15 and then compute the prices of derivative securities, mutual funds, and\\ncorporate liabilities using CCA. There is one signiﬁcant difference, however: the\\nﬁrst-part calculation of equilibrium real-sector allocations is valid if and only if there\\nexists a sufﬁciently rich set of securities and intermediaries in the ﬁnancial sector to\\nmake these allocations feasible for agents who cannot trade without cost. Because\\nof this conditioning. perhaps a more appropriate term for this separation is “quasi-\\ndichotomy.”\\nWith the assumption that not all agents can trade continuously without cost, a\\nsigniﬁcant economic role is established for derivative-security markets and ﬁnancial\\nintermediaries in the model. Somewhat paradoxically, we ﬁnd that, if intermediation\\nis efﬁcient, then derivative securities and the ﬁnancial products of the intermediaries\\nwill be priced as if they are redundant.51Under these conditions, quasi-dichotomy\\nobtains, and we can derive equilibrium real-sector allocations and asset prices from\\nthe frictionless-market version of the model.\\n14.6 Afterword: Policy and Strategy in Financial Intermediation\\nIn this chapter, as throughout the book, the focus has been on theory. Allusions to\\npractice were concentrated on the micro quantitative applications of the continuous-\\ntime model to product technologies and risk management. Still, I cannot wholly\\nresist the temptation to call attention to the model’s potential for addressing broader\\nissues in the practice of intermediation. And so this afterword shall ever so brieﬂy\\ntouch upon implications of the model for intermediation policy and strategy in the\\nhope that it will lead others, better qualiﬁed, to explore this matter elsewhere.\\nDerivative securities have long been an integral part of the ﬁnancial markets,52\\nbut most would mark the creation of the Chicago Board Options Exchange in April\\n1973 as the start of the current wave of ﬁnancial innovations involving derivative\\nsecurities. The succeeding years have witnessed an unprecedented proliferation of\\norganized trading markets in both equity and ﬁxed-income derivative instruments.\\nIn turn, these markets made possible the creation of a wide range of ﬁnancial prod-\\n51Thus, our model provides a resolution to Hakansson’s (1979, p. 722) “The Catch 22 of Option Pricing.”\\nAlthough the equilibrium prices of options and other derivative securities satisfy the redundancy condition of\\nCCA, they are nevertheless needed to support the equilibrium allocations, and hence their elimination would\\nreduce social welfare.\\n52Bernstein (1992) reports that Aristotle’s anecdote about Thales in Book I of Politics is the ﬁrst recorded\\nmention of a ﬁnancial option. Schaede (1988) makes the case that the Dojima rice market in Osaka was a', 'market efficiency and price discovery processes throughout the simulation.\\nAgent performance metrics include absolute position tracking (shares, cash, and total\\nwealth), wealth composition analysis, position change metrics, and return calculations. The\\nsystem computes both absolute and percentage returns on various portfolio components\\nand compares performance across agent types to identify relative advantages of different\\nstrategies. Trading flow analysis visualizes the volume of shares moving between different\\nagent types and cumulative net trading flows, revealing which agents act as net buyers or\\nsellers in different market conditions.\\nDecision pattern analysis employs heatmaps to visualize the consistency of agent decision-\\nmaking over time, allowing researchers to identify shifts in strategic behavior. This is com-\\nplemented by decision quantities visualization that plots order sizes to highlight variations\\nin trade aggressiveness across agent types. When agent reasoning data is available, the\\nsystem generates wordclouds to extract key terms from agent explanations, providing qual-\\nitative insights into decision drivers for different agent strategies. Additional visualizations\\ntrack price target accuracy and compare agent-specific valuations to realized market prices,\\n28\\noffering insights into the forecasting abilities of different agents.\\nA key advantage of simulation-based analysis is complete observability of all market\\nprocesses and agent states. Unlike real-world markets where data availability is often limited,\\nthe framework captures every interaction, decision, and state change with perfect fidelity.\\nThis comprehensive data collection allows researchers to compute additional metrics beyond\\nstandard market measures, enabling novel analyses such as counterfactual testing (e.g., how\\nwould markets evolve with different agent compositions), causal inference of specific agent\\nbehaviors on market outcomes, and the development of custom efficiency or stability metrics\\ntailored to particular research questions. The system’s modular design facilitates rapid\\nimplementation of new metrics and visualizations as research questions evolve.\\n3 Experimental Design and Results\\nOur experimental framework implements a dividend-paying asset market with heterogeneous\\nagents. The baseline simulation runs for 15 to 20 rounds with 8 participating agents, although\\nthese parameters are fully configurable. Each agent begins with an initial endowment of\\n1,000,000 monetary units and 10,000 shares of the asset. The fundamental value of the asset\\nis set at $28.00, with a final redemption value matching this fundamental price in finite\\nhorizon scenarios. Transaction costs are set to zero to isolate the effects of agent behavior\\nand market structure.\\nThe dividend structure follows a stochastic process with a base payment of $1.40 and a\\nvariation of ±$1.00, paid with 50% probability each round. This design creates uncertainty\\nin the asset’s income stream while maintaining a known expected value. Cash holdings earn\\na risk-free interest rate of 5% per round, providing an opportunity cost for asset investment.\\nAgent composition is controlled through a flexible distribution system that allows for\\nvarious experimental configurations. In our baseline setup, we employ a mixed population\\nof value investors, momentum traders, and market makers. Each agent type implements\\n29\\ndistinct trading strategies through Large Language Model (LLM) prompts, with GPT-4o as\\nthe decision-making engine.\\nThe data collection system captures comprehensive market activity across multiple di-\\nmensions. At the market level, it tracks the evolution of prices, fundamental values, and\\nrealized dividends, providing insights into overall market dynamics. Individual agent data\\nincludes detailed wealth trajectories and portfolio compositions, enabling analysis of strategy\\neffectiveness and wealth distribution patterns. The system maintains complete transaction']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision (ragas): 31.25% pass rate\n",
      "Faithfulness (ragas): 31.25% pass rate\n",
      "Contextual Recall (ragas): 93.75% pass rate\n",
      "Answer Relevancy (ragas): 75.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">✓</span> Tests finished 🎉! Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval login'</span> to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "✨👀 Looking for a place for your LLM test data to live 🏡❤️ ? Use <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span> to get &amp; share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run <span style=\"color: #008080; text-decoration-color: #008080\">'deepeval login'</span> in the CLI. \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[38;2;5;245;141m✓\u001b[0m Tests finished 🎉! Run \u001b[1;32m'deepeval login'\u001b[0m to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "✨👀 Looking for a place for your LLM test data to live 🏡❤️ ? Use \u001b[38;2;106;0;255mConfident AI\u001b[0m to get & share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run \u001b[36m'deepeval login'\u001b[0m in the CLI. \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m results \u001b[38;5;241m=\u001b[39m evaluate_rag_system(test_cases)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (Passed: …)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'score'"
     ]
    }
   ],
   "source": [
    "results = evaluate_rag_system(test_cases)\n",
    "for metric in results:\n",
    "    print(f\"{metric.__class__.__name__}: {metric.score:.3f} (Passed: …)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
