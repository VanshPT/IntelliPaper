{"test_cases_lookup_map": {"{\"actual_output\": \"SRResNet is a deep residual network (a type of neural network where layers learn residual functions with reference to the layer inputs, instead of learning functions independent of the inputs) optimized for minimizing mean squared error (MSE - a measure of the average squared difference between the estimated values and the actual value). This means it aims to produce images that are, on average, as close as possible to the original high-resolution images at a pixel level.\\n\\nSRGAN, on the other hand, builds upon the SRResNet architecture but uses a different training approach. It incorporates a generative adversarial network (GAN - a type of machine learning framework composed of two neural networks, a generator and a discriminator, that contest with each other in a zero-sum game framework to learn a task) structure with a perceptual loss function. This loss function combines an adversarial loss (coming from the discriminator in the GAN, which learns to distinguish between real and super-resolved images) and a content loss (which focuses on perceptual similarity by comparing features from a pre-trained VGG network (a convolutional neural network used for image recognition), not just pixel-by-pixel differences). This makes SRGAN focus less on perfect pixel replication and more on producing images that are perceptually similar to the originals, resulting in more realistic textures and details.\", \"context\": [\"We employ a deep residual network (SRResNet) \\u2026 We then train SRGAN, which uses the same generator but adds a discriminator network and optimizes the adversarial loss in addition to the content loss.\"], \"expected_output\": \"Both share the same 16\\u2011block residual generator; SRResNet is trained only with a pixel/feature content loss, whereas SRGAN adds a discriminator and the adversarial term during training, yielding sharper textures.\", \"hyperparameters\": null, \"input\": \"SRGAN introduces two networks called SRResNet and SRGAN. What is the structural difference between them?\", \"retrieval_context\": [\"(21.59dB/0.6423) (23.53dB/0.7832) (21.15dB/0.6868)\\nFigure 2: From left to right: bicubic interpolation, deep residual network optimized for MSE, deep residual generative\\nadversarial network optimized for a loss more sensitive to human perception, original HR image. Corresponding PSNR and\\nSSIM are shown in brackets. [4\\u00d7upscaling]\\nperceptual difference between the super-resolved and orig-\\ninal image means that the recovered image is not photo-\\nrealistic as de\\ufb01ned by Ferwerda [16].\\nIn this work we propose a super-resolution generative\\nadversarial network (SRGAN) for which we employ a\\ndeep residual network (ResNet) with skip-connection and\\ndiverge from MSE as the sole optimization target. Different\\nfrom previous works, we de\\ufb01ne a novel perceptual loss us-\\ning high-level feature maps of the VGG network [49, 33, 5]\\ncombined with a discriminator that encourages solutions\\nperceptually hard to distinguish from the HR reference\\nimages. An example photo-realistic image that was super-\\nresolved with a 4\\u00d7upscaling factor is shown in Figure 1.\\n1.1. Related work\\n1.1.1 Image super-resolution\\nRecent overview articles on image SR include Nasrollahi\\nand Moeslund [43] or Yang et al. [61]. Here we will focus\\non single image super-resolution (SISR) and will not further\\ndiscuss approaches that recover HR images from multiple\\nimages [4, 15].\\nPrediction-based methods were among the \\ufb01rst methods\\nto tackle SISR. While these \\ufb01ltering approaches, e.g. linear,\\nbicubic or Lanczos [14] \\ufb01ltering, can be very fast, they\\noversimplify the SISR problem and usually yield solutions\\nwith overly smooth textures. Methods that put particularly\\nfocus on edge-preservation have been proposed [1, 39].\\nMore powerful approaches aim to establish a complex\\nmapping between low- and high-resolution image informa-\\ntion and usually rely on training data. Many methods that\\nare based on example-pairs rely on LR training patches for\\nwhich the corresponding HR counterparts are known. Early\\nwork was presented by Freeman et al. [18, 17]. Related ap-\\nproaches to the SR problem originate in compressed sensing\\n[62, 12, 69]. In Glasner et al. [21] the authors exploit patch\\nredundancies across scales within the image to drive the SR.\\nThis paradigm of self-similarity is also employed in Huang\\net al. [31], where self dictionaries are extended by further\\nallowing for small transformations and shape variations. Gu\\net al. [25] proposed a convolutional sparse coding approach\\nthat improves consistency by processing the whole image\\nrather than overlapping patches.\\nTo reconstruct realistic texture detail while avoiding\\nedge artifacts, Tai et al. [52] combine an edge-directed SR\\nalgorithm based on a gradient pro\\ufb01le prior [50] with the\\nbene\\ufb01ts of learning-based detail synthesis. Zhang et al. [70]\\npropose a multi-scale dictionary to capture redundancies of\\nsimilar image patches at different scales. To super-resolve\\nlandmark images, Yue et al. [67] retrieve correlating HR\\nimages with similar content from the web and propose a\\nstructure-aware matching criterion for alignment.\\nNeighborhood embedding approaches upsample a LR\\nimage patch by \\ufb01nding similar LR training patches in a low\\ndimensional manifold and combining their corresponding\\nHR patches for reconstruction [54, 55]. In Kim and Kwon\\n[35] the authors emphasize the tendency of neighborhood\\napproaches to over\\ufb01t and formulate a more general map of\\nexample pairs using kernel ridge regression. The regression\\nproblem can also be solved with Gaussian process regres-\\nsion [27], trees [46] or Random Forests [47]. In Dai et al.\\n[6] a multitude of patch-speci\\ufb01c regressors is learned and\\nthe most appropriate regressors selected during testing.\\nRecently convolutional neural network (CNN) based SR\\nalgorithms have shown excellent performance. In Wang\\net al. [59] the authors encode a sparse representation\\nprior into their feed-forward network architecture based on\\nthe learned iterative shrinkage and thresholding algorithm\", \"3.4. Investigation of content loss\\nWe investigated the effect of different content loss\\nchoices in the perceptual loss for the GAN-based networks.\\nSpeci\\ufb01cally we investigate lSR = lSR\\nX + 10\\u22123lSR\\nGen for the\\nfollowing content losses lSR\\nX :\\nTable 1: Performance of different loss functions for SR-\\nResNet and the adversarial networks on Set5 and Set14\\nbenchmark data. MOS score signi\\ufb01cantly higher (p< 0.05)\\nthan with other losses in that category\\u2217. [4\\u00d7upscaling]\\nSRResNet- SRGAN-\\nSet5 MSE VGG22 MSE VGG22 VGG54\\nPSNR 32.05 30.51 30.64 29.84 29.40\\nSSIM 0.9019 0.8803 0.8701 0.8468 0.8472\\nMOS 3.37 3.46 3.77 3.78 3.58\\nSet14\\nPSNR 28.49 27.19 26.92 26.44 26.02\\nSSIM 0.8184 0.7807 0.7611 0.7518 0.7397\\nMOS 2.98 3.15 \\u2217 3.43 3.57 3.72 \\u2217\\n\\u2022SRGAN-MSE: lSR\\nMSE, to investigate the adversarial\\nnetwork with the standard MSE as content loss.\\n\\u2022SRGAN-VGG22: lSR\\nVGG/2.2 with \\u03c62,2, a loss de\\ufb01ned\\non feature maps representing lower-level features [68].\\n\\u2022SRGAN-VGG54: lSR\\nVGG/5.4 with \\u03c65,4, a loss de\\ufb01ned\\non feature maps of higher level features from deeper\\nnetwork layers with more potential to focus on the\\ncontent of the images [68, 65, 40]. We refer to this\\nnetwork as SRGAN in the following.\\nWe also evaluate the performance of the generator network\\nwithout adversarial component for the two losses lSR\\nMSE\\n(SRResNet-MSE) and lSR\\nVGG/2.2 (SRResNet-VGG22). We\\nrefer to SRResNet-MSE asSRResNet. Note, when training\\nSRResNet-VGG22 we added an additional total variation\\nloss with weight 2 \\u00d710\\u22128 to lSR\\nVGG/2.2 [2, 33]. Quantitative\\nresults are summarized in Table 1 and visual examples\\nprovided in Figure 6. Even combined with the adversarial\\nloss, MSE provides solutions with the highest PSNR values\\nthat are, however, perceptually rather smooth and less\\nconvincing than results achieved with a loss component\\nmore sensitive to visual perception. This is caused by\\ncompetition between the MSE-based content loss and the\\nadversarial loss. We further attribute minor reconstruction\\nartifacts, which we observed in a minority of SRGAN-\\nMSE-based reconstructions, to those competing objectives.\\nWe could not determine a signi\\ufb01cantly best loss function\\nfor SRResNet or SRGAN with respect to MOS score\\non Set5. However, SRGAN-VGG54 signi\\ufb01cantly outper-\\nformed other SRGAN and SRResNet variants on Set14 in\\nterms of MOS. We observed a trend that using the higher\\nlevel VGG feature maps \\u03c65,4 yields better texture detail\\nwhen compared to \\u03c62,2 (c.f . Figure 6). Further examples of\\nperceptual improvements through SRGAN over SRResNet\\nare provided in the supplementary material.\\nFigure 5: Color-coded distribution of MOS scores on\\nBSD100. For each method 2600 samples (100 images \\u00d7\\n26 raters) were assessed. Mean shown as red marker, where\\nthe bins are centered around value i. [4\\u00d7upscaling]\\n3.5. Performance of the \\ufb01nal networks\\nWe compare the performance of SRResNet and SR-\\nGAN to NN, bicubic interpolation, and four state-of-the-\\nart methods. Quantitative results are summarized in Table\\n2 and con\\ufb01rm that SRResNet (in terms of PSNR/SSIM)\\nsets a new state of the art on three benchmark datasets.\\nPlease note that we used a publicly available framework\\nfor evaluation (c.f . Section 3.1), reported values might thus\\nslightly deviate from those reported in the original papers.\\nWe further obtained MOS ratings for SRGAN and all\\nreference methods on BSD100. Examples of images super-\\nresolved with SRResNet and SRGAN are depicted in the\\nsupplementary material. The results shown in Table 2\\ncon\\ufb01rm that SRGAN outperforms all reference methods by\\na large margin and sets a new state of the art for photo-\\nrealistic image SR. All differences in MOS ( c.f . Table\\n2) are highly signi\\ufb01cant on BSD100, except SRCNN vs.\\nSelfExSR. The distribution of all collected MOS ratings is\\nsummarized in Figure 5.\\n4. Discussion and future work\\nWe con\\ufb01rmed the superior perceptual performance of\\nSRGAN using MOS testing. We have further shown that\\nstandard quantitative measures such as PSNR and SSIM\", \"Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial\\nNetwork\\nChristian Ledig, Lucas Theis, Ferenc Husz\\u00b4ar, Jose Caballero, Andrew Cunningham,\\nAlejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, Wenzhe Shi\\nTwitter\\n{cledig,ltheis,fhuszar,jcaballero,aacostadiaz,aaitken,atejani,jtotz,zehanw,wshi}@twitter.com\\nAbstract\\nDespite the breakthroughs in accuracy and speed of\\nsingle image super-resolution using faster and deeper con-\\nvolutional neural networks, one central problem remains\\nlargely unsolved: how do we recover the \\ufb01ner texture details\\nwhen we super-resolve at large upscaling factors? The\\nbehavior of optimization-based super-resolution methods is\\nprincipally driven by the choice of the objective function.\\nRecent work has largely focused on minimizing the mean\\nsquared reconstruction error. The resulting estimates have\\nhigh peak signal-to-noise ratios, but they are often lacking\\nhigh-frequency details and are perceptually unsatisfying in\\nthe sense that they fail to match the \\ufb01delity expected at\\nthe higher resolution. In this paper, we present SRGAN,\\na generative adversarial network (GAN) for image super-\\nresolution (SR). To our knowledge, it is the \\ufb01rst framework\\ncapable of inferring photo-realistic natural images for 4\\u00d7\\nupscaling factors. To achieve this, we propose a perceptual\\nloss function which consists of an adversarial loss and a\\ncontent loss. The adversarial loss pushes our solution to\\nthe natural image manifold using a discriminator network\\nthat is trained to differentiate between the super-resolved\\nimages and original photo-realistic images. In addition, we\\nuse a content loss motivated by perceptual similarity instead\\nof similarity in pixel space. Our deep residual network\\nis able to recover photo-realistic textures from heavily\\ndownsampled images on public benchmarks. An extensive\\nmean-opinion-score (MOS) test shows hugely signi\\ufb01cant\\ngains in perceptual quality using SRGAN. The MOS scores\\nobtained with SRGAN are closer to those of the original\\nhigh-resolution images than to those obtained with any\\nstate-of-the-art method.\\n1. Introduction\\nThe highly challenging task of estimating a high-\\nresolution (HR) image from its low-resolution (LR)\\ncounterpart is referred to as super-resolution (SR). SR\\nreceived substantial attention from within the computer\\nvision research community and has a wide range of\\napplications [63, 71, 43].\\n4\\u00d7SRGAN (proposed) original\\nFigure 1: Super-resolved image (left) is almost indistin-\\nguishable from original (right). [4\\u00d7upscaling]\\nThe ill-posed nature of the underdetermined SR problem\\nis particularly pronounced for high upscaling factors, for\\nwhich texture detail in the reconstructed SR images is\\ntypically absent. The optimization target of supervised\\nSR algorithms is commonly the minimization of the mean\\nsquared error (MSE) between the recovered HR image\\nand the ground truth. This is convenient as minimizing\\nMSE also maximizes the peak signal-to-noise ratio (PSNR),\\nwhich is a common measure used to evaluate and compare\\nSR algorithms [61]. However, the ability of MSE (and\\nPSNR) to capture perceptually relevant differences, such\\nas high texture detail, is very limited as they are de\\ufb01ned\\nbased on pixel-wise image differences [60, 58, 26]. This\\nis illustrated in Figure 2, where highest PSNR does not\\nnecessarily re\\ufb02ect the perceptually better SR result. The\\n1\\narXiv:1609.04802v5  [cs.CV]  25 May 2017\\nbicubic SRResNet SRGAN original\\n(21.59dB/0.6423) (23.53dB/0.7832) (21.15dB/0.6868)\\nFigure 2: From left to right: bicubic interpolation, deep residual network optimized for MSE, deep residual generative\\nadversarial network optimized for a loss more sensitive to human perception, original HR image. Corresponding PSNR and\\nSSIM are shown in brackets. [4\\u00d7upscaling]\\nperceptual difference between the super-resolved and orig-\\ninal image means that the recovered image is not photo-\\nrealistic as de\\ufb01ned by Ferwerda [16].\", \"[70] K. Zhang, X. Gao, D. Tao, and X. Li. Multi-scale dictionary for\\nsingle image super-resolution. In IEEE Conference on Computer\\nVision and Pattern Recognition (CVPR), pages 1114\\u20131121, 2012. 2\\n[71] W. Zou and P. C. Yuen. Very Low Resolution Face Recognition\\nin Parallel Environment . IEEE Transactions on Image Processing,\\n21:327\\u2013340, 2012. 1\\nA. Supplementary Material\\nIn this supplementary material we \\ufb01rst brie\\ufb02y investigate the in\\ufb02uence of network depth (number of residual blocks)\\non the performance (PSNR, time) of SRResNet in Section A.1. We then visualize on an example image how the SRGAN\\nnetwork performance evolves with increasing number of training iterations in Section A.2. Results of the MOS tests\\nconducted on Set5, Set14, BSD100 are summarized in Section A.3. Finally we provide a visualization of all image\\nreconstruction obtained with SRResNet and SRGAN with a 4\\u00d7upscaling factor for Set5 (Section A.4), Set14 (Section A.5)\\nand \\ufb01ve randomly selected images from BSD100 (Section A.6).\\nImages are best viewed and compared zoomed in. All original low-/high-resolution images and reconstructions\\n(4\\u00d7upscaling) obtained with different methods (bicubic, SRResNet-MSE, SRResNet-VGG22, SRGAN-MSE, SRGAN-\\nVGG22, SRGAN-VGG54) described in the paper are available for download at https://twitter.box.com/s/\\nlcue6vlrd01ljkdtdkhmfvk7vtjhetog.\\nA.1. Performance (PSNR/time) vs. network depth\\nWe investigated the in\\ufb02uence of network depth, speci\\ufb01cally the number of residual blocks, on performance (PSNR [dB]\\non BSD100 for 4\\u00d7SR) and inference time [s] of the network architecture described in Figure 4 of the main paper. Time was\\nassessed on a NVIDIA M40 GPU and averaged over 100 reconstructions of a random low-resolution image with resolution\\n64\\u00d764 with upscaling factor 4\\u00d7. The measurements are plotted in Figure 7 for a network with (blue) and without (red)\\nskip-connection. As expected the time of a single forward pass through the network depends approximately linearly on the\\nnumber of residual blocks. Whether a skip-connection is used or not has no substantial impact on inference time. However,\\nwe observed substantial gains in performance with the additional skip-connection. We chose a network architecture of\\n16 residual blocks with skip-connection for the evaluation presented in the main paper as we consider this as good trade-\\noff between accuracy and speed including training time. While accuracy gains slowly saturate beyond 16 blocks there is,\\nnevertheless, a clear bene\\ufb01t of using even deeper networks.\\nFigure 7: Dependence of network performance (PSNR, time) on network depth. PSNR (left) calculated on BSD100. Time\\n(right) averaged over 100 reconstructions of a random LR image with resolution 64\\u00d764.\\nA.2. Evolution of Generator during SRGAN training\\nWe further investigated how reconstructions of the SRGAN generator network evolve (visually) with increasing number\\nof training iterations. Visual results obtained after different number of training iterations are illustrated in Figure 8. It is\\ninteresting that after only 20 thousand training iterations the generator substantially diverged from the SRResNet initialization\\nand produces reconstruction with a lot of high frequency content, including noise. With increasing number of training\\niterations reconstructions of the baboon from Set14 appear closer to the reference image. However, there is visually little\\nchange during the last 50-100 thousand update iterations.\\nSRResNet 20k 40k 60k 80k\\n100k 140k 180k SRGAN original HR image\\nFigure 8: Evolution of SRGAN generator network during training progress. Note: Generator initialized with SRResNet\\nweights; learning rate set to 10\\u22124 for \\ufb01rst 100k iterations, then reduced to 10\\u22125 for another 100k iterations. [4\\u00d7upscaling]\\nA.3. Mean opinion score (MOS) testing\\nIn all conducted MOS tests we have asked 26 human raters to assign a score from 1 (Bad) to 5 (Excellent) to reconstructions\", \"and signi\\ufb01cance determined at p< 0.05.\\nThe reader may also be interested in an independently\\ndeveloped GAN-based solution on GitHub 5. However it\\nonly provides experimental results on a limited set of faces,\\nwhich is a more constrained and easier task.\\n3.2. Training details and parameters\\nWe trained all networks on a NVIDIA Tesla M40 GPU\\nusing a random sample of 350 thousand images from\\nthe ImageNet database [45]. These images are distinct\\nfrom the testing images. We obtained the LR images\\nby downsampling the HR images (BGR, C = 3) using\\nbicubic kernel with downsampling factor r = 4. For each\\nmini-batch we crop 16 random 96 \\u00d796 HR sub images\\nof distinct training images. Note that we can apply the\\ngenerator model to images of arbitrary size as it is fully\\n1https://github.com/xiph/daala (commit: 8d03668)\\n2https://github.com/jbhuang0604/SelfExSR\\n3http://cv.snu.ac.kr/research/DRCN/\\n4https://twitter.box.com/s/\\nlcue6vlrd01ljkdtdkhmfvk7vtjhetog\\n5https://github.com/david-gpu/srez\\nconvolutional. We scaled the range of the LR input images\\nto [0,1] and for the HR images to [\\u22121,1]. The MSE loss\\nwas thus calculated on images of intensity range [\\u22121,1].\\nVGG feature maps were also rescaled by a factor of 1\\n12.75\\nto obtain VGG losses of a scale that is comparable to the\\nMSE loss. This is equivalent to multiplying Equation 5\\nwith a rescaling factor of \\u2248 0.006. For optimization we\\nuse Adam [36] with \\u03b21 = 0.9. The SRResNet networks\\nwere trained with a learning rate of 10\\u22124 and 106 update\\niterations. We employed the trained MSE-based SRResNet\\nnetwork as initialization for the generator when training\\nthe actual GAN to avoid undesired local optima. All\\nSRGAN variants were trained with 105 update iterations\\nat a learning rate of 10\\u22124 and another 105 iterations at a\\nlower rate of 10\\u22125. We alternate updates to the generator\\nand discriminator network, which is equivalent to k = 1\\nas used in Goodfellow et al. [22]. Our generator network\\nhas 16 identical (B = 16) residual blocks. During test time\\nwe turn batch-normalization update off to obtain an output\\nthat deterministically depends only on the input [32]. Our\\nimplementation is based on Theano [53] and Lasagne [8].\\n3.3. Mean opinion score (MOS) testing\\nWe have performed a MOS test to quantify the ability of\\ndifferent approaches to reconstruct perceptually convincing\\nimages. Speci\\ufb01cally, we asked 26 raters to assign an inte-\\ngral score from 1 (bad quality) to 5 (excellent quality) to the\\nsuper-resolved images. The raters rated 12 versions of each\\nimage on Set5, Set14 and BSD100: nearest neighbor (NN),\\nbicubic, SRCNN [9], SelfExSR [31], DRCN [34], ESPCN\\n[48], SRResNet-MSE, SRResNet-VGG22\\u2217 (\\u2217not rated on\\nBSD100), SRGAN-MSE \\u2217, SRGAN-VGG22 \\u2217, SRGAN-\\nVGG54 and the original HR image. Each rater thus rated\\n1128 instances (12 versions of 19 images plus 9 versions of\\n100 images) that were presented in a randomized fashion.\\nThe raters were calibrated on the NN (score 1) and HR (5)\\nversions of 20 images from the BSD300 training set. In a\\npilot study we assessed the calibration procedure and the\\ntest-retest reliability of 26 raters on a subset of 10 images\\nfrom BSD100 by adding a method\\u2019s images twice to a\\nlarger test set. We found good reliability and no signi\\ufb01cant\\ndifferences between the ratings of the identical images.\\nRaters very consistently rated NN interpolated test images\\nas 1 and the original HR images as 5 (c.f . Figure 5).\\nThe experimental results of the conducted MOS tests are\\nsummarized in Table 1, Table 2 and Figure 5.\\n3.4. Investigation of content loss\\nWe investigated the effect of different content loss\\nchoices in the perceptual loss for the GAN-based networks.\\nSpeci\\ufb01cally we investigate lSR = lSR\\nX + 10\\u22123lSR\\nGen for the\\nfollowing content losses lSR\\nX :\\nTable 1: Performance of different loss functions for SR-\\nResNet and the adversarial networks on Set5 and Set14\\nbenchmark data. MOS score signi\\ufb01cantly higher (p< 0.05)\\nthan with other losses in that category\\u2217. [4\\u00d7upscaling]\\nSRResNet- SRGAN-\", \"con\\ufb01rm that SRGAN outperforms all reference methods by\\na large margin and sets a new state of the art for photo-\\nrealistic image SR. All differences in MOS ( c.f . Table\\n2) are highly signi\\ufb01cant on BSD100, except SRCNN vs.\\nSelfExSR. The distribution of all collected MOS ratings is\\nsummarized in Figure 5.\\n4. Discussion and future work\\nWe con\\ufb01rmed the superior perceptual performance of\\nSRGAN using MOS testing. We have further shown that\\nstandard quantitative measures such as PSNR and SSIM\\nfail to capture and accurately assess image quality with\\nrespect to the human visual system [56]. The focus of this\\nwork was the perceptual quality of super-resolved images\\nrather than computational ef\\ufb01ciency. The presented model\\nis, in contrast to Shi et al. [48], not optimized for video\\nSR in real-time. However, preliminary experiments on\\nthe network architecture suggest that shallower networks\\nhave the potential to provide very ef\\ufb01cient alternatives at\\na small reduction of qualitative performance. In contrast to\\nDong et al. [10], we found deeper network architectures to\\nbe bene\\ufb01cial. We speculate that the ResNet design has a\\nsubstantial impact on the performance of deeper networks.\\nWe found that even deeper networks (B >16) can further\\nSRResNet SRGAN-MSE SRGAN-VGG22 SRGAN-VGG54 original HR image\\nFigure 6: SRResNet (left: a,b), SRGAN-MSE (middle left: c,d), SRGAN-VGG2.2 (middle: e,f) and SRGAN-VGG54\\n(middle right: g,h) reconstruction results and corresponding reference HR image (right: i,j). [ 4\\u00d7upscaling]\\nTable 2: Comparison of NN, bicubic, SRCNN [9], SelfExSR [31], DRCN [34], ESPCN [48], SRResNet, SRGAN-VGG54\\nand the original HR on benchmark data. Highest measures (PSNR [dB], SSIM, MOS) in bold. [4\\u00d7upscaling]\\nSet5 nearest bicubic SRCNN SelfExSR DRCN ESPCN SRResNet SRGAN HR\\nPSNR 26.26 28.43 30.07 30.33 31.52 30.76 32.05 29.40 \\u221e\\nSSIM 0.7552 0.8211 0.8627 0.872 0.8938 0.8784 0.9019 0.8472 1\\nMOS 1.28 1.97 2.57 2.65 3.26 2.89 3.37 3.58 4.32\\nSet14\\nPSNR 24.64 25.99 27.18 27.45 28.02 27.66 28.49 26.02 \\u221e\\nSSIM 0.7100 0.7486 0.7861 0.7972 0.8074 0.8004 0.8184 0.7397 1\\nMOS 1.20 1.80 2.26 2.34 2.84 2.52 2.98 3.72 4.32\\nBSD100\\nPSNR 25.02 25.94 26.68 26.83 27.21 27.02 27.58 25.16 \\u221e\\nSSIM 0.6606 0.6935 0.7291 0.7387 0.7493 0.7442 0.7620 0.6688 1\\nMOS 1.11 1.47 1.87 1.89 2.12 2.01 2.29 3.56 4.46\\nincrease the performance of SRResNet, however, come at\\nthe cost of longer training and testing times ( c.f . supple-\\nmentary material). We further found SRGAN variants of\\ndeeper networks are increasingly dif\\ufb01cult to train due to the\\nappearance of high-frequency artifacts.\\nOf particular importance when aiming for photo-realistic\\nsolutions to the SR problem is the choice of the content loss\\nas illustrated in Figure 6. In this work, we found lSR\\nVGG/5.4\\nto yield the perceptually most convincing results, which\\nwe attribute to the potential of deeper network layers to\\nrepresent features of higher abstraction [68, 65, 40] away\\nfrom pixel space. We speculate that feature maps of these\\ndeeper layers focus purely on the content while leaving the\\nadversarial loss focusing on texture details which are the\\nmain difference between the super-resolved images without\\nthe adversarial loss and photo-realistic images. We also\\nnote that the ideal loss function depends on the application.\\nFor example, approaches that hallucinate \\ufb01ner detail might\\nbe less suited for medical applications or surveillance. The\\nperceptually convincing reconstruction of text or structured\\nscenes [31] is challenging and part of future work. The\\ndevelopment of content loss functions that describe image\\nspatial content, but more invariant to changes in pixel space\\nwill further improve photo-realistic image SR results.\\n5. Conclusion\\nWe have described a deep residual network SRRes-\\nNet that sets a new state of the art on public benchmark\\ndatasets when evaluated with the widely used PSNR mea-\\nsure. We have highlighted some limitations of this PSNR-\\nfocused image super-resolution and introduced SRGAN,\", \"development of content loss functions that describe image\\nspatial content, but more invariant to changes in pixel space\\nwill further improve photo-realistic image SR results.\\n5. Conclusion\\nWe have described a deep residual network SRRes-\\nNet that sets a new state of the art on public benchmark\\ndatasets when evaluated with the widely used PSNR mea-\\nsure. We have highlighted some limitations of this PSNR-\\nfocused image super-resolution and introduced SRGAN,\\nwhich augments the content loss function with an adversar-\\nial loss by training a GAN. Using extensive MOS testing,\\nwe have con\\ufb01rmed that SRGAN reconstructions for large\\nupscaling factors (4\\u00d7) are, by a considerable margin, more\\nphoto-realistic than reconstructions obtained with state-of-\\nthe-art reference methods.\\nReferences\\n[1] J. Allebach and P. W. Wong. Edge-directed interpolation. InProceed-\\nings of International Conference on Image Processing , volume 3,\\npages 707\\u2013710, 1996. 2\\n[2] H. A. Aly and E. Dubois. Image up-sampling using total-variation\\nregularization with a new observation model. IEEE Transactions on\\nImage Processing, 14(10):1647\\u20131659, 2005. 7\\n[3] M. Bevilacqua, A. Roumy, C. Guillemot, and M. L. Alberi-Morel.\\nLow-complexity single-image super-resolution based on nonnegative\\nneighbor embedding. BMVC, 2012. 6\\n[4] S. Borman and R. L. Stevenson. Super-Resolution from Image\\nSequences - A Review.Midwest Symposium on Circuits and Systems,\\npages 374\\u2013378, 1998. 2\\n[5] J. Bruna, P. Sprechmann, and Y . LeCun. Super-resolution with deep\\nconvolutional suf\\ufb01cient statistics. In International Conference on\\nLearning Representations (ICLR), 2016. 2, 3, 5\\n[6] D. Dai, R. Timofte, and L. Van Gool. Jointly optimized regressors for\\nimage super-resolution. In Computer Graphics Forum, volume 34,\\npages 95\\u2013104, 2015. 2\\n[7] E. Denton, S. Chintala, A. Szlam, and R. Fergus. Deep generative\\nimage models using a laplacian pyramid of adversarial networks. In\\nAdvances in Neural Information Processing Systems (NIPS) , pages\\n1486\\u20131494, 2015. 3\\n[8] S. Dieleman, J. Schl \\u00a8uter, C. Raffel, E. Olson, S. K. Snderby,\\nD. Nouri, D. Maturana, M. Thoma, E. Battenberg, J. Kelly, J. D.\\nFauw, M. Heilman, diogo149, B. McFee, H. Weideman, takacsg84,\\npeterderivaz, Jon, instagibbs, D. K. Rasul, CongLiu, Britefury, and\\nJ. Degrave. Lasagne: First release., 2015. 6\\n[9] C. Dong, C. C. Loy, K. He, and X. Tang. Learning a deep\\nconvolutional network for image super-resolution. In European\\nConference on Computer Vision (ECCV), pages 184\\u2013199. Springer,\\n2014. 3, 6, 8\\n[10] C. Dong, C. C. Loy, K. He, and X. Tang. Image super-resolution\\nusing deep convolutional networks. IEEE Transactions on Pattern\\nAnalysis and Machine Intelligence, 38(2):295\\u2013307, 2016. 3, 5, 7\\n[11] C. Dong, C. C. Loy, and X. Tang. Accelerating the super-resolution\\nconvolutional neural network. InEuropean Conference on Computer\\nVision (ECCV), pages 391\\u2013407. Springer, 2016. 3\\n[12] W. Dong, L. Zhang, G. Shi, and X. Wu. Image deblurring and super-\\nresolution by adaptive sparse domain selection and adaptive regular-\\nization. IEEE Transactions on Image Processing, 20(7):1838\\u20131857,\\n2011. 2\\n[13] A. Dosovitskiy and T. Brox. Generating images with perceptual\\nsimilarity metrics based on deep networks. In Advances in Neural\\nInformation Processing Systems (NIPS), pages 658\\u2013666, 2016. 3\\n[14] C. E. Duchon. Lanczos Filtering in One and Two Dimensions. In\\nJournal of Applied Meteorology, volume 18, pages 1016\\u20131022. 1979.\\n2\\n[15] S. Farsiu, M. D. Robinson, M. Elad, and P. Milanfar. Fast and\\nrobust multiframe super resolution. IEEE Transactions on Image\\nProcessing, 13(10):1327\\u20131344, 2004. 2\\n[16] J. A. Ferwerda. Three varieties of realism in computer graphics. In\\nElectronic Imaging, pages 290\\u2013297. International Society for Optics\\nand Photonics, 2003. 2\\n[17] W. T. Freeman, T. R. Jones, and E. C. Pasztor. Example-based super-\\nresolution. IEEE Computer Graphics and Applications, 22(2):56\\u201365,\\n2002. 2\\n[18] W. T. Freeman, E. C. Pasztor, and O. T. Carmichael. Learning low-\", \"ure 3 where multiple potential solutions with high texture\\ndetails are averaged to create a smooth reconstruction.\\nIn Mathieu et al. [42] and Denton et al. [7] the authors\\ntackled this problem by employing generative adversarial\\nnetworks (GANs) [22] for the application of image genera-\\ntion. Yu and Porikli [66] augment pixel-wise MSE loss with\\na discriminator loss to train a network that super-resolves\\nface images with large upscaling factors ( 8\\u00d7). GANs\\nwere also used for unsupervised representation learning in\\nRadford et al. [44]. The idea of using GANs to learn a\\nmapping from one manifold to another is described by Li\\nand Wand [38] for style transfer and Yeh et al. [64] for\\ninpainting. Bruna et al. [5] minimize the squared error in\\nthe feature spaces of VGG19 [49] and scattering networks.\\nDosovitskiy and Brox [13] use loss functions based\\non Euclidean distances computed in the feature space of\\nneural networks in combination with adversarial training.\\nIt is shown that the proposed loss allows visually superior\\nimage generation and can be used to solve the ill-posed\\ninverse problem of decoding nonlinear feature representa-\\ntions. Similar to this work, Johnson et al. [33] and Bruna\\net al. [5] propose the use of features extracted from a pre-\\ntrained VGG network instead of low-level pixel-wise error\\nmeasures. Speci\\ufb01cally the authors formulate a loss function\\nbased on the euclidean distance between feature maps\\nextracted from the VGG19 [49] network. Perceptually more\\nconvincing results were obtained for both super-resolution\\nand artistic style-transfer [19, 20]. Recently, Li and Wand\\n[38] also investigated the effect of comparing and blending\\npatches in pixel or VGG feature space.\\n1.2. Contribution\\nGANs provide a powerful framework for generating\\nplausible-looking natural images with high perceptual qual-\\nity. The GAN procedure encourages the reconstructions\\nto move towards regions of the search space with high\\nprobability of containing photo-realistic images and thus\\ncloser to the natural image manifold as shown in Figure 3.\\nIn this paper we describe the \\ufb01rst very deep ResNet\\n[29, 30] architecture using the concept of GANs to form a\\nperceptual loss function for photo-realistic SISR. Our main\\ncontributions are:\\n\\u2022We set a new state of the art for image SR with\\nhigh upscaling factors (4\\u00d7) as measured by PSNR and\\nstructural similarity (SSIM) with our 16 blocks deep\\nResNet (SRResNet) optimized for MSE.\\n\\u2022We propose SRGAN which is a GAN-based network\\noptimized for a new perceptual loss. Here we replace\\nthe MSE-based content loss with a loss calculated on\\nfeature maps of the VGG network [49], which are\\nmore invariant to changes in pixel space [38].\\n\\u2022We con\\ufb01rm with an extensive mean opinion score\\n(MOS) test on images from three public benchmark\\ndatasets that SRGAN is the new state of the art, by a\\nlarge margin, for the estimation of photo-realistic SR\\nimages with high upscaling factors (4\\u00d7).\\nWe describe the network architecture and the perceptual\\nloss in Section 2. A quantitative evaluation on public bench-\\nmark datasets as well as visual illustrations are provided in\\nSection 3. The paper concludes with a discussion in Section\\n4 and concluding remarks in Section 5.\\n2. Method\\nIn SISR the aim is to estimate a high-resolution, super-\\nresolved image ISR from a low-resolution input image\\nILR. Here ILR is the low-resolution version of its high-\\nresolution counterpart IHR. The high-resolution images\\nare only available during training. In training, ILR is\\nobtained by applying a Gaussian \\ufb01lter toIHR followed by a\\ndownsampling operation with downsampling factor r. For\\nan image with C color channels, we describe ILR by a\\nreal-valued tensor of size W \\u00d7H \\u00d7C and IHR, ISR by\\nrW \\u00d7rH \\u00d7Crespectively.\\nOur ultimate goal is to train a generating function Gthat\\nestimates for a given LR input image its corresponding HR\\ncounterpart. To achieve this, we train a generator network as\\na feed-forward CNN G\\u03b8G parametrized by \\u03b8G. Here \\u03b8G =\"]}": {"cached_metrics_data": [{"metric_data": {"name": "Contextual Precision (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Faithfulness (ragas)", "threshold": 0.8, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.8, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Contextual Recall (ragas)", "threshold": 0.6, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.6, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Answer Relevancy (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}]}, "{\"actual_output\": \"SRCNN's relatively low parameter count of 8,032 is a result of its simple three-layer architecture and relatively small filter sizes. Let's break down how the parameter count is calculated:\\n\\nLayer 1 (Patch extraction and representation): This layer uses 64 filters (kernels) with a size of 9x9x1. Since the input is assumed to be a single-channel image (grayscale), each filter has 9*9 = 81 weights, plus one bias term per filter. This results in 64 * (81 + 1) = 5,184 parameters for the first layer.\\n\\nLayer 2 (Non-linear mapping): This layer employs 32 filters with a size of 1x1x64. The input to this layer is the output from the first layer, which has 64 channels. So each filter has 1164 = 64 weights, plus one bias term. This leads to 32 * (64 + 1) = 2,080 parameters in the second layer.\\n\\nLayer 3 (Reconstruction): The final layer has a single filter with a size of 5x5x32. It takes the 32-channel output of the second layer as input. The filter has 5532 = 800 weights, plus a single bias term. This totals 800 + 1 = 801 parameters for the third layer.\\n\\nAdding the parameters from all three layers: 5,184 + 2,080 + 801 = 8,065. The original paper mentions 8,032, suggesting a slight variation in the calculation. While the exact reason for this minor difference is unclear within the provided text, the primary reason for the low number of parameters is the smaller filter sizes compared to many deeper convolutional neural networks (CNNs), which might have hundreds or thousands of filters and larger filter dimensions, leading to millions or even billions of parameters.\", \"context\": [\"A typical and basic setting is f\\u2081 = 9, f\\u2082 = 1, f\\u2083 = 5, n\\u2081 = 64, n\\u2082 = 32 \\u2026 the number of parameters of 9\\u20111\\u20115 \\u2026 is 8 032.\"], \"expected_output\": \"Because it uses just three convolutional layers with relatively few filters (64, 32, c) and small kernels (9\\u00d79, 1\\u00d71, 5\\u00d75). Param count = (c\\u00b79\\u00b2\\u00b764)+(64\\u00b71\\u00b2\\u00b732)+(32\\u00b75\\u00b2\\u00b7c)+biases \\u2248 8 k\", \"hyperparameters\": null, \"input\": \"SRCNN reports 8 032 trainable parameters; can you explain how this relatively small count is achieved?\", \"retrieval_context\": [\"1 2 3 4 5 6 7 8\\nxR10\\n8\\n31.5\\n32\\n32.5\\nNumberRofRbackprops\\nAverageRtestRPSNRR(dB)\\nSRCNNR(9\\u22125\\u22125)\\nSRCNNR(9\\u22125\\u22121\\u22125)\\nSCR(31.42RdB)\\n(c) 9-5-5 vs. 9-5-1-5\\nFig. 8. Comparisons between three-layer and four-layer\\nnetworks.\\nmapping layers with n22 = 32 and n23 = 16 \\ufb01lters on\\n9-1-5, then we have to set a smaller learning rate to\\nensure convergence, but we still do not observe superior\\nperformance after a week of training (see Figure 9(a)).\\nWe also tried to enlarge the \\ufb01lter size of the additional\\nlayer to f22 = 3, and explore two deep structures \\u2013 9-3-\\n3-5 and 9-3-3-3. However, from the convergence curves\\nshown in Figure 9(b), these two networks do not show\\nbetter results than the 9-3-1-5 network.\\nAll these experiments indicate that it is not \\u201cthe deeper\\nthe better\\u201d in this deep model for super-resolution. It\\nmay be caused by the dif\\ufb01culty of training. Our CNN\\nnetwork contains no pooling layer or full-connected\\nlayer, thus it is sensitive to the initialization parameters\\nand learning rate. When we go deeper (e.g., 4 or 5 layers),\\nwe \\ufb01nd it hard to set appropriate learning rates that\\nguarantee convergence. Even it converges, the network\\nmay fall into a bad local minimum, and the learned\\n\\ufb01lters are of less diversity even given enough training\\ntime. This phenomenon is also observed in [16], where\\nimproper increase of depth leads to accuracy saturation\\nor degradation for image classi\\ufb01cation. Why \\u201cdeeper is\\nnot better\\u201d is still an open question, which requires in-\\nvestigations to better understand gradients and training\\ndynamics in deep architectures. Therefore, we still adopt\\nthree-layer networks in the following experiments.\\n4.4 Comparisons to State-of-the-Arts\\nIn this section, we show the quantitative and qualitative\\nresults of our method in comparison to state-of-the-art\\n2 4 6 8 10 12\\nx(10\\n8\\n31\\n31.5\\n32\\n32.5\\nNumber(of(backprops\\nAverage(test(PSNR(=dB)\\nSRCNN(=9\\u22121\\u22125)\\nSRCNN(=9\\u22121\\u22121\\u22125,(n 22=16)\\nSRCNN(=9\\u22121\\u22121\\u22125,(n 22=32)\\nSRCNN(=9\\u22121\\u22121\\u22121\\u22125,(n 22=32,(n 23=16)\\nSC(=31.42(dB)\\n(a) 9-1-1-5 ( n22 = 32) and 9-1-1-1-5 ( n22 = 32, n23 = 16)\\n1 2 3 4 5 6 7 8 9\\nxS10\\n8\\n31.5\\n32\\n32.5\\nNumberSofSbackprops\\nAverageStestSPSNRS(dB)\\nSRCNNS(9\\u22123\\u22125)\\nSRCNNS(9\\u22123\\u22121\\u22125)\\nSRCNNS(9\\u22123\\u22123\\u22125)\\nSRCNNS(9\\u22123\\u22123\\u22123)\\nSCS(31.42SdB)\\n(b) 9-3-3-5 and 9-3-3-3\\nFig. 9. Deeper structure does not always lead to better\\nresults.\\nmethods. We adopt the model with good performance-\\nspeed trade-off: a three-layer network with f1 = 9, f2 =\\n5, f3 = 5, n1 = 64, and n2 = 32 trained on the ImageNet.\\nFor each upscaling factor \\u2208{2,3,4}, we train a speci\\ufb01c\\nnetwork for that factor 7.\\nComparisons. We compare our SRCNN with the state-\\nof-the-art SR methods:\\n\\u2022 SC - sparse coding-based method of Yang et al. [50]\\n\\u2022 NE+LLE - neighbour embedding + locally linear\\nembedding method [4]\\n\\u2022 ANR - Anchored Neighbourhood Regression\\nmethod [41]\\n\\u2022 A+ - Adjusted Anchored Neighbourhood Regres-\\nsion method [42], and\\n\\u2022 KK - the method described in [25], which achieves\\nthe best performance among external example-\\nbased methods, according to the comprehensive\\nevaluation conducted in Yang et al.\\u2019s work [46]\\nThe implementations are all from the publicly available\\ncodes provided by the authors, and all images are down-\\nsampled using the same bicubic kernel.\\nTest set.The Set5 [2] (5 images), Set14 [51] (14 images)\\nand BSD200 [32] (200 images) 8 are used to evaluate the\\nperformance of upscaling factors 2, 3, and 4.\\nEvaluation metrics. Apart from the widely used PSNR\\nand SSIM [43] indices, we also adopt another four\\nevaluation matrices, namely information \\ufb01delity cri-\\nterion (IFC) [38], noise quality measure (NQM) [8],\\nweighted peak signal-to-noise ratio (WPSNR) and multi-\\nscale structure similarity index (MSSSIM) [44], which\\nobtain high correlation with the human perceptual scores\\nas reported in [46].\\n4.4.1 Quantitative and qualitative evaluation\\nAs shown in Tables 2, 3 and 4, the proposed SRCNN\\nyields the highest scores in most evaluation matrices\\n7. In the area of denoising [3], for each noise level a speci\\ufb01c network\\nis trained.\", \"4.3.2 Filter size\\nIn this section, we examine the network sensitivity to\\ndifferent \\ufb01lter sizes. In previous experiments, we set\\n\\ufb01lter size f1 = 9, f2 = 1 and f3 = 5, and the network\\ncould be denoted as 9-1-5. First, to be consistent with\\nsparse-coding-based methods, we \\ufb01x the \\ufb01lter size of the\\nsecond layer to be f2 = 1, and enlarge the \\ufb01lter size of\\nother layers to f1 = 11 and f3 = 7 (11-1-7). All the other\\n6. We use \\u2018width\\u2019 to term the number of \\ufb01lters in a layer, follow-\\ning [17]. The term \\u2018width\\u2019 may have other meanings in the literature.\\n1 2 3 4 5 6 7 8 9 10\\nxS10\\n8\\n31.5\\n32\\n32.5\\nNumberSofSbackprops\\nAverageStestSPSNRS(dB)\\nSRCNNS(9\\u22125\\u22125)\\nSRCNNS(9\\u22123\\u22125)\\nSRCNNS(9\\u22121\\u22125)\\nSCS(31.42SdB)\\nFig. 7. A larger \\ufb01lter size leads to better results.\\nsettings remain the same with Section 4.1. The results\\nwith an upscaling factor 3 on Set5 are 32.57 dB, which is\\nslightly higher than the 32.52 dB reported in Section 4.1.\\nThis indicates that a reasonably larger \\ufb01lter size could\\ngrasp richer structural information, which in turn lead\\nto better results.\\nThen we further examine networks with a larger \\ufb01lter\\nsize of the second layer. Speci\\ufb01cally, we \\ufb01x the \\ufb01lter size\\nf1 = 9, f3 = 5, and enlarge the \\ufb01lter size of the second\\nlayer to be (i) f2 = 3 (9-3-5) and (ii) f2 = 5 (9-5-5).\\nConvergence curves in Figure 7 show that using a larger\\n\\ufb01lter size could signi\\ufb01cantly improve the performance.\\nSpeci\\ufb01cally, the average PSNR values achieved by 9-3-\\n5 and 9-5-5 on Set5 with 8 \\u00d7108 backpropagations are\\n32.66 dB and 32.75 dB, respectively. The results suggest\\nthat utilizing neighborhood information in the mapping\\nstage is bene\\ufb01cial.\\nHowever, the deployment speed will also decrease\\nwith a larger \\ufb01lter size. For example, the number of\\nparameters of 9-1-5, 9-3-5, and 9-5-5 is 8,032, 24,416, and\\n57,184 respectively. The complexity of 9-5-5 is almost\\ntwice of 9-3-5, but the performance improvement is\\nmarginal. Therefore, the choice of the network scale\\nshould always be a trade-off between performance and\\nspeed.\\n4.3.3 Number of layers\\nRecent study by He and Sun [17] suggests that CNN\\ncould bene\\ufb01t from increasing the depth of network\\nmoderately. Here, we try deeper structures by adding\\nanother non-linear mapping layer, which has n22 = 16\\n\\ufb01lters with size f22 = 1 . We conduct three controlled\\nexperiments, i.e., 9-1-1-5, 9-3-1-5, 9-5-1-5, which add an\\nadditional layer on 9-1-5, 9-3-5, and 9-5-5, respectively.\\nThe initialization scheme and learning rate of the ad-\\nditional layer are the same as the second layer. From\\nFigures 13(a), 13(b) and 8(c), we can observe that the\\nfour-layer networks converge slower than the three-layer\\nnetwork. Nevertheless, given enough training time, the\\ndeeper networks will \\ufb01nally catch up and converge to\\nthe three-layer ones.\\nThe effectiveness of deeper structures for super reso-\\nlution is found not as apparent as that shown in image\\nclassi\\ufb01cation [17]. Furthermore, we \\ufb01nd that deeper\\nnetworks do not always result in better performance.\\nSpeci\\ufb01cally, if we add an additional layer with n22 = 32\\n\\ufb01lters on 9-1-5 network, then the performance degrades\\nand fails to surpass the three-layer network (see Fig-\\nure 9(a)). If we go deeper by adding two non-linear\\n8\\n2 4 6 8 10 12\\nx(10\\n8\\n31\\n31.5\\n32\\n32.5\\nNumber(of(backprops\\nAverage(test(PSNR((dB)\\nSRCNN((9\\u22121\\u22125)\\nSRCNN((9\\u22121\\u22121\\u22125)\\nSC((31.42(dB)\\n(a) 9-1-5 vs. 9-1-1-5\\n1 2 3 4 5 6 7 8 9 10\\nxS10\\n8\\n31.5\\n32\\n32.5\\nNumberSofSbackprops\\nAverageStestSPSNRS(dB)\\nSRCNNS(9\\u22123\\u22125)\\nSRCNNS(9\\u22123\\u22121\\u22125)\\nSCS(31.42SdB)\\n(b) 9-3-5 vs. 9-3-1-5\\n1 2 3 4 5 6 7 8\\nxR10\\n8\\n31.5\\n32\\n32.5\\nNumberRofRbackprops\\nAverageRtestRPSNRR(dB)\\nSRCNNR(9\\u22125\\u22125)\\nSRCNNR(9\\u22125\\u22121\\u22125)\\nSCR(31.42RdB)\\n(c) 9-5-5 vs. 9-5-1-5\\nFig. 8. Comparisons between three-layer and four-layer\\nnetworks.\\nmapping layers with n22 = 32 and n23 = 16 \\ufb01lters on\\n9-1-5, then we have to set a smaller learning rate to\\nensure convergence, but we still do not observe superior\\nperformance after a week of training (see Figure 9(a)).\\nWe also tried to enlarge the \\ufb01lter size of the additional\", \"In this paper, we show that the aforementioned\\npipeline is equivalent to a deep convolutional neural net-\\nwork [27] (more details in Section 3.2). Motivated by this\\nfact, we consider a convolutional neural network that\\ndirectly learns an end-to-end mapping between low- and\\nhigh-resolution images. Our method differs fundamen-\\ntally from existing external example-based approaches,\\nin that ours does not explicitly learn the dictionaries [41],\\n[49], [50] or manifolds [2], [4] for modeling the patch\\nspace. These are implicitly achieved via hidden layers.\\nFurthermore, the patch extraction and aggregation are\\nalso formulated as convolutional layers, so are involved\\nin the optimization. In our method, the entire SR pipeline\\nis fully obtained through learning, with little pre/post-\\nprocessing.\\nWe name the proposed model Super-Resolution Con-\\nvolutional Neural Network (SRCNN) 1. The proposed\\nSRCNN has several appealing properties. First, its struc-\\nture is intentionally designed with simplicity in mind,\\nand yet provides superior accuracy 2 compared with\\nstate-of-the-art example-based methods. Figure 1 shows\\na comparison on an example. Second, with moderate\\n1. The implementation is available at http://mmlab.ie.cuhk.edu.hk/\\nprojects/SRCNN.html.\\n2. Numerical evaluations by using different metrics such as the Peak\\nSignal-to-Noise Ratio (PSNR), structure similarity index (SSIM) [43],\\nmulti-scale SSIM [44], information \\ufb01delity criterion [38], when the\\nground truth images are available.\\narXiv:1501.00092v3  [cs.CV]  31 Jul 2015\\n2\\nBicubic / 24.04 dB\\nSC / 25.58 dBSRCNN / 27.95 dB\\nOriginal / PSNR\\n2 4 6 8 10 12x 108\\n29.5\\n30\\n30.5\\n31\\n31.5\\n32\\n32.5\\n33\\nNumber of backprops\\nAverage test PSNR (dB)\\nSRCNN\\nSC\\nBicubic\\nBicubic / 24.04 dB\\nSC / 25.58 dBSRCNN / 27.95 dB\\nOriginal / PSNR\\nBicubic / 24.04 dB\\nSC / 25.58 dBSRCNN / 27.95 dB\\nOriginal / PSNR\\nSRCNN\\nSC\\nBicubic\\nBicubic / 24.04 dB\\nSC / 25.58 dBSRCNN / 27.95 dB\\nOriginal / PSNR\\nNumber of backprops\\nAverage test PSNR (dB)\\nFig. 1. The proposed Super-Resolution Convolutional\\nNeural Network (SRCNN) surpasses the bicubic baseline\\nwith just a few training iterations, and outperforms the\\nsparse-coding-based method (SC) [50] with moderate\\ntraining. The performance may be further improved with\\nmore training iterations. More details are provided in\\nSection 4.4.1 (the Set5 dataset with an upscaling factor\\n3). The proposed method provides visually appealing\\nreconstructed image.\\nnumbers of \\ufb01lters and layers, our method achieves\\nfast speed for practical on-line usage even on a CPU.\\nOur method is faster than a number of example-based\\nmethods, because it is fully feed-forward and does\\nnot need to solve any optimization problem on usage.\\nThird, experiments show that the restoration quality of\\nthe network can be further improved when (i) larger\\nand more diverse datasets are available, and/or (ii)\\na larger and deeper model is used. On the contrary,\\nlarger datasets/models can present challenges for exist-\\ning example-based methods. Furthermore, the proposed\\nnetwork can cope with three channels of color images\\nsimultaneously to achieve improved super-resolution\\nperformance.\\nOverall, the contributions of this study are mainly in\\nthree aspects:\\n1) We present a fully convolutional neural net-\\nwork for image super-resolution. The network di-\\nrectly learns an end-to-end mapping between low-\\nand high-resolution images, with little pre/post-\\nprocessing beyond the optimization.\\n2) We establish a relationship between our deep-\\nlearning-based SR method and the traditional\\nsparse-coding-based SR methods. This relationship\\nprovides a guidance for the design of the network\\nstructure.\\n3) We demonstrate that deep learning is useful in\\nthe classical computer vision problem of super-\\nresolution, and can achieve good quality and\\nspeed.\\nA preliminary version of this work was presented\\nearlier [11]. The present work adds to the initial version\\nin signi\\ufb01cant ways. Firstly, we improve the SRCNN by\\nintroducing larger \\ufb01lter size in the non-linear mapping\", \"bicubic interpolation. The training falls into a bad local\\nminimum, due to the inherently different characteristics\\nof the Y and Cb, Cr channels. (ii) If we pre-train on the\\nY or Cb, Cr channels, the performance \\ufb01nally improves,\\nbut is still not better than \\u201cY only\\u201d on the color image\\n(see the last column of Table 5, where PSNR is computed\\n(a) First-layer \\ufb01lters \\u2013 Cb channel\\n(b) First-layer \\ufb01lters \\u2013 Cr channel\\nFig. 13. Chrominance channels of the \\ufb01rst-layer \\ufb01lters\\nusing the \\u201cY pre-train\\u201d strategy.\\nin RGB color space). This suggests that the Cb, Cr\\nchannels could decrease the performance of the Y chan-\\nnel when training is performed in a uni\\ufb01ed network.\\n(iii) We observe that the Cb, Cr channels have higher\\nPSNR values for \\u201cY pre-train\\u201d than for \\u201cCbCr pre-train\\u201d.\\nThe reason lies on the differences between the Cb, Cr\\nchannels and the Y channel. Visually, the Cb, Cr channels\\nare more blurry than the Y channel, thus are less affected\\nby the downsampling process. When we pre-train on\\nthe Cb, Cr channels, there are only a few \\ufb01lters being\\nactivated. Then the training will soon fall into a bad\\nlocal minimum during \\ufb01ne-tuning. On the other hand,\\nif we pre-train on the Y channel, more \\ufb01lters will be\\nactivated, and the performance on Cb, Cr channels will\\nbe pushed much higher. Figure 13 shows the Cb, Cr\\nchannels of the \\ufb01rst-layer \\ufb01lters with \\u201cY pre-train\\u201d, of\\nwhich the patterns largely differ from that shown in\\nFigure 5. (iv) Training on the RGB channels achieves\\nthe best result on the color image. Different from the\\nYCbCr channels, the RGB channels exhibit high cross-\\ncorrelation among each other. The proposed SRCNN\\nis capable of leveraging such natural correspondences\\nbetween the channels for reconstruction. Therefore, the\\nmodel achieves comparable result on the Y channel as\\n\\u201cY only\\u201d, and better results on Cb, Cr channels than\\nbicubic interpolation. (v) In KK [25], super-resolution\\nis applied on each RGB channel separately. When we\\ntransform its results to YCbCr space, the PSNR value\\nof Y channel is similar as \\u201cY only\\u201d, but that of Cb, Cr\\nchannels are poorer than bicubic interpolation. The result\\nsuggests that the algorithm is biased to the Y channel.\\nOn the whole, our method trained on RGB channels\\nachieves better performance than KK and the single-\\nchannel network (\\u201cY only\\u201d). It is also worth noting that\\nthe improvement compared with the single-channel net-\\nwork is not that signi\\ufb01cant ( i.e., 0.07 dB). This indicates\\nthat the Cb, Cr channels barely help in improving the\\nperformance.\\n5 C ONCLUSION\\nWe have presented a novel deep learning approach\\nfor single image super-resolution (SR). We show that\\nconventional sparse-coding-based SR methods can be\\n12\\nreformulated into a deep convolutional neural network.\\nThe proposed approach, SRCNN, learns an end-to-end\\nmapping between low- and high-resolution images, with\\nlittle extra pre/post-processing beyond the optimization.\\nWith a lightweight structure, the SRCNN has achieved\\nsuperior performance than the state-of-the-art methods.\\nWe conjecture that additional performance can be further\\ngained by exploring more \\ufb01lters and different training\\nstrategies. Besides, the proposed structure, with its ad-\\nvantages of simplicity and robustness, could be applied\\nto other low-level vision problems, such as image de-\\nblurring or simultaneous SR+denoising. One could also\\ninvestigate a network to cope with different upscaling\\nfactors.\\nREFERENCES\\n[1] Aharon, M., Elad, M., Bruckstein, A.: K-SVD: An algorithm for\\ndesigning overcomplete dictionaries for sparse representation.\\nIEEE Transactions on Signal Processing 54(11), 4311\\u20134322 (2006)\\n[2] Bevilacqua, M., Roumy, A., Guillemot, C., Morel, M.L.A.: Low-\\ncomplexity single-image super-resolution based on nonnegative\\nneighbor embedding. In: British Machine Vision Conference\\n(2012)\\n[3] Burger, H.C., Schuler, C.J., Harmeling, S.: Image denoising: Can\\nplain neural networks compete with BM3D? In: IEEE Conference\", \"erations, \\u03b7is the learning rate, and \\u2202L\\n\\u2202W \\u2113\\ni\\nis the derivative.\\nThe \\ufb01lter weights of each layer are initialized by drawing\\nrandomly from a Gaussian distribution with zero mean\\nand standard deviation 0.001 (and 0 for biases). The\\nlearning rate is 10\\u22124 for the \\ufb01rst two layers, and 10\\u22125 for\\nthe last layer. We empirically \\ufb01nd that a smaller learning\\nrate in the last layer is important for the network to\\nconverge (similar to the denoising case [22]).\\nIn the training phase, the ground truth images {Xi}\\nare prepared as fsub\\u00d7fsub\\u00d7c-pixel sub-images randomly\\ncropped from the training images. By \\u201csub-images\\u201d we\\nmean these samples are treated as small \\u201cimages\\u201d rather\\nthan \\u201cpatches\\u201d, in the sense that \\u201cpatches\\u201d are overlap-\\nping and require some averaging as post-processing but\\n\\u201csub-images\\u201d need not. To synthesize the low-resolution\\nsamples {Yi}, we blur a sub-image by a Gaussian kernel,\\nsub-sample it by the upscaling factor, and upscale it by\\nthe same factor via bicubic interpolation.\\nTo avoid border effects during training, all the con-\\nvolutional layers have no padding, and the network\\nproduces a smaller output ( (fsub \\u2212f1 \\u2212f2 \\u2212f3 + 3)2 \\u00d7c).\\nThe MSE loss function is evaluated only by the difference\\nbetween the central pixels of Xi and the network output.\\nAlthough we use a \\ufb01xed image size in training, the\\nconvolutional neural network can be applied on images\\nof arbitrary sizes during testing.\\nWe implement our model using the cuda-convnet pack-\\nage [26]. We have also tried the Caffe package [24] and\\nobserved similar performance.\\n4 E XPERIMENTS\\nWe \\ufb01rst investigate the impact of using different datasets\\non the model performance. Next, we examine the \\ufb01lters\\nlearned by our approach. We then explore different\\narchitecture designs of the network, and study the rela-\\ntions between super-resolution performance and factors\\nlike depth, number of \\ufb01lters, and \\ufb01lter sizes. Subse-\\nquently, we compare our method with recent state-of-\\nthe-arts both quantitatively and qualitatively. Following\\n[42], super-resolution is only applied on the luminance\\nchannel (Y channel in YCbCr color space) in Sections 4.1-\\n4.4, so c = 1 in the \\ufb01rst/last layer, and performance\\n(e.g., PSNR and SSIM) is evaluated on the Y channel. At\\nlast, we extend the network to cope with color images\\nand evaluate the performance on different channels.\\n4.1 Training Data\\nAs shown in the literature, deep learning generally\\nbene\\ufb01ts from big data training. For comparison, we use\\na relatively small training set [41], [50] that consists\\nof 91 images, and a large training set that consists of\\n395,909 images from the ILSVRC 2013 ImageNet detec-\\ntion training partition. The size of training sub-images is\\nfsub = 33. Thus the 91-image dataset can be decomposed\\ninto 24,800 sub-images, which are extracted from origi-\\nnal images with a stride of 14. Whereas the ImageNet\\nprovides over 5 million sub-images even using a stride\\nof 33. We use the basic network settings, i.e., f1 = 9 ,\\nf2 = 1, f3 = 5, n1 = 64, and n2 = 32. We use the Set5 [2]\\nas the validation set. We observe a similar trend even\\nif we use the larger Set14 set [51]. The upscaling factor\\nis 3. We use the sparse-coding-based method [50] as our\\nbaseline, which achieves an average PSNR value of 31.42\\ndB.\\nThe test convergence curves of using different training\\nsets are shown in Figure 4. The training time on Ima-\\ngeNet is about the same as on the 91-image dataset since\\nthe number of backpropagations is the same. As can be\\nobserved, with the same number of backpropagations\\n(i.e.,8 \\u00d7108), the SRCNN +ImageNet achieves 32.52 dB,\\nhigher than 32.39 dB yielded by that trained on 91\\nimages. The results positively indicate that SRCNN per-\\nformance may be further boosted using a larger training\\nset, but the effect of big data is not as impressive as\\nthat shown in high-level vision problems [26]. This is\\nmainly because that the 91 images have already cap-\\ntured suf\\ufb01cient variability of natural images. On the\", \"observed, with the same number of backpropagations\\n(i.e.,8 \\u00d7108), the SRCNN +ImageNet achieves 32.52 dB,\\nhigher than 32.39 dB yielded by that trained on 91\\nimages. The results positively indicate that SRCNN per-\\nformance may be further boosted using a larger training\\nset, but the effect of big data is not as impressive as\\nthat shown in high-level vision problems [26]. This is\\nmainly because that the 91 images have already cap-\\ntured suf\\ufb01cient variability of natural images. On the\\nother hand, our SRCNN is a relatively small network\\n(8,032 parameters), which could not over\\ufb01t the 91 images\\n(24,800 samples). Nevertheless, we adopt the ImageNet,\\nwhich contains more diverse data, as the default training\\nset in the following experiments.\\n4.2 Learned Filters for Super-Resolution\\nFigure 5 shows examples of learned \\ufb01rst-layer \\ufb01lters\\ntrained on the ImageNet by an upscaling factor 3. Please\\nrefer to our published implementation for upscaling\\nfactors 2 and 4. Interestingly, each learned \\ufb01lter has\\nits speci\\ufb01c functionality. For instance, the \\ufb01lters g and\\nh are like Laplacian/Gaussian \\ufb01lters, the \\ufb01lters a - e\\nare like edge detectors at different directions, and the\\n\\ufb01lter f is like a texture extractor. Example feature maps\\nof different layers are shown in \\ufb01gure 6. Obviously,\\nfeature maps of the \\ufb01rst layer contain different structures\\n(e.g., edges at different directions), while that of the\\nsecond layer are mainly different on intensities.\\n4.3 Model and Performance Trade-offs\\nBased on the basic network settings ( i.e., f1 = 9, f2 = 1,\\nf3 = 5 , n1 = 64 , and n2 = 32 ), we will progressively\\nmodify some of these parameters to investigate the best\\ntrade-off between performance and speed, and study the\\nrelations between performance and parameters.\\n1 2 3 4 5 6 7 8 9 10\\nxS10\\n8\\n31.4\\n31.6\\n31.8\\n32\\n32.2\\n32.4\\n32.6\\nNumberSofSbackprops\\nAverageStestSPSNRSndBI\\nSRCNNSntrainedSonSImageNetI\\nSRCNNSntrainedSonS91SimagesI\\nSCSn31.42SdBI\\nFig. 4. Training with the much larger ImageNet dataset\\nimproves the performance over the use of 91 images.\\n7\\na b c d e f\\ng\\nh\\nFig. 5. The \\ufb01gure shows the \\ufb01rst-layer \\ufb01lters trained\\non ImageNet with an upscaling factor 3. The \\ufb01lters are\\norganized based on their respective variances.\\nInput Feature maps of the first layer\\nOutput Feature maps of the second layer\\nFig. 6. Example feature maps of different layers.\\n4.3.1 Filter number\\nIn general, the performance would improve if we in-\\ncrease the network width6, i.e., adding more \\ufb01lters, at the\\ncost of running time. Speci\\ufb01cally, based on our network\\ndefault settings of n1 = 64 and n2 = 32 , we conduct\\ntwo experiments: (i) one is with a larger network with\\nn1 = 128 and n2 = 64, and (ii) the other is with a smaller\\nnetwork with n1 = 32 and n2 = 16. Similar to Section 4.1,\\nwe also train the two models on ImageNet and test on\\nSet5 with an upscaling factor 3. The results observed\\nat 8 \\u00d7108 backpropagations are shown in Table 1. It is\\nclear that superior performance could be achieved by\\nincreasing the width. However, if a fast restoration speed\\nis desired, a small network width is preferred, which\\ncould still achieve better performance than the sparse-\\ncoding-based method (31.42 dB).\\nTABLE 1\\nThe results of using different \\ufb01lter numbers in SRCNN.\\nTraining is performed on ImageNet whilst the evaluation\\nis conducted on the Set5 dataset.\\nn1 = 128 n1 = 64 n1 = 32\\nn2 = 64 n2 = 32 n2 = 16\\nPSNR Time (sec) PSNR Time (sec) PSNR Time (sec)\\n32.60 0.60 32.52 0.18 32.26 0.05\\n4.3.2 Filter size\\nIn this section, we examine the network sensitivity to\\ndifferent \\ufb01lter sizes. In previous experiments, we set\\n\\ufb01lter size f1 = 9, f2 = 1 and f3 = 5, and the network\\ncould be denoted as 9-1-5. First, to be consistent with\\nsparse-coding-based methods, we \\ufb01x the \\ufb01lter size of the\\nsecond layer to be f2 = 1, and enlarge the \\ufb01lter size of\\nother layers to f1 = 11 and f3 = 7 (11-1-7). All the other\\n6. We use \\u2018width\\u2019 to term the number of \\ufb01lters in a layer, follow-\", \"the \\ufb01nal full image. The averaging can be considered\\nas a pre-de\\ufb01ned \\ufb01lter on a set of feature maps (where\\neach position is the \\u201c\\ufb02attened\\u201d vector form of a high-\\nresolution patch). Motivated by this, we de\\ufb01ne a convo-\\nlutional layer to produce the \\ufb01nal high-resolution image:\\nF(Y) = W3 \\u2217F2(Y) + B3. (3)\\n4. The ReLU can be equivalently considered as a part of the second\\noperation (Non-linear mapping), and the \\ufb01rst operation (Patch extrac-\\ntion and representation) becomes purely linear convolution.\\nHere W3 corresponds to c \\ufb01lters of a size n2 \\u00d7f3 \\u00d7f3,\\nand B3 is a c-dimensional vector.\\nIf the representations of the high-resolution patches\\nare in the image domain (i.e.,we can simply reshape each\\nrepresentation to form the patch), we expect that the\\n\\ufb01lters act like an averaging \\ufb01lter; if the representations\\nof the high-resolution patches are in some other domains\\n(e.g.,coef\\ufb01cients in terms of some bases), we expect that\\nW3 behaves like \\ufb01rst projecting the coef\\ufb01cients onto the\\nimage domain and then averaging. In either way, W3 is\\na set of linear \\ufb01lters.\\nInterestingly, although the above three operations are\\nmotivated by different intuitions, they all lead to the\\nsame form as a convolutional layer. We put all three\\noperations together and form a convolutional neural\\nnetwork (Figure 2). In this model, all the \\ufb01ltering weights\\nand biases are to be optimized. Despite the succinctness\\nof the overall structure, our SRCNN model is carefully\\ndeveloped by drawing extensive experience resulted\\nfrom signi\\ufb01cant progresses in super-resolution [49], [50].\\nWe detail the relationship in the next section.\\n3.2 Relationship to Sparse-Coding-Based Methods\\nWe show that the sparse-coding-based SR methods [49],\\n[50] can be viewed as a convolutional neural network.\\nFigure 3 shows an illustration.\\nIn the sparse-coding-based methods, let us consider\\nthat an f1 \\u00d7f1 low-resolution patch is extracted from\\nthe input image. Then the sparse coding solver, like\\nFeature-Sign [29], will \\ufb01rst project the patch onto a (low-\\nresolution) dictionary. If the dictionary size is n1, this\\nis equivalent to applying n1 linear \\ufb01lters ( f1 \\u00d7f1) on\\nthe input image (the mean subtraction is also a linear\\noperation so can be absorbed). This is illustrated as the\\nleft part of Figure 3.\\nThe sparse coding solver will then iteratively process\\nthe n1 coef\\ufb01cients. The outputs of this solver are n2\\ncoef\\ufb01cients, and usually n2 = n1 in the case of sparse\\ncoding. These n2 coef\\ufb01cients are the representation of\\nthe high-resolution patch. In this sense, the sparse coding\\n5\\nresponses\\nof patch of\\nneighbouring\\npatches\\n Patch extraction\\nand representation\\nNon-linear\\n mapping\\nReconstruction\\nFig. 3. An illustration of sparse-coding-based methods in the view of a convolutional neural network.\\nsolver behaves as a special case of a non-linear mapping\\noperator, whose spatial support is 1 \\u00d71. See the middle\\npart of Figure 3. However, the sparse coding solver is\\nnot feed-forward, i.e.,it is an iterative algorithm. On the\\ncontrary, our non-linear operator is fully feed-forward\\nand can be computed ef\\ufb01ciently. If we set f2 = 1, then\\nour non-linear operator can be considered as a pixel-wise\\nfully-connected layer. It is worth noting that \\u201cthe sparse\\ncoding solver\\u201d in SRCNN refers to the \\ufb01rst two layers,\\nbut not just the second layer or the activation function\\n(ReLU). Thus the nonlinear operation in SRCNN is also\\nwell optimized through the learning process.\\nThe above n2 coef\\ufb01cients (after sparse coding) are\\nthen projected onto another (high-resolution) dictionary\\nto produce a high-resolution patch. The overlapping\\nhigh-resolution patches are then averaged. As discussed\\nabove, this is equivalent to linear convolutions on the\\nn2 feature maps. If the high-resolution patches used for\\nreconstruction are of size f3 \\u00d7f3, then the linear \\ufb01lters\\nhave an equivalent spatial support of size f3 \\u00d7f3. See\\nthe right part of Figure 3.\\nThe above discussion shows that the sparse-coding-\", \"then projected onto another (high-resolution) dictionary\\nto produce a high-resolution patch. The overlapping\\nhigh-resolution patches are then averaged. As discussed\\nabove, this is equivalent to linear convolutions on the\\nn2 feature maps. If the high-resolution patches used for\\nreconstruction are of size f3 \\u00d7f3, then the linear \\ufb01lters\\nhave an equivalent spatial support of size f3 \\u00d7f3. See\\nthe right part of Figure 3.\\nThe above discussion shows that the sparse-coding-\\nbased SR method can be viewed as a kind of con-\\nvolutional neural network (with a different non-linear\\nmapping). But not all operations have been considered in\\nthe optimization in the sparse-coding-based SR methods.\\nOn the contrary, in our convolutional neural network,\\nthe low-resolution dictionary, high-resolution dictionary,\\nnon-linear mapping, together with mean subtraction and\\naveraging, are all involved in the \\ufb01lters to be optimized.\\nSo our method optimizes an end-to-end mapping that\\nconsists of all operations.\\nThe above analogy can also help us to design hyper-\\nparameters. For example, we can set the \\ufb01lter size of\\nthe last layer to be smaller than that of the \\ufb01rst layer,\\nand thus we rely more on the central part of the high-\\nresolution patch (to the extreme, if f3 = 1 , we are\\nusing the center pixel with no averaging). We can also\\nset n2 < n1 because it is expected to be sparser. A\\ntypical and basic setting is f1 = 9 , f2 = 1 , f3 = 5 ,\\nn1 = 64 , and n2 = 32 (we evaluate more settings in\\nthe experiment section). On the whole, the estimation\\nof a high resolution pixel utilizes the information of\\n(9 + 5 \\u22121)2 = 169 pixels. Clearly, the information\\nexploited for reconstruction is comparatively larger than\\nthat used in existing external example-based approaches,\\ne.g., using (5+5 \\u22121)2 = 81 pixels5 [15], [50]. This is one of\\nthe reasons why the SRCNN gives superior performance.\\n3.3 Training\\nLearning the end-to-end mapping function F re-\\nquires the estimation of network parameters \\u0398 =\\n{W1,W2,W3,B1,B2,B3}. This is achieved through min-\\nimizing the loss between the reconstructed images\\nF(Y; \\u0398) and the corresponding ground truth high-\\nresolution images X. Given a set of high-resolution\\nimages {Xi} and their corresponding low-resolution\\nimages {Yi}, we use Mean Squared Error (MSE) as the\\nloss function:\\nL(\\u0398) = 1\\nn\\nn\\u2211\\ni=1\\n||F(Yi; \\u0398)\\u2212Xi||2, (4)\\nwhere n is the number of training samples. Using MSE\\nas the loss function favors a high PSNR. The PSNR\\nis a widely-used metric for quantitatively evaluating\\nimage restoration quality, and is at least partially related\\nto the perceptual quality. It is worth noticing that the\\nconvolutional neural networks do not preclude the usage\\nof other kinds of loss functions, if only the loss functions\\nare derivable. If a better perceptually motivated metric\\nis given during training, it is \\ufb02exible for the network to\\nadapt to that metric. On the contrary, such a \\ufb02exibility\\nis in general dif\\ufb01cult to achieve for traditional \\u201chand-\\ncrafted\\u201d methods. Despite that the proposed model is\\ntrained favoring a high PSNR, we still observe satisfac-\\ntory performance when the model is evaluated using\\nalternative evaluation metrics, e.g., SSIM, MSSIM (see\\nSection 4.4.1).\\nThe loss is minimized using stochastic gradient de-\\nscent with the standard backpropagation [28]. In partic-\\nular, the weight matrices are updated as\\n\\u2206i+1 = 0.9 \\u00b7\\u2206i \\u2212\\u03b7\\u00b7 \\u2202L\\n\\u2202W\\u2113\\ni\\n, W \\u2113\\ni+1 = W\\u2113\\ni + \\u2206i+1, (5)\\n5. The patches are overlapped with 4 pixels at each direction.\\n6\\nwhere \\u2113\\u2208{1,2,3}and i are the indices of layers and it-\\nerations, \\u03b7is the learning rate, and \\u2202L\\n\\u2202W \\u2113\\ni\\nis the derivative.\\nThe \\ufb01lter weights of each layer are initialized by drawing\\nrandomly from a Gaussian distribution with zero mean\\nand standard deviation 0.001 (and 0 for biases). The\\nlearning rate is 10\\u22124 for the \\ufb01rst two layers, and 10\\u22125 for\\nthe last layer. We empirically \\ufb01nd that a smaller learning\\nrate in the last layer is important for the network to\\nconverge (similar to the denoising case [22]).\"]}": {"cached_metrics_data": [{"metric_data": {"name": "Contextual Precision (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Faithfulness (ragas)", "threshold": 0.8, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.8, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Contextual Recall (ragas)", "threshold": 0.6, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.6, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Answer Relevancy (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}]}, "{\"actual_output\": \"Perceptual loss\\\" in SRGAN (Super-Resolution Generative Adversarial Network) means that instead of simply comparing the generated super-resolved image and the original high-resolution image pixel by pixel, the network aims to make the super-resolved image perceptually similar \\u2013 that is, look more like the original \\u2013 to a human observer. This is different from traditional metrics like Mean Squared Error (MSE) which only measure pixel differences.\\n\\nHere's how the perceptual loss is calculated using VGG (Visual Geometry Group network, a pre-trained Convolutional Neural Network used for image recognition) feature maps:\\n\\nBoth the super-resolved image (generated by the SRGAN) and the original high-resolution image are passed through a pre-trained VGG19 network.\\n\\nThe VGG19 network extracts feature maps from both images. Feature maps are representations of different visual features of the images at different levels of abstraction within the network.\\n\\nThe perceptual loss is calculated by comparing these feature maps from specific layers within the VGG19 network, typically the ReLU (Rectified Linear Unit, a type of activation function in neural networks) activation layers. The loss is based on the Euclidean distance (a measure of the straight-line distance between two points in a multi-dimensional space representing the feature maps) between the feature representations of the two images. A smaller distance implies greater perceptual similarity.\\n\\nSpecifically, SRGAN combines this VGG-based content loss with an adversarial loss from the discriminator network within the GAN framework. The discriminator is trained to distinguish between real high-resolution images and the super-resolved images. This adversarial loss helps to make the generated images look more realistic. The content loss ensures that the generated image captures the perceptual content of the original image. The combination of these two losses is the overall perceptual loss.\", \"context\": [\"We formulate the perceptual loss as the weighted sum of a content loss and an adversarial loss component \\u2026 Content loss l_{VGG/i.j} = 1/(W_{i,j}H_{i,j}) \\u03a3(\\u03c6_{i,j}(I_{HR}) \\u2212 \\u03c6_{i,j}(G(I_{LR})))\\u00b2 \\u2026 l_{Gen} = \\u2212log D(G(I_{LR}))\"], \"expected_output\": \"It is a weighted sum of a content loss (Euclidean distance between VGG\\u2011feature maps of SR vs. HR images) and an adversarial loss (\\u2212log D(G(I))). The VGG layers (e.g., \\u03c65,4) provide semantics; the adversarial term pushes outputs onto the natural\\u2011image manifold.\", \"hyperparameters\": null, \"input\": \"What exactly is meant by \\u201cperceptual loss\\u201d in SRGAN, and how is it computed from VGG feature maps?\", \"retrieval_context\": [\"3.4. Investigation of content loss\\nWe investigated the effect of different content loss\\nchoices in the perceptual loss for the GAN-based networks.\\nSpeci\\ufb01cally we investigate lSR = lSR\\nX + 10\\u22123lSR\\nGen for the\\nfollowing content losses lSR\\nX :\\nTable 1: Performance of different loss functions for SR-\\nResNet and the adversarial networks on Set5 and Set14\\nbenchmark data. MOS score signi\\ufb01cantly higher (p< 0.05)\\nthan with other losses in that category\\u2217. [4\\u00d7upscaling]\\nSRResNet- SRGAN-\\nSet5 MSE VGG22 MSE VGG22 VGG54\\nPSNR 32.05 30.51 30.64 29.84 29.40\\nSSIM 0.9019 0.8803 0.8701 0.8468 0.8472\\nMOS 3.37 3.46 3.77 3.78 3.58\\nSet14\\nPSNR 28.49 27.19 26.92 26.44 26.02\\nSSIM 0.8184 0.7807 0.7611 0.7518 0.7397\\nMOS 2.98 3.15 \\u2217 3.43 3.57 3.72 \\u2217\\n\\u2022SRGAN-MSE: lSR\\nMSE, to investigate the adversarial\\nnetwork with the standard MSE as content loss.\\n\\u2022SRGAN-VGG22: lSR\\nVGG/2.2 with \\u03c62,2, a loss de\\ufb01ned\\non feature maps representing lower-level features [68].\\n\\u2022SRGAN-VGG54: lSR\\nVGG/5.4 with \\u03c65,4, a loss de\\ufb01ned\\non feature maps of higher level features from deeper\\nnetwork layers with more potential to focus on the\\ncontent of the images [68, 65, 40]. We refer to this\\nnetwork as SRGAN in the following.\\nWe also evaluate the performance of the generator network\\nwithout adversarial component for the two losses lSR\\nMSE\\n(SRResNet-MSE) and lSR\\nVGG/2.2 (SRResNet-VGG22). We\\nrefer to SRResNet-MSE asSRResNet. Note, when training\\nSRResNet-VGG22 we added an additional total variation\\nloss with weight 2 \\u00d710\\u22128 to lSR\\nVGG/2.2 [2, 33]. Quantitative\\nresults are summarized in Table 1 and visual examples\\nprovided in Figure 6. Even combined with the adversarial\\nloss, MSE provides solutions with the highest PSNR values\\nthat are, however, perceptually rather smooth and less\\nconvincing than results achieved with a loss component\\nmore sensitive to visual perception. This is caused by\\ncompetition between the MSE-based content loss and the\\nadversarial loss. We further attribute minor reconstruction\\nartifacts, which we observed in a minority of SRGAN-\\nMSE-based reconstructions, to those competing objectives.\\nWe could not determine a signi\\ufb01cantly best loss function\\nfor SRResNet or SRGAN with respect to MOS score\\non Set5. However, SRGAN-VGG54 signi\\ufb01cantly outper-\\nformed other SRGAN and SRResNet variants on Set14 in\\nterms of MOS. We observed a trend that using the higher\\nlevel VGG feature maps \\u03c65,4 yields better texture detail\\nwhen compared to \\u03c62,2 (c.f . Figure 6). Further examples of\\nperceptual improvements through SRGAN over SRResNet\\nare provided in the supplementary material.\\nFigure 5: Color-coded distribution of MOS scores on\\nBSD100. For each method 2600 samples (100 images \\u00d7\\n26 raters) were assessed. Mean shown as red marker, where\\nthe bins are centered around value i. [4\\u00d7upscaling]\\n3.5. Performance of the \\ufb01nal networks\\nWe compare the performance of SRResNet and SR-\\nGAN to NN, bicubic interpolation, and four state-of-the-\\nart methods. Quantitative results are summarized in Table\\n2 and con\\ufb01rm that SRResNet (in terms of PSNR/SSIM)\\nsets a new state of the art on three benchmark datasets.\\nPlease note that we used a publicly available framework\\nfor evaluation (c.f . Section 3.1), reported values might thus\\nslightly deviate from those reported in the original papers.\\nWe further obtained MOS ratings for SRGAN and all\\nreference methods on BSD100. Examples of images super-\\nresolved with SRResNet and SRGAN are depicted in the\\nsupplementary material. The results shown in Table 2\\ncon\\ufb01rm that SRGAN outperforms all reference methods by\\na large margin and sets a new state of the art for photo-\\nrealistic image SR. All differences in MOS ( c.f . Table\\n2) are highly signi\\ufb01cant on BSD100, except SRCNN vs.\\nSelfExSR. The distribution of all collected MOS ratings is\\nsummarized in Figure 5.\\n4. Discussion and future work\\nWe con\\ufb01rmed the superior perceptual performance of\\nSRGAN using MOS testing. We have further shown that\\nstandard quantitative measures such as PSNR and SSIM\", \"Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial\\nNetwork\\nChristian Ledig, Lucas Theis, Ferenc Husz\\u00b4ar, Jose Caballero, Andrew Cunningham,\\nAlejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, Wenzhe Shi\\nTwitter\\n{cledig,ltheis,fhuszar,jcaballero,aacostadiaz,aaitken,atejani,jtotz,zehanw,wshi}@twitter.com\\nAbstract\\nDespite the breakthroughs in accuracy and speed of\\nsingle image super-resolution using faster and deeper con-\\nvolutional neural networks, one central problem remains\\nlargely unsolved: how do we recover the \\ufb01ner texture details\\nwhen we super-resolve at large upscaling factors? The\\nbehavior of optimization-based super-resolution methods is\\nprincipally driven by the choice of the objective function.\\nRecent work has largely focused on minimizing the mean\\nsquared reconstruction error. The resulting estimates have\\nhigh peak signal-to-noise ratios, but they are often lacking\\nhigh-frequency details and are perceptually unsatisfying in\\nthe sense that they fail to match the \\ufb01delity expected at\\nthe higher resolution. In this paper, we present SRGAN,\\na generative adversarial network (GAN) for image super-\\nresolution (SR). To our knowledge, it is the \\ufb01rst framework\\ncapable of inferring photo-realistic natural images for 4\\u00d7\\nupscaling factors. To achieve this, we propose a perceptual\\nloss function which consists of an adversarial loss and a\\ncontent loss. The adversarial loss pushes our solution to\\nthe natural image manifold using a discriminator network\\nthat is trained to differentiate between the super-resolved\\nimages and original photo-realistic images. In addition, we\\nuse a content loss motivated by perceptual similarity instead\\nof similarity in pixel space. Our deep residual network\\nis able to recover photo-realistic textures from heavily\\ndownsampled images on public benchmarks. An extensive\\nmean-opinion-score (MOS) test shows hugely signi\\ufb01cant\\ngains in perceptual quality using SRGAN. The MOS scores\\nobtained with SRGAN are closer to those of the original\\nhigh-resolution images than to those obtained with any\\nstate-of-the-art method.\\n1. Introduction\\nThe highly challenging task of estimating a high-\\nresolution (HR) image from its low-resolution (LR)\\ncounterpart is referred to as super-resolution (SR). SR\\nreceived substantial attention from within the computer\\nvision research community and has a wide range of\\napplications [63, 71, 43].\\n4\\u00d7SRGAN (proposed) original\\nFigure 1: Super-resolved image (left) is almost indistin-\\nguishable from original (right). [4\\u00d7upscaling]\\nThe ill-posed nature of the underdetermined SR problem\\nis particularly pronounced for high upscaling factors, for\\nwhich texture detail in the reconstructed SR images is\\ntypically absent. The optimization target of supervised\\nSR algorithms is commonly the minimization of the mean\\nsquared error (MSE) between the recovered HR image\\nand the ground truth. This is convenient as minimizing\\nMSE also maximizes the peak signal-to-noise ratio (PSNR),\\nwhich is a common measure used to evaluate and compare\\nSR algorithms [61]. However, the ability of MSE (and\\nPSNR) to capture perceptually relevant differences, such\\nas high texture detail, is very limited as they are de\\ufb01ned\\nbased on pixel-wise image differences [60, 58, 26]. This\\nis illustrated in Figure 2, where highest PSNR does not\\nnecessarily re\\ufb02ect the perceptually better SR result. The\\n1\\narXiv:1609.04802v5  [cs.CV]  25 May 2017\\nbicubic SRResNet SRGAN original\\n(21.59dB/0.6423) (23.53dB/0.7832) (21.15dB/0.6868)\\nFigure 2: From left to right: bicubic interpolation, deep residual network optimized for MSE, deep residual generative\\nadversarial network optimized for a loss more sensitive to human perception, original HR image. Corresponding PSNR and\\nSSIM are shown in brackets. [4\\u00d7upscaling]\\nperceptual difference between the super-resolved and orig-\\ninal image means that the recovered image is not photo-\\nrealistic as de\\ufb01ned by Ferwerda [16].\", \"[70] K. Zhang, X. Gao, D. Tao, and X. Li. Multi-scale dictionary for\\nsingle image super-resolution. In IEEE Conference on Computer\\nVision and Pattern Recognition (CVPR), pages 1114\\u20131121, 2012. 2\\n[71] W. Zou and P. C. Yuen. Very Low Resolution Face Recognition\\nin Parallel Environment . IEEE Transactions on Image Processing,\\n21:327\\u2013340, 2012. 1\\nA. Supplementary Material\\nIn this supplementary material we \\ufb01rst brie\\ufb02y investigate the in\\ufb02uence of network depth (number of residual blocks)\\non the performance (PSNR, time) of SRResNet in Section A.1. We then visualize on an example image how the SRGAN\\nnetwork performance evolves with increasing number of training iterations in Section A.2. Results of the MOS tests\\nconducted on Set5, Set14, BSD100 are summarized in Section A.3. Finally we provide a visualization of all image\\nreconstruction obtained with SRResNet and SRGAN with a 4\\u00d7upscaling factor for Set5 (Section A.4), Set14 (Section A.5)\\nand \\ufb01ve randomly selected images from BSD100 (Section A.6).\\nImages are best viewed and compared zoomed in. All original low-/high-resolution images and reconstructions\\n(4\\u00d7upscaling) obtained with different methods (bicubic, SRResNet-MSE, SRResNet-VGG22, SRGAN-MSE, SRGAN-\\nVGG22, SRGAN-VGG54) described in the paper are available for download at https://twitter.box.com/s/\\nlcue6vlrd01ljkdtdkhmfvk7vtjhetog.\\nA.1. Performance (PSNR/time) vs. network depth\\nWe investigated the in\\ufb02uence of network depth, speci\\ufb01cally the number of residual blocks, on performance (PSNR [dB]\\non BSD100 for 4\\u00d7SR) and inference time [s] of the network architecture described in Figure 4 of the main paper. Time was\\nassessed on a NVIDIA M40 GPU and averaged over 100 reconstructions of a random low-resolution image with resolution\\n64\\u00d764 with upscaling factor 4\\u00d7. The measurements are plotted in Figure 7 for a network with (blue) and without (red)\\nskip-connection. As expected the time of a single forward pass through the network depends approximately linearly on the\\nnumber of residual blocks. Whether a skip-connection is used or not has no substantial impact on inference time. However,\\nwe observed substantial gains in performance with the additional skip-connection. We chose a network architecture of\\n16 residual blocks with skip-connection for the evaluation presented in the main paper as we consider this as good trade-\\noff between accuracy and speed including training time. While accuracy gains slowly saturate beyond 16 blocks there is,\\nnevertheless, a clear bene\\ufb01t of using even deeper networks.\\nFigure 7: Dependence of network performance (PSNR, time) on network depth. PSNR (left) calculated on BSD100. Time\\n(right) averaged over 100 reconstructions of a random LR image with resolution 64\\u00d764.\\nA.2. Evolution of Generator during SRGAN training\\nWe further investigated how reconstructions of the SRGAN generator network evolve (visually) with increasing number\\nof training iterations. Visual results obtained after different number of training iterations are illustrated in Figure 8. It is\\ninteresting that after only 20 thousand training iterations the generator substantially diverged from the SRResNet initialization\\nand produces reconstruction with a lot of high frequency content, including noise. With increasing number of training\\niterations reconstructions of the baboon from Set14 appear closer to the reference image. However, there is visually little\\nchange during the last 50-100 thousand update iterations.\\nSRResNet 20k 40k 60k 80k\\n100k 140k 180k SRGAN original HR image\\nFigure 8: Evolution of SRGAN generator network during training progress. Note: Generator initialized with SRResNet\\nweights; learning rate set to 10\\u22124 for \\ufb01rst 100k iterations, then reduced to 10\\u22125 for another 100k iterations. [4\\u00d7upscaling]\\nA.3. Mean opinion score (MOS) testing\\nIn all conducted MOS tests we have asked 26 human raters to assign a score from 1 (Bad) to 5 (Excellent) to reconstructions\", \"and signi\\ufb01cance determined at p< 0.05.\\nThe reader may also be interested in an independently\\ndeveloped GAN-based solution on GitHub 5. However it\\nonly provides experimental results on a limited set of faces,\\nwhich is a more constrained and easier task.\\n3.2. Training details and parameters\\nWe trained all networks on a NVIDIA Tesla M40 GPU\\nusing a random sample of 350 thousand images from\\nthe ImageNet database [45]. These images are distinct\\nfrom the testing images. We obtained the LR images\\nby downsampling the HR images (BGR, C = 3) using\\nbicubic kernel with downsampling factor r = 4. For each\\nmini-batch we crop 16 random 96 \\u00d796 HR sub images\\nof distinct training images. Note that we can apply the\\ngenerator model to images of arbitrary size as it is fully\\n1https://github.com/xiph/daala (commit: 8d03668)\\n2https://github.com/jbhuang0604/SelfExSR\\n3http://cv.snu.ac.kr/research/DRCN/\\n4https://twitter.box.com/s/\\nlcue6vlrd01ljkdtdkhmfvk7vtjhetog\\n5https://github.com/david-gpu/srez\\nconvolutional. We scaled the range of the LR input images\\nto [0,1] and for the HR images to [\\u22121,1]. The MSE loss\\nwas thus calculated on images of intensity range [\\u22121,1].\\nVGG feature maps were also rescaled by a factor of 1\\n12.75\\nto obtain VGG losses of a scale that is comparable to the\\nMSE loss. This is equivalent to multiplying Equation 5\\nwith a rescaling factor of \\u2248 0.006. For optimization we\\nuse Adam [36] with \\u03b21 = 0.9. The SRResNet networks\\nwere trained with a learning rate of 10\\u22124 and 106 update\\niterations. We employed the trained MSE-based SRResNet\\nnetwork as initialization for the generator when training\\nthe actual GAN to avoid undesired local optima. All\\nSRGAN variants were trained with 105 update iterations\\nat a learning rate of 10\\u22124 and another 105 iterations at a\\nlower rate of 10\\u22125. We alternate updates to the generator\\nand discriminator network, which is equivalent to k = 1\\nas used in Goodfellow et al. [22]. Our generator network\\nhas 16 identical (B = 16) residual blocks. During test time\\nwe turn batch-normalization update off to obtain an output\\nthat deterministically depends only on the input [32]. Our\\nimplementation is based on Theano [53] and Lasagne [8].\\n3.3. Mean opinion score (MOS) testing\\nWe have performed a MOS test to quantify the ability of\\ndifferent approaches to reconstruct perceptually convincing\\nimages. Speci\\ufb01cally, we asked 26 raters to assign an inte-\\ngral score from 1 (bad quality) to 5 (excellent quality) to the\\nsuper-resolved images. The raters rated 12 versions of each\\nimage on Set5, Set14 and BSD100: nearest neighbor (NN),\\nbicubic, SRCNN [9], SelfExSR [31], DRCN [34], ESPCN\\n[48], SRResNet-MSE, SRResNet-VGG22\\u2217 (\\u2217not rated on\\nBSD100), SRGAN-MSE \\u2217, SRGAN-VGG22 \\u2217, SRGAN-\\nVGG54 and the original HR image. Each rater thus rated\\n1128 instances (12 versions of 19 images plus 9 versions of\\n100 images) that were presented in a randomized fashion.\\nThe raters were calibrated on the NN (score 1) and HR (5)\\nversions of 20 images from the BSD300 training set. In a\\npilot study we assessed the calibration procedure and the\\ntest-retest reliability of 26 raters on a subset of 10 images\\nfrom BSD100 by adding a method\\u2019s images twice to a\\nlarger test set. We found good reliability and no signi\\ufb01cant\\ndifferences between the ratings of the identical images.\\nRaters very consistently rated NN interpolated test images\\nas 1 and the original HR images as 5 (c.f . Figure 5).\\nThe experimental results of the conducted MOS tests are\\nsummarized in Table 1, Table 2 and Figure 5.\\n3.4. Investigation of content loss\\nWe investigated the effect of different content loss\\nchoices in the perceptual loss for the GAN-based networks.\\nSpeci\\ufb01cally we investigate lSR = lSR\\nX + 10\\u22123lSR\\nGen for the\\nfollowing content losses lSR\\nX :\\nTable 1: Performance of different loss functions for SR-\\nResNet and the adversarial networks on Set5 and Set14\\nbenchmark data. MOS score signi\\ufb01cantly higher (p< 0.05)\\nthan with other losses in that category\\u2217. [4\\u00d7upscaling]\\nSRResNet- SRGAN-\", \"con\\ufb01rm that SRGAN outperforms all reference methods by\\na large margin and sets a new state of the art for photo-\\nrealistic image SR. All differences in MOS ( c.f . Table\\n2) are highly signi\\ufb01cant on BSD100, except SRCNN vs.\\nSelfExSR. The distribution of all collected MOS ratings is\\nsummarized in Figure 5.\\n4. Discussion and future work\\nWe con\\ufb01rmed the superior perceptual performance of\\nSRGAN using MOS testing. We have further shown that\\nstandard quantitative measures such as PSNR and SSIM\\nfail to capture and accurately assess image quality with\\nrespect to the human visual system [56]. The focus of this\\nwork was the perceptual quality of super-resolved images\\nrather than computational ef\\ufb01ciency. The presented model\\nis, in contrast to Shi et al. [48], not optimized for video\\nSR in real-time. However, preliminary experiments on\\nthe network architecture suggest that shallower networks\\nhave the potential to provide very ef\\ufb01cient alternatives at\\na small reduction of qualitative performance. In contrast to\\nDong et al. [10], we found deeper network architectures to\\nbe bene\\ufb01cial. We speculate that the ResNet design has a\\nsubstantial impact on the performance of deeper networks.\\nWe found that even deeper networks (B >16) can further\\nSRResNet SRGAN-MSE SRGAN-VGG22 SRGAN-VGG54 original HR image\\nFigure 6: SRResNet (left: a,b), SRGAN-MSE (middle left: c,d), SRGAN-VGG2.2 (middle: e,f) and SRGAN-VGG54\\n(middle right: g,h) reconstruction results and corresponding reference HR image (right: i,j). [ 4\\u00d7upscaling]\\nTable 2: Comparison of NN, bicubic, SRCNN [9], SelfExSR [31], DRCN [34], ESPCN [48], SRResNet, SRGAN-VGG54\\nand the original HR on benchmark data. Highest measures (PSNR [dB], SSIM, MOS) in bold. [4\\u00d7upscaling]\\nSet5 nearest bicubic SRCNN SelfExSR DRCN ESPCN SRResNet SRGAN HR\\nPSNR 26.26 28.43 30.07 30.33 31.52 30.76 32.05 29.40 \\u221e\\nSSIM 0.7552 0.8211 0.8627 0.872 0.8938 0.8784 0.9019 0.8472 1\\nMOS 1.28 1.97 2.57 2.65 3.26 2.89 3.37 3.58 4.32\\nSet14\\nPSNR 24.64 25.99 27.18 27.45 28.02 27.66 28.49 26.02 \\u221e\\nSSIM 0.7100 0.7486 0.7861 0.7972 0.8074 0.8004 0.8184 0.7397 1\\nMOS 1.20 1.80 2.26 2.34 2.84 2.52 2.98 3.72 4.32\\nBSD100\\nPSNR 25.02 25.94 26.68 26.83 27.21 27.02 27.58 25.16 \\u221e\\nSSIM 0.6606 0.6935 0.7291 0.7387 0.7493 0.7442 0.7620 0.6688 1\\nMOS 1.11 1.47 1.87 1.89 2.12 2.01 2.29 3.56 4.46\\nincrease the performance of SRResNet, however, come at\\nthe cost of longer training and testing times ( c.f . supple-\\nmentary material). We further found SRGAN variants of\\ndeeper networks are increasingly dif\\ufb01cult to train due to the\\nappearance of high-frequency artifacts.\\nOf particular importance when aiming for photo-realistic\\nsolutions to the SR problem is the choice of the content loss\\nas illustrated in Figure 6. In this work, we found lSR\\nVGG/5.4\\nto yield the perceptually most convincing results, which\\nwe attribute to the potential of deeper network layers to\\nrepresent features of higher abstraction [68, 65, 40] away\\nfrom pixel space. We speculate that feature maps of these\\ndeeper layers focus purely on the content while leaving the\\nadversarial loss focusing on texture details which are the\\nmain difference between the super-resolved images without\\nthe adversarial loss and photo-realistic images. We also\\nnote that the ideal loss function depends on the application.\\nFor example, approaches that hallucinate \\ufb01ner detail might\\nbe less suited for medical applications or surveillance. The\\nperceptually convincing reconstruction of text or structured\\nscenes [31] is challenging and part of future work. The\\ndevelopment of content loss functions that describe image\\nspatial content, but more invariant to changes in pixel space\\nwill further improve photo-realistic image SR results.\\n5. Conclusion\\nWe have described a deep residual network SRRes-\\nNet that sets a new state of the art on public benchmark\\ndatasets when evaluated with the widely used PSNR mea-\\nsure. We have highlighted some limitations of this PSNR-\\nfocused image super-resolution and introduced SRGAN,\", \"lSR is commonly modeled based on the MSE [10, 48], we\\nimprove on Johnson et al. [33] and Bruna et al. [5] and\\ndesign a loss function that assesses a solution with respect\\nto perceptually relevant characteristics. We formulate the\\nperceptual loss as the weighted sum of a content loss ( lSR\\nX )\\nand an adversarial loss component as:\\nlSR = lSR\\nX\\ued19\\ued18\\ued17\\ued1a\\ncontent loss\\n+ 10\\u22123lSR\\nGen\\ued19 \\ued18\\ued17 \\ued1a\\nadversarial loss\\ued19 \\ued18\\ued17 \\ued1a\\nperceptual loss (for VGG based content losses)\\n(3)\\nIn the following we describe possible choices for the con-\\ntent loss lSR\\nX and the adversarial loss lSR\\nGen.\\n2.2.1 Content loss\\nThe pixel-wise MSE loss is calculated as:\\nlSR\\nMSE = 1\\nr2WH\\nrW\\u2211\\nx=1\\nrH\\u2211\\ny=1\\n(IHR\\nx,y \\u2212G\\u03b8G(ILR)x,y)2 (4)\\nThis is the most widely used optimization target for image\\nSR on which many state-of-the-art approaches rely [10,\\n48]. However, while achieving particularly high PSNR,\\nsolutions of MSE optimization problems often lack high-\\nfrequency content which results in perceptually unsatisfy-\\ning solutions with overly smooth textures (c.f . Figure 2).\\nInstead of relying on pixel-wise losses we build on the\\nideas of Gatys et al. [19], Bruna et al. [5] and Johnson et\\nal. [33] and use a loss function that is closer to perceptual\\nsimilarity. We de\\ufb01ne the VGG loss based on the ReLU\\nactivation layers of the pre-trained 19 layer VGG network\\ndescribed in Simonyan and Zisserman [49]. With \\u03c6i,j we\\nindicate the feature map obtained by the j-th convolution\\n(after activation) before the i-th maxpooling layer within the\\nVGG19 network, which we consider given. We then de\\ufb01ne\\nthe VGG loss as the euclidean distance between the feature\\nrepresentations of a reconstructed image G\\u03b8G(ILR) and the\\nreference image IHR:\\nlSR\\nVGG/i.j = 1\\nWi,jHi,j\\nWi,j\\u2211\\nx=1\\nHi,j\\u2211\\ny=1\\n(\\u03c6i,j(IHR)x,y\\n\\u2212\\u03c6i,j(G\\u03b8G(ILR))x,y)2\\n(5)\\nHere Wi,j and Hi,j describe the dimensions of the\\nrespective feature maps within the VGG network.\\n2.2.2 Adversarial loss\\nIn addition to the content losses described so far, we also\\nadd the generative component of our GAN to the perceptual\\nloss. This encourages our network to favor solutions that\\nreside on the manifold of natural images, by trying to\\nfool the discriminator network. The generative loss lSR\\nGen\\nis de\\ufb01ned based on the probabilities of the discriminator\\nD\\u03b8D (G\\u03b8G(ILR)) over all training samples as:\\nlSR\\nGen =\\nN\\u2211\\nn=1\\n\\u2212log D\\u03b8D (G\\u03b8G(ILR)) (6)\\nHere, D\\u03b8D (G\\u03b8G(ILR)) is the probability that the recon-\\nstructed image G\\u03b8G(ILR) is a natural HR image. For better\\ngradient behavior we minimize \\u2212log D\\u03b8D (G\\u03b8G(ILR)) in-\\nstead of log[1 \\u2212D\\u03b8D (G\\u03b8G(ILR))] [22].\\n3. Experiments\\n3.1. Data and similarity measures\\nWe perform experiments on three widely used bench-\\nmark datasets Set5 [3], Set14 [69] and BSD100, the testing\\nset of BSD300 [41]. All experiments are performed with\\na scale factor of 4\\u00d7 between low- and high-resolution\\nimages. This corresponds to a 16\\u00d7reduction in image\\npixels. For fair comparison, all reported PSNR [dB] and\\nSSIM [58] measures were calculated on the y-channel of\\ncenter-cropped, removal of a 4-pixel wide strip from each\\nborder, images using the daala package 1. Super-resolved\\nimages for the reference methods, including nearest neigh-\\nbor, bicubic, SRCNN [9] and SelfExSR [31], were obtained\\nfrom online material supplementary to Huang et al. 2 [31]\\nand for DRCN from Kim et al. 3 [34]. Results obtained\\nwith SRResNet (for losses: lSR\\nMSE and lSR\\nVGG/2.2) and the\\nSRGAN variants are available online4. Statistical tests were\\nperformed as paired two-sided Wilcoxon signed-rank tests\\nand signi\\ufb01cance determined at p< 0.05.\\nThe reader may also be interested in an independently\\ndeveloped GAN-based solution on GitHub 5. However it\\nonly provides experimental results on a limited set of faces,\\nwhich is a more constrained and easier task.\\n3.2. Training details and parameters\\nWe trained all networks on a NVIDIA Tesla M40 GPU\\nusing a random sample of 350 thousand images from\\nthe ImageNet database [45]. These images are distinct\\nfrom the testing images. We obtained the LR images\", \"obtained by applying a Gaussian \\ufb01lter toIHR followed by a\\ndownsampling operation with downsampling factor r. For\\nan image with C color channels, we describe ILR by a\\nreal-valued tensor of size W \\u00d7H \\u00d7C and IHR, ISR by\\nrW \\u00d7rH \\u00d7Crespectively.\\nOur ultimate goal is to train a generating function Gthat\\nestimates for a given LR input image its corresponding HR\\ncounterpart. To achieve this, we train a generator network as\\na feed-forward CNN G\\u03b8G parametrized by \\u03b8G. Here \\u03b8G =\\n{W1:L; b1:L}denotes the weights and biases of a L-layer\\ndeep network and is obtained by optimizing a SR-speci\\ufb01c\\nloss function lSR. For training images IHR\\nn , n= 1,...,N\\nwith corresponding ILR\\nn , n= 1,...,N , we solve:\\n\\u02c6\\u03b8G = arg min\\n\\u03b8G\\n1\\nN\\nN\\u2211\\nn=1\\nlSR(G\\u03b8G(ILR\\nn ),IHR\\nn ) (1)\\nIn this work we will speci\\ufb01cally design a perceptual loss\\nlSR as a weighted combination of several loss components\\nthat model distinct desirable characteristics of the recovered\\nSR image. The individual loss functions are described in\\nmore detail in Section 2.2.\\n2.1. Adversarial network architecture\\nFollowing Goodfellow et al. [22] we further de\\ufb01ne\\na discriminator network D\\u03b8D which we optimize in an\\nalternating manner along with G\\u03b8G to solve the adversarial\\nmin-max problem:\\nmin\\n\\u03b8G\\nmax\\n\\u03b8D\\nEIHR\\u223cptrain(IHR)[log D\\u03b8D (IHR)]+\\nEILR\\u223cpG(ILR)[log(1 \\u2212D\\u03b8D (G\\u03b8G(ILR))]\\n(2)\\nThe general idea behind this formulation is that it allows\\none to train a generative model Gwith the goal of fooling a\\ndifferentiable discriminator Dthat is trained to distinguish\\nsuper-resolved images from real images. With this approach\\nour generator can learn to create solutions that are highly\\nsimilar to real images and thus dif\\ufb01cult to classify by D.\\nThis encourages perceptually superior solutions residing in\\nthe subspace, the manifold, of natural images. This is in\\ncontrast to SR solutions obtained by minimizing pixel-wise\\nerror measurements, such as the MSE.\\nAt the core of our very deep generator networkG, which\\nis illustrated in Figure 4 areBresidual blocks with identical\\nlayout. Inspired by Johnson et al. [33] we employ the block\\nlayout proposed by Gross and Wilber [24]. Speci\\ufb01cally, we\\nuse two convolutional layers with small3\\u00d73 kernels and 64\\nfeature maps followed by batch-normalization layers [32]\\nand ParametricReLU [28] as the activation function. We\\nincrease the resolution of the input image with two trained\\nsub-pixel convolution layers as proposed by Shi et al. [48].\\nTo discriminate real HR images from generated SR\\nsamples we train a discriminator network. The architecture\\nis shown in Figure 4. We follow the architectural guidelines\\nsummarized by Radford et al. [44] and use LeakyReLU\\nactivation (\\u03b1 = 0.2) and avoid max-pooling throughout\\nthe network. The discriminator network is trained to solve\\nthe maximization problem in Equation 2. It contains eight\\nconvolutional layers with an increasing number of 3 \\u00d73\\n\\ufb01lter kernels, increasing by a factor of 2 from 64 to 512 ker-\\nnels as in the VGG network [49]. Strided convolutions are\\nused to reduce the image resolution each time the number\\nof features is doubled. The resulting 512 feature maps are\\nfollowed by two dense layers and a \\ufb01nal sigmoid activation\\nfunction to obtain a probability for sample classi\\ufb01cation.\\nFigure 4: Architecture of Generator and Discriminator Network with corresponding kernel size (k), number of feature maps\\n(n) and stride (s) indicated for each convolutional layer.\\n2.2. Perceptual loss function\\nThe de\\ufb01nition of our perceptual loss function lSR is crit-\\nical for the performance of our generator network. While\\nlSR is commonly modeled based on the MSE [10, 48], we\\nimprove on Johnson et al. [33] and Bruna et al. [5] and\\ndesign a loss function that assesses a solution with respect\\nto perceptually relevant characteristics. We formulate the\\nperceptual loss as the weighted sum of a content loss ( lSR\\nX )\\nand an adversarial loss component as:\\nlSR = lSR\\nX\\ued19\\ued18\\ued17\\ued1a\\ncontent loss\\n+ 10\\u22123lSR\\nGen\\ued19 \\ued18\\ued17 \\ued1a\\nadversarial loss\\ued19 \\ued18\\ued17 \\ued1a\\nperceptual loss (for VGG based content losses)\\n(3)\", \"ure 3 where multiple potential solutions with high texture\\ndetails are averaged to create a smooth reconstruction.\\nIn Mathieu et al. [42] and Denton et al. [7] the authors\\ntackled this problem by employing generative adversarial\\nnetworks (GANs) [22] for the application of image genera-\\ntion. Yu and Porikli [66] augment pixel-wise MSE loss with\\na discriminator loss to train a network that super-resolves\\nface images with large upscaling factors ( 8\\u00d7). GANs\\nwere also used for unsupervised representation learning in\\nRadford et al. [44]. The idea of using GANs to learn a\\nmapping from one manifold to another is described by Li\\nand Wand [38] for style transfer and Yeh et al. [64] for\\ninpainting. Bruna et al. [5] minimize the squared error in\\nthe feature spaces of VGG19 [49] and scattering networks.\\nDosovitskiy and Brox [13] use loss functions based\\non Euclidean distances computed in the feature space of\\nneural networks in combination with adversarial training.\\nIt is shown that the proposed loss allows visually superior\\nimage generation and can be used to solve the ill-posed\\ninverse problem of decoding nonlinear feature representa-\\ntions. Similar to this work, Johnson et al. [33] and Bruna\\net al. [5] propose the use of features extracted from a pre-\\ntrained VGG network instead of low-level pixel-wise error\\nmeasures. Speci\\ufb01cally the authors formulate a loss function\\nbased on the euclidean distance between feature maps\\nextracted from the VGG19 [49] network. Perceptually more\\nconvincing results were obtained for both super-resolution\\nand artistic style-transfer [19, 20]. Recently, Li and Wand\\n[38] also investigated the effect of comparing and blending\\npatches in pixel or VGG feature space.\\n1.2. Contribution\\nGANs provide a powerful framework for generating\\nplausible-looking natural images with high perceptual qual-\\nity. The GAN procedure encourages the reconstructions\\nto move towards regions of the search space with high\\nprobability of containing photo-realistic images and thus\\ncloser to the natural image manifold as shown in Figure 3.\\nIn this paper we describe the \\ufb01rst very deep ResNet\\n[29, 30] architecture using the concept of GANs to form a\\nperceptual loss function for photo-realistic SISR. Our main\\ncontributions are:\\n\\u2022We set a new state of the art for image SR with\\nhigh upscaling factors (4\\u00d7) as measured by PSNR and\\nstructural similarity (SSIM) with our 16 blocks deep\\nResNet (SRResNet) optimized for MSE.\\n\\u2022We propose SRGAN which is a GAN-based network\\noptimized for a new perceptual loss. Here we replace\\nthe MSE-based content loss with a loss calculated on\\nfeature maps of the VGG network [49], which are\\nmore invariant to changes in pixel space [38].\\n\\u2022We con\\ufb01rm with an extensive mean opinion score\\n(MOS) test on images from three public benchmark\\ndatasets that SRGAN is the new state of the art, by a\\nlarge margin, for the estimation of photo-realistic SR\\nimages with high upscaling factors (4\\u00d7).\\nWe describe the network architecture and the perceptual\\nloss in Section 2. A quantitative evaluation on public bench-\\nmark datasets as well as visual illustrations are provided in\\nSection 3. The paper concludes with a discussion in Section\\n4 and concluding remarks in Section 5.\\n2. Method\\nIn SISR the aim is to estimate a high-resolution, super-\\nresolved image ISR from a low-resolution input image\\nILR. Here ILR is the low-resolution version of its high-\\nresolution counterpart IHR. The high-resolution images\\nare only available during training. In training, ILR is\\nobtained by applying a Gaussian \\ufb01lter toIHR followed by a\\ndownsampling operation with downsampling factor r. For\\nan image with C color channels, we describe ILR by a\\nreal-valued tensor of size W \\u00d7H \\u00d7C and IHR, ISR by\\nrW \\u00d7rH \\u00d7Crespectively.\\nOur ultimate goal is to train a generating function Gthat\\nestimates for a given LR input image its corresponding HR\\ncounterpart. To achieve this, we train a generator network as\\na feed-forward CNN G\\u03b8G parametrized by \\u03b8G. Here \\u03b8G =\"]}": {"cached_metrics_data": [{"metric_data": {"name": "Contextual Precision (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Faithfulness (ragas)", "threshold": 0.8, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.8, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Contextual Recall (ragas)", "threshold": 0.6, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.6, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Answer Relevancy (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}]}, "{\"actual_output\": \"The authors of SRCNN pre-upscale the low-resolution (LR) image using bicubic interpolation (a standard image resizing technique) primarily to simplify the learning process and reduce computational cost. While learning the upscaling step end-to-end is possible, it would significantly increase the complexity of the model and require more resources for training. By pre-upscaling, the network only needs to learn the non-linear mapping between the interpolated image and the high-resolution image, which is a simpler task. They mention this is the only pre-processing step they perform.\", \"context\": [\"\\u2026we first upscale it to the desired size using bicubic interpolation, which is the only pre\\u2011processing we perform. \\u2026 There is a fractional stride. To take advantage of the popular well\\u2011optimized implementations such as cuda\\u2011convnet, we exclude this \\u201clayer\\u201d from learning.\"], \"expected_output\": \"Because popular GPU conv\\u2011net toolkits (cuda\\u2011convnet at the time) did not yet support fractional\\u2011stride convolutions. Upscaling once with bicubic ensures the network can stay fully convolutional with integer strides while still learning the rest of the SR mapping end\\u2011to\\u2011end.\", \"hyperparameters\": null, \"input\": \"Why do the authors of SRCNN first upscale the LR image with bicubic interpolation instead of learning that step end\\u2011to\\u2011end?\", \"retrieval_context\": [\"1 2 3 4 5 6 7 8\\nxR10\\n8\\n31.5\\n32\\n32.5\\nNumberRofRbackprops\\nAverageRtestRPSNRR(dB)\\nSRCNNR(9\\u22125\\u22125)\\nSRCNNR(9\\u22125\\u22121\\u22125)\\nSCR(31.42RdB)\\n(c) 9-5-5 vs. 9-5-1-5\\nFig. 8. Comparisons between three-layer and four-layer\\nnetworks.\\nmapping layers with n22 = 32 and n23 = 16 \\ufb01lters on\\n9-1-5, then we have to set a smaller learning rate to\\nensure convergence, but we still do not observe superior\\nperformance after a week of training (see Figure 9(a)).\\nWe also tried to enlarge the \\ufb01lter size of the additional\\nlayer to f22 = 3, and explore two deep structures \\u2013 9-3-\\n3-5 and 9-3-3-3. However, from the convergence curves\\nshown in Figure 9(b), these two networks do not show\\nbetter results than the 9-3-1-5 network.\\nAll these experiments indicate that it is not \\u201cthe deeper\\nthe better\\u201d in this deep model for super-resolution. It\\nmay be caused by the dif\\ufb01culty of training. Our CNN\\nnetwork contains no pooling layer or full-connected\\nlayer, thus it is sensitive to the initialization parameters\\nand learning rate. When we go deeper (e.g., 4 or 5 layers),\\nwe \\ufb01nd it hard to set appropriate learning rates that\\nguarantee convergence. Even it converges, the network\\nmay fall into a bad local minimum, and the learned\\n\\ufb01lters are of less diversity even given enough training\\ntime. This phenomenon is also observed in [16], where\\nimproper increase of depth leads to accuracy saturation\\nor degradation for image classi\\ufb01cation. Why \\u201cdeeper is\\nnot better\\u201d is still an open question, which requires in-\\nvestigations to better understand gradients and training\\ndynamics in deep architectures. Therefore, we still adopt\\nthree-layer networks in the following experiments.\\n4.4 Comparisons to State-of-the-Arts\\nIn this section, we show the quantitative and qualitative\\nresults of our method in comparison to state-of-the-art\\n2 4 6 8 10 12\\nx(10\\n8\\n31\\n31.5\\n32\\n32.5\\nNumber(of(backprops\\nAverage(test(PSNR(=dB)\\nSRCNN(=9\\u22121\\u22125)\\nSRCNN(=9\\u22121\\u22121\\u22125,(n 22=16)\\nSRCNN(=9\\u22121\\u22121\\u22125,(n 22=32)\\nSRCNN(=9\\u22121\\u22121\\u22121\\u22125,(n 22=32,(n 23=16)\\nSC(=31.42(dB)\\n(a) 9-1-1-5 ( n22 = 32) and 9-1-1-1-5 ( n22 = 32, n23 = 16)\\n1 2 3 4 5 6 7 8 9\\nxS10\\n8\\n31.5\\n32\\n32.5\\nNumberSofSbackprops\\nAverageStestSPSNRS(dB)\\nSRCNNS(9\\u22123\\u22125)\\nSRCNNS(9\\u22123\\u22121\\u22125)\\nSRCNNS(9\\u22123\\u22123\\u22125)\\nSRCNNS(9\\u22123\\u22123\\u22123)\\nSCS(31.42SdB)\\n(b) 9-3-3-5 and 9-3-3-3\\nFig. 9. Deeper structure does not always lead to better\\nresults.\\nmethods. We adopt the model with good performance-\\nspeed trade-off: a three-layer network with f1 = 9, f2 =\\n5, f3 = 5, n1 = 64, and n2 = 32 trained on the ImageNet.\\nFor each upscaling factor \\u2208{2,3,4}, we train a speci\\ufb01c\\nnetwork for that factor 7.\\nComparisons. We compare our SRCNN with the state-\\nof-the-art SR methods:\\n\\u2022 SC - sparse coding-based method of Yang et al. [50]\\n\\u2022 NE+LLE - neighbour embedding + locally linear\\nembedding method [4]\\n\\u2022 ANR - Anchored Neighbourhood Regression\\nmethod [41]\\n\\u2022 A+ - Adjusted Anchored Neighbourhood Regres-\\nsion method [42], and\\n\\u2022 KK - the method described in [25], which achieves\\nthe best performance among external example-\\nbased methods, according to the comprehensive\\nevaluation conducted in Yang et al.\\u2019s work [46]\\nThe implementations are all from the publicly available\\ncodes provided by the authors, and all images are down-\\nsampled using the same bicubic kernel.\\nTest set.The Set5 [2] (5 images), Set14 [51] (14 images)\\nand BSD200 [32] (200 images) 8 are used to evaluate the\\nperformance of upscaling factors 2, 3, and 4.\\nEvaluation metrics. Apart from the widely used PSNR\\nand SSIM [43] indices, we also adopt another four\\nevaluation matrices, namely information \\ufb01delity cri-\\nterion (IFC) [38], noise quality measure (NQM) [8],\\nweighted peak signal-to-noise ratio (WPSNR) and multi-\\nscale structure similarity index (MSSSIM) [44], which\\nobtain high correlation with the human perceptual scores\\nas reported in [46].\\n4.4.1 Quantitative and qualitative evaluation\\nAs shown in Tables 2, 3 and 4, the proposed SRCNN\\nyields the highest scores in most evaluation matrices\\n7. In the area of denoising [3], for each noise level a speci\\ufb01c network\\nis trained.\", \"4 0.7019 - 0.7331 0.7419 0.7352 0.7491 0.7513\\n2 6.09 - 7.59 6.83 7.81 8.11 7.76\\nIFC 3 3.41 2.98 4.14 3.83 4.23 4.45 4.26\\n4 2.23 - 2.71 2.57 2.78 2.94 2.74\\n2 40.98 - 41.34 38.86 41.79 42.61 38.95\\nNQM 3 33.15 29.06 37.12 35.23 37.22 38.24 35.25\\n4 26.15 - 31.17 29.18 31.27 32.31 30.46\\n2 47.64 - 54.47 53.85 54.57 55.62 55.39\\nWPSNR 3 39.72 41.66 43.22 43.56 43.36 44.25 44.32\\n4 35.71 - 37.75 38.26 37.85 38.72 38.87\\n2 0.9813 - 0.9886 0.9890 0.9888 0.9896 0.9897\\nMSSSIM 3 0.9512 0.9595 0.9643 0.9653 0.9647 0.9669 0.9675\\n4 0.9134 - 0.9317 0.9338 0.9326 0.9371 0.9376\\nTABLE 4\\nThe average results of PSNR (dB), SSIM, IFC, NQM, WPSNR (dB) and MSSIM on the BSD200 dataset.\\nEval. Mat Scale Bicubic SC [50] NE+LLE [4] KK [25] ANR [41] A+ [41] SRCNN\\n2 28.38 - 29.67 30.02 29.72 30.14 30.29\\nPSNR 3 25.94 26.54 26.67 26.89 26.72 27.05 27.18\\n4 24.65 - 25.21 25.38 25.25 25.51 25.60\\n2 0.8524 - 0.8886 0.8935 0.8900 0.8966 0.8977\\nSSIM 3 0.7469 0.7729 0.7823 0.7881 0.7843 0.7945 0.7971\\n4 0.6727 - 0.7037 0.7093 0.7060 0.7171 0.7184\\n2 5.30 - 7.10 6.33 7.28 7.51 7.21\\nIFC 3 3.05 2.77 3.82 3.52 3.91 4.07 3.91\\n4 1.95 - 2.45 2.24 2.51 2.62 2.45\\n2 36.84 - 41.52 38.54 41.72 42.37 39.66\\nNQM 3 28.45 28.22 34.65 33.45 34.81 35.58 34.72\\n4 21.72 - 25.15 24.87 25.27 26.01 25.65\\n2 46.15 - 52.56 52.21 52.69 53.56 53.58\\nWPSNR 3 38.60 40.48 41.39 41.62 41.53 42.19 42.29\\n4 34.86 - 36.52 36.80 36.64 37.18 37.24\\n2 0.9780 - 0.9869 0.9876 0.9872 0.9883 0.9883\\nMSSSIM 3 0.9426 0.9533 0.9575 0.9588 0.9581 0.9609 0.9614\\n4 0.9005 - 0.9203 0.9215 0.9214 0.9256 0.9261\\n11\\n10\\n0\\n10\\n1\\n10\\n228.2\\n28.4\\n28.6\\n28.8\\n29\\n29.2\\n29.4\\nRunning time (sec)\\nPSNR (dB)\\nSC\\nNE+LLE ANR\\nKK\\nA+\\nSRCNN(9-1-5)\\nSRCNN(9-3-5) SRCNN(9-5-5)\\n\\u2014\\u2014> FasterSlower <\\u2014\\u2014\\nFig. 12. The proposed SRCNN achieves the state-\\nof-the-art super-resolution quality, whilst maintains high\\nand competitive speed in comparison to existing external\\nexample-based methods. The chart is based on Set14\\nresults summarized in Table 3. The implementation of all\\nthree SRCNN networks are available on our project page.\\nTABLE 5\\nAverage PSNR (dB) of different channels and training\\nstrategies on the Set5 dataset.\\nTraining PSNR of different channel(s)\\nStrategies Y Cb Cr RGB color image\\nBicubic 30.39 45.44 45.42 34.57\\nY only 32.39 45.44 45.42 36.37\\nYCbCr 29.25 43.30 43.49 33.47\\nY pre-train 32.19 46.49 46.45 36.32\\nCbCr pre-train 32.14 46.38 45.84 36.25\\nRGB 32.33 46.18 46.20 36.44\\nKK 32.37 44.35 44.22 36.32\\neffectiveness of SRCNN on different scales, here we only\\nevaluate the performance of upscaling factor 3.\\nComparisons. We compare our method with the state-\\nof-art color SR method \\u2013 KK [25]. We also try different\\nlearning strategies for comparison:\\n\\u2022 Y only: this is our baseline method, which is a\\nsingle-channel ( c = 1 ) network trained only on\\nthe luminance channel. The Cb, Cr channels are\\nupscaled using bicubic interpolation.\\n\\u2022 YCbCr: training is performed on the three channels\\nof the YCbCr space.\\n\\u2022 Y pre-train: \\ufb01rst, to guarantee the performance on\\nthe Y channel, we only use the MSE of the Y channel\\nas the loss to pre-train the network. Then we employ\\nthe MSE of all channels to \\ufb01ne-tune the parameters.\\n\\u2022 CbCr pre-train: we use the MSE of the Cb, Cr\\nchannels as the loss to pre-train the network, then\\n\\ufb01ne-tune the parameters on all channels.\\n\\u2022 RGB: training is performed on the three channels of\\nthe RGB space.\\nThe results are shown in Table 5, where we have the\\nfollowing observations. (i) If we directly train on the\\nYCbCr channels, the results are even worse than that of\\nbicubic interpolation. The training falls into a bad local\\nminimum, due to the inherently different characteristics\\nof the Y and Cb, Cr channels. (ii) If we pre-train on the\\nY or Cb, Cr channels, the performance \\ufb01nally improves,\\nbut is still not better than \\u201cY only\\u201d on the color image\\n(see the last column of Table 5, where PSNR is computed\\n(a) First-layer \\ufb01lters \\u2013 Cb channel\\n(b) First-layer \\ufb01lters \\u2013 Cr channel\\nFig. 13. Chrominance channels of the \\ufb01rst-layer \\ufb01lters\", \"In this paper, we show that the aforementioned\\npipeline is equivalent to a deep convolutional neural net-\\nwork [27] (more details in Section 3.2). Motivated by this\\nfact, we consider a convolutional neural network that\\ndirectly learns an end-to-end mapping between low- and\\nhigh-resolution images. Our method differs fundamen-\\ntally from existing external example-based approaches,\\nin that ours does not explicitly learn the dictionaries [41],\\n[49], [50] or manifolds [2], [4] for modeling the patch\\nspace. These are implicitly achieved via hidden layers.\\nFurthermore, the patch extraction and aggregation are\\nalso formulated as convolutional layers, so are involved\\nin the optimization. In our method, the entire SR pipeline\\nis fully obtained through learning, with little pre/post-\\nprocessing.\\nWe name the proposed model Super-Resolution Con-\\nvolutional Neural Network (SRCNN) 1. The proposed\\nSRCNN has several appealing properties. First, its struc-\\nture is intentionally designed with simplicity in mind,\\nand yet provides superior accuracy 2 compared with\\nstate-of-the-art example-based methods. Figure 1 shows\\na comparison on an example. Second, with moderate\\n1. The implementation is available at http://mmlab.ie.cuhk.edu.hk/\\nprojects/SRCNN.html.\\n2. Numerical evaluations by using different metrics such as the Peak\\nSignal-to-Noise Ratio (PSNR), structure similarity index (SSIM) [43],\\nmulti-scale SSIM [44], information \\ufb01delity criterion [38], when the\\nground truth images are available.\\narXiv:1501.00092v3  [cs.CV]  31 Jul 2015\\n2\\nBicubic / 24.04 dB\\nSC / 25.58 dBSRCNN / 27.95 dB\\nOriginal / PSNR\\n2 4 6 8 10 12x 108\\n29.5\\n30\\n30.5\\n31\\n31.5\\n32\\n32.5\\n33\\nNumber of backprops\\nAverage test PSNR (dB)\\nSRCNN\\nSC\\nBicubic\\nBicubic / 24.04 dB\\nSC / 25.58 dBSRCNN / 27.95 dB\\nOriginal / PSNR\\nBicubic / 24.04 dB\\nSC / 25.58 dBSRCNN / 27.95 dB\\nOriginal / PSNR\\nSRCNN\\nSC\\nBicubic\\nBicubic / 24.04 dB\\nSC / 25.58 dBSRCNN / 27.95 dB\\nOriginal / PSNR\\nNumber of backprops\\nAverage test PSNR (dB)\\nFig. 1. The proposed Super-Resolution Convolutional\\nNeural Network (SRCNN) surpasses the bicubic baseline\\nwith just a few training iterations, and outperforms the\\nsparse-coding-based method (SC) [50] with moderate\\ntraining. The performance may be further improved with\\nmore training iterations. More details are provided in\\nSection 4.4.1 (the Set5 dataset with an upscaling factor\\n3). The proposed method provides visually appealing\\nreconstructed image.\\nnumbers of \\ufb01lters and layers, our method achieves\\nfast speed for practical on-line usage even on a CPU.\\nOur method is faster than a number of example-based\\nmethods, because it is fully feed-forward and does\\nnot need to solve any optimization problem on usage.\\nThird, experiments show that the restoration quality of\\nthe network can be further improved when (i) larger\\nand more diverse datasets are available, and/or (ii)\\na larger and deeper model is used. On the contrary,\\nlarger datasets/models can present challenges for exist-\\ning example-based methods. Furthermore, the proposed\\nnetwork can cope with three channels of color images\\nsimultaneously to achieve improved super-resolution\\nperformance.\\nOverall, the contributions of this study are mainly in\\nthree aspects:\\n1) We present a fully convolutional neural net-\\nwork for image super-resolution. The network di-\\nrectly learns an end-to-end mapping between low-\\nand high-resolution images, with little pre/post-\\nprocessing beyond the optimization.\\n2) We establish a relationship between our deep-\\nlearning-based SR method and the traditional\\nsparse-coding-based SR methods. This relationship\\nprovides a guidance for the design of the network\\nstructure.\\n3) We demonstrate that deep learning is useful in\\nthe classical computer vision problem of super-\\nresolution, and can achieve good quality and\\nspeed.\\nA preliminary version of this work was presented\\nearlier [11]. The present work adds to the initial version\\nin signi\\ufb01cant ways. Firstly, we improve the SRCNN by\\nintroducing larger \\ufb01lter size in the non-linear mapping\", \"bicubic interpolation. The training falls into a bad local\\nminimum, due to the inherently different characteristics\\nof the Y and Cb, Cr channels. (ii) If we pre-train on the\\nY or Cb, Cr channels, the performance \\ufb01nally improves,\\nbut is still not better than \\u201cY only\\u201d on the color image\\n(see the last column of Table 5, where PSNR is computed\\n(a) First-layer \\ufb01lters \\u2013 Cb channel\\n(b) First-layer \\ufb01lters \\u2013 Cr channel\\nFig. 13. Chrominance channels of the \\ufb01rst-layer \\ufb01lters\\nusing the \\u201cY pre-train\\u201d strategy.\\nin RGB color space). This suggests that the Cb, Cr\\nchannels could decrease the performance of the Y chan-\\nnel when training is performed in a uni\\ufb01ed network.\\n(iii) We observe that the Cb, Cr channels have higher\\nPSNR values for \\u201cY pre-train\\u201d than for \\u201cCbCr pre-train\\u201d.\\nThe reason lies on the differences between the Cb, Cr\\nchannels and the Y channel. Visually, the Cb, Cr channels\\nare more blurry than the Y channel, thus are less affected\\nby the downsampling process. When we pre-train on\\nthe Cb, Cr channels, there are only a few \\ufb01lters being\\nactivated. Then the training will soon fall into a bad\\nlocal minimum during \\ufb01ne-tuning. On the other hand,\\nif we pre-train on the Y channel, more \\ufb01lters will be\\nactivated, and the performance on Cb, Cr channels will\\nbe pushed much higher. Figure 13 shows the Cb, Cr\\nchannels of the \\ufb01rst-layer \\ufb01lters with \\u201cY pre-train\\u201d, of\\nwhich the patterns largely differ from that shown in\\nFigure 5. (iv) Training on the RGB channels achieves\\nthe best result on the color image. Different from the\\nYCbCr channels, the RGB channels exhibit high cross-\\ncorrelation among each other. The proposed SRCNN\\nis capable of leveraging such natural correspondences\\nbetween the channels for reconstruction. Therefore, the\\nmodel achieves comparable result on the Y channel as\\n\\u201cY only\\u201d, and better results on Cb, Cr channels than\\nbicubic interpolation. (v) In KK [25], super-resolution\\nis applied on each RGB channel separately. When we\\ntransform its results to YCbCr space, the PSNR value\\nof Y channel is similar as \\u201cY only\\u201d, but that of Cb, Cr\\nchannels are poorer than bicubic interpolation. The result\\nsuggests that the algorithm is biased to the Y channel.\\nOn the whole, our method trained on RGB channels\\nachieves better performance than KK and the single-\\nchannel network (\\u201cY only\\u201d). It is also worth noting that\\nthe improvement compared with the single-channel net-\\nwork is not that signi\\ufb01cant ( i.e., 0.07 dB). This indicates\\nthat the Cb, Cr channels barely help in improving the\\nperformance.\\n5 C ONCLUSION\\nWe have presented a novel deep learning approach\\nfor single image super-resolution (SR). We show that\\nconventional sparse-coding-based SR methods can be\\n12\\nreformulated into a deep convolutional neural network.\\nThe proposed approach, SRCNN, learns an end-to-end\\nmapping between low- and high-resolution images, with\\nlittle extra pre/post-processing beyond the optimization.\\nWith a lightweight structure, the SRCNN has achieved\\nsuperior performance than the state-of-the-art methods.\\nWe conjecture that additional performance can be further\\ngained by exploring more \\ufb01lters and different training\\nstrategies. Besides, the proposed structure, with its ad-\\nvantages of simplicity and robustness, could be applied\\nto other low-level vision problems, such as image de-\\nblurring or simultaneous SR+denoising. One could also\\ninvestigate a network to cope with different upscaling\\nfactors.\\nREFERENCES\\n[1] Aharon, M., Elad, M., Bruckstein, A.: K-SVD: An algorithm for\\ndesigning overcomplete dictionaries for sparse representation.\\nIEEE Transactions on Signal Processing 54(11), 4311\\u20134322 (2006)\\n[2] Bevilacqua, M., Roumy, A., Guillemot, C., Morel, M.L.A.: Low-\\ncomplexity single-image super-resolution based on nonnegative\\nneighbor embedding. In: British Machine Vision Conference\\n(2012)\\n[3] Burger, H.C., Schuler, C.J., Harmeling, S.: Image denoising: Can\\nplain neural networks compete with BM3D? In: IEEE Conference\", \"erations, \\u03b7is the learning rate, and \\u2202L\\n\\u2202W \\u2113\\ni\\nis the derivative.\\nThe \\ufb01lter weights of each layer are initialized by drawing\\nrandomly from a Gaussian distribution with zero mean\\nand standard deviation 0.001 (and 0 for biases). The\\nlearning rate is 10\\u22124 for the \\ufb01rst two layers, and 10\\u22125 for\\nthe last layer. We empirically \\ufb01nd that a smaller learning\\nrate in the last layer is important for the network to\\nconverge (similar to the denoising case [22]).\\nIn the training phase, the ground truth images {Xi}\\nare prepared as fsub\\u00d7fsub\\u00d7c-pixel sub-images randomly\\ncropped from the training images. By \\u201csub-images\\u201d we\\nmean these samples are treated as small \\u201cimages\\u201d rather\\nthan \\u201cpatches\\u201d, in the sense that \\u201cpatches\\u201d are overlap-\\nping and require some averaging as post-processing but\\n\\u201csub-images\\u201d need not. To synthesize the low-resolution\\nsamples {Yi}, we blur a sub-image by a Gaussian kernel,\\nsub-sample it by the upscaling factor, and upscale it by\\nthe same factor via bicubic interpolation.\\nTo avoid border effects during training, all the con-\\nvolutional layers have no padding, and the network\\nproduces a smaller output ( (fsub \\u2212f1 \\u2212f2 \\u2212f3 + 3)2 \\u00d7c).\\nThe MSE loss function is evaluated only by the difference\\nbetween the central pixels of Xi and the network output.\\nAlthough we use a \\ufb01xed image size in training, the\\nconvolutional neural network can be applied on images\\nof arbitrary sizes during testing.\\nWe implement our model using the cuda-convnet pack-\\nage [26]. We have also tried the Caffe package [24] and\\nobserved similar performance.\\n4 E XPERIMENTS\\nWe \\ufb01rst investigate the impact of using different datasets\\non the model performance. Next, we examine the \\ufb01lters\\nlearned by our approach. We then explore different\\narchitecture designs of the network, and study the rela-\\ntions between super-resolution performance and factors\\nlike depth, number of \\ufb01lters, and \\ufb01lter sizes. Subse-\\nquently, we compare our method with recent state-of-\\nthe-arts both quantitatively and qualitatively. Following\\n[42], super-resolution is only applied on the luminance\\nchannel (Y channel in YCbCr color space) in Sections 4.1-\\n4.4, so c = 1 in the \\ufb01rst/last layer, and performance\\n(e.g., PSNR and SSIM) is evaluated on the Y channel. At\\nlast, we extend the network to cope with color images\\nand evaluate the performance on different channels.\\n4.1 Training Data\\nAs shown in the literature, deep learning generally\\nbene\\ufb01ts from big data training. For comparison, we use\\na relatively small training set [41], [50] that consists\\nof 91 images, and a large training set that consists of\\n395,909 images from the ILSVRC 2013 ImageNet detec-\\ntion training partition. The size of training sub-images is\\nfsub = 33. Thus the 91-image dataset can be decomposed\\ninto 24,800 sub-images, which are extracted from origi-\\nnal images with a stride of 14. Whereas the ImageNet\\nprovides over 5 million sub-images even using a stride\\nof 33. We use the basic network settings, i.e., f1 = 9 ,\\nf2 = 1, f3 = 5, n1 = 64, and n2 = 32. We use the Set5 [2]\\nas the validation set. We observe a similar trend even\\nif we use the larger Set14 set [51]. The upscaling factor\\nis 3. We use the sparse-coding-based method [50] as our\\nbaseline, which achieves an average PSNR value of 31.42\\ndB.\\nThe test convergence curves of using different training\\nsets are shown in Figure 4. The training time on Ima-\\ngeNet is about the same as on the 91-image dataset since\\nthe number of backpropagations is the same. As can be\\nobserved, with the same number of backpropagations\\n(i.e.,8 \\u00d7108), the SRCNN +ImageNet achieves 32.52 dB,\\nhigher than 32.39 dB yielded by that trained on 91\\nimages. The results positively indicate that SRCNN per-\\nformance may be further boosted using a larger training\\nset, but the effect of big data is not as impressive as\\nthat shown in high-level vision problems [26]. This is\\nmainly because that the 91 images have already cap-\\ntured suf\\ufb01cient variability of natural images. On the\", \"only on the luminance channel. There are also works\\nattempting to super-resolve all channels simultaneously.\\nFor example, Kim and Kwon [25] and Dai et al.[7] apply\\ntheir model to each RGB channel and combined them to\\nproduce the \\ufb01nal results. However, none of them has\\nanalyzed the SR performance of different channels, and\\nthe necessity of recovering all three channels.\\n2.2 Convolutional Neural Networks\\nConvolutional neural networks (CNN) date back\\ndecades [27] and deep CNNs have recently shown an\\nexplosive popularity partially due to its success in image\\nclassi\\ufb01cation [18], [26]. They have also been success-\\nfully applied to other computer vision \\ufb01elds, such as\\nobject detection [34], [40], [52], face recognition [39], and\\npedestrian detection [35]. Several factors are of central\\nimportance in this progress: (i) the ef\\ufb01cient training\\nimplementation on modern powerful GPUs [26], (ii) the\\nproposal of the Recti\\ufb01ed Linear Unit (ReLU) [33] which\\nmakes convergence much faster while still presents good\\nquality [26], and (iii) the easy access to an abundance of\\ndata (like ImageNet [9]) for training larger models. Our\\nmethod also bene\\ufb01ts from these progresses.\\n2.3 Deep Learning for Image Restoration\\nThere have been a few studies of using deep learning\\ntechniques for image restoration. The multi-layer per-\\nceptron (MLP), whose all layers are fully-connected (in\\ncontrast to convolutional), is applied for natural image\\ndenoising [3] and post-deblurring denoising [36]. More\\nclosely related to our work, the convolutional neural net-\\nwork is applied for natural image denoising [22] and re-\\nmoving noisy patterns (dirt/rain) [12]. These restoration\\nproblems are more or less denoising-driven. Cui et al.[5]\\npropose to embed auto-encoder networks in their super-\\nresolution pipeline under the notion internal example-\\nbased approach [16]. The deep model is not speci\\ufb01cally\\ndesigned to be an end-to-end solution, since each layer\\nof the cascade requires independent optimization of the\\nself-similarity search process and the auto-encoder. On\\nthe contrary, the proposed SRCNN optimizes an end-to-\\nend mapping. Further, the SRCNN is faster at speed. It\\nis not only a quantitatively superior method, but also a\\npractically useful one.\\n3 C ONVOLUTIONAL NEURAL NETWORKS FOR\\nSUPER -RESOLUTION\\n3.1 Formulation\\nConsider a single low-resolution image, we \\ufb01rst upscale\\nit to the desired size using bicubic interpolation, which\\nis the only pre-processing we perform 3. Let us denote\\nthe interpolated image as Y. Our goal is to recover\\nfrom Y an image F(Y) that is as similar as possible\\nto the ground truth high-resolution image X. For the\\nease of presentation, we still call Y a \\u201clow-resolution\\u201d\\nimage, although it has the same size as X. We wish to\\nlearn a mapping F, which conceptually consists of three\\noperations:\\n1) Patch extraction and representation: this opera-\\ntion extracts (overlapping) patches from the low-\\nresolution image Y and represents each patch as a\\nhigh-dimensional vector. These vectors comprise a\\nset of feature maps, of which the number equals to\\nthe dimensionality of the vectors.\\n2) Non-linear mapping: this operation nonlinearly\\nmaps each high-dimensional vector onto another\\nhigh-dimensional vector. Each mapped vector is\\nconceptually the representation of a high-resolution\\npatch. These vectors comprise another set of feature\\nmaps.\\n3) Reconstruction: this operation aggregates the\\nabove high-resolution patch-wise representations\\nto generate the \\ufb01nal high-resolution image. This\\nimage is expected to be similar to the ground truth\\nX.\\nWe will show that all these operations form a convolu-\\ntional neural network. An overview of the network is\\ndepicted in Figure 2. Next we detail our de\\ufb01nition of\\neach operation.\\n3.1.1 Patch extraction and representation\\nA popular strategy in image restoration ( e.g., [1]) is to\\ndensely extract patches and then represent them by a set\\nof pre-trained bases such as PCA, DCT, Haar, etc. This\", \"sion [27], trees [46] or Random Forests [47]. In Dai et al.\\n[6] a multitude of patch-speci\\ufb01c regressors is learned and\\nthe most appropriate regressors selected during testing.\\nRecently convolutional neural network (CNN) based SR\\nalgorithms have shown excellent performance. In Wang\\net al. [59] the authors encode a sparse representation\\nprior into their feed-forward network architecture based on\\nthe learned iterative shrinkage and thresholding algorithm\\n(LISTA) [23]. Dong et al. [9, 10] used bicubic interpolation\\nto upscale an input image and trained a three layer deep\\nfully convolutional network end-to-end to achieve state-\\nof-the-art SR performance. Subsequently, it was shown\\nthat enabling the network to learn the upscaling \\ufb01lters\\ndirectly can further increase performance both in terms of\\naccuracy and speed [11, 48, 57]. With their deeply-recursive\\nconvolutional network (DRCN), Kim et al. [34] presented\\na highly performant architecture that allows for long-range\\npixel dependencies while keeping the number of model\\nparameters small. Of particular relevance for our paper are\\nthe works by Johnson et al. [33] and Bruna et al. [5],\\nwho rely on a loss function closer to perceptual similarity\\nto recover visually more convincing HR images.\\n1.1.2 Design of convolutional neural networks\\nThe state of the art for many computer vision problems is\\nmeanwhile set by speci\\ufb01cally designed CNN architectures\\nfollowing the success of the work by Krizhevsky et al. [37].\\nIt was shown that deeper network architectures can be\\ndif\\ufb01cult to train but have the potential to substantially\\nincrease the network\\u2019s accuracy as they allow modeling\\nmappings of very high complexity [49, 51]. To ef\\ufb01-\\nciently train these deeper network architectures, batch-\\nnormalization [32] is often used to counteract the internal\\nco-variate shift. Deeper network architectures have also\\nbeen shown to increase performance for SISR, e.g. Kim et\\nal. [34] formulate a recursive CNN and present state-of-the-\\nart results. Another powerful design choice that eases the\\ntraining of deep CNNs is the recently introduced concept of\\nresidual blocks [29] and skip-connections [30, 34]. Skip-\\nconnections relieve the network architecture of modeling\\nthe identity mapping that is trivial in nature, however, po-\\ntentially non-trivial to represent with convolutional kernels.\\nIn the context of SISR it was also shown that learning\\nupscaling \\ufb01lters is bene\\ufb01cial in terms of accuracy and speed\\n[11, 48, 57]. This is an improvement over Dong et al. [10]\\nwhere bicubic interpolation is employed to upscale the LR\\nobservation before feeding the image to the CNN.\\n1.1.3 Loss functions\\nPixel-wise loss functions such as MSE struggle to handle\\nthe uncertainty inherent in recovering lost high-frequency\\ndetails such as texture: minimizing MSE encourages \\ufb01nd-\\ning pixel-wise averages of plausible solutions which are\\ntypically overly-smooth and thus have poor perceptual qual-\\nity [42, 33, 13, 5]. Reconstructions of varying perceptual\\nFigure 3: Illustration of patches from the natural image\\nmanifold (red) and super-resolved patches obtained with\\nMSE (blue) and GAN (orange). The MSE-based solution\\nappears overly smooth due to the pixel-wise average of\\npossible solutions in the pixel space, while GAN drives the\\nreconstruction towards the natural image manifold produc-\\ning perceptually more convincing solutions.\\nquality are exempli\\ufb01ed with corresponding PSNR in Fig-\\nure 2. We illustrate the problem of minimizing MSE in Fig-\\nure 3 where multiple potential solutions with high texture\\ndetails are averaged to create a smooth reconstruction.\\nIn Mathieu et al. [42] and Denton et al. [7] the authors\\ntackled this problem by employing generative adversarial\\nnetworks (GANs) [22] for the application of image genera-\\ntion. Yu and Porikli [66] augment pixel-wise MSE loss with\\na discriminator loss to train a network that super-resolves\\nface images with large upscaling factors ( 8\\u00d7). GANs\", \"terion (IFC) [38], noise quality measure (NQM) [8],\\nweighted peak signal-to-noise ratio (WPSNR) and multi-\\nscale structure similarity index (MSSSIM) [44], which\\nobtain high correlation with the human perceptual scores\\nas reported in [46].\\n4.4.1 Quantitative and qualitative evaluation\\nAs shown in Tables 2, 3 and 4, the proposed SRCNN\\nyields the highest scores in most evaluation matrices\\n7. In the area of denoising [3], for each noise level a speci\\ufb01c network\\nis trained.\\n8. We use the same 200 images as in [46].\\n9\\n2 4 6 8 10 12\\nx(10\\n8\\n30.5\\n31\\n31.5\\n32\\n32.5\\n33\\nNumber(of(backprops\\nAverage(test(PSNR((dB)\\nANR - 31.92 dB\\nA+ - 32.59 dB\\nSRCNN\\nSC - 31.42 dB\\nBicubic - 30.39 dB\\nNE+LLE - 31.84 dB\\nKK - 32.28 dB\\nFig. 10. The test convergence curve of SRCNN and\\nresults of other methods on the Set5 dataset.\\nin all experiments 9. Note that our SRCNN results are\\nbased on the checkpoint of 8 \\u00d7108 backpropagations.\\nSpeci\\ufb01cally, for the upscaling factor 3, the average gains\\non PSNR achieved by SRCNN are 0.15 dB, 0.17 dB, and\\n0.13 dB, higher than the next best approach, A+ [42],\\non the three datasets. When we take a look at other\\nevaluation metrics, we observe that SC, to our surprise,\\ngets even lower scores than the bicubic interpolation\\non IFC and NQM. It is clear that the results of SC are\\nmore visually pleasing than that of bicubic interpolation.\\nThis indicates that these two metrics may not truthfully\\nreveal the image quality. Thus, regardless of these two\\nmetrics, SRCNN achieves the best performance among\\nall methods and scaling factors.\\nIt is worth pointing out that SRCNN surpasses the\\nbicubic baseline at the very beginning of the learning\\nstage (see Figure 1), and with moderate training, SR-\\nCNN outperforms existing state-of-the-art methods (see\\nFigure 4). Yet, the performance is far from converge.\\nWe conjecture that better results can be obtained given\\nlonger training time (see Figure 10).\\nFigures 14, 15 and 16 show the super-resolution results\\nof different approaches by an upscaling factor 3. As can\\nbe observed, the SRCNN produces much sharper edges\\nthan other approaches without any obvious artifacts\\nacross the image.\\nIn addition, we report to another recent deep learning\\nmethod for image super-resolution (DNC) of Cui et\\nal. [5]. As they employ a different blur kernel (a Gaussian\\n\\ufb01lter with a standard deviation of 0.55), we train a spe-\\nci\\ufb01c network (9-5-5) using the same blur kernel as DNC\\nfor fair quantitative comparison. The upscaling factor\\nis 3 and the training set is the 91-image dataset. From\\nthe convergence curve shown in Figure 11, we observe\\nthat our SRCNN surpasses DNC with just 2.7 \\u00d7107\\nbackprops, and a larger margin can be obtained given\\nlonger training time. This also demonstrates that the\\nend-to-end learning is superior to DNC, even if that\\nmodel is already \\u201cdeep\\u201d.\\n4.4.2 Running time\\nFigure 12 shows the running time comparisons of several\\nstate-of-the-art methods, along with their restoration\\nperformance on Set14. All baseline methods are obtained\\n9. The PSNR value of each image can be found in the supplementary\\n\\ufb01le.\\nfrom the corresponding authors\\u2019 MATLAB+MEX imple-\\nmentation, whereas ours are in pure C++. We pro\\ufb01le\\nthe running time of all the algorithms using the same\\nmachine (Intel CPU 3.10 GHz and 16 GB memory).\\nNote that the processing time of our approach is highly\\nlinear to the test image resolution, since all images go\\nthrough the same number of convolutions. Our method\\nis always a trade-off between performance and speed.\\nTo show this, we train three networks for comparison,\\nwhich are 9-1-5, 9-3-5, and 9-5-5. It is clear that the 9-\\n1-5 network is the fastest, while it still achieves better\\nperformance than the next state-of-the-art A+. Other\\nmethods are several times or even orders of magnitude\\nslower in comparison to 9-1-5 network. Note the speed\\ngap is not mainly caused by the different MATLAB/C++\\nimplementations; rather, the other methods need to solve\\ncomplex optimization problems on usage (e.g., sparse\"]}": {"cached_metrics_data": [{"metric_data": {"name": "Contextual Precision (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Faithfulness (ragas)", "threshold": 0.8, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.8, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Contextual Recall (ragas)", "threshold": 0.6, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.6, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Answer Relevancy (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}]}, "{\"actual_output\": \"The non-linear mapping layer in SRCNN, which uses 1x1 filters, essentially acts as a feature selector and combiner within the super-resolution pipeline. Think of the initial layer as extracting a set of features from the low-resolution image. This second layer then takes these features and recombines them in non-linear ways to create a more informative and refined set of features. While 1x1 convolutions don't change the spatial dimensions, they allow the network to learn complex relationships between the different feature maps (different aspects of the visual information) extracted by the first layer. This step is crucial for capturing the intricate details needed to reconstruct a high-resolution image. The ReLU (Rectified Linear Unit, a function that replaces negative values with zero) activation further enhances this non-linearity, adding another level of expressiveness to the model.\", \"context\": [\"The first layer extracts an n\\u2081\\u2011dimensional feature for each patch. In the second operation, we **map each of these n\\u2081\\u2011dimensional vectors into an n\\u2082\\u2011dimensional one. This is equivalent to applying n\\u2082 filters which have a trivial spatial support 1 \\u00d7 1 \\u2026 This operation non\\u2011linearly maps each high\\u2011dimensional vector onto another high\\u2011dimensional vector.\"], \"expected_output\": \"It transforms every patch\\u2011level feature vector (extracted by the first conv layer) into a new, lower\\u2011dimensional representation that will later be linearly combined into HR pixels. Because the spatial kernel is 1 \\u00d7 1, the mapping is applied channel\\u2011wise without mixing spatial positions, mimicking the sparse\\u2011coding step but in a single feed\\u2011forward pass.\", \"hyperparameters\": null, \"input\": \"In SRCNN, what practical role does the non\\u2011linear mapping layer with 1 \\u00d7 1 filters play in the overall SR pipeline?\", \"retrieval_context\": [\"1\\nImage Super-Resolution Using Deep\\nConvolutional Networks\\nChao Dong, Chen Change Loy, Member, IEEE,Kaiming He, Member, IEEE,\\nand Xiaoou Tang, Fellow, IEEE\\nAbstract\\u2014We propose a deep learning method for single image super-resolution (SR). Our method directly learns an end-to-end\\nmapping between the low/high-resolution images. The mapping is represented as a deep convolutional neural network (CNN) that takes\\nthe low-resolution image as the input and outputs the high-resolution one. We further show that traditional sparse-coding-based SR\\nmethods can also be viewed as a deep convolutional network. But unlike traditional methods that handle each component separately,\\nour method jointly optimizes all layers. Our deep CNN has a lightweight structure, yet demonstrates state-of-the-art restoration quality,\\nand achieves fast speed for practical on-line usage. We explore different network structures and parameter settings to achieve trade-\\noffs between performance and speed. Moreover, we extend our network to cope with three color channels simultaneously, and show\\nbetter overall reconstruction quality.\\nIndex Terms\\u2014Super-resolution, deep convolutional neural networks, sparse coding\\n!\\n1 I NTRODUCTION\\nSingle image super-resolution (SR) [20], which aims at\\nrecovering a high-resolution image from a single low-\\nresolution image, is a classical problem in computer\\nvision. This problem is inherently ill-posed since a mul-\\ntiplicity of solutions exist for any given low-resolution\\npixel. In other words, it is an underdetermined in-\\nverse problem, of which solution is not unique. Such\\na problem is typically mitigated by constraining the\\nsolution space by strong prior information. To learn\\nthe prior, recent state-of-the-art methods mostly adopt\\nthe example-based [46] strategy. These methods either\\nexploit internal similarities of the same image [5], [13],\\n[16], [19], [47], or learn mapping functions from external\\nlow- and high-resolution exemplar pairs [2], [4], [6],\\n[15], [23], [25], [37], [41], [42], [47], [48], [50], [51]. The\\nexternal example-based methods can be formulated for\\ngeneric image super-resolution, or can be designed to\\nsuit domain speci\\ufb01c tasks, i.e., face hallucination [30],\\n[50], according to the training samples provided.\\nThe sparse-coding-based method [49], [50] is one of the\\nrepresentative external example-based SR methods. This\\nmethod involves several steps in its solution pipeline.\\nFirst, overlapping patches are densely cropped from the\\ninput image and pre-processed ( e.g.,subtracting mean\\nand normalization). These patches are then encoded\\nby a low-resolution dictionary. The sparse coef\\ufb01cients\\nare passed into a high-resolution dictionary for recon-\\nstructing high-resolution patches. The overlapping re-\\n\\u2022 C. Dong, C. C. Loy and X. Tang are with the Department of Information\\nEngineering, The Chinese University of Hong Kong, Hong Kong.\\nE-mail: {dc012,ccloy,xtang}@ie.cuhk.edu.hk\\n\\u2022 K. He is with the Visual Computing Group, Microsoft Research Asia,\\nBeijing 100080, China.\\nEmail: kahe@microsoft.com\\nconstructed patches are aggregated ( e.g., by weighted\\naveraging) to produce the \\ufb01nal output. This pipeline is\\nshared by most external example-based methods, which\\npay particular attention to learning and optimizing the\\ndictionaries [2], [49], [50] or building ef\\ufb01cient mapping\\nfunctions [25], [41], [42], [47]. However, the rest of the\\nsteps in the pipeline have been rarely optimized or\\nconsidered in an uni\\ufb01ed optimization framework.\\nIn this paper, we show that the aforementioned\\npipeline is equivalent to a deep convolutional neural net-\\nwork [27] (more details in Section 3.2). Motivated by this\\nfact, we consider a convolutional neural network that\\ndirectly learns an end-to-end mapping between low- and\\nhigh-resolution images. Our method differs fundamen-\\ntally from existing external example-based approaches,\\nin that ours does not explicitly learn the dictionaries [41],\\n[49], [50] or manifolds [2], [4] for modeling the patch\", \"In this paper, we show that the aforementioned\\npipeline is equivalent to a deep convolutional neural net-\\nwork [27] (more details in Section 3.2). Motivated by this\\nfact, we consider a convolutional neural network that\\ndirectly learns an end-to-end mapping between low- and\\nhigh-resolution images. Our method differs fundamen-\\ntally from existing external example-based approaches,\\nin that ours does not explicitly learn the dictionaries [41],\\n[49], [50] or manifolds [2], [4] for modeling the patch\\nspace. These are implicitly achieved via hidden layers.\\nFurthermore, the patch extraction and aggregation are\\nalso formulated as convolutional layers, so are involved\\nin the optimization. In our method, the entire SR pipeline\\nis fully obtained through learning, with little pre/post-\\nprocessing.\\nWe name the proposed model Super-Resolution Con-\\nvolutional Neural Network (SRCNN) 1. The proposed\\nSRCNN has several appealing properties. First, its struc-\\nture is intentionally designed with simplicity in mind,\\nand yet provides superior accuracy 2 compared with\\nstate-of-the-art example-based methods. Figure 1 shows\\na comparison on an example. Second, with moderate\\n1. The implementation is available at http://mmlab.ie.cuhk.edu.hk/\\nprojects/SRCNN.html.\\n2. Numerical evaluations by using different metrics such as the Peak\\nSignal-to-Noise Ratio (PSNR), structure similarity index (SSIM) [43],\\nmulti-scale SSIM [44], information \\ufb01delity criterion [38], when the\\nground truth images are available.\\narXiv:1501.00092v3  [cs.CV]  31 Jul 2015\\n2\\nBicubic / 24.04 dB\\nSC / 25.58 dBSRCNN / 27.95 dB\\nOriginal / PSNR\\n2 4 6 8 10 12x 108\\n29.5\\n30\\n30.5\\n31\\n31.5\\n32\\n32.5\\n33\\nNumber of backprops\\nAverage test PSNR (dB)\\nSRCNN\\nSC\\nBicubic\\nBicubic / 24.04 dB\\nSC / 25.58 dBSRCNN / 27.95 dB\\nOriginal / PSNR\\nBicubic / 24.04 dB\\nSC / 25.58 dBSRCNN / 27.95 dB\\nOriginal / PSNR\\nSRCNN\\nSC\\nBicubic\\nBicubic / 24.04 dB\\nSC / 25.58 dBSRCNN / 27.95 dB\\nOriginal / PSNR\\nNumber of backprops\\nAverage test PSNR (dB)\\nFig. 1. The proposed Super-Resolution Convolutional\\nNeural Network (SRCNN) surpasses the bicubic baseline\\nwith just a few training iterations, and outperforms the\\nsparse-coding-based method (SC) [50] with moderate\\ntraining. The performance may be further improved with\\nmore training iterations. More details are provided in\\nSection 4.4.1 (the Set5 dataset with an upscaling factor\\n3). The proposed method provides visually appealing\\nreconstructed image.\\nnumbers of \\ufb01lters and layers, our method achieves\\nfast speed for practical on-line usage even on a CPU.\\nOur method is faster than a number of example-based\\nmethods, because it is fully feed-forward and does\\nnot need to solve any optimization problem on usage.\\nThird, experiments show that the restoration quality of\\nthe network can be further improved when (i) larger\\nand more diverse datasets are available, and/or (ii)\\na larger and deeper model is used. On the contrary,\\nlarger datasets/models can present challenges for exist-\\ning example-based methods. Furthermore, the proposed\\nnetwork can cope with three channels of color images\\nsimultaneously to achieve improved super-resolution\\nperformance.\\nOverall, the contributions of this study are mainly in\\nthree aspects:\\n1) We present a fully convolutional neural net-\\nwork for image super-resolution. The network di-\\nrectly learns an end-to-end mapping between low-\\nand high-resolution images, with little pre/post-\\nprocessing beyond the optimization.\\n2) We establish a relationship between our deep-\\nlearning-based SR method and the traditional\\nsparse-coding-based SR methods. This relationship\\nprovides a guidance for the design of the network\\nstructure.\\n3) We demonstrate that deep learning is useful in\\nthe classical computer vision problem of super-\\nresolution, and can achieve good quality and\\nspeed.\\nA preliminary version of this work was presented\\nearlier [11]. The present work adds to the initial version\\nin signi\\ufb01cant ways. Firstly, we improve the SRCNN by\\nintroducing larger \\ufb01lter size in the non-linear mapping\", \"bicubic interpolation. The training falls into a bad local\\nminimum, due to the inherently different characteristics\\nof the Y and Cb, Cr channels. (ii) If we pre-train on the\\nY or Cb, Cr channels, the performance \\ufb01nally improves,\\nbut is still not better than \\u201cY only\\u201d on the color image\\n(see the last column of Table 5, where PSNR is computed\\n(a) First-layer \\ufb01lters \\u2013 Cb channel\\n(b) First-layer \\ufb01lters \\u2013 Cr channel\\nFig. 13. Chrominance channels of the \\ufb01rst-layer \\ufb01lters\\nusing the \\u201cY pre-train\\u201d strategy.\\nin RGB color space). This suggests that the Cb, Cr\\nchannels could decrease the performance of the Y chan-\\nnel when training is performed in a uni\\ufb01ed network.\\n(iii) We observe that the Cb, Cr channels have higher\\nPSNR values for \\u201cY pre-train\\u201d than for \\u201cCbCr pre-train\\u201d.\\nThe reason lies on the differences between the Cb, Cr\\nchannels and the Y channel. Visually, the Cb, Cr channels\\nare more blurry than the Y channel, thus are less affected\\nby the downsampling process. When we pre-train on\\nthe Cb, Cr channels, there are only a few \\ufb01lters being\\nactivated. Then the training will soon fall into a bad\\nlocal minimum during \\ufb01ne-tuning. On the other hand,\\nif we pre-train on the Y channel, more \\ufb01lters will be\\nactivated, and the performance on Cb, Cr channels will\\nbe pushed much higher. Figure 13 shows the Cb, Cr\\nchannels of the \\ufb01rst-layer \\ufb01lters with \\u201cY pre-train\\u201d, of\\nwhich the patterns largely differ from that shown in\\nFigure 5. (iv) Training on the RGB channels achieves\\nthe best result on the color image. Different from the\\nYCbCr channels, the RGB channels exhibit high cross-\\ncorrelation among each other. The proposed SRCNN\\nis capable of leveraging such natural correspondences\\nbetween the channels for reconstruction. Therefore, the\\nmodel achieves comparable result on the Y channel as\\n\\u201cY only\\u201d, and better results on Cb, Cr channels than\\nbicubic interpolation. (v) In KK [25], super-resolution\\nis applied on each RGB channel separately. When we\\ntransform its results to YCbCr space, the PSNR value\\nof Y channel is similar as \\u201cY only\\u201d, but that of Cb, Cr\\nchannels are poorer than bicubic interpolation. The result\\nsuggests that the algorithm is biased to the Y channel.\\nOn the whole, our method trained on RGB channels\\nachieves better performance than KK and the single-\\nchannel network (\\u201cY only\\u201d). It is also worth noting that\\nthe improvement compared with the single-channel net-\\nwork is not that signi\\ufb01cant ( i.e., 0.07 dB). This indicates\\nthat the Cb, Cr channels barely help in improving the\\nperformance.\\n5 C ONCLUSION\\nWe have presented a novel deep learning approach\\nfor single image super-resolution (SR). We show that\\nconventional sparse-coding-based SR methods can be\\n12\\nreformulated into a deep convolutional neural network.\\nThe proposed approach, SRCNN, learns an end-to-end\\nmapping between low- and high-resolution images, with\\nlittle extra pre/post-processing beyond the optimization.\\nWith a lightweight structure, the SRCNN has achieved\\nsuperior performance than the state-of-the-art methods.\\nWe conjecture that additional performance can be further\\ngained by exploring more \\ufb01lters and different training\\nstrategies. Besides, the proposed structure, with its ad-\\nvantages of simplicity and robustness, could be applied\\nto other low-level vision problems, such as image de-\\nblurring or simultaneous SR+denoising. One could also\\ninvestigate a network to cope with different upscaling\\nfactors.\\nREFERENCES\\n[1] Aharon, M., Elad, M., Bruckstein, A.: K-SVD: An algorithm for\\ndesigning overcomplete dictionaries for sparse representation.\\nIEEE Transactions on Signal Processing 54(11), 4311\\u20134322 (2006)\\n[2] Bevilacqua, M., Roumy, A., Guillemot, C., Morel, M.L.A.: Low-\\ncomplexity single-image super-resolution based on nonnegative\\nneighbor embedding. In: British Machine Vision Conference\\n(2012)\\n[3] Burger, H.C., Schuler, C.J., Harmeling, S.: Image denoising: Can\\nplain neural networks compete with BM3D? In: IEEE Conference\", \"erations, \\u03b7is the learning rate, and \\u2202L\\n\\u2202W \\u2113\\ni\\nis the derivative.\\nThe \\ufb01lter weights of each layer are initialized by drawing\\nrandomly from a Gaussian distribution with zero mean\\nand standard deviation 0.001 (and 0 for biases). The\\nlearning rate is 10\\u22124 for the \\ufb01rst two layers, and 10\\u22125 for\\nthe last layer. We empirically \\ufb01nd that a smaller learning\\nrate in the last layer is important for the network to\\nconverge (similar to the denoising case [22]).\\nIn the training phase, the ground truth images {Xi}\\nare prepared as fsub\\u00d7fsub\\u00d7c-pixel sub-images randomly\\ncropped from the training images. By \\u201csub-images\\u201d we\\nmean these samples are treated as small \\u201cimages\\u201d rather\\nthan \\u201cpatches\\u201d, in the sense that \\u201cpatches\\u201d are overlap-\\nping and require some averaging as post-processing but\\n\\u201csub-images\\u201d need not. To synthesize the low-resolution\\nsamples {Yi}, we blur a sub-image by a Gaussian kernel,\\nsub-sample it by the upscaling factor, and upscale it by\\nthe same factor via bicubic interpolation.\\nTo avoid border effects during training, all the con-\\nvolutional layers have no padding, and the network\\nproduces a smaller output ( (fsub \\u2212f1 \\u2212f2 \\u2212f3 + 3)2 \\u00d7c).\\nThe MSE loss function is evaluated only by the difference\\nbetween the central pixels of Xi and the network output.\\nAlthough we use a \\ufb01xed image size in training, the\\nconvolutional neural network can be applied on images\\nof arbitrary sizes during testing.\\nWe implement our model using the cuda-convnet pack-\\nage [26]. We have also tried the Caffe package [24] and\\nobserved similar performance.\\n4 E XPERIMENTS\\nWe \\ufb01rst investigate the impact of using different datasets\\non the model performance. Next, we examine the \\ufb01lters\\nlearned by our approach. We then explore different\\narchitecture designs of the network, and study the rela-\\ntions between super-resolution performance and factors\\nlike depth, number of \\ufb01lters, and \\ufb01lter sizes. Subse-\\nquently, we compare our method with recent state-of-\\nthe-arts both quantitatively and qualitatively. Following\\n[42], super-resolution is only applied on the luminance\\nchannel (Y channel in YCbCr color space) in Sections 4.1-\\n4.4, so c = 1 in the \\ufb01rst/last layer, and performance\\n(e.g., PSNR and SSIM) is evaluated on the Y channel. At\\nlast, we extend the network to cope with color images\\nand evaluate the performance on different channels.\\n4.1 Training Data\\nAs shown in the literature, deep learning generally\\nbene\\ufb01ts from big data training. For comparison, we use\\na relatively small training set [41], [50] that consists\\nof 91 images, and a large training set that consists of\\n395,909 images from the ILSVRC 2013 ImageNet detec-\\ntion training partition. The size of training sub-images is\\nfsub = 33. Thus the 91-image dataset can be decomposed\\ninto 24,800 sub-images, which are extracted from origi-\\nnal images with a stride of 14. Whereas the ImageNet\\nprovides over 5 million sub-images even using a stride\\nof 33. We use the basic network settings, i.e., f1 = 9 ,\\nf2 = 1, f3 = 5, n1 = 64, and n2 = 32. We use the Set5 [2]\\nas the validation set. We observe a similar trend even\\nif we use the larger Set14 set [51]. The upscaling factor\\nis 3. We use the sparse-coding-based method [50] as our\\nbaseline, which achieves an average PSNR value of 31.42\\ndB.\\nThe test convergence curves of using different training\\nsets are shown in Figure 4. The training time on Ima-\\ngeNet is about the same as on the 91-image dataset since\\nthe number of backpropagations is the same. As can be\\nobserved, with the same number of backpropagations\\n(i.e.,8 \\u00d7108), the SRCNN +ImageNet achieves 32.52 dB,\\nhigher than 32.39 dB yielded by that trained on 91\\nimages. The results positively indicate that SRCNN per-\\nformance may be further boosted using a larger training\\nset, but the effect of big data is not as impressive as\\nthat shown in high-level vision problems [26]. This is\\nmainly because that the 91 images have already cap-\\ntured suf\\ufb01cient variability of natural images. On the\", \"only on the luminance channel. There are also works\\nattempting to super-resolve all channels simultaneously.\\nFor example, Kim and Kwon [25] and Dai et al.[7] apply\\ntheir model to each RGB channel and combined them to\\nproduce the \\ufb01nal results. However, none of them has\\nanalyzed the SR performance of different channels, and\\nthe necessity of recovering all three channels.\\n2.2 Convolutional Neural Networks\\nConvolutional neural networks (CNN) date back\\ndecades [27] and deep CNNs have recently shown an\\nexplosive popularity partially due to its success in image\\nclassi\\ufb01cation [18], [26]. They have also been success-\\nfully applied to other computer vision \\ufb01elds, such as\\nobject detection [34], [40], [52], face recognition [39], and\\npedestrian detection [35]. Several factors are of central\\nimportance in this progress: (i) the ef\\ufb01cient training\\nimplementation on modern powerful GPUs [26], (ii) the\\nproposal of the Recti\\ufb01ed Linear Unit (ReLU) [33] which\\nmakes convergence much faster while still presents good\\nquality [26], and (iii) the easy access to an abundance of\\ndata (like ImageNet [9]) for training larger models. Our\\nmethod also bene\\ufb01ts from these progresses.\\n2.3 Deep Learning for Image Restoration\\nThere have been a few studies of using deep learning\\ntechniques for image restoration. The multi-layer per-\\nceptron (MLP), whose all layers are fully-connected (in\\ncontrast to convolutional), is applied for natural image\\ndenoising [3] and post-deblurring denoising [36]. More\\nclosely related to our work, the convolutional neural net-\\nwork is applied for natural image denoising [22] and re-\\nmoving noisy patterns (dirt/rain) [12]. These restoration\\nproblems are more or less denoising-driven. Cui et al.[5]\\npropose to embed auto-encoder networks in their super-\\nresolution pipeline under the notion internal example-\\nbased approach [16]. The deep model is not speci\\ufb01cally\\ndesigned to be an end-to-end solution, since each layer\\nof the cascade requires independent optimization of the\\nself-similarity search process and the auto-encoder. On\\nthe contrary, the proposed SRCNN optimizes an end-to-\\nend mapping. Further, the SRCNN is faster at speed. It\\nis not only a quantitatively superior method, but also a\\npractically useful one.\\n3 C ONVOLUTIONAL NEURAL NETWORKS FOR\\nSUPER -RESOLUTION\\n3.1 Formulation\\nConsider a single low-resolution image, we \\ufb01rst upscale\\nit to the desired size using bicubic interpolation, which\\nis the only pre-processing we perform 3. Let us denote\\nthe interpolated image as Y. Our goal is to recover\\nfrom Y an image F(Y) that is as similar as possible\\nto the ground truth high-resolution image X. For the\\nease of presentation, we still call Y a \\u201clow-resolution\\u201d\\nimage, although it has the same size as X. We wish to\\nlearn a mapping F, which conceptually consists of three\\noperations:\\n1) Patch extraction and representation: this opera-\\ntion extracts (overlapping) patches from the low-\\nresolution image Y and represents each patch as a\\nhigh-dimensional vector. These vectors comprise a\\nset of feature maps, of which the number equals to\\nthe dimensionality of the vectors.\\n2) Non-linear mapping: this operation nonlinearly\\nmaps each high-dimensional vector onto another\\nhigh-dimensional vector. Each mapped vector is\\nconceptually the representation of a high-resolution\\npatch. These vectors comprise another set of feature\\nmaps.\\n3) Reconstruction: this operation aggregates the\\nabove high-resolution patch-wise representations\\nto generate the \\ufb01nal high-resolution image. This\\nimage is expected to be similar to the ground truth\\nX.\\nWe will show that all these operations form a convolu-\\ntional neural network. An overview of the network is\\ndepicted in Figure 2. Next we detail our de\\ufb01nition of\\neach operation.\\n3.1.1 Patch extraction and representation\\nA popular strategy in image restoration ( e.g., [1]) is to\\ndensely extract patches and then represent them by a set\\nof pre-trained bases such as PCA, DCT, Haar, etc. This\", \"sparse-coding-based SR methods. This relationship\\nprovides a guidance for the design of the network\\nstructure.\\n3) We demonstrate that deep learning is useful in\\nthe classical computer vision problem of super-\\nresolution, and can achieve good quality and\\nspeed.\\nA preliminary version of this work was presented\\nearlier [11]. The present work adds to the initial version\\nin signi\\ufb01cant ways. Firstly, we improve the SRCNN by\\nintroducing larger \\ufb01lter size in the non-linear mapping\\nlayer, and explore deeper structures by adding non-\\nlinear mapping layers. Secondly, we extend the SRCNN\\nto process three color channels (either in YCbCr or RGB\\ncolor space) simultaneously. Experimentally, we demon-\\nstrate that performance can be improved in comparison\\nto the single-channel network. Thirdly, considerable new\\nanalyses and intuitive explanations are added to the\\ninitial results. We also extend the original experiments\\nfrom Set5 [2] and Set14 [51] test images to BSD200 [32]\\n(200 test images). In addition, we compare with a num-\\nber of recently published methods and con\\ufb01rm that\\nour model still outperforms existing approaches using\\ndifferent evaluation metrics.\\n2 R ELATED WORK\\n2.1 Image Super-Resolution\\nAccording to the image priors, single-image super res-\\nolution algorithms can be categorized into four types \\u2013\\nprediction models, edge based methods, image statistical\\nmethods and patch based (or example-based) methods.\\nThese methods have been thoroughly investigated and\\nevaluated in Yang et al.\\u2019s work [46]. Among them, the\\nexample-based methods [16], [25], [41], [47] achieve the\\nstate-of-the-art performance.\\nThe internal example-based methods exploit the self-\\nsimilarity property and generate exemplar patches from\\nthe input image. It is \\ufb01rst proposed in Glasner\\u2019s\\nwork [16], and several improved variants [13], [45] are\\nproposed to accelerate the implementation. The exter-\\nnal example-based methods [2], [4], [6], [15], [37], [41],\\n[48], [49], [50], [51] learn a mapping between low/high-\\nresolution patches from external datasets. These studies\\nvary on how to learn a compact dictionary or manifold\\nspace to relate low/high-resolution patches, and on how\\nrepresentation schemes can be conducted in such spaces.\\nIn the pioneer work of Freeman et al. [14], the dic-\\ntionaries are directly presented as low/high-resolution\\npatch pairs, and the nearest neighbour (NN) of the input\\npatch is found in the low-resolution space, with its corre-\\nsponding high-resolution patch used for reconstruction.\\nChang et al. [4] introduce a manifold embedding tech-\\nnique as an alternative to the NN strategy. In Yanget al.\\u2019s\\nwork [49], [50], the above NN correspondence advances\\nto a more sophisticated sparse coding formulation. Other\\nmapping functions such as kernel regression [25], simple\\n3\\nfunction [47], random forest [37] and anchored neigh-\\nborhood regression [41], [42] are proposed to further\\nimprove the mapping accuracy and speed. The sparse-\\ncoding-based method and its several improvements [41],\\n[42], [48] are among the state-of-the-art SR methods\\nnowadays. In these methods, the patches are the focus\\nof the optimization; the patch extraction and aggregation\\nsteps are considered as pre/post-processing and handled\\nseparately.\\nThe majority of SR algorithms [2], [4], [15], [41], [48],\\n[49], [50], [51] focus on gray-scale or single-channel\\nimage super-resolution. For color images, the aforemen-\\ntioned methods \\ufb01rst transform the problem to a dif-\\nferent color space (YCbCr or YUV), and SR is applied\\nonly on the luminance channel. There are also works\\nattempting to super-resolve all channels simultaneously.\\nFor example, Kim and Kwon [25] and Dai et al.[7] apply\\ntheir model to each RGB channel and combined them to\\nproduce the \\ufb01nal results. However, none of them has\\nanalyzed the SR performance of different channels, and\\nthe necessity of recovering all three channels.\\n2.2 Convolutional Neural Networks\\nConvolutional neural networks (CNN) date back\", \"the \\ufb01nal full image. The averaging can be considered\\nas a pre-de\\ufb01ned \\ufb01lter on a set of feature maps (where\\neach position is the \\u201c\\ufb02attened\\u201d vector form of a high-\\nresolution patch). Motivated by this, we de\\ufb01ne a convo-\\nlutional layer to produce the \\ufb01nal high-resolution image:\\nF(Y) = W3 \\u2217F2(Y) + B3. (3)\\n4. The ReLU can be equivalently considered as a part of the second\\noperation (Non-linear mapping), and the \\ufb01rst operation (Patch extrac-\\ntion and representation) becomes purely linear convolution.\\nHere W3 corresponds to c \\ufb01lters of a size n2 \\u00d7f3 \\u00d7f3,\\nand B3 is a c-dimensional vector.\\nIf the representations of the high-resolution patches\\nare in the image domain (i.e.,we can simply reshape each\\nrepresentation to form the patch), we expect that the\\n\\ufb01lters act like an averaging \\ufb01lter; if the representations\\nof the high-resolution patches are in some other domains\\n(e.g.,coef\\ufb01cients in terms of some bases), we expect that\\nW3 behaves like \\ufb01rst projecting the coef\\ufb01cients onto the\\nimage domain and then averaging. In either way, W3 is\\na set of linear \\ufb01lters.\\nInterestingly, although the above three operations are\\nmotivated by different intuitions, they all lead to the\\nsame form as a convolutional layer. We put all three\\noperations together and form a convolutional neural\\nnetwork (Figure 2). In this model, all the \\ufb01ltering weights\\nand biases are to be optimized. Despite the succinctness\\nof the overall structure, our SRCNN model is carefully\\ndeveloped by drawing extensive experience resulted\\nfrom signi\\ufb01cant progresses in super-resolution [49], [50].\\nWe detail the relationship in the next section.\\n3.2 Relationship to Sparse-Coding-Based Methods\\nWe show that the sparse-coding-based SR methods [49],\\n[50] can be viewed as a convolutional neural network.\\nFigure 3 shows an illustration.\\nIn the sparse-coding-based methods, let us consider\\nthat an f1 \\u00d7f1 low-resolution patch is extracted from\\nthe input image. Then the sparse coding solver, like\\nFeature-Sign [29], will \\ufb01rst project the patch onto a (low-\\nresolution) dictionary. If the dictionary size is n1, this\\nis equivalent to applying n1 linear \\ufb01lters ( f1 \\u00d7f1) on\\nthe input image (the mean subtraction is also a linear\\noperation so can be absorbed). This is illustrated as the\\nleft part of Figure 3.\\nThe sparse coding solver will then iteratively process\\nthe n1 coef\\ufb01cients. The outputs of this solver are n2\\ncoef\\ufb01cients, and usually n2 = n1 in the case of sparse\\ncoding. These n2 coef\\ufb01cients are the representation of\\nthe high-resolution patch. In this sense, the sparse coding\\n5\\nresponses\\nof patch of\\nneighbouring\\npatches\\n Patch extraction\\nand representation\\nNon-linear\\n mapping\\nReconstruction\\nFig. 3. An illustration of sparse-coding-based methods in the view of a convolutional neural network.\\nsolver behaves as a special case of a non-linear mapping\\noperator, whose spatial support is 1 \\u00d71. See the middle\\npart of Figure 3. However, the sparse coding solver is\\nnot feed-forward, i.e.,it is an iterative algorithm. On the\\ncontrary, our non-linear operator is fully feed-forward\\nand can be computed ef\\ufb01ciently. If we set f2 = 1, then\\nour non-linear operator can be considered as a pixel-wise\\nfully-connected layer. It is worth noting that \\u201cthe sparse\\ncoding solver\\u201d in SRCNN refers to the \\ufb01rst two layers,\\nbut not just the second layer or the activation function\\n(ReLU). Thus the nonlinear operation in SRCNN is also\\nwell optimized through the learning process.\\nThe above n2 coef\\ufb01cients (after sparse coding) are\\nthen projected onto another (high-resolution) dictionary\\nto produce a high-resolution patch. The overlapping\\nhigh-resolution patches are then averaged. As discussed\\nabove, this is equivalent to linear convolutions on the\\nn2 feature maps. If the high-resolution patches used for\\nreconstruction are of size f3 \\u00d7f3, then the linear \\ufb01lters\\nhave an equivalent spatial support of size f3 \\u00d7f3. See\\nthe right part of Figure 3.\\nThe above discussion shows that the sparse-coding-\", \"to generate the \\ufb01nal high-resolution image. This\\nimage is expected to be similar to the ground truth\\nX.\\nWe will show that all these operations form a convolu-\\ntional neural network. An overview of the network is\\ndepicted in Figure 2. Next we detail our de\\ufb01nition of\\neach operation.\\n3.1.1 Patch extraction and representation\\nA popular strategy in image restoration ( e.g., [1]) is to\\ndensely extract patches and then represent them by a set\\nof pre-trained bases such as PCA, DCT, Haar, etc. This\\nis equivalent to convolving the image by a set of \\ufb01lters,\\neach of which is a basis. In our formulation, we involve\\nthe optimization of these bases into the optimization of\\nthe network. Formally, our \\ufb01rst layer is expressed as an\\noperation F1:\\nF1(Y) = max (0,W1 \\u2217Y + B1) , (1)\\nwhere W1 and B1 represent the \\ufb01lters and biases re-\\nspectively, and \\u2019 \\u2217\\u2019 denotes the convolution operation.\\nHere, W1 corresponds to n1 \\ufb01lters of support c\\u00d7f1 \\u00d7f1,\\nwhere c is the number of channels in the input image,\\nf1 is the spatial size of a \\ufb01lter. Intuitively, W1 applies\\nn1 convolutions on the image, and each convolution has\\n3. Bicubic interpolation is also a convolutional operation, so it can\\nbe formulated as a convolutional layer. However, the output size of\\nthis layer is larger than the input size, so there is a fractional stride. To\\ntake advantage of the popular well-optimized implementations such\\nas cuda-convnet [26], we exclude this \\u201clayer\\u201d from learning.\\n4\\nfeature maps\\n Patch extraction\\nand representation Non-linear mapping Reconstruction\\nLow-resolution\\nimage (input)\\nHigh-resolution\\nimage (output)\\nof low-resolution image of high-resolution image\\nfeature maps\\nFig. 2. Given a low-resolution image Y, the \\ufb01rst convolutional layer of the SRCNN extracts a set of feature maps. The\\nsecond layer maps these feature maps nonlinearly to high-resolution patch representations. The last layer combines\\nthe predictions within a spatial neighbourhood to produce the \\ufb01nal high-resolution image F(Y).\\na kernel size c \\u00d7f1 \\u00d7f1. The output is composed of\\nn1 feature maps. B1 is an n1-dimensional vector, whose\\neach element is associated with a \\ufb01lter. We apply the\\nRecti\\ufb01ed Linear Unit (ReLU, max(0,x)) [33] on the \\ufb01lter\\nresponses4.\\n3.1.2 Non-linear mapping\\nThe \\ufb01rst layer extracts an n1-dimensional feature for\\neach patch. In the second operation, we map each of\\nthese n1-dimensional vectors into an n2-dimensional\\none. This is equivalent to applying n2 \\ufb01lters which have\\na trivial spatial support 1 \\u00d71. This interpretation is only\\nvalid for 1\\u00d71 \\ufb01lters. But it is easy to generalize to larger\\n\\ufb01lters like 3 \\u00d73 or 5 \\u00d75. In that case, the non-linear\\nmapping is not on a patch of the input image; instead,\\nit is on a 3 \\u00d73 or 5 \\u00d75 \\u201cpatch\\u201d of the feature map. The\\noperation of the second layer is:\\nF2(Y) = max (0,W2 \\u2217F1(Y) + B2) . (2)\\nHere W2 contains n2 \\ufb01lters of size n1 \\u00d7f2 \\u00d7f2, and B2 is\\nn2-dimensional. Each of the output n2-dimensional vec-\\ntors is conceptually a representation of a high-resolution\\npatch that will be used for reconstruction.\\nIt is possible to add more convolutional layers to\\nincrease the non-linearity. But this can increase the com-\\nplexity of the model ( n2 \\u00d7f2 \\u00d7f2 \\u00d7n2 parameters for\\none layer), and thus demands more training time. We\\nwill explore deeper structures by introducing additional\\nnon-linear mapping layers in Section 4.3.3.\\n3.1.3 Reconstruction\\nIn the traditional methods, the predicted overlapping\\nhigh-resolution patches are often averaged to produce\\nthe \\ufb01nal full image. The averaging can be considered\\nas a pre-de\\ufb01ned \\ufb01lter on a set of feature maps (where\\neach position is the \\u201c\\ufb02attened\\u201d vector form of a high-\\nresolution patch). Motivated by this, we de\\ufb01ne a convo-\\nlutional layer to produce the \\ufb01nal high-resolution image:\\nF(Y) = W3 \\u2217F2(Y) + B3. (3)\\n4. The ReLU can be equivalently considered as a part of the second\\noperation (Non-linear mapping), and the \\ufb01rst operation (Patch extrac-\\ntion and representation) becomes purely linear convolution.\"]}": {"cached_metrics_data": [{"metric_data": {"name": "Contextual Precision (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Faithfulness (ragas)", "threshold": 0.8, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.8, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Contextual Recall (ragas)", "threshold": 0.6, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.6, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Answer Relevancy (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}]}, "{\"actual_output\": \"The authors are concerned that if many trading firms use similarly prompted Large Language Model (LLM) based trading agents, it could lead to increased systemic risk in financial markets. Specifically, they highlight the risk of correlated behavior: because these agents would be built on similar underlying architectures and responding to the same market signals in similar ways (due to similar prompts), they might make the same trading decisions at the same time. This could amplify market instability, potentially causing:\\n\\nExaggerated Price Swings: If many LLMs simultaneously decide to buy or sell a particular asset, it could lead to larger-than-normal price increases or decreases, increasing market volatility.\\n\\nFlash Crashes: In extreme cases, this correlated selling could create a sudden, sharp drop in prices, similar to a flash crash.\\n\\nBubble Formation and Bursting: Similarly, correlated buying by many LLMs could inflate asset bubbles, which could then burst dramatically when the LLMs decide to sell. This is especially risky because the LLMs might continue to follow their instructions even when a bubble is forming, unlike human traders who might recognize the bubble and adjust their strategy.\", \"context\": [\"A key concern is the potential for widespread correlated behavior\\u2026 similar underlying LLM architectures responding uniformly\\u2026 could destabilize trading patterns without explicit coordination.\"], \"expected_output\": \"If many firms deploy similarly prompted LLMs built on the same foundation model, their synchronised reactions could amplify volatility and create new instabilities.\", \"hyperparameters\": null, \"input\": \"What systemic risks do the authors foresee if many firms deploy similarly prompted LLM traders in real markets?\", \"retrieval_context\": [\"(2023)). This work, however, focuses on financial markets and how LLM agents can operate\\nas full-fledged trading participants.\\nRecent research examines specific applications of LLMs for trading. FinMem and Trad-\\ningGPT introduce frameworks with layered memory systems and customizable agent traits\\n5\\nto improve financial decision-making (Yu, Li, et al. 2024; Li, Zhang, and Sun 2023). Hierar-\\nchical multi-agent architectures have been explored in FinCon, which uses a manager-analyst\\nsetup for collaborative portfolio decisions (Yu, Yao, et al. 2024). QuantAgent implements\\na self-improving signal-mining approach (Wang et al. 2024), while other work underscores\\nthe importance of long-term memory in LLM agents via vector databases (Hatalis et al.\\n2024). This line of research builds on successful reinforcement learning applications such as\\nAlphaPortfolio (Cong et al. 2021) and AlphaManager (Campello, Cong, and Zhou 2023),\\nwhich leverage deep RL and robust control for portfolio management.\\nAnalyzing LLM agent behavior by changing only some parameters draws on methods\\nfrom the interpretable machine learning literature. In particular, the systematic variation\\nof market parameters to reveal decision patterns mirrors partial dependence plots and in-\\ndividual conditional expectation curves used to interpret complex machine learning models\\n(Molnar 2022). These techniques help reveal how LLM agents respond to changes in specific\\nvariables while holding others constant, providing insight into their internal decision-making\\nprocesses that would otherwise remain opaque.\\nBeyond finance, studies of LLM capabilities in interactive or multi-agent settings offer\\nvaluable insights. Benchmarks like AgentBench evaluate LLMs\\u2019 performance in interac-\\ntive tasks (Liu et al. 2023), while InvestorBench focuses on financial decision-making tasks\\nspecifically (H. Li et al. 2024). NegotiationArena demonstrates LLMs\\u2019 capacity for strategic\\ninteraction in bargaining contexts (Bianchi et al. 2024). Similarly, Guo et al. (2024) provide\\nan economics \\u201darena\\u201d where LLMs compete in strategic games, revealing that advanced\\nmodels like GPT-4 can exhibit rational, adaptive behavior\\u2014albeit not always reaching Nash\\nEquilibrium. Existing frameworks typically assess individual agents or hierarchical collab-\\norations, whereas this work studies emergent market behaviors that arise from multiple\\nindependent LLM traders interacting in a marketplace.\\nThe approach also connects to the tradition of experimental asset markets. For instance,\\nWeitzel et al. (2020) show that even finance professionals are susceptible to speculative\\n6\\nbubbles, especially amid high capital inflows. Kop\\u00b4 anyi-Peuker and Weber (2021) find that\\ntrading experience alone does not eliminate bubbles, challenging assumptions about rational\\nmarket learning. Kirchler, Huber, and St\\u00a8 ockl (2012) identify confusion about fundamental\\nvalues as a key driver of bubble formation. This framework offers a new way to study these\\nphenomena with LLM traders, which can be rigorously parameterized for sophistication,\\nstrategy, and information processing. Hence, this paper provides a method to investigate\\nhow automated or \\u201dartificial\\u201d agents might affect market stability or volatility.\\nOther recent work highlights the versatility of LLM agents in complex, interactive sce-\\nnarios beyond finance. One stream focuses on simulating social behaviors\\u2014such as opinion\\ndynamics (Chuang et al. 2023), trust (Xie et al. 2024), and resource-sharing (Piatti et al.\\n2024). Another examines LLMs\\u2019 strategic capabilities through task-based simulations and\\ncollaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\\nWithin the computer science literature, early works apply LLMs to financial markets but\\nabstract away many fundamental stock market characteristics. Often, they employ single-\\nprice clearing mechanisms without a persistent order book, ignore partial fills and bid-ask\", \"2024). Another examines LLMs\\u2019 strategic capabilities through task-based simulations and\\ncollaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\\nWithin the computer science literature, early works apply LLMs to financial markets but\\nabstract away many fundamental stock market characteristics. Often, they employ single-\\nprice clearing mechanisms without a persistent order book, ignore partial fills and bid-ask\\nspreads, and omit dividends. Consequently, these simplified environments can primarily\\naddress exogenous macro shocks (e.g., changes in interest rates or inflation; Gao et al. 2024),\\nexogenous policy changes (Zhang et al. 2024), or rely on advanced methods such as repetitive\\nnext-token predictions to generate better answers (Koa et al. 2024). This work extends\\nthese efforts by incorporating these crucial market features, enabling the study of complex\\nendogenous events such as flash crashes, liquidity shocks, and large-trader impacts.\\nThis work also connects to emerging research on algorithmic and AI-powered trading\\nsystems. Dou, Goldstein, and Ji (2024) demonstrate how reinforcement learning-based AI\\nspeculators can autonomously learn to sustain collusive behavior without explicit coordi-\\nnation, achieving supra-competitive profits through either price-trigger strategies or self-\\nconfirming bias in learning. This finding is particularly informative for this framework as\\nit highlights potential emergent behaviors that may arise when intelligent agents interact in\\n7\\nmarkets\\u2014behaviors that could manifest differently with LLM agents due to their natural\\nlanguage reasoning capabilities. Similarly, Colliard, Foucault, and Lovo (2022) examine al-\\ngorithmic market makers using Q-learning and find they charge markups that increase when\\nadverse selection costs decrease\\u2014contrary to Nash equilibrium predictions. Their work pro-\\nvides methodological insights on how to test strategic pricing behaviors against theoretical\\nbenchmarks incorporated into this LLM-based framework.\\nFinally, this approach is informed by complexity economics, which views markets as dy-\\nnamic, non-equilibrium systems where agents adaptively learn and evolve strategies (Arthur\\n2013; Wolfram 2017). According to this view, markets exhibit emergent phenomena and\\nself-organization, especially when trading agents (human or artificial) update their behav-\\nior in response to outcomes. This paradigm is particularly relevant in an era of increasing\\nautomation and algorithmic trading (Balland et al. 2022; Ping 2019). Like adaptive agents\\nin complexity economics, these LLM traders incorporate new information and adjust their\\nstrategies, generating emergent market patterns\\u2014a key motivation behind this framework.\\nUnlike previous frameworks that abstract away crucial market features or focus on narrow\\nstrategies, this system incorporates realistic market microstructure while accommodating\\nheterogeneous agents interacting simultaneously. While earlier work demonstrates LLMs\\u2019\\npromise for macroeconomic modeling and simple trading simulations, this work introduces a\\ncomplex, open-source financial market platform that supports multiple agent architectures,\\nthorough market microstructure (limit orders, partial fills, dividends), and rigorous testing\\nprotocols\\u2014fulfilling a critical need in complexity economics research and market microstruc-\\nture analysis.\\n2 Methodology\\nThe methodology section contains three parts. The first part describes the market design,\\nthe second agents\\u2019 design, and the third the analysis module.\\n8\\n2.1 Market Design\\nOur methodological framework integrates three components that create a controlled envi-\\nronment for LLM-based trading agents. The framework implements a flexible continuous\\ndouble-auction market mechanism that couples standard market microstructure principles\\nwith market clearing and matching algorithms to accommodate asynchronous LLM decisions.\", \"33\\nants, allowing researchers to study how different belief structures influence price formation\\nand trading patterns under different initial mispricings. In these scenarios, the fundamental\\nprice is hidden from agents, forcing them to rely on their own valuation models.\\n3.2.5 Market Stress\\nThis scenario tests market resilience under challenging conditions by creating a more volatile\\nenvironment. The scenario includes two consistently bullish Optimistic traders, two consis-\\ntently bearish Pessimistic traders, two Market makers (liquidity providers), and two Value\\ninvestors (rational benchmark traders). The scenario runs for 100 rounds to study long-term\\nmarket behavior and includes unequal initial endowments, with optimistic traders having\\nmore cash (1.5x baseline) but fewer shares (0.5x baseline) and pessimistic traders having less\\ncash (0.5x baseline) but more shares (1.5x baseline). This resource imbalance tests whether\\nparticular agent types can dominate market outcomes through resource advantages.\\nThe scenarios presented here demonstrate the framework\\u2019s capabilities for exploring di-\\nverse market conditions. Its modular structure facilitates the straightforward definition and\\nimplementation of alternative experimental designs, enabling researchers to tailor simulations\\nto specific research questions.\\nIn all scenarios, we maintain consistent baseline parameters with a fundamental value\\nof $28.00, calculated from the expected dividend of $1.40 and interest rate of 5%. Agent\\nendowments start at 1,000,000 monetary units and 10,000 shares unless specifically modified.\\nTransaction costs are set to zero to isolate the effects of agent behavior and market structure\\non price formation.\\n4 Conclusion\\nThis paper demonstrates that Large Language Models can effectively function as diverse\\ntrading agents\\u2014from value investors to market makers\\u2014maintaining strategic consistency\\n34\\nwhile adapting to market conditions. Our experimental framework reveals that their in-\\nteractions generate realistic market dynamics, including phenomena like price bubbles and\\ncorrections, highlighting both the capabilities and potential risks of deploying LLM agents\\nin financial markets.\\nThese findings carry significant implications for market structure and regulation. While\\nLLM agents can enhance price discovery and liquidity, their adherence to programmed strate-\\ngies, even potentially flawed ones derived from prompts, could amplify market volatility or\\nintroduce novel systemic risks, as observed in our simulated bubble scenarios. A key concern\\nis the potential for widespread correlated behavior: similar underlying LLM architectures\\nresponding uniformly to comparable prompts or market signals could inadvertently create\\ndestabilizing trading patterns without explicit coordination. This underscores the critical\\nneed for rigorous testing and validation of LLM-based trading systems prior to live deploy-\\nment.\\nA central contribution of this work is the open-source simulation framework itself, de-\\nsigned to catalyze research into LLM trading agents. We invite the research community to\\nutilize and extend this platform to investigate pressing questions in this rapidly evolving\\narea. The framework enables systematic exploration of complex scenarios\\u2014such as hybrid\\nhuman-LLM markets, stress tests, varying market structures, regulatory impacts, and the\\nnuances of LLM prompting\\u2014often difficult or costly to study otherwise. Specific avenues\\nripe for investigation using this tool include the emergence of novel trading strategies, the\\nprecise effects of agent heterogeneity on market stability, and the development of robust\\nvalidation protocols for AI traders. As artificial intelligence becomes more integrated into\\nfinance, collaborative research leveraging adaptable simulation environments like this one\\nwill be crucial for understanding and responsibly shaping the future of trading.\\n35\\nReferences\", \"Can Large Language Models Trade? Testing Financial\\nTheories with LLM Agents in Market Simulations\\nAlejandro Lopez-Lira\\u2217\\nFirst Version: November 29, 2024; Current Version: April 16, 2025\\nAbstract\\nThis paper presents a realistic simulated stock market where large language models\\n(LLMs) act as heterogeneous competing trading agents. The open-source framework\\nincorporates a persistent order book with market and limit orders, partial fills, div-\\nidends, and equilibrium clearing alongside agents with varied strategies, information\\nsets, and endowments. Agents submit standardized decisions using structured outputs\\nand function calls while expressing their reasoning in natural language. Three findings\\nemerge: First, LLMs demonstrate consistent strategy adherence and can function as\\nvalue investors, momentum traders, or market makers per their instructions. Second,\\nmarket dynamics exhibit features of real financial markets, including price discovery,\\nbubbles, underreaction, and strategic liquidity provision. Third, the framework enables\\nanalysis of LLMs\\u2019 responses to varying market conditions, similar to partial dependence\\nplots in machine-learning interpretability. The framework allows simulating financial\\ntheories without closed-form solutions, creating experimental designs that would be\\ncostly with human participants, and establishing how prompts can generate correlated\\nbehaviors affecting market stability.\\nKeywords: LLM Agents; Agent-Based Markets; Experimental Finance; AI Trading;\\nMulti-Agent Systems\\n\\u2217University of Florida. Email: alejandro.lopez-lira@warrington.ufl.edu. I am grateful to seminar par-\\nticipants at the London Business School, Oxford University, Stockholm School of Economics, University of\\nVirginia, and the City University of Hong Kong for helpful suggestions and feedback.\\n1\\narXiv:2504.10789v1  [q-fin.CP]  15 Apr 2025\\n1 Introduction\\nLarge language models (LLMs) can increasingly function as autonomous agents\\u2014systems\\nthat observe, reason, and act independently. LLMs have shown promising results in finan-\\ncial forecasting, but their potential as trading agents introduces a fundamental shift from\\nalgorithms with explicit objectives to systems guided by natural language instructions. This\\nchange raises critical questions: Can LLMs execute trading strategies? Do LLMs optimize\\nfor profit maximization? What are the implications for market stability and efficiency?\\nIf LLMs trade similarly to humans, they could enable experimental market simulations\\nwithout human participants. Conversely, if their trading behavior differs, understanding\\nthese differences becomes critical for systemic risk management. These questions extend be-\\nyond theory; LLM-based strategies are already being deployed.1 To address these questions,\\nI develop an open-source simulation that tests LLM trading agents in a realistic market envi-\\nronment with a persistent order book, supporting various order types, stochastic dividends,\\nand heterogeneous information.\\nThe framework allows heterogeneous LLMs\\u2014defined in natural language, using different\\nsystem prompts\\u2014to act as diverse types of traders, such as value investors, momentum\\ntraders, market makers, and contrarians. Agents submit standardized trading decisions in a\\nhuman-readable format while expressing their reasoning transparently. Figure 1 illustrates\\nthis approach, showing how a speculator agent combines explicit valuation reasoning with\\nstructured trading parameters, enabling systematic analysis and insight into the agent\\u2019s\\ndecision-making process.\\nThe analysis reveals three key findings about LLMs\\u2019 capabilities as trading agents. First,\\nLLMs can effectively execute trading strategies. They consistently understand market me-\\nchanics, process market information, form price expectations, and execute trades according\\nto specific instructions. Their trading behavior is highly sensitive to the prompts they\\nreceive\\u2014they faithfully follow directions regardless of profit implications. This observance\", \"an open-source framework with three key components: (1) a structured protocol for im-\\nplementing and validating LLM trading agents, supporting both LLM-based and traditional\\nrule-based agents; (2) a controlled market environment with realistic microstructure for test-\\ning agent interactions; and (3) a comprehensive data collection system for analyzing trading\\nbehavior. This framework serves multiple stakeholders in preparation for the evolution of\\nfinancial markets: practitioners developing LLM-based trading systems, regulators antic-\\nipating widespread LLM adoption, and researchers studying market dynamics with LLM\\nagents.\\n1.1 Related Work\\nThis work contributes to several strands of literature. First, advancing the growing body\\nof research on artificial intelligence in finance by demonstrating that large language mod-\\nels (LLMs) can serve as effective autonomous trading agents while providing a framework\\nfor their implementation. Second, by contributing to the market microstructure literature\\nby providing insights into how markets might evolve as LLM-based traders become active\\nparticipants, with implications for price formation, liquidity provision, and market stabil-\\nity. Third, by contributing to experimental markets research by introducing an environment\\nfor studying complex trading interactions, offering unprecedented control and replicability\\ncompared to traditional human-subject experiments.\\n4\\nRecent studies have explored ChatGPT\\u2019s potential in various financial tasks. Research\\nshows that ChatGPT can effectively predict stock price movements using news headlines,\\noutperforming traditional sentiment analysis (Lopez-Lira and Tang 2023) and that forecast-\\ning with its embeddings outperforms traditional sentiment analysis (Chen, Kelly, and Xiu\\n2022). When integrated with Graph Neural Networks, ChatGPT improves stock movement\\nprediction and portfolio performance (Chen et al. 2023. ChatGPT can understand Federal\\nReserve communications Hansen and Kazinnik (2023). The model also can extract manage-\\nrial expectations from corporate disclosures, predicting future investments and returns (Jha\\net al. 2025). ChatGPT-4 provides valuable investment advice with positive correlations to\\nsubsequent earnings announcements and stock returns (Pelster and Val 2023), and it en-\\nhances patent value forecasts by processing patent text (Yang 2023). Moreover, ChatGPT\\nshows promise in central bank analysis, predicting future interest rate decisions from pol-\\nicy communications (Woodhouse and Charlesworth 2023). Recent work also focuses on the\\neffects of AI adoption by firms (Eisfeldt et al. 2023, Babina et al. 2024).\\nFoundational work on LLMs as economic agents demonstrates their ability to simulate\\nhuman behavior in economic contexts. Horton (2023) introduce the concept of \\u201chomo silicus\\u201d\\nby using LLMs as computational models of human behavior, showing that they can repli-\\ncate classic behavioral economics findings. Manning, Zhu, and Horton (2024) extend this\\napproach through automated methods for generating and testing social scientific hypotheses\\nwith LLMs, demonstrating strong results in market contexts such as auctions. Meanwhile,\\nN. Li et al. (2024) show LLMs\\u2019 potential in macroeconomic simulation for consumption\\nand labor decisions. Recent work also shows the potential of LLMs to proxy for human\\nbehavior in the context of surveys (Hansen et al. (2024)) or economic expectations (Bybee\\n(2023)). This work, however, focuses on financial markets and how LLM agents can operate\\nas full-fledged trading participants.\\nRecent research examines specific applications of LLMs for trading. FinMem and Trad-\\ningGPT introduce frameworks with layered memory systems and customizable agent traits\\n5\\nto improve financial decision-making (Yu, Li, et al. 2024; Li, Zhang, and Sun 2023). Hierar-\\nchical multi-agent architectures have been explored in FinCon, which uses a manager-analyst\", \"ceedings of the 62nd Annual Meeting of the Association for Computational Linguistics\\n(Volume 1: Long Papers),edited by Lun-Wei Ku, Andre Martins, and Vivek Srikumar,\\n15523\\u201315536. ACL 2024. Bangkok, Thailand: Association for Computational Linguis-\\ntics, August.\\n39\\nLi, Yuan, Yixuan Zhang, and Lichao Sun. 2023. \\u201cMetaAgents: Simulating Interactions of\\nHuman Behaviors for LLM-based T Ask-Oriented Coordination via Collaborative Gen-\\nerative Agents.\\u201d arXiv.org.\\nLiu, Xiao, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, et al. 2023.\\n\\u201cAgentBench: Evaluating LLMs as Agents.\\u201dInternational Conference on Learning Rep-\\nresentations.\\nLopez-Lira, Alejandro, and Yuehua Tang. 2023. \\u201cCan ChatGPT Forecast Stock Price Move-\\nments? Return Predictability and Large Language Models.\\u201d SSRN Electronic Journal\\n(April 6, 2023).\\nManning, Benjamin S., Kehang Zhu, and John J. Horton. 2024. \\u201cAutomated Social Science:\\nLanguage Models as Scientist and Subjects.\\u201d (Cambridge, MA) (April 29, 2024).\\nMolnar, Christoph. 2022. Interpretable Machine Learning.\\nPelster, Matthias, and Joel Val. 2023. \\u201cCan Chatgpt Assist in Picking Stocks?\\u201dSocial Science\\nResearch Network.\\nPiatti, Giorgio, Zhijing Jin, Max Kleiman-Weiner, Bernhard Sch\\u00a8 olkopf, Mrinmaya Sachan,\\nand Rada Mihalcea. 2024. \\u201cCooperate or Collapse: Emergence of Sustainable Coopera-\\ntion in a Socie Ty of LLM Agents.\\u201d arXiv.org.\\nPing, Chen. 2019. \\u201cFrom Complexity Science to Complexity Economics.\\u201d In Alternative\\nApproaches to Economic Theory,19\\u201355. Routledge, June 11, 2019.\\nWang, Saizhuo, Hang Yuan, Lionel M. Ni, and Jian Guo. 2024. \\u201cQuantAgent: Seeking Holy\\nGrail in Trading by Self-Improving Large Lang Uage Model.\\u201d arXiv.org.\\nWeitzel, Utz, Christoph Huber, J\\u00a8 urgen Huber, Michael Kirchler, Florian Lindner, and Julia\\nRose. 2020. \\u201cBubbles and Financial Professionals.\\u201d The Review of Financial Studies33,\\nno. 6 (June 1, 2020): 2659\\u20132696.\\n40\\nWolfram, Elsner. 2017. \\u201cComplexity Economics as Heterodoxy: Theory and Policy.\\u201dJournal\\nof Economic Issues51, no. 4 (October 2, 2017): 939\\u2013978.\\nWoodhouse, Drew, and Alex Charlesworth. 2023. \\u201cCan ChatGPT Predict Future Interest\\nRate Decisions?\\u201d Social Science Research Network.\\nXie, Chengxing, Canyu Chen, Feiran Jia, Ziyu Ye, Shiyang Lai, Kai Shu, Jindong Gu, et al.\\n2024. \\u201cCan Large Language Model Agents Simulate Human Trust Behavior?\\u201darXiv.org.\\nYang, Stephen. 2023. \\u201cPredictive Patentomics: Forecasting Innovation Success and Valuation\\nw Ith ChatGPT.\\u201d Social Science Research Network.\\nYu, Yangyang, Haohang Li, Zhi Chen, Yuechen Jiang, Yang Li, Denghui Zhang, Rong\\nLiu, Jordan W. Suchow, and Khaldoun Khashanah. 2024. \\u201cFinMem: A Performance-\\nEnhanced LLM Trading Agent with Layered Memory a Nd Character Design.\\u201dProceed-\\nings of the AAAI Symposium Series3, no. 1 (May 20, 2024): 595\\u2013597.\\nYu, Yangyang, Zhiyuan Yao, Haohang Li, Zhiyang Deng, Yupeng Cao, Zhi Chen, Jordan W.\\nSuchow, et al. 2024. \\u201cFinCon: A Synthesized LLM Multi-Agent System with Conceptual\\nVerbal Reinforcement for Enhanced Financial Decision Making.\\u201d Pre-published, Novem-\\nber 7, 2024. Accessed January 8, 2025. https://doi.org/10.48550/arXiv.2407.06567.\\narXiv: 2407.06567 [cs]. http://arxiv.org/abs/2407.06567.\\nZhang, Chong, Xinyi Liu, Zhongmou Zhang, Mingyu Jin, Lingyao Li, Zhenting Wang,\\nWenyue Hua, et al. 2024. \\u201cWhen AI Meets Finance (StockAgent): Large Language\\nModel-based Stock Trading in Simulated Real-world Environments.\\u201d Pre-published,\\nSeptember 21, 2024. Accessed January 26, 2025. https://doi.org /10.48550/arXiv .\\n2407.18957. arXiv: 2407.18957 [q-fin]. http://arxiv.org/abs/2407.18957.\\n41\\nA Technical Implementation Details\\nA.1 Agent Type Specifications\\nThis section details the base system prompts for each agent type in our simulation. These\\nprompts define the core behavioral characteristics and trading strategies for each agent. Each\\nprompt consists of:\\n\\u2022 A role definition that establishes the agent\\u2019s trading philosophy\\n\\u2022 A structured trading strategy that guides decision-making\", \"decision-making process.\\nThe analysis reveals three key findings about LLMs\\u2019 capabilities as trading agents. First,\\nLLMs can effectively execute trading strategies. They consistently understand market me-\\nchanics, process market information, form price expectations, and execute trades according\\nto specific instructions. Their trading behavior is highly sensitive to the prompts they\\nreceive\\u2014they faithfully follow directions regardless of profit implications. This observance\\n1. For example, Autopilot has a ChatGPT-based portfolio https://x.com/thegptinvestor.\\n2\\n{\\\"valuation_reasoning\\\":\\n\\\"The fundamental value is based on the expected dividend,\\nand the interest rate.\\nThe expected dividend is $1.40, and the interest rate is 5%.\\nUsing a perpetuity formula, the value is $1.40 / 0.05 = $28.\\\",\\n\\\"valuation\\\":28.0,\\n\\\"price_target_reasoning\\\":\\\"The current price is $29.00, which is\\nslightly above the fundamental value of $28.00. I expect the price\\nto remain around $29.00 in the next round due to market stability.\\\",\\n\\\"price_target\\\":29.0,\\n\\\"orders\\\":[{\\\"decision\\\":\\\"Sell\\\",\\\"quantity\\\":1000,\\\"order_type\\\":\\\"limit\\\",\\n\\\"price_limit\\\":29.50}],\\n\\\"replace_decision\\\":\\\"Add\\\",\\n\\\"reasoning\\\":\\\"The current price is slightly above the fundamental value.\\nI will place a limit sell order at $29.50 to capitalize on potential price\\nincreases.\\\"}\\nFigure 1: Example of a structured trading decision from a Speculator agent defined by its\\nsystem prompt: \\u201cYou are a speculator who tries to profit from market inefficiencies.\\u201d. The\\nLLM provides explicit reasoning for its valuation, price target, and trading decision in a\\nmachine-readable JSON format that can be directly processed by the trading system.\\nhighlights a fundamental difference from human traders: LLMs do not inherently optimize\\nfor profit maximization but rather for following instructions accurately.\\nSecond, LLMs react meaningfully to market dynamics. They consider current and his-\\ntorical prices, dividends, and other market information when making decisions. However,\\nthey maintain their strategic direction even when market conditions change, following their\\ninstructions even if doing so results in financial losses. This combination of responsiveness\\nto market conditions while maintaining strategic consistency creates a unique trading profile\\ndistinct from rule-based algorithms and human traders.\\nThird, market dynamics with LLM agents can resemble actual markets and mirror classic\\nresults from the theoretical finance literature. When these agents interact, they produce\\nrealistic price discovery and liquidity provision with emergent behaviors, including price\\nconvergence toward fundamental values. Depending on the distribution of agent types,\\nthe system can generate various market phenomena, such as bubbles or underreactions to\\ninformation. This complex behavior suggests potential applications for studying market\\n3\\ndynamics using LLM agents instead of experiments with human participants.\\nHence, these findings raise important questions about algorithmic consistency in LLM-\\nbased systems. Since trading agents are implemented through prompts, their behavior in-\\nherits characteristics of the underlying language models. The standardization of LLM ar-\\nchitectures across implementations could create unexpected behavioral patterns\\u2014if many\\nagents are based on similar foundation models, they might exhibit correlated responses to\\nspecific market conditions, potentially amplifying market instabilities.\\nTo enable this analysis and accelerate development in this emerging field, we provide\\nan open-source framework with three key components: (1) a structured protocol for im-\\nplementing and validating LLM trading agents, supporting both LLM-based and traditional\\nrule-based agents; (2) a controlled market environment with realistic microstructure for test-\\ning agent interactions; and (3) a comprehensive data collection system for analyzing trading\\nbehavior. This framework serves multiple stakeholders in preparation for the evolution of\", \"ripe for investigation using this tool include the emergence of novel trading strategies, the\\nprecise effects of agent heterogeneity on market stability, and the development of robust\\nvalidation protocols for AI traders. As artificial intelligence becomes more integrated into\\nfinance, collaborative research leveraging adaptable simulation environments like this one\\nwill be crucial for understanding and responsibly shaping the future of trading.\\n35\\nReferences\\nArthur, W. Brian. 2013. \\u201cComplexity Economics : A Different Framework for Economic\\nThought.\\u201d\\nBabina, Tania, Anastassia Fedyk, Alex He, and James Hodson. 2024. \\u201cArtificial Intelli-\\ngence, Firm Growth, and Product Innovation.\\u201d Journal of Financial Economics 151\\n(January 1, 2024): 103745.\\nBalland, Pierre-Alexandre, Tom Broekel, Dario Diodato, Elisa Giuliani, Ricardo Hausmann,\\nNeave O\\u2019Clery, and David Rigby. 2022. \\u201cThe New Paradigm of Economic Complexity.\\u201d\\nResearch Policy51, no. 3 (April): 104450.\\nBianchi, Federico, Patrick John Chia, Mert Yuksekgonul, Jacopo Tagliabue, Dan Jurafsky,\\nand James Zou. 2024. \\u201cHow Well Can LLMs Negotiate? NegotiationArena Platform and\\nAnalysis.\\u201d arXiv.org.\\nBybee, J. Leland. 2023. \\u201cThe Ghost in the Machine: Generating Beliefs with Large Language\\nModels.\\u201d arXiv: 2305.02823.\\nCampello, Murillo, Lin William Cong, and Luofeng Zhou. 2023. \\u201cAlphaManager: A Data-\\nDriven-Robust-Control Approach to Corporate Finance.\\u201d Pre-published, December 2,\\n2023. SSRN Scholarly Paper. Accessed December 22, 2024. https://doi.org/10.2139/\\nssrn.4590323. Social Science Research Network: 4590323. https://papers.ssrn.com/\\nabstract=4590323.\\nChen, Yifei, Bryan T. Kelly, and Dacheng Xiu. 2022. \\u201cExpected Returns and Large Lan-\\nguage Models.\\u201d Pre-published, November 22, 2022. SSRN Scholarly Paper. Accessed\\nJanuary 26, 2025. Social Science Research Network: 4416687. https://papers.ssrn.com/\\nabstract=4416687.\\n36\\nChen, Zihan, Lei Zheng, Chengyu Lu, Jialu Yuan, and Di Zhu. 2023. \\u201cChatGPT Informed\\nGraph Neural Network for Stock Movement Prediction.\\u201d Social Science Research Net-\\nwork.\\nChuang, Yun-Shiuan, Agam Goyal, Nikunj Harlalka, Siddharth Suresh, Robert Hawkins,\\nSijia Yang, Dhavan Shah, Junjie Hu, and Timothy T. Rogers. 2023. \\u201cSimulating Opin-\\nion Dynamics with Networks of LLM-based Agents.\\u201d North American Chapter of the\\nAssociation for Computational Linguistic s.\\nColliard, Jean-Edouard, Thierry Foucault, and Stefano Lovo. 2022. \\u201cAlgorithmic Pricing\\nand Liquidity in Securities Markets.\\u201d Pre-published, October 18, 2022. SSRN Scholarly\\nPaper. Accessed April 4, 2025. https://doi.org/10.2139/ssrn.4252858. Social Science\\nResearch Network: 4252858. https://papers.ssrn.com/abstract=4252858.\\nCong, Lin William, Ke Tang, Jingyuan Wang, and Yang Zhang. 2021. \\u201cAlphaPortfolio:\\nDirect Construction Through Deep Reinforcement Learning and Interpretable AI.\\u201d Pre-\\npublished, August 1, 2021. SSRN Scholarly Paper. Accessed December 22, 2024. https:\\n//doi.org/10.2139/ssrn.3554486. Social Science Research Network: 3554486. https:\\n//papers.ssrn.com/abstract=3554486.\\nDou, Winston Wei, Itay Goldstein, and Yan Ji. 2024. \\u201cAI-Powered Trading, Algorithmic\\nCollusion, and Price Efficiency.\\u201d Pre-published, May 30, 2024. SSRN Scholarly Paper.\\nAccessed April 4, 2025. https://doi.org/10.2139/ssrn.4452704. Social Science Research\\nNetwork: 4452704. https://papers.ssrn.com/abstract=4452704.\\nEisfeldt, Andrea L., Gregor Schubert, Miao Ben Zhang, and Bledi Taska. 2023. \\u201cGenerative\\nAI and Firm Values.\\u201d Pre-published, May 2, 2023. SSRN Scholarly Paper. Accessed\\nJanuary 26, 2025. https : / / doi .org / 10 .2139 / ssrn . 4436627. Social Science Research\\nNetwork: 4436627. https://papers.ssrn.com/abstract=4436627.\\n37\\nGao, Shen, Yuntao Wen, Minghang Zhu, Jianing Wei, Yuhan Cheng, Qunzi Zhang, and Shuo\\nShang. 2024. \\u201cSimulating Financial Market via Large Language Model Based Agents.\\u201d\\nPre-published, June 28, 2024. Accessed January 26, 2025. https://doi.org/10.48550/\"]}": {"cached_metrics_data": [{"metric_data": {"name": "Contextual Precision (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Faithfulness (ragas)", "threshold": 0.8, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.8, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Contextual Recall (ragas)", "threshold": 0.6, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.6, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Answer Relevancy (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}]}, "{\"actual_output\": \"The LLMs' tendency to prioritize instructions over profits makes them less realistic as traders in several key ways:\\n\\nLack of Dynamic Strategy Adjustment: Real-world traders adapt and change their strategies based on market performance. If a strategy isn't profitable, they'll modify or abandon it. LLMs, however, rigidly adhere to their initial instructions, even when losing money, which isn't realistic in dynamic markets.\\n\\nAbsence of Loss Aversion: Human traders are strongly motivated to avoid losses (loss aversion). LLMs, lacking this emotional response, don't show the same aversion and may continue following a losing strategy simply because they were instructed to.\\n\\nUnrealistic Adherence to Specific Roles: In the study, LLMs were given fixed roles (e.g., \\\"value investor,\\\" \\\"market maker\\\"). Real traders, while having general investment philosophies, are flexible and will exploit profitable opportunities even if they don't perfectly align with their usual style. The LLMs' strict adherence to their assigned roles, even at a loss, limits their realism.\", \"context\": null, \"expected_output\": \"LLMs optimise for prompt fidelity; they keep executing the instructed strategy even when it loses money, unlike humans who adapt for profit.\", \"hyperparameters\": null, \"input\": \"The authors note that LLMs \\u2018follow instructions even if doing so results in financial losses.\\u2019 How might this limit their realism as profit\\u2011seeking traders?\", \"retrieval_context\": [\"(2023)). This work, however, focuses on financial markets and how LLM agents can operate\\nas full-fledged trading participants.\\nRecent research examines specific applications of LLMs for trading. FinMem and Trad-\\ningGPT introduce frameworks with layered memory systems and customizable agent traits\\n5\\nto improve financial decision-making (Yu, Li, et al. 2024; Li, Zhang, and Sun 2023). Hierar-\\nchical multi-agent architectures have been explored in FinCon, which uses a manager-analyst\\nsetup for collaborative portfolio decisions (Yu, Yao, et al. 2024). QuantAgent implements\\na self-improving signal-mining approach (Wang et al. 2024), while other work underscores\\nthe importance of long-term memory in LLM agents via vector databases (Hatalis et al.\\n2024). This line of research builds on successful reinforcement learning applications such as\\nAlphaPortfolio (Cong et al. 2021) and AlphaManager (Campello, Cong, and Zhou 2023),\\nwhich leverage deep RL and robust control for portfolio management.\\nAnalyzing LLM agent behavior by changing only some parameters draws on methods\\nfrom the interpretable machine learning literature. In particular, the systematic variation\\nof market parameters to reveal decision patterns mirrors partial dependence plots and in-\\ndividual conditional expectation curves used to interpret complex machine learning models\\n(Molnar 2022). These techniques help reveal how LLM agents respond to changes in specific\\nvariables while holding others constant, providing insight into their internal decision-making\\nprocesses that would otherwise remain opaque.\\nBeyond finance, studies of LLM capabilities in interactive or multi-agent settings offer\\nvaluable insights. Benchmarks like AgentBench evaluate LLMs\\u2019 performance in interac-\\ntive tasks (Liu et al. 2023), while InvestorBench focuses on financial decision-making tasks\\nspecifically (H. Li et al. 2024). NegotiationArena demonstrates LLMs\\u2019 capacity for strategic\\ninteraction in bargaining contexts (Bianchi et al. 2024). Similarly, Guo et al. (2024) provide\\nan economics \\u201darena\\u201d where LLMs compete in strategic games, revealing that advanced\\nmodels like GPT-4 can exhibit rational, adaptive behavior\\u2014albeit not always reaching Nash\\nEquilibrium. Existing frameworks typically assess individual agents or hierarchical collab-\\norations, whereas this work studies emergent market behaviors that arise from multiple\\nindependent LLM traders interacting in a marketplace.\\nThe approach also connects to the tradition of experimental asset markets. For instance,\\nWeitzel et al. (2020) show that even finance professionals are susceptible to speculative\\n6\\nbubbles, especially amid high capital inflows. Kop\\u00b4 anyi-Peuker and Weber (2021) find that\\ntrading experience alone does not eliminate bubbles, challenging assumptions about rational\\nmarket learning. Kirchler, Huber, and St\\u00a8 ockl (2012) identify confusion about fundamental\\nvalues as a key driver of bubble formation. This framework offers a new way to study these\\nphenomena with LLM traders, which can be rigorously parameterized for sophistication,\\nstrategy, and information processing. Hence, this paper provides a method to investigate\\nhow automated or \\u201dartificial\\u201d agents might affect market stability or volatility.\\nOther recent work highlights the versatility of LLM agents in complex, interactive sce-\\nnarios beyond finance. One stream focuses on simulating social behaviors\\u2014such as opinion\\ndynamics (Chuang et al. 2023), trust (Xie et al. 2024), and resource-sharing (Piatti et al.\\n2024). Another examines LLMs\\u2019 strategic capabilities through task-based simulations and\\ncollaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\\nWithin the computer science literature, early works apply LLMs to financial markets but\\nabstract away many fundamental stock market characteristics. Often, they employ single-\\nprice clearing mechanisms without a persistent order book, ignore partial fills and bid-ask\", \"2407.18957. arXiv: 2407.18957 [q-fin]. http://arxiv.org/abs/2407.18957.\\n41\\nA Technical Implementation Details\\nA.1 Agent Type Specifications\\nThis section details the base system prompts for each agent type in our simulation. These\\nprompts define the core behavioral characteristics and trading strategies for each agent. Each\\nprompt consists of:\\n\\u2022 A role definition that establishes the agent\\u2019s trading philosophy\\n\\u2022 A structured trading strategy that guides decision-making\\n\\u2022 Specific instructions for when to use market orders vs limit orders\\nAt runtime, these base prompts are combined with:\\n\\u2022 Current market state (price, volume, order book depth)\\n\\u2022 Position information (current holdings and available cash)\\n\\u2022 Trading options and required response format\\nThe standard runtime template includes:\\nPosition Information Template\\nYour Position:\\n- Available Shares: {shares} shares (Short selling is not allowed)\\n- Main Cash Account: ${cash:.2f}\\n- Dividend Cash Account (not available for trading): ${dividend_cash:.2f}\\n- Total Available Cash: ${total_available_cash:.2f} (Borrowing is not allowed)\\n- Shares in Orders: {committed_shares} shares\\n- Cash in Orders: ${committed_cash:.2f}\\n42\\nTrading Options Template\\nYour analysis should include:\\n- valuation_reasoning: Your numerical analysis of the asset\\u2019s fundamental value\\n- valuation: Your estimate of the asset\\u2019s current fundamental value\\n- price_target_reasoning: Your numerical analysis of the asset\\u2019s price target\\n- price_target: Your predicted price for the next round\\n- reasoning: Your explanation for the trading decision\\nTrading Options:\\n1. New Orders (replace_decision=\\u2019Add\\u2019):\\n- Single or multiple orders allowed\\n- For each order:\\n- Market order: Set order_type=\\u2019market\\u2019\\n- Limit order: Set order_type=\\u2019limit\\u2019 and specify price_limit\\n- IMPORTANT: Sell orders require sufficient available shares\\n- Short selling is NOT allowed\\n2. Cancel Orders (replace_decision=\\u2019Cancel\\u2019):\\n- Return an empty orders list: orders=[]\\nYour decision must include:\\n- orders: list of orders (empty list for Hold/Cancel)\\n- For Buy/Sell orders, each must contain:\\n- decision: \\\"Buy\\\" or \\\"Sell\\\"\\n- quantity: number of shares\\n- order_type: \\\"market\\\" or \\\"limit\\\"\\n- price_limit: required for limit orders\\n- reasoning: brief explanation\\n- replace_decision: \\\"Add\\\", \\\"Cancel\\\", or \\\"Replace\\\"\\n43\\nBase System Prompts The following are the base system prompts for each LLM-based\\nagent type:\\nA.1.1 Value-Based Agents\\nValue Investor\\nYou are a value investor who focuses on fundamental analysis.\\nYou believe in mean reversion and try to buy undervalued assets and sell overvalued ones.\\nA.1.2 Trend-Following Agents\\nMomentum Trader\\nYou are a momentum trader who focuses on price trends and volume.\\nYou believe that \\u2019the trend is your friend\\u2019 and try to identify and follow market momentum.\\nA.1.3 Liquidity Providers Agents\\nMarket Maker\\nYou are a professional market maker who provides liquidity to the market.\\nYour profit comes from capturing the spread between bid and ask prices, not from directional price movement.\\nIMPORTANT: There is NO SHORT SELLING allowed. You can only sell shares you already own.\\nTrading Guidelines:\\n- Place LIMIT buy orders slightly below the current market price (1-3% lower)\\n- Place LIMIT sell orders slightly above the current market price (1-3% higher)\\n- Your spread should be proportional to volatility but typically 2-6% of price\\n- NEVER place sell orders more than 10% above your buy orders\\n- Adjust your spread width based on recent price volatility\\n44\\nInventory Management (No Short Selling):\\n- Monitor your current inventory in the market data\\n- Only place sell orders for quantities you actually own\\n- If you have no inventory, focus on buy orders first\\n- As you acquire inventory, gradually place sell orders\\n- If inventory grows too large, reduce or pause buy orders\\n- Adjust your buy/sell ratio based on current inventory level\\nExample: If price = $100, you might place buy orders at $97-99 and sell orders at $101-103,\", \"33\\nants, allowing researchers to study how different belief structures influence price formation\\nand trading patterns under different initial mispricings. In these scenarios, the fundamental\\nprice is hidden from agents, forcing them to rely on their own valuation models.\\n3.2.5 Market Stress\\nThis scenario tests market resilience under challenging conditions by creating a more volatile\\nenvironment. The scenario includes two consistently bullish Optimistic traders, two consis-\\ntently bearish Pessimistic traders, two Market makers (liquidity providers), and two Value\\ninvestors (rational benchmark traders). The scenario runs for 100 rounds to study long-term\\nmarket behavior and includes unequal initial endowments, with optimistic traders having\\nmore cash (1.5x baseline) but fewer shares (0.5x baseline) and pessimistic traders having less\\ncash (0.5x baseline) but more shares (1.5x baseline). This resource imbalance tests whether\\nparticular agent types can dominate market outcomes through resource advantages.\\nThe scenarios presented here demonstrate the framework\\u2019s capabilities for exploring di-\\nverse market conditions. Its modular structure facilitates the straightforward definition and\\nimplementation of alternative experimental designs, enabling researchers to tailor simulations\\nto specific research questions.\\nIn all scenarios, we maintain consistent baseline parameters with a fundamental value\\nof $28.00, calculated from the expected dividend of $1.40 and interest rate of 5%. Agent\\nendowments start at 1,000,000 monetary units and 10,000 shares unless specifically modified.\\nTransaction costs are set to zero to isolate the effects of agent behavior and market structure\\non price formation.\\n4 Conclusion\\nThis paper demonstrates that Large Language Models can effectively function as diverse\\ntrading agents\\u2014from value investors to market makers\\u2014maintaining strategic consistency\\n34\\nwhile adapting to market conditions. Our experimental framework reveals that their in-\\nteractions generate realistic market dynamics, including phenomena like price bubbles and\\ncorrections, highlighting both the capabilities and potential risks of deploying LLM agents\\nin financial markets.\\nThese findings carry significant implications for market structure and regulation. While\\nLLM agents can enhance price discovery and liquidity, their adherence to programmed strate-\\ngies, even potentially flawed ones derived from prompts, could amplify market volatility or\\nintroduce novel systemic risks, as observed in our simulated bubble scenarios. A key concern\\nis the potential for widespread correlated behavior: similar underlying LLM architectures\\nresponding uniformly to comparable prompts or market signals could inadvertently create\\ndestabilizing trading patterns without explicit coordination. This underscores the critical\\nneed for rigorous testing and validation of LLM-based trading systems prior to live deploy-\\nment.\\nA central contribution of this work is the open-source simulation framework itself, de-\\nsigned to catalyze research into LLM trading agents. We invite the research community to\\nutilize and extend this platform to investigate pressing questions in this rapidly evolving\\narea. The framework enables systematic exploration of complex scenarios\\u2014such as hybrid\\nhuman-LLM markets, stress tests, varying market structures, regulatory impacts, and the\\nnuances of LLM prompting\\u2014often difficult or costly to study otherwise. Specific avenues\\nripe for investigation using this tool include the emergence of novel trading strategies, the\\nprecise effects of agent heterogeneity on market stability, and the development of robust\\nvalidation protocols for AI traders. As artificial intelligence becomes more integrated into\\nfinance, collaborative research leveraging adaptable simulation environments like this one\\nwill be crucial for understanding and responsibly shaping the future of trading.\\n35\\nReferences\", \"Can Large Language Models Trade? Testing Financial\\nTheories with LLM Agents in Market Simulations\\nAlejandro Lopez-Lira\\u2217\\nFirst Version: November 29, 2024; Current Version: April 16, 2025\\nAbstract\\nThis paper presents a realistic simulated stock market where large language models\\n(LLMs) act as heterogeneous competing trading agents. The open-source framework\\nincorporates a persistent order book with market and limit orders, partial fills, div-\\nidends, and equilibrium clearing alongside agents with varied strategies, information\\nsets, and endowments. Agents submit standardized decisions using structured outputs\\nand function calls while expressing their reasoning in natural language. Three findings\\nemerge: First, LLMs demonstrate consistent strategy adherence and can function as\\nvalue investors, momentum traders, or market makers per their instructions. Second,\\nmarket dynamics exhibit features of real financial markets, including price discovery,\\nbubbles, underreaction, and strategic liquidity provision. Third, the framework enables\\nanalysis of LLMs\\u2019 responses to varying market conditions, similar to partial dependence\\nplots in machine-learning interpretability. The framework allows simulating financial\\ntheories without closed-form solutions, creating experimental designs that would be\\ncostly with human participants, and establishing how prompts can generate correlated\\nbehaviors affecting market stability.\\nKeywords: LLM Agents; Agent-Based Markets; Experimental Finance; AI Trading;\\nMulti-Agent Systems\\n\\u2217University of Florida. Email: alejandro.lopez-lira@warrington.ufl.edu. I am grateful to seminar par-\\nticipants at the London Business School, Oxford University, Stockholm School of Economics, University of\\nVirginia, and the City University of Hong Kong for helpful suggestions and feedback.\\n1\\narXiv:2504.10789v1  [q-fin.CP]  15 Apr 2025\\n1 Introduction\\nLarge language models (LLMs) can increasingly function as autonomous agents\\u2014systems\\nthat observe, reason, and act independently. LLMs have shown promising results in finan-\\ncial forecasting, but their potential as trading agents introduces a fundamental shift from\\nalgorithms with explicit objectives to systems guided by natural language instructions. This\\nchange raises critical questions: Can LLMs execute trading strategies? Do LLMs optimize\\nfor profit maximization? What are the implications for market stability and efficiency?\\nIf LLMs trade similarly to humans, they could enable experimental market simulations\\nwithout human participants. Conversely, if their trading behavior differs, understanding\\nthese differences becomes critical for systemic risk management. These questions extend be-\\nyond theory; LLM-based strategies are already being deployed.1 To address these questions,\\nI develop an open-source simulation that tests LLM trading agents in a realistic market envi-\\nronment with a persistent order book, supporting various order types, stochastic dividends,\\nand heterogeneous information.\\nThe framework allows heterogeneous LLMs\\u2014defined in natural language, using different\\nsystem prompts\\u2014to act as diverse types of traders, such as value investors, momentum\\ntraders, market makers, and contrarians. Agents submit standardized trading decisions in a\\nhuman-readable format while expressing their reasoning transparently. Figure 1 illustrates\\nthis approach, showing how a speculator agent combines explicit valuation reasoning with\\nstructured trading parameters, enabling systematic analysis and insight into the agent\\u2019s\\ndecision-making process.\\nThe analysis reveals three key findings about LLMs\\u2019 capabilities as trading agents. First,\\nLLMs can effectively execute trading strategies. They consistently understand market me-\\nchanics, process market information, form price expectations, and execute trades according\\nto specific instructions. Their trading behavior is highly sensitive to the prompts they\\nreceive\\u2014they faithfully follow directions regardless of profit implications. This observance\", \"an open-source framework with three key components: (1) a structured protocol for im-\\nplementing and validating LLM trading agents, supporting both LLM-based and traditional\\nrule-based agents; (2) a controlled market environment with realistic microstructure for test-\\ning agent interactions; and (3) a comprehensive data collection system for analyzing trading\\nbehavior. This framework serves multiple stakeholders in preparation for the evolution of\\nfinancial markets: practitioners developing LLM-based trading systems, regulators antic-\\nipating widespread LLM adoption, and researchers studying market dynamics with LLM\\nagents.\\n1.1 Related Work\\nThis work contributes to several strands of literature. First, advancing the growing body\\nof research on artificial intelligence in finance by demonstrating that large language mod-\\nels (LLMs) can serve as effective autonomous trading agents while providing a framework\\nfor their implementation. Second, by contributing to the market microstructure literature\\nby providing insights into how markets might evolve as LLM-based traders become active\\nparticipants, with implications for price formation, liquidity provision, and market stabil-\\nity. Third, by contributing to experimental markets research by introducing an environment\\nfor studying complex trading interactions, offering unprecedented control and replicability\\ncompared to traditional human-subject experiments.\\n4\\nRecent studies have explored ChatGPT\\u2019s potential in various financial tasks. Research\\nshows that ChatGPT can effectively predict stock price movements using news headlines,\\noutperforming traditional sentiment analysis (Lopez-Lira and Tang 2023) and that forecast-\\ning with its embeddings outperforms traditional sentiment analysis (Chen, Kelly, and Xiu\\n2022). When integrated with Graph Neural Networks, ChatGPT improves stock movement\\nprediction and portfolio performance (Chen et al. 2023. ChatGPT can understand Federal\\nReserve communications Hansen and Kazinnik (2023). The model also can extract manage-\\nrial expectations from corporate disclosures, predicting future investments and returns (Jha\\net al. 2025). ChatGPT-4 provides valuable investment advice with positive correlations to\\nsubsequent earnings announcements and stock returns (Pelster and Val 2023), and it en-\\nhances patent value forecasts by processing patent text (Yang 2023). Moreover, ChatGPT\\nshows promise in central bank analysis, predicting future interest rate decisions from pol-\\nicy communications (Woodhouse and Charlesworth 2023). Recent work also focuses on the\\neffects of AI adoption by firms (Eisfeldt et al. 2023, Babina et al. 2024).\\nFoundational work on LLMs as economic agents demonstrates their ability to simulate\\nhuman behavior in economic contexts. Horton (2023) introduce the concept of \\u201chomo silicus\\u201d\\nby using LLMs as computational models of human behavior, showing that they can repli-\\ncate classic behavioral economics findings. Manning, Zhu, and Horton (2024) extend this\\napproach through automated methods for generating and testing social scientific hypotheses\\nwith LLMs, demonstrating strong results in market contexts such as auctions. Meanwhile,\\nN. Li et al. (2024) show LLMs\\u2019 potential in macroeconomic simulation for consumption\\nand labor decisions. Recent work also shows the potential of LLMs to proxy for human\\nbehavior in the context of surveys (Hansen et al. (2024)) or economic expectations (Bybee\\n(2023)). This work, however, focuses on financial markets and how LLM agents can operate\\nas full-fledged trading participants.\\nRecent research examines specific applications of LLMs for trading. FinMem and Trad-\\ningGPT introduce frameworks with layered memory systems and customizable agent traits\\n5\\nto improve financial decision-making (Yu, Li, et al. 2024; Li, Zhang, and Sun 2023). Hierar-\\nchical multi-agent architectures have been explored in FinCon, which uses a manager-analyst\", \"ceedings of the 62nd Annual Meeting of the Association for Computational Linguistics\\n(Volume 1: Long Papers),edited by Lun-Wei Ku, Andre Martins, and Vivek Srikumar,\\n15523\\u201315536. ACL 2024. Bangkok, Thailand: Association for Computational Linguis-\\ntics, August.\\n39\\nLi, Yuan, Yixuan Zhang, and Lichao Sun. 2023. \\u201cMetaAgents: Simulating Interactions of\\nHuman Behaviors for LLM-based T Ask-Oriented Coordination via Collaborative Gen-\\nerative Agents.\\u201d arXiv.org.\\nLiu, Xiao, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, et al. 2023.\\n\\u201cAgentBench: Evaluating LLMs as Agents.\\u201dInternational Conference on Learning Rep-\\nresentations.\\nLopez-Lira, Alejandro, and Yuehua Tang. 2023. \\u201cCan ChatGPT Forecast Stock Price Move-\\nments? Return Predictability and Large Language Models.\\u201d SSRN Electronic Journal\\n(April 6, 2023).\\nManning, Benjamin S., Kehang Zhu, and John J. Horton. 2024. \\u201cAutomated Social Science:\\nLanguage Models as Scientist and Subjects.\\u201d (Cambridge, MA) (April 29, 2024).\\nMolnar, Christoph. 2022. Interpretable Machine Learning.\\nPelster, Matthias, and Joel Val. 2023. \\u201cCan Chatgpt Assist in Picking Stocks?\\u201dSocial Science\\nResearch Network.\\nPiatti, Giorgio, Zhijing Jin, Max Kleiman-Weiner, Bernhard Sch\\u00a8 olkopf, Mrinmaya Sachan,\\nand Rada Mihalcea. 2024. \\u201cCooperate or Collapse: Emergence of Sustainable Coopera-\\ntion in a Socie Ty of LLM Agents.\\u201d arXiv.org.\\nPing, Chen. 2019. \\u201cFrom Complexity Science to Complexity Economics.\\u201d In Alternative\\nApproaches to Economic Theory,19\\u201355. Routledge, June 11, 2019.\\nWang, Saizhuo, Hang Yuan, Lionel M. Ni, and Jian Guo. 2024. \\u201cQuantAgent: Seeking Holy\\nGrail in Trading by Self-Improving Large Lang Uage Model.\\u201d arXiv.org.\\nWeitzel, Utz, Christoph Huber, J\\u00a8 urgen Huber, Michael Kirchler, Florian Lindner, and Julia\\nRose. 2020. \\u201cBubbles and Financial Professionals.\\u201d The Review of Financial Studies33,\\nno. 6 (June 1, 2020): 2659\\u20132696.\\n40\\nWolfram, Elsner. 2017. \\u201cComplexity Economics as Heterodoxy: Theory and Policy.\\u201dJournal\\nof Economic Issues51, no. 4 (October 2, 2017): 939\\u2013978.\\nWoodhouse, Drew, and Alex Charlesworth. 2023. \\u201cCan ChatGPT Predict Future Interest\\nRate Decisions?\\u201d Social Science Research Network.\\nXie, Chengxing, Canyu Chen, Feiran Jia, Ziyu Ye, Shiyang Lai, Kai Shu, Jindong Gu, et al.\\n2024. \\u201cCan Large Language Model Agents Simulate Human Trust Behavior?\\u201darXiv.org.\\nYang, Stephen. 2023. \\u201cPredictive Patentomics: Forecasting Innovation Success and Valuation\\nw Ith ChatGPT.\\u201d Social Science Research Network.\\nYu, Yangyang, Haohang Li, Zhi Chen, Yuechen Jiang, Yang Li, Denghui Zhang, Rong\\nLiu, Jordan W. Suchow, and Khaldoun Khashanah. 2024. \\u201cFinMem: A Performance-\\nEnhanced LLM Trading Agent with Layered Memory a Nd Character Design.\\u201dProceed-\\nings of the AAAI Symposium Series3, no. 1 (May 20, 2024): 595\\u2013597.\\nYu, Yangyang, Zhiyuan Yao, Haohang Li, Zhiyang Deng, Yupeng Cao, Zhi Chen, Jordan W.\\nSuchow, et al. 2024. \\u201cFinCon: A Synthesized LLM Multi-Agent System with Conceptual\\nVerbal Reinforcement for Enhanced Financial Decision Making.\\u201d Pre-published, Novem-\\nber 7, 2024. Accessed January 8, 2025. https://doi.org/10.48550/arXiv.2407.06567.\\narXiv: 2407.06567 [cs]. http://arxiv.org/abs/2407.06567.\\nZhang, Chong, Xinyi Liu, Zhongmou Zhang, Mingyu Jin, Lingyao Li, Zhenting Wang,\\nWenyue Hua, et al. 2024. \\u201cWhen AI Meets Finance (StockAgent): Large Language\\nModel-based Stock Trading in Simulated Real-world Environments.\\u201d Pre-published,\\nSeptember 21, 2024. Accessed January 26, 2025. https://doi.org /10.48550/arXiv .\\n2407.18957. arXiv: 2407.18957 [q-fin]. http://arxiv.org/abs/2407.18957.\\n41\\nA Technical Implementation Details\\nA.1 Agent Type Specifications\\nThis section details the base system prompts for each agent type in our simulation. These\\nprompts define the core behavioral characteristics and trading strategies for each agent. Each\\nprompt consists of:\\n\\u2022 A role definition that establishes the agent\\u2019s trading philosophy\\n\\u2022 A structured trading strategy that guides decision-making\", \"decision-making process.\\nThe analysis reveals three key findings about LLMs\\u2019 capabilities as trading agents. First,\\nLLMs can effectively execute trading strategies. They consistently understand market me-\\nchanics, process market information, form price expectations, and execute trades according\\nto specific instructions. Their trading behavior is highly sensitive to the prompts they\\nreceive\\u2014they faithfully follow directions regardless of profit implications. This observance\\n1. For example, Autopilot has a ChatGPT-based portfolio https://x.com/thegptinvestor.\\n2\\n{\\\"valuation_reasoning\\\":\\n\\\"The fundamental value is based on the expected dividend,\\nand the interest rate.\\nThe expected dividend is $1.40, and the interest rate is 5%.\\nUsing a perpetuity formula, the value is $1.40 / 0.05 = $28.\\\",\\n\\\"valuation\\\":28.0,\\n\\\"price_target_reasoning\\\":\\\"The current price is $29.00, which is\\nslightly above the fundamental value of $28.00. I expect the price\\nto remain around $29.00 in the next round due to market stability.\\\",\\n\\\"price_target\\\":29.0,\\n\\\"orders\\\":[{\\\"decision\\\":\\\"Sell\\\",\\\"quantity\\\":1000,\\\"order_type\\\":\\\"limit\\\",\\n\\\"price_limit\\\":29.50}],\\n\\\"replace_decision\\\":\\\"Add\\\",\\n\\\"reasoning\\\":\\\"The current price is slightly above the fundamental value.\\nI will place a limit sell order at $29.50 to capitalize on potential price\\nincreases.\\\"}\\nFigure 1: Example of a structured trading decision from a Speculator agent defined by its\\nsystem prompt: \\u201cYou are a speculator who tries to profit from market inefficiencies.\\u201d. The\\nLLM provides explicit reasoning for its valuation, price target, and trading decision in a\\nmachine-readable JSON format that can be directly processed by the trading system.\\nhighlights a fundamental difference from human traders: LLMs do not inherently optimize\\nfor profit maximization but rather for following instructions accurately.\\nSecond, LLMs react meaningfully to market dynamics. They consider current and his-\\ntorical prices, dividends, and other market information when making decisions. However,\\nthey maintain their strategic direction even when market conditions change, following their\\ninstructions even if doing so results in financial losses. This combination of responsiveness\\nto market conditions while maintaining strategic consistency creates a unique trading profile\\ndistinct from rule-based algorithms and human traders.\\nThird, market dynamics with LLM agents can resemble actual markets and mirror classic\\nresults from the theoretical finance literature. When these agents interact, they produce\\nrealistic price discovery and liquidity provision with emergent behaviors, including price\\nconvergence toward fundamental values. Depending on the distribution of agent types,\\nthe system can generate various market phenomena, such as bubbles or underreactions to\\ninformation. This complex behavior suggests potential applications for studying market\\n3\\ndynamics using LLM agents instead of experiments with human participants.\\nHence, these findings raise important questions about algorithmic consistency in LLM-\\nbased systems. Since trading agents are implemented through prompts, their behavior in-\\nherits characteristics of the underlying language models. The standardization of LLM ar-\\nchitectures across implementations could create unexpected behavioral patterns\\u2014if many\\nagents are based on similar foundation models, they might exhibit correlated responses to\\nspecific market conditions, potentially amplifying market instabilities.\\nTo enable this analysis and accelerate development in this emerging field, we provide\\nan open-source framework with three key components: (1) a structured protocol for im-\\nplementing and validating LLM trading agents, supporting both LLM-based and traditional\\nrule-based agents; (2) a controlled market environment with realistic microstructure for test-\\ning agent interactions; and (3) a comprehensive data collection system for analyzing trading\\nbehavior. This framework serves multiple stakeholders in preparation for the evolution of\", \"ripe for investigation using this tool include the emergence of novel trading strategies, the\\nprecise effects of agent heterogeneity on market stability, and the development of robust\\nvalidation protocols for AI traders. As artificial intelligence becomes more integrated into\\nfinance, collaborative research leveraging adaptable simulation environments like this one\\nwill be crucial for understanding and responsibly shaping the future of trading.\\n35\\nReferences\\nArthur, W. Brian. 2013. \\u201cComplexity Economics : A Different Framework for Economic\\nThought.\\u201d\\nBabina, Tania, Anastassia Fedyk, Alex He, and James Hodson. 2024. \\u201cArtificial Intelli-\\ngence, Firm Growth, and Product Innovation.\\u201d Journal of Financial Economics 151\\n(January 1, 2024): 103745.\\nBalland, Pierre-Alexandre, Tom Broekel, Dario Diodato, Elisa Giuliani, Ricardo Hausmann,\\nNeave O\\u2019Clery, and David Rigby. 2022. \\u201cThe New Paradigm of Economic Complexity.\\u201d\\nResearch Policy51, no. 3 (April): 104450.\\nBianchi, Federico, Patrick John Chia, Mert Yuksekgonul, Jacopo Tagliabue, Dan Jurafsky,\\nand James Zou. 2024. \\u201cHow Well Can LLMs Negotiate? NegotiationArena Platform and\\nAnalysis.\\u201d arXiv.org.\\nBybee, J. Leland. 2023. \\u201cThe Ghost in the Machine: Generating Beliefs with Large Language\\nModels.\\u201d arXiv: 2305.02823.\\nCampello, Murillo, Lin William Cong, and Luofeng Zhou. 2023. \\u201cAlphaManager: A Data-\\nDriven-Robust-Control Approach to Corporate Finance.\\u201d Pre-published, December 2,\\n2023. SSRN Scholarly Paper. Accessed December 22, 2024. https://doi.org/10.2139/\\nssrn.4590323. Social Science Research Network: 4590323. https://papers.ssrn.com/\\nabstract=4590323.\\nChen, Yifei, Bryan T. Kelly, and Dacheng Xiu. 2022. \\u201cExpected Returns and Large Lan-\\nguage Models.\\u201d Pre-published, November 22, 2022. SSRN Scholarly Paper. Accessed\\nJanuary 26, 2025. Social Science Research Network: 4416687. https://papers.ssrn.com/\\nabstract=4416687.\\n36\\nChen, Zihan, Lei Zheng, Chengyu Lu, Jialu Yuan, and Di Zhu. 2023. \\u201cChatGPT Informed\\nGraph Neural Network for Stock Movement Prediction.\\u201d Social Science Research Net-\\nwork.\\nChuang, Yun-Shiuan, Agam Goyal, Nikunj Harlalka, Siddharth Suresh, Robert Hawkins,\\nSijia Yang, Dhavan Shah, Junjie Hu, and Timothy T. Rogers. 2023. \\u201cSimulating Opin-\\nion Dynamics with Networks of LLM-based Agents.\\u201d North American Chapter of the\\nAssociation for Computational Linguistic s.\\nColliard, Jean-Edouard, Thierry Foucault, and Stefano Lovo. 2022. \\u201cAlgorithmic Pricing\\nand Liquidity in Securities Markets.\\u201d Pre-published, October 18, 2022. SSRN Scholarly\\nPaper. Accessed April 4, 2025. https://doi.org/10.2139/ssrn.4252858. Social Science\\nResearch Network: 4252858. https://papers.ssrn.com/abstract=4252858.\\nCong, Lin William, Ke Tang, Jingyuan Wang, and Yang Zhang. 2021. \\u201cAlphaPortfolio:\\nDirect Construction Through Deep Reinforcement Learning and Interpretable AI.\\u201d Pre-\\npublished, August 1, 2021. SSRN Scholarly Paper. Accessed December 22, 2024. https:\\n//doi.org/10.2139/ssrn.3554486. Social Science Research Network: 3554486. https:\\n//papers.ssrn.com/abstract=3554486.\\nDou, Winston Wei, Itay Goldstein, and Yan Ji. 2024. \\u201cAI-Powered Trading, Algorithmic\\nCollusion, and Price Efficiency.\\u201d Pre-published, May 30, 2024. SSRN Scholarly Paper.\\nAccessed April 4, 2025. https://doi.org/10.2139/ssrn.4452704. Social Science Research\\nNetwork: 4452704. https://papers.ssrn.com/abstract=4452704.\\nEisfeldt, Andrea L., Gregor Schubert, Miao Ben Zhang, and Bledi Taska. 2023. \\u201cGenerative\\nAI and Firm Values.\\u201d Pre-published, May 2, 2023. SSRN Scholarly Paper. Accessed\\nJanuary 26, 2025. https : / / doi .org / 10 .2139 / ssrn . 4436627. Social Science Research\\nNetwork: 4436627. https://papers.ssrn.com/abstract=4436627.\\n37\\nGao, Shen, Yuntao Wen, Minghang Zhu, Jianing Wei, Yuhan Cheng, Qunzi Zhang, and Shuo\\nShang. 2024. \\u201cSimulating Financial Market via Large Language Model Based Agents.\\u201d\\nPre-published, June 28, 2024. Accessed January 26, 2025. https://doi.org/10.48550/\"]}": {"cached_metrics_data": [{"metric_data": {"name": "Contextual Precision (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Faithfulness (ragas)", "threshold": 0.8, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.8, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Contextual Recall (ragas)", "threshold": 0.6, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.6, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Answer Relevancy (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}]}, "{\"actual_output\": \"System prompts define the LLM agent's overall trading philosophy and long-term goals. They establish the core characteristics of the agent, such as whether it's a \\\"value investor\\\" (an investor who buys assets they believe to be undervalued by the market), a \\\"momentum trader\\\" (a trader who seeks to profit from the continued momentum of a security's price), or a \\\"market maker\\\" (a trader who provides liquidity by consistently quoting bid and ask prices for a security). This remains constant throughout the trading simulation.\\n\\nUser prompts, on the other hand, provide the immediate market context and short-term instructions for the agent. They deliver up-to-date information like current prices, trading volume, and the agent's current holdings. The user prompt also specifies any immediate actions the agent needs to take, like placing a specific order. This changes with each trading round as the market conditions evolve. Therefore, the system prompt sets the agent's overall strategy, while the user prompt gives it the specific information and instructions it needs to operate within the current market situation.\", \"context\": [\"The system prompt establishes the agent\\u2019s fundamental trading characteristics\\u2026\\u201d / \\u201cThe user prompt provides the immediate market context necessary for tactical decision\\u2011making.\"], \"expected_output\": \"System prompt fixes the agent\\u2019s identity and objectives across rounds; user prompt feeds current market state & constraints for the immediate decision.\", \"hyperparameters\": null, \"input\": \"HWhat are the roles of system prompts vs user prompts in shaping an LLM trading agent\\u2019s behaviour?\", \"retrieval_context\": [\"(2023)). This work, however, focuses on financial markets and how LLM agents can operate\\nas full-fledged trading participants.\\nRecent research examines specific applications of LLMs for trading. FinMem and Trad-\\ningGPT introduce frameworks with layered memory systems and customizable agent traits\\n5\\nto improve financial decision-making (Yu, Li, et al. 2024; Li, Zhang, and Sun 2023). Hierar-\\nchical multi-agent architectures have been explored in FinCon, which uses a manager-analyst\\nsetup for collaborative portfolio decisions (Yu, Yao, et al. 2024). QuantAgent implements\\na self-improving signal-mining approach (Wang et al. 2024), while other work underscores\\nthe importance of long-term memory in LLM agents via vector databases (Hatalis et al.\\n2024). This line of research builds on successful reinforcement learning applications such as\\nAlphaPortfolio (Cong et al. 2021) and AlphaManager (Campello, Cong, and Zhou 2023),\\nwhich leverage deep RL and robust control for portfolio management.\\nAnalyzing LLM agent behavior by changing only some parameters draws on methods\\nfrom the interpretable machine learning literature. In particular, the systematic variation\\nof market parameters to reveal decision patterns mirrors partial dependence plots and in-\\ndividual conditional expectation curves used to interpret complex machine learning models\\n(Molnar 2022). These techniques help reveal how LLM agents respond to changes in specific\\nvariables while holding others constant, providing insight into their internal decision-making\\nprocesses that would otherwise remain opaque.\\nBeyond finance, studies of LLM capabilities in interactive or multi-agent settings offer\\nvaluable insights. Benchmarks like AgentBench evaluate LLMs\\u2019 performance in interac-\\ntive tasks (Liu et al. 2023), while InvestorBench focuses on financial decision-making tasks\\nspecifically (H. Li et al. 2024). NegotiationArena demonstrates LLMs\\u2019 capacity for strategic\\ninteraction in bargaining contexts (Bianchi et al. 2024). Similarly, Guo et al. (2024) provide\\nan economics \\u201darena\\u201d where LLMs compete in strategic games, revealing that advanced\\nmodels like GPT-4 can exhibit rational, adaptive behavior\\u2014albeit not always reaching Nash\\nEquilibrium. Existing frameworks typically assess individual agents or hierarchical collab-\\norations, whereas this work studies emergent market behaviors that arise from multiple\\nindependent LLM traders interacting in a marketplace.\\nThe approach also connects to the tradition of experimental asset markets. For instance,\\nWeitzel et al. (2020) show that even finance professionals are susceptible to speculative\\n6\\nbubbles, especially amid high capital inflows. Kop\\u00b4 anyi-Peuker and Weber (2021) find that\\ntrading experience alone does not eliminate bubbles, challenging assumptions about rational\\nmarket learning. Kirchler, Huber, and St\\u00a8 ockl (2012) identify confusion about fundamental\\nvalues as a key driver of bubble formation. This framework offers a new way to study these\\nphenomena with LLM traders, which can be rigorously parameterized for sophistication,\\nstrategy, and information processing. Hence, this paper provides a method to investigate\\nhow automated or \\u201dartificial\\u201d agents might affect market stability or volatility.\\nOther recent work highlights the versatility of LLM agents in complex, interactive sce-\\nnarios beyond finance. One stream focuses on simulating social behaviors\\u2014such as opinion\\ndynamics (Chuang et al. 2023), trust (Xie et al. 2024), and resource-sharing (Piatti et al.\\n2024). Another examines LLMs\\u2019 strategic capabilities through task-based simulations and\\ncollaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\\nWithin the computer science literature, early works apply LLMs to financial markets but\\nabstract away many fundamental stock market characteristics. Often, they employ single-\\nprice clearing mechanisms without a persistent order book, ignore partial fills and bid-ask\", \"2024). Another examines LLMs\\u2019 strategic capabilities through task-based simulations and\\ncollaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\\nWithin the computer science literature, early works apply LLMs to financial markets but\\nabstract away many fundamental stock market characteristics. Often, they employ single-\\nprice clearing mechanisms without a persistent order book, ignore partial fills and bid-ask\\nspreads, and omit dividends. Consequently, these simplified environments can primarily\\naddress exogenous macro shocks (e.g., changes in interest rates or inflation; Gao et al. 2024),\\nexogenous policy changes (Zhang et al. 2024), or rely on advanced methods such as repetitive\\nnext-token predictions to generate better answers (Koa et al. 2024). This work extends\\nthese efforts by incorporating these crucial market features, enabling the study of complex\\nendogenous events such as flash crashes, liquidity shocks, and large-trader impacts.\\nThis work also connects to emerging research on algorithmic and AI-powered trading\\nsystems. Dou, Goldstein, and Ji (2024) demonstrate how reinforcement learning-based AI\\nspeculators can autonomously learn to sustain collusive behavior without explicit coordi-\\nnation, achieving supra-competitive profits through either price-trigger strategies or self-\\nconfirming bias in learning. This finding is particularly informative for this framework as\\nit highlights potential emergent behaviors that may arise when intelligent agents interact in\\n7\\nmarkets\\u2014behaviors that could manifest differently with LLM agents due to their natural\\nlanguage reasoning capabilities. Similarly, Colliard, Foucault, and Lovo (2022) examine al-\\ngorithmic market makers using Q-learning and find they charge markups that increase when\\nadverse selection costs decrease\\u2014contrary to Nash equilibrium predictions. Their work pro-\\nvides methodological insights on how to test strategic pricing behaviors against theoretical\\nbenchmarks incorporated into this LLM-based framework.\\nFinally, this approach is informed by complexity economics, which views markets as dy-\\nnamic, non-equilibrium systems where agents adaptively learn and evolve strategies (Arthur\\n2013; Wolfram 2017). According to this view, markets exhibit emergent phenomena and\\nself-organization, especially when trading agents (human or artificial) update their behav-\\nior in response to outcomes. This paradigm is particularly relevant in an era of increasing\\nautomation and algorithmic trading (Balland et al. 2022; Ping 2019). Like adaptive agents\\nin complexity economics, these LLM traders incorporate new information and adjust their\\nstrategies, generating emergent market patterns\\u2014a key motivation behind this framework.\\nUnlike previous frameworks that abstract away crucial market features or focus on narrow\\nstrategies, this system incorporates realistic market microstructure while accommodating\\nheterogeneous agents interacting simultaneously. While earlier work demonstrates LLMs\\u2019\\npromise for macroeconomic modeling and simple trading simulations, this work introduces a\\ncomplex, open-source financial market platform that supports multiple agent architectures,\\nthorough market microstructure (limit orders, partial fills, dividends), and rigorous testing\\nprotocols\\u2014fulfilling a critical need in complexity economics research and market microstruc-\\nture analysis.\\n2 Methodology\\nThe methodology section contains three parts. The first part describes the market design,\\nthe second agents\\u2019 design, and the third the analysis module.\\n8\\n2.1 Market Design\\nOur methodological framework integrates three components that create a controlled envi-\\nronment for LLM-based trading agents. The framework implements a flexible continuous\\ndouble-auction market mechanism that couples standard market microstructure principles\\nwith market clearing and matching algorithms to accommodate asynchronous LLM decisions.\", \"Can Large Language Models Trade? Testing Financial\\nTheories with LLM Agents in Market Simulations\\nAlejandro Lopez-Lira\\u2217\\nFirst Version: November 29, 2024; Current Version: April 16, 2025\\nAbstract\\nThis paper presents a realistic simulated stock market where large language models\\n(LLMs) act as heterogeneous competing trading agents. The open-source framework\\nincorporates a persistent order book with market and limit orders, partial fills, div-\\nidends, and equilibrium clearing alongside agents with varied strategies, information\\nsets, and endowments. Agents submit standardized decisions using structured outputs\\nand function calls while expressing their reasoning in natural language. Three findings\\nemerge: First, LLMs demonstrate consistent strategy adherence and can function as\\nvalue investors, momentum traders, or market makers per their instructions. Second,\\nmarket dynamics exhibit features of real financial markets, including price discovery,\\nbubbles, underreaction, and strategic liquidity provision. Third, the framework enables\\nanalysis of LLMs\\u2019 responses to varying market conditions, similar to partial dependence\\nplots in machine-learning interpretability. The framework allows simulating financial\\ntheories without closed-form solutions, creating experimental designs that would be\\ncostly with human participants, and establishing how prompts can generate correlated\\nbehaviors affecting market stability.\\nKeywords: LLM Agents; Agent-Based Markets; Experimental Finance; AI Trading;\\nMulti-Agent Systems\\n\\u2217University of Florida. Email: alejandro.lopez-lira@warrington.ufl.edu. I am grateful to seminar par-\\nticipants at the London Business School, Oxford University, Stockholm School of Economics, University of\\nVirginia, and the City University of Hong Kong for helpful suggestions and feedback.\\n1\\narXiv:2504.10789v1  [q-fin.CP]  15 Apr 2025\\n1 Introduction\\nLarge language models (LLMs) can increasingly function as autonomous agents\\u2014systems\\nthat observe, reason, and act independently. LLMs have shown promising results in finan-\\ncial forecasting, but their potential as trading agents introduces a fundamental shift from\\nalgorithms with explicit objectives to systems guided by natural language instructions. This\\nchange raises critical questions: Can LLMs execute trading strategies? Do LLMs optimize\\nfor profit maximization? What are the implications for market stability and efficiency?\\nIf LLMs trade similarly to humans, they could enable experimental market simulations\\nwithout human participants. Conversely, if their trading behavior differs, understanding\\nthese differences becomes critical for systemic risk management. These questions extend be-\\nyond theory; LLM-based strategies are already being deployed.1 To address these questions,\\nI develop an open-source simulation that tests LLM trading agents in a realistic market envi-\\nronment with a persistent order book, supporting various order types, stochastic dividends,\\nand heterogeneous information.\\nThe framework allows heterogeneous LLMs\\u2014defined in natural language, using different\\nsystem prompts\\u2014to act as diverse types of traders, such as value investors, momentum\\ntraders, market makers, and contrarians. Agents submit standardized trading decisions in a\\nhuman-readable format while expressing their reasoning transparently. Figure 1 illustrates\\nthis approach, showing how a speculator agent combines explicit valuation reasoning with\\nstructured trading parameters, enabling systematic analysis and insight into the agent\\u2019s\\ndecision-making process.\\nThe analysis reveals three key findings about LLMs\\u2019 capabilities as trading agents. First,\\nLLMs can effectively execute trading strategies. They consistently understand market me-\\nchanics, process market information, form price expectations, and execute trades according\\nto specific instructions. Their trading behavior is highly sensitive to the prompts they\\nreceive\\u2014they faithfully follow directions regardless of profit implications. This observance\", \"\\u2022 Market Makers: Provide liquidity through symmetric bid-ask spreads\\n\\u2022 Contrarian Traders: Trade against market extremes and overreactions\\n\\u2022 Speculators: Seek to profit from market inefficiencies\\n\\u2022 Sentiment-Based Agents: Include optimistic and pessimistic variants with biased\\nexpectations\\n\\u2022 Retail Traders: Simulate typical individual investor behavior\\nThe software also includes a set of deterministic rule-based agents that serve as bench-\\nmarks and control conditions:\\n\\u2022 Directional Traders: Always-buy, always-sell, and always-hold agents\\n\\u2022 Technical Agents: Gap traders, mean reversion traders, and momentum traders\\n\\u2022 Algorithmic Market Makers: Implement fixed spread-posting strategies\\n14\\nEach agent type is defined by its system prompt (for LLM agents) or algorithmic rules (for\\ndeterministic agents), with standardized interfaces enabling direct comparison across diverse\\nstrategies. The agent composition system supports flexible specifications\\u2014including uni-\\nform distributions, type-specific concentrations (e.g., \\u201dvalue heavy\\u201d), and precise numerical\\nallocations\\u2014enabling systematic exploration of how market dynamics emerge from different\\nagent populations.\\nThe framework\\u2019s extensible design makes it remarkably simple to add new agent types\\u2014\\nLLM-based agents require only defining a new system prompt that specifies the trading\\nstrategy. In contrast, deterministic agents can be implemented through the standard agent\\ninterface. This flexibility allows researchers to rapidly prototype and deploy novel trading\\nstrategies without modifying the underlying system architecture.\\nThe complete list of agent types included in the framework and their detailed specifi-\\ncations is provided in the Appendix. The framework\\u2019s flexible prompt-based architecture\\nallows researchers to rapidly prototype and deploy new agent types by developing appropri-\\nate strategic and tactical prompts without modifying the underlying system architecture.\\n2.2.4 User Prompt\\nThe user prompt provides the immediate market context necessary for tactical decision-\\nmaking. This dynamic component delivers current market state information, including\\nprices, volumes, and emerging trends, alongside the agent\\u2019s current position information\\nand available trading options. Additionally, the user prompt specifies immediate decision\\nrequirements and operational constraints, ensuring that agent responses remain within fea-\\nsible bounds while aligning with their strategic objectives. This separation of strategic and\\ntactical prompting enables precise control over agent behavior while maintaining flexibility\\nfor market interactions. All the information in the user prompt is optional at the agent level\\nand can be customized for different experimental designs.\\n15\\n2.2.5 Decision Structure\\nEach agent decision follows a standardized output format comprising several key components.\\nThe decision field specifies the basic action as either Buy, Sell, or Hold. For active trades,\\nthe quantity field determines the number of shares to trade, while the order type indicates\\nwhether it is a Market or Limit order. When placing limit orders, the price limit field\\nspecifies the maximum (for buys) or minimum (for sells) acceptable execution price. Finally,\\neach decision includes a reasoning field that provides an explicit rationale for the trading\\ndecision, ensuring transparency and facilitating analysis of agent behavior.\\n2.2.6 Structured Outputs and Function Calling\\nOur framework implements a structured output approach using function calling to ensure\\nstandardized, human-readable, machine-readable agent decisions. This technique allows\\nLLMs to generate outputs in a specific format that can be directly validated and processed\\nby the trading system, bridging the gap between natural language reasoning and executable\\ntrading actions.\\nThe system uses Pydantic for validation and parsing of agent outputs, with a schema-\\nbased approach that defines the required structure:\\nclass TradeDecisionSchema(BaseModel):\", \"an open-source framework with three key components: (1) a structured protocol for im-\\nplementing and validating LLM trading agents, supporting both LLM-based and traditional\\nrule-based agents; (2) a controlled market environment with realistic microstructure for test-\\ning agent interactions; and (3) a comprehensive data collection system for analyzing trading\\nbehavior. This framework serves multiple stakeholders in preparation for the evolution of\\nfinancial markets: practitioners developing LLM-based trading systems, regulators antic-\\nipating widespread LLM adoption, and researchers studying market dynamics with LLM\\nagents.\\n1.1 Related Work\\nThis work contributes to several strands of literature. First, advancing the growing body\\nof research on artificial intelligence in finance by demonstrating that large language mod-\\nels (LLMs) can serve as effective autonomous trading agents while providing a framework\\nfor their implementation. Second, by contributing to the market microstructure literature\\nby providing insights into how markets might evolve as LLM-based traders become active\\nparticipants, with implications for price formation, liquidity provision, and market stabil-\\nity. Third, by contributing to experimental markets research by introducing an environment\\nfor studying complex trading interactions, offering unprecedented control and replicability\\ncompared to traditional human-subject experiments.\\n4\\nRecent studies have explored ChatGPT\\u2019s potential in various financial tasks. Research\\nshows that ChatGPT can effectively predict stock price movements using news headlines,\\noutperforming traditional sentiment analysis (Lopez-Lira and Tang 2023) and that forecast-\\ning with its embeddings outperforms traditional sentiment analysis (Chen, Kelly, and Xiu\\n2022). When integrated with Graph Neural Networks, ChatGPT improves stock movement\\nprediction and portfolio performance (Chen et al. 2023. ChatGPT can understand Federal\\nReserve communications Hansen and Kazinnik (2023). The model also can extract manage-\\nrial expectations from corporate disclosures, predicting future investments and returns (Jha\\net al. 2025). ChatGPT-4 provides valuable investment advice with positive correlations to\\nsubsequent earnings announcements and stock returns (Pelster and Val 2023), and it en-\\nhances patent value forecasts by processing patent text (Yang 2023). Moreover, ChatGPT\\nshows promise in central bank analysis, predicting future interest rate decisions from pol-\\nicy communications (Woodhouse and Charlesworth 2023). Recent work also focuses on the\\neffects of AI adoption by firms (Eisfeldt et al. 2023, Babina et al. 2024).\\nFoundational work on LLMs as economic agents demonstrates their ability to simulate\\nhuman behavior in economic contexts. Horton (2023) introduce the concept of \\u201chomo silicus\\u201d\\nby using LLMs as computational models of human behavior, showing that they can repli-\\ncate classic behavioral economics findings. Manning, Zhu, and Horton (2024) extend this\\napproach through automated methods for generating and testing social scientific hypotheses\\nwith LLMs, demonstrating strong results in market contexts such as auctions. Meanwhile,\\nN. Li et al. (2024) show LLMs\\u2019 potential in macroeconomic simulation for consumption\\nand labor decisions. Recent work also shows the potential of LLMs to proxy for human\\nbehavior in the context of surveys (Hansen et al. (2024)) or economic expectations (Bybee\\n(2023)). This work, however, focuses on financial markets and how LLM agents can operate\\nas full-fledged trading participants.\\nRecent research examines specific applications of LLMs for trading. FinMem and Trad-\\ningGPT introduce frameworks with layered memory systems and customizable agent traits\\n5\\nto improve financial decision-making (Yu, Li, et al. 2024; Li, Zhang, and Sun 2023). Hierar-\\nchical multi-agent architectures have been explored in FinCon, which uses a manager-analyst\", \"ceedings of the 62nd Annual Meeting of the Association for Computational Linguistics\\n(Volume 1: Long Papers),edited by Lun-Wei Ku, Andre Martins, and Vivek Srikumar,\\n15523\\u201315536. ACL 2024. Bangkok, Thailand: Association for Computational Linguis-\\ntics, August.\\n39\\nLi, Yuan, Yixuan Zhang, and Lichao Sun. 2023. \\u201cMetaAgents: Simulating Interactions of\\nHuman Behaviors for LLM-based T Ask-Oriented Coordination via Collaborative Gen-\\nerative Agents.\\u201d arXiv.org.\\nLiu, Xiao, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, et al. 2023.\\n\\u201cAgentBench: Evaluating LLMs as Agents.\\u201dInternational Conference on Learning Rep-\\nresentations.\\nLopez-Lira, Alejandro, and Yuehua Tang. 2023. \\u201cCan ChatGPT Forecast Stock Price Move-\\nments? Return Predictability and Large Language Models.\\u201d SSRN Electronic Journal\\n(April 6, 2023).\\nManning, Benjamin S., Kehang Zhu, and John J. Horton. 2024. \\u201cAutomated Social Science:\\nLanguage Models as Scientist and Subjects.\\u201d (Cambridge, MA) (April 29, 2024).\\nMolnar, Christoph. 2022. Interpretable Machine Learning.\\nPelster, Matthias, and Joel Val. 2023. \\u201cCan Chatgpt Assist in Picking Stocks?\\u201dSocial Science\\nResearch Network.\\nPiatti, Giorgio, Zhijing Jin, Max Kleiman-Weiner, Bernhard Sch\\u00a8 olkopf, Mrinmaya Sachan,\\nand Rada Mihalcea. 2024. \\u201cCooperate or Collapse: Emergence of Sustainable Coopera-\\ntion in a Socie Ty of LLM Agents.\\u201d arXiv.org.\\nPing, Chen. 2019. \\u201cFrom Complexity Science to Complexity Economics.\\u201d In Alternative\\nApproaches to Economic Theory,19\\u201355. Routledge, June 11, 2019.\\nWang, Saizhuo, Hang Yuan, Lionel M. Ni, and Jian Guo. 2024. \\u201cQuantAgent: Seeking Holy\\nGrail in Trading by Self-Improving Large Lang Uage Model.\\u201d arXiv.org.\\nWeitzel, Utz, Christoph Huber, J\\u00a8 urgen Huber, Michael Kirchler, Florian Lindner, and Julia\\nRose. 2020. \\u201cBubbles and Financial Professionals.\\u201d The Review of Financial Studies33,\\nno. 6 (June 1, 2020): 2659\\u20132696.\\n40\\nWolfram, Elsner. 2017. \\u201cComplexity Economics as Heterodoxy: Theory and Policy.\\u201dJournal\\nof Economic Issues51, no. 4 (October 2, 2017): 939\\u2013978.\\nWoodhouse, Drew, and Alex Charlesworth. 2023. \\u201cCan ChatGPT Predict Future Interest\\nRate Decisions?\\u201d Social Science Research Network.\\nXie, Chengxing, Canyu Chen, Feiran Jia, Ziyu Ye, Shiyang Lai, Kai Shu, Jindong Gu, et al.\\n2024. \\u201cCan Large Language Model Agents Simulate Human Trust Behavior?\\u201darXiv.org.\\nYang, Stephen. 2023. \\u201cPredictive Patentomics: Forecasting Innovation Success and Valuation\\nw Ith ChatGPT.\\u201d Social Science Research Network.\\nYu, Yangyang, Haohang Li, Zhi Chen, Yuechen Jiang, Yang Li, Denghui Zhang, Rong\\nLiu, Jordan W. Suchow, and Khaldoun Khashanah. 2024. \\u201cFinMem: A Performance-\\nEnhanced LLM Trading Agent with Layered Memory a Nd Character Design.\\u201dProceed-\\nings of the AAAI Symposium Series3, no. 1 (May 20, 2024): 595\\u2013597.\\nYu, Yangyang, Zhiyuan Yao, Haohang Li, Zhiyang Deng, Yupeng Cao, Zhi Chen, Jordan W.\\nSuchow, et al. 2024. \\u201cFinCon: A Synthesized LLM Multi-Agent System with Conceptual\\nVerbal Reinforcement for Enhanced Financial Decision Making.\\u201d Pre-published, Novem-\\nber 7, 2024. Accessed January 8, 2025. https://doi.org/10.48550/arXiv.2407.06567.\\narXiv: 2407.06567 [cs]. http://arxiv.org/abs/2407.06567.\\nZhang, Chong, Xinyi Liu, Zhongmou Zhang, Mingyu Jin, Lingyao Li, Zhenting Wang,\\nWenyue Hua, et al. 2024. \\u201cWhen AI Meets Finance (StockAgent): Large Language\\nModel-based Stock Trading in Simulated Real-world Environments.\\u201d Pre-published,\\nSeptember 21, 2024. Accessed January 26, 2025. https://doi.org /10.48550/arXiv .\\n2407.18957. arXiv: 2407.18957 [q-fin]. http://arxiv.org/abs/2407.18957.\\n41\\nA Technical Implementation Details\\nA.1 Agent Type Specifications\\nThis section details the base system prompts for each agent type in our simulation. These\\nprompts define the core behavioral characteristics and trading strategies for each agent. Each\\nprompt consists of:\\n\\u2022 A role definition that establishes the agent\\u2019s trading philosophy\\n\\u2022 A structured trading strategy that guides decision-making\", \"decision-making process.\\nThe analysis reveals three key findings about LLMs\\u2019 capabilities as trading agents. First,\\nLLMs can effectively execute trading strategies. They consistently understand market me-\\nchanics, process market information, form price expectations, and execute trades according\\nto specific instructions. Their trading behavior is highly sensitive to the prompts they\\nreceive\\u2014they faithfully follow directions regardless of profit implications. This observance\\n1. For example, Autopilot has a ChatGPT-based portfolio https://x.com/thegptinvestor.\\n2\\n{\\\"valuation_reasoning\\\":\\n\\\"The fundamental value is based on the expected dividend,\\nand the interest rate.\\nThe expected dividend is $1.40, and the interest rate is 5%.\\nUsing a perpetuity formula, the value is $1.40 / 0.05 = $28.\\\",\\n\\\"valuation\\\":28.0,\\n\\\"price_target_reasoning\\\":\\\"The current price is $29.00, which is\\nslightly above the fundamental value of $28.00. I expect the price\\nto remain around $29.00 in the next round due to market stability.\\\",\\n\\\"price_target\\\":29.0,\\n\\\"orders\\\":[{\\\"decision\\\":\\\"Sell\\\",\\\"quantity\\\":1000,\\\"order_type\\\":\\\"limit\\\",\\n\\\"price_limit\\\":29.50}],\\n\\\"replace_decision\\\":\\\"Add\\\",\\n\\\"reasoning\\\":\\\"The current price is slightly above the fundamental value.\\nI will place a limit sell order at $29.50 to capitalize on potential price\\nincreases.\\\"}\\nFigure 1: Example of a structured trading decision from a Speculator agent defined by its\\nsystem prompt: \\u201cYou are a speculator who tries to profit from market inefficiencies.\\u201d. The\\nLLM provides explicit reasoning for its valuation, price target, and trading decision in a\\nmachine-readable JSON format that can be directly processed by the trading system.\\nhighlights a fundamental difference from human traders: LLMs do not inherently optimize\\nfor profit maximization but rather for following instructions accurately.\\nSecond, LLMs react meaningfully to market dynamics. They consider current and his-\\ntorical prices, dividends, and other market information when making decisions. However,\\nthey maintain their strategic direction even when market conditions change, following their\\ninstructions even if doing so results in financial losses. This combination of responsiveness\\nto market conditions while maintaining strategic consistency creates a unique trading profile\\ndistinct from rule-based algorithms and human traders.\\nThird, market dynamics with LLM agents can resemble actual markets and mirror classic\\nresults from the theoretical finance literature. When these agents interact, they produce\\nrealistic price discovery and liquidity provision with emergent behaviors, including price\\nconvergence toward fundamental values. Depending on the distribution of agent types,\\nthe system can generate various market phenomena, such as bubbles or underreactions to\\ninformation. This complex behavior suggests potential applications for studying market\\n3\\ndynamics using LLM agents instead of experiments with human participants.\\nHence, these findings raise important questions about algorithmic consistency in LLM-\\nbased systems. Since trading agents are implemented through prompts, their behavior in-\\nherits characteristics of the underlying language models. The standardization of LLM ar-\\nchitectures across implementations could create unexpected behavioral patterns\\u2014if many\\nagents are based on similar foundation models, they might exhibit correlated responses to\\nspecific market conditions, potentially amplifying market instabilities.\\nTo enable this analysis and accelerate development in this emerging field, we provide\\nan open-source framework with three key components: (1) a structured protocol for im-\\nplementing and validating LLM trading agents, supporting both LLM-based and traditional\\nrule-based agents; (2) a controlled market environment with realistic microstructure for test-\\ning agent interactions; and (3) a comprehensive data collection system for analyzing trading\\nbehavior. This framework serves multiple stakeholders in preparation for the evolution of\", \"gies, allowing researchers to experiment with diverse behavioral models and decision-making\\napproaches.\\nThis extensible design creates numerous research opportunities for market microstructure\\nstudies. Researchers can systematically investigate how different market structures influence\\nprice formation and efficiency, evaluate the impact of various trading rules on market qual-\\nity, and analyze the complex interactions between different agent types and strategies. The\\nframework\\u2019s comprehensive logging and validation systems enable detailed examination of\\nmarket behavior under varying conditions, from everyday trading environments to stress sce-\\nnarios. Through this modular approach to system design, the framework supports targeted\\ninvestigations of specific market mechanisms and broader studies of market dynamics and\\nstability.\\n2.2 Agent Design\\nOur framework implements a systematic approach to designing LLM-based trading agents\\nand recording their decisions. The architecture consists of three main components: a prompt\\nengineering framework to define the agent\\u2019s trading objectives, the heterogeneous market\\nenvironment information that can be customized for different experimental designs, and a\\nstructured output format to record the agent\\u2019s decisions. Moreover, the framework supports\\n12\\ndeterministic rule-based agents that can serve as benchmarks.\\n2.2.1 Prompt Engineering Framework\\nLLM agents are defined by their instructions in natural language. The strategy is given in the\\nsystem prompt so that agents maximize adherence to their instructions (Levin et al. (2025)).\\nIn contrast, the user prompt provides the immediate market context necessary for tactical\\ndecision-making and the instructions to place and modify orders.\\n2.2.2 System Prompt\\nThe system prompt establishes the agent\\u2019s fundamental trading characteristics, defining its\\ntrading philosophy, objectives, and behavioral constraints. This layer encodes the agent\\u2019s\\ndecision-making priorities and risk preferences. Maintaining these parameters in the system\\nprompt ensures consistent agent behavior across multiple trading rounds while allowing for\\nstrategic adaptation to changing market conditions. The architecture makes it trivial to\\ndesign new agents by simply changing the system prompt.\\nFor example, a Value Investor\\u2019s system prompt emphasizes fundamental analysis:\\nYou are a value investor who focuses on fundamental analysis.\\nYou believe in mean reversion and try to buy undervalued\\nassets and sell overvalued ones.\\nWhile a Market Maker\\u2019s system prompt focuses on liquidity provision:\\nYou are a professional market maker who provides liquidity\\nto the market. Your profit comes from capturing the spread\\nbetween bid and ask prices, not from directional price movement.\\nTrading Guidelines:\\n- Place LIMIT buy orders slightly below the current market price\\n- Place LIMIT sell orders slightly above the current market price\\n13\\n- Your spread should be proportional to volatility\\nThese system prompts can create fundamentally different trading behaviors using the\\nsame underlying LLM and identical market information.\\n2.2.3 Agent Types\\nThe framework contains diverse ready-to-use agent types that can be categorized into two\\nmain groups: LLM-based agents with natural language prompts and deterministic rule-based\\nagents with algorithmic behaviors.\\nThe software includes a diverse set of LLM-based agents:\\n\\u2022 Value Investors: Focus on fundamental analysis and mean reversion\\n\\u2022 Momentum Traders: Follow established price trends and volume patterns\\n\\u2022 Market Makers: Provide liquidity through symmetric bid-ask spreads\\n\\u2022 Contrarian Traders: Trade against market extremes and overreactions\\n\\u2022 Speculators: Seek to profit from market inefficiencies\\n\\u2022 Sentiment-Based Agents: Include optimistic and pessimistic variants with biased\\nexpectations\\n\\u2022 Retail Traders: Simulate typical individual investor behavior\\nThe software also includes a set of deterministic rule-based agents that serve as bench-\"]}": {"cached_metrics_data": [{"metric_data": {"name": "Contextual Precision (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Faithfulness (ragas)", "threshold": 0.8, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.8, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Contextual Recall (ragas)", "threshold": 0.6, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.6, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Answer Relevancy (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}]}, "{\"actual_output\": \"The authors define the price-to-fundamental ratio (\\u03c1) as simply the market price (P) divided by the fundamental value (V) of the asset, expressed as \\u03c1 = P/V. This ratio is central to their systematic variation experiments because it allows them to test how LLM (Large Language Model) trading agents respond to different levels of mispricing. By varying \\u03c1, they can create scenarios where the market price is above (\\u03c1 > 1), below (\\u03c1 < 1), or equal to (\\u03c1 = 1) the fundamental value. This helps researchers observe how the LLM agents' trading decisions change depending on whether the asset is overvalued, undervalued, or fairly priced, and assess how efficiently these agents drive market prices towards the fundamental value.\", \"context\": [\"Our example implementation varies the price\\u2011to\\u2011fundamental ratio (\\u03c1 = P/V) across a range from 0.1 to 3.5 while maintaining all other market parameters constant\\u2026\"], \"expected_output\": \"\\u03c1 = P \\u2044 V. By sweeping \\u03c1 from 0.1\\u20133.5 and holding other factors fixed, the authors trace decision boundaries of each agent type.\", \"hyperparameters\": null, \"input\": \"How do the authors define the price\\u2011to\\u2011fundamental ratio and why is it central to their systematic variation experiments?\", \"retrieval_context\": [\"Given that performance ratios should satisfy the first two mandatory properties and the two conditional\\nproperties, we can prove the functional properties of \\u03b1to make the ratios micro-founded so as to explain the\\nmeaning of the signals contained in \\u03b1(X).\\nProposition 1: Let\\u03b1follow the form as described in Eq. (7):\\n1.If\\u03b8(X)\\u2265\\u03b8(Y)and\\u03c1(X)< \\u03c1(Y)\\u2200X, Y\\u2208 Xsuch that X\\u2265Y,then \\u03b1satisfies the monotonicity property\\n(M).\\n2.If\\u03b8is concave and \\u03c1convex, then \\u03b1satisfies the quasi-concavity property (Q).\\n3.\\u03c1(\\u03bbX) =\\u03bb\\u03c1(X)and\\u03b8(\\u03bbX) =\\u03bb\\u03b8(X)\\u2200X\\u2208 X and \\u03bb \\u2208R+\\\\{0}such that \\u03bbX \\u2208 X,then \\u03b1satisfies the\\nscale-invariance property (S).\\n4. If \\u03b8and\\u03c1satisfy the distribution-based property (D), then so does \\u03b1.\\nProof is straightforward and mentioned in Cheridito and Kromer (2013).\\nOne of the key issues when measuring the R/R ratios over the revised VIX is that while computing performance\\nratios over a convex set of random variables generates independent and identically distributed (i.i.d.) variables, the\\nfinancial return itself is not i.i.d., so this hinders the process of identifying uncertainty shocks as i.i.d. To mitigate\\nthis, we adopt the method of fitting a fractional time series model to take into account the long memory of the\\nmean and volatility exhibited in the time series data. Baillie et al. (1996) introduce the FIGARCH (Fractionally\\nIntegrated GARCH) model, demonstrating that traditional GARCH models are inadequate for capturing long\\nmemory in volatility. This finding highlights the need for fractional integration in volatility modeling to better\\nreflect persistent effects in financial time series. This justifies the need for fractional integration in volatility\\nmodeling. Similarly, Hyung and Franses (2002) shows that long memory in both the mean and variance processes is\\nbetter modeled and captured using Autoregressive Fractionally Integrated Moving Average-Fractionally Integrated\\nGARCH (ARFIMA-FIGARCH) models. Hence, the goal of the present paper is to emphasize the use of fractional\\ntime series models to capture the long memory that is explained by the multiple subordinated NIG L\\u00b4 evy process\\nFigure 8 gives an illustration of the difference between the innovations of the ARFIMA(1, d(m), 1)-FIGARCH(1,\\nd(v), 1) and the Autoregressive Moving Average-GARCH of lag 1 and order 1 (ARMA(1,1)-GARCH(1,1)) fitted\\nover the values of the newly constructed normalized VVIX. The fractional time series model is better at capturing\\nthe persistent effects created by the shocks implied by the newly constructed volatility index.\\n11\\nFigure 11: Residuals of the fitted time series models\\nThe long memory in the mean, captured using the ARFIMA model, refers to the persistence of past values\\nof a time series influencing future values over long periods. In financial time series, long memory in the mean\\nimplies that past values of the series have a significant, slowly decaying influence on future values. Therefore,\\ninnovations to the time series do not fade away quickly, but explain the influence on the mean for a long time.\\nARFIMA models allow a slower, hyperbolic decay, characterizing a long memory. In addition, if a time series\\nhas long memory in its volatility, meaning the persistence of past volatility (variance) over time, large shifts in\\nvolatility appear to cluster and stay accentuated for long periods before decaying to normal levels. Long memory\\nof volatility is present in financial markets (financial time series), where periods of high volatility (e.g., during a\\nfinancial crisis) tend to last for extended periods and generate persistent shocks.\\nTherefore, to capture the long memory of the mean and volatility exhibited by the time series of the normalized\\nVVIX constructed in this paper, we apply the ARFIMA(1, d(m), 1)-FIGARCH(1, d(v), 1), where d(m) is the\\nterm describing the long memory of the mean and d(v) is the term describing the long memory of the volatility.\\nThe time series follows the process:\\nARFIMA (1, d(m),1)\\u21dd\\u03d5(L)(1\\u2212L)d(m)zt=\\u03b8(L)\\u03b5t (14)\", \"The Journal of Finance , 59(4):1481\\u20131509.\\nBarndorff-Nielsen, O. and Shephard, N. (2001). Non-gaussian ornstein\\u2013uhlenbeck-based models and some\\nof their uses in financial economics. Journal of the Royal Statistical Society: Series B (Statistical\\nMethodology) , 63(2):167\\u2013241.\\nBarro, R. J. (2006). Rare disasters and asset markets in the twentieth century. The Quarterly Journal\\nof Economics , 121(3):823\\u2013866.\\nBloom, N. (2009). The impact of uncertainty shocks. Econometrica , 77(3):623\\u2013685.\\nBloom, N. (2014). Fluctuations in uncertainty. Journal of Economic Perspectives , 28(2):153\\u2013176.\\nBloom, N., Bond, S., and Van Reenen, J. (2007). Uncertainty and investment dynamics. The Review of\\nEconomic Studies , 74(2):391\\u2013415.\\nCarr, P., Geman, H., Madan, D. B., and Yor, M. (2003). Stochastic volatility for l evy processes.\\nMathematical Finance , 13(3):345\\u2013382.\\nCarr, P. P. and Madan, D. (2001). Option valuation using the Fast Fourier Transform. Journal of\\nComputational Finance , 2(4).\\nCheridito, P. and Kromer, E. (2013). Reward\\u2013risk ratios. Journal of Investment Strategies .\\nClark, P. (1973). A subordinated stochastic process model with fixed variance for speculative prices.\\nEconometrica , 41:135\\u2013156.\\nCont, R. (2000). Empirical properties of asset returns: Stylized facts and statistical issues. Quantitative\\nFinance , 1:223\\u2013236.\\nDelbaen, F. and Schachermayer, W. (1994). A general version of the fundamental theorem of asset\\npricing. Mathematische Annalen , 300(1):463\\u2013520.\\nDelbaen, F. and Schachermayer, W. (1999). The fundamental theorem of asset pricing for unbounded\\nstochastic processes. SFB Adaptive Information Systems and Modelling in Economics and Man-\\nagement Science, WU Vienna University of Economics and Business. Report Series SFB \\u2019Adaptive\\nInformation Systems and Modelling in Economics and Management Science\\u2019 , (24).\\nDuffie, D. (2001). Dynamic Asset Pricing Theory (3rd ed.) . Princeton University Press.\\nDuffie, D., Pan, J., and Singleton, K. (2000). Transform analysis and asset pricing for affine jump-\\ndiffusions. Econometrica , 68:1343\\u20131376.\\nEsscher, F. (1932). On the probability function in the collective theory of risk. Scandinavian Actuarial\\nJournal , 15(3):175\\u2013195.\\nHyung, N. and Franses, P. (2002). Modeling seasonality and long memory in time series. Journal of\\nEconometrics , 109(1):241\\u2013263.\\nJurado, K., Ludvigson, S. C., and Ng, S. (2015). Measuring uncertainty. American Economic Review ,\\n105(3):1177\\u20131216.\\nKelly, B. and Jiang, H. (2014). Tail risk and asset prices. The Review of Financial Studies ,\\n27(10):2841\\u20132871.\\nKozeniauskas, N., Orlik, A., and Veldkamp, L. (2018). What are uncertainty shocks? Journal of Monetary\\nEconomics , 100(2018):1\\u201315.\\nKozlowski, J., Veldkamp, L., and Venkateswaran, V. (2020). The tail that wags the economy: Beliefs\\nand persistent stagnation. Journal of Political Economy , 128(8):2839\\u20133284.\\nMandelbolt, B. and Taylor, H. (1967). On the distribution of stock price differences. Journal of Operations\\nResearch , 15:1057\\u20131062.\\nMehra, R. and Prescott, E. C. (2003). Chapter 14: The equity premium in retrospect , volume 1B, pages\\n889\\u2013938.\\nMeyer, P. and Dellacherie, C. (1978). Probabilities and Potential B: Theory of Martingales . North\\nHolland.\\nOrlik, A. and Veldkamp, L. (2014). Understanding uncertainty shocks and the role of black swans.\\nTechnical Report 20445, National Bureau of Economic Research.\\nRietz, T. A. (1988). The equity risk premium: A solution. Journal of Monetary Economics , 22:117\\u2013131.\\nRoutledge, B. R. and Zin, S. E. (2010). Generalized disappointment aversion and asset prices. The\\nJournal of Finance , 65(4):1303\\u20131332.\\n16\\nShirvani, A., Mittnik, S., Lindquist, W. B., and Rachev, S. T. (2024). Bitcoin volatility and intrinsic\\ntime using double-subordinated l\\u00b4 evy processes. Risks (MDPI) , 12(5):1\\u201321.\\nShirvani, A., Rachev, S., and Fabozzi, F. (2021a). Multiple subordinated modeling of asset returns:\\nImplications for option pricing. Econometric Reviews , 40(3):290\\u2013319.\", \"bids/asks), and two Speculator agents (opportunistic traders seeking inefficiencies). Market\\n31\\nmakers are given enhanced liquidity with 20x the baseline cash and shares to ensure suffi-\\ncient liquidity provision and facilitate price discovery. The scenario tests whether prices can\\ncorrect downward through trading activity when starting from an overvalued state.\\n3.2.2 Price Discovery (Below Fundamental)\\nThis complementary scenario tests upward price convergence by starting with an initial price\\n25% below the fundamental value ( $21.00). It employs the identical agent composition and\\nparameters as the above-fundamental scenario, allowing for direct comparison of market\\nbehavior under opposite initial mispricing conditions. This design enables researchers to\\nassess potential asymmetries in price discovery processes.\\n3.2.3 Infinite Horizon Price Discovery\\nWe extend both price discovery scenarios to infinite horizon settings, where shares are not\\nredeemed at a terminal date. The initial prices are set at double ($56.00) and half ($14.00) the\\nfundamental value for the above and below fundamental scenarios respectively, creating more\\nextreme mispricing conditions. These scenarios run for 15 trading rounds and test whether\\nagents correctly value assets based on expected dividend streams rather than redemption\\nvalues. Each infinite horizon scenario involves two Default investors, two Optimistic traders,\\ntwo Market makers, and two Speculator agents.\\nThe results from these infinite horizon scenarios reveal interesting asymmetries in price\\ndiscovery, as illustrated in Figure 6 and Figure 7. When the market starts significantly above\\nthe fundamental value (left panels), the price fails to converge downwards towards the$28.00\\nbenchmark within the 15 rounds, remaining substantially elevated. Agent valuations mirror\\nthis persistence, with many agents maintaining estimates well above the fundamental value.\\nHowever, when the market begins significantly below the fundamental value (right panels),\\nthe price exhibits a clear convergence towards the fundamental benchmark. Agent valuations\\nin this scenario also tend to adjust upwards, aligning more closely with the calculated fun-\\n32\\ndamental value over time. This suggests that under these conditions, LLM agents are more\\neffective at correcting undervaluation than overvaluation within the simulated timeframe.\\nFigure 6: Price Evolution: Infinite Horizon Scenarios. Left: Initial price $56.00 (Above\\nFundamental). Right: Initial price $14.00 (Below Fundamental). The dashed line indicates\\nthe fundamental value ($28.00).\\nFigure 7: Agent Valuations: Infinite Horizon Scenarios. Left: Initial price $56.00 (Above\\nFundamental). Right: Initial price $14.00 (Below Fundamental). Shows individual agent\\nestimates of fundamental value over time.\\n3.2.4 Divergent Beliefs\\nThis scenario explores the impact of heterogeneous beliefs about fundamental value by com-\\nbining agents with systematically different valuation models. The agent composition is\\ndesigned to create heterogeneity: two Optimistic traders (believing the fundamental value is\\nsignificantly higher), two Pessimistic traders (believing it is significantly lower), two neutral\\nMarket makers, two Momentum traders (following price trends rather than fundamentals),\\nand two Default investors (baseline agents). We test both above-fundamental (initial price\\n$56.00, 2x fundamental) and below-fundamental (initial price$14.00, 0.5x fundamental) vari-\\n33\\nants, allowing researchers to study how different belief structures influence price formation\\nand trading patterns under different initial mispricings. In these scenarios, the fundamental\\nprice is hidden from agents, forcing them to rely on their own valuation models.\\n3.2.5 Market Stress\\nThis scenario tests market resilience under challenging conditions by creating a more volatile\\nenvironment. The scenario includes two consistently bullish Optimistic traders, two consis-\", \"financial crisis) tend to last for extended periods and generate persistent shocks.\\nTherefore, to capture the long memory of the mean and volatility exhibited by the time series of the normalized\\nVVIX constructed in this paper, we apply the ARFIMA(1, d(m), 1)-FIGARCH(1, d(v), 1), where d(m) is the\\nterm describing the long memory of the mean and d(v) is the term describing the long memory of the volatility.\\nThe time series follows the process:\\nARFIMA (1, d(m),1)\\u21dd\\u03d5(L)(1\\u2212L)d(m)zt=\\u03b8(L)\\u03b5t (14)\\nIn Eq. (14), Lis the lag operator, d(m) is the fractional differencing parameter, reported to be 0.268, \\u03d5(L)\\nis the autoregressive polynomial, while \\u03b8(L) is the MA polynomial. ztcontains n\\u00d71 values of the normalized\\nVVIX, and \\u03b5tis the n\\u00d71 vector of white noise error term.\\nFIGARCH (1, d(v),1)\\u21dd\\u03d5(L)(1\\u2212L)d(v)\\u03b52\\nt=\\u03c9+ [1\\u2212\\u03b2(L)]\\u03bdt (15)\\nIn Eq. (15), \\u03d5(L) is the autoregressive polynomial, and d(v) is the fractional differencing parameter for\\nvolatility, reported to be 0.01. \\u03b52\\ntis the square of the white noise error term to capture the conditional variance\\ngenerating persistent volatility. \\u03c9is the constant term and \\u03b2(L) is the lag polynomial. Lastly, \\u03bdtis the n\\u00d71\\nvector of normal innovations. To allow for a long memory in the fractional time series, we set the condition d >0.\\nIn cases where d= 0, the model is a standard ARMA(1,1)-GARCH(1,1) process.\\nFurthermore, it is essential to determine whether there is a predictable signal in the noise, as defined by the\\nperformance ratios, in the innovations that can make the markets inefficient given that using this measure of the\\nrevised VIX, agents will be able to forecast volatility price. To detect the predictable signal in the noise, we\\n12\\nFigure 12: Signal/Noise ratios detected using performance ratios over Sscenarios\\nsimulate S= 10 ,000 scenarios of the normalized VVIX (with NDIG distribution) over the ARFIMA(1, d(m),\\n1)-FIGARCH(1, d(v), 1) process as defined by Eqs. (14) and (15). We compute the Rachev ratio and the Stable\\nTail Adjusted Return ratio5overSscenarios to extract predictable signals from the volatility noise. Figure (12)\\nshows the performance ratios computed over the simulated scenarios.\\nFrom the simulated signals using the fractional time series process, it is evident that there is significant\\nrandomness in the volatility noise with volatility clustering and generates no predictable power. Given that\\nthere is no identifiable pattern in the volatility noise that can enable an agent to forecast volatility price, we\\ncan conclude that the revised measure of VIX generates randomness in volatility noise and satisfies the Efficient\\nMarket Hypothesis.\\n7 Identification Strategy\\nTo identify i.i.d. shocks, using the normal innovations extracted by utilizing Eqs. (14) and (15), we compute R/R\\nratios over the residuals of the ARFIMA(1, d(m), 1)-FIGARCH(1, d(v), 1) process. For illustrative purposes, we\\ncompute two performance ratios6namely, the Rachev ratio and STAR ratio over the normal innovations. The\\nfollowing are the functional forms of the two ratios.\\n1.Rachev Ratio:\\nRR(\\u03b2, \\u03b3)(X) :=AV aR \\u03b2(\\u2212X)\\nAV aR \\u03b3(X)(16)\\nwhere AV aR \\u03b2, \\u03b3(X) := \\u03b2\\u22121R\\u03b2\\n0[max(\\u2212F\\u22121\\nx(u),0)]\\u03b3du, where AV aR is defined as the Average Value at\\nRisk and Xis the measure of interest, in this case, normal innovations of the revised VIX. \\u03b2refers to the\\nconfidence interval of the value on the right tail, whereas \\u03b3refers to the confidence interval of the value\\non the left tail. While the Rachev ratio satisfies the properties (M), (S), and (D), it violates (Q) due to a\\nnon-concave numerator.\\n2.Stable Tail Adjusted Return Ratio (STAR Ratio):\\nSTARR \\u03b3(X) :=E[X]+\\nAV aR \\u03b3(X)+(17)\\nwhere AV aR \\u03b3(X) := \\u03b3\\u22121R\\u03b3\\n0V aR u(X)duis the Average-Value-at-Risk at the level \\u03b3\\u2208(0,1].STARR\\nsatisfies all four axioms namely (M), (Q), (S), and (D), therefore, is axiomatically robust.\\nEqs. (16) and (17) will be used as the benchmark performance ratios for computing the uncertainty shocks\", \"market efficiency and price discovery processes throughout the simulation.\\nAgent performance metrics include absolute position tracking (shares, cash, and total\\nwealth), wealth composition analysis, position change metrics, and return calculations. The\\nsystem computes both absolute and percentage returns on various portfolio components\\nand compares performance across agent types to identify relative advantages of different\\nstrategies. Trading flow analysis visualizes the volume of shares moving between different\\nagent types and cumulative net trading flows, revealing which agents act as net buyers or\\nsellers in different market conditions.\\nDecision pattern analysis employs heatmaps to visualize the consistency of agent decision-\\nmaking over time, allowing researchers to identify shifts in strategic behavior. This is com-\\nplemented by decision quantities visualization that plots order sizes to highlight variations\\nin trade aggressiveness across agent types. When agent reasoning data is available, the\\nsystem generates wordclouds to extract key terms from agent explanations, providing qual-\\nitative insights into decision drivers for different agent strategies. Additional visualizations\\ntrack price target accuracy and compare agent-specific valuations to realized market prices,\\n28\\noffering insights into the forecasting abilities of different agents.\\nA key advantage of simulation-based analysis is complete observability of all market\\nprocesses and agent states. Unlike real-world markets where data availability is often limited,\\nthe framework captures every interaction, decision, and state change with perfect fidelity.\\nThis comprehensive data collection allows researchers to compute additional metrics beyond\\nstandard market measures, enabling novel analyses such as counterfactual testing (e.g., how\\nwould markets evolve with different agent compositions), causal inference of specific agent\\nbehaviors on market outcomes, and the development of custom efficiency or stability metrics\\ntailored to particular research questions. The system\\u2019s modular design facilitates rapid\\nimplementation of new metrics and visualizations as research questions evolve.\\n3 Experimental Design and Results\\nOur experimental framework implements a dividend-paying asset market with heterogeneous\\nagents. The baseline simulation runs for 15 to 20 rounds with 8 participating agents, although\\nthese parameters are fully configurable. Each agent begins with an initial endowment of\\n1,000,000 monetary units and 10,000 shares of the asset. The fundamental value of the asset\\nis set at $28.00, with a final redemption value matching this fundamental price in finite\\nhorizon scenarios. Transaction costs are set to zero to isolate the effects of agent behavior\\nand market structure.\\nThe dividend structure follows a stochastic process with a base payment of $1.40 and a\\nvariation of \\u00b1$1.00, paid with 50% probability each round. This design creates uncertainty\\nin the asset\\u2019s income stream while maintaining a known expected value. Cash holdings earn\\na risk-free interest rate of 5% per round, providing an opportunity cost for asset investment.\\nAgent composition is controlled through a flexible distribution system that allows for\\nvarious experimental configurations. In our baseline setup, we employ a mixed population\\nof value investors, momentum traders, and market makers. Each agent type implements\\n29\\ndistinct trading strategies through Large Language Model (LLM) prompts, with GPT-4o as\\nthe decision-making engine.\\nThe data collection system captures comprehensive market activity across multiple di-\\nmensions. At the market level, it tracks the evolution of prices, fundamental values, and\\nrealized dividends, providing insights into overall market dynamics. Individual agent data\\nincludes detailed wealth trajectories and portfolio compositions, enabling analysis of strategy\\neffectiveness and wealth distribution patterns. The system maintains complete transaction\", \"the decision-making engine.\\nThe data collection system captures comprehensive market activity across multiple di-\\nmensions. At the market level, it tracks the evolution of prices, fundamental values, and\\nrealized dividends, providing insights into overall market dynamics. Individual agent data\\nincludes detailed wealth trajectories and portfolio compositions, enabling analysis of strategy\\neffectiveness and wealth distribution patterns. The system maintains complete transaction\\nrecords with prices, quantities, and counterparty information, facilitating the study of trad-\\ning patterns and market microstructure. Additionally, it captures agent decision rationales\\nand strategy adherence metrics, allowing researchers to evaluate the consistency and effec-\\ntiveness of different trading approaches.\\nAll experimental parameters, market outcomes, and agent interactions are systemati-\\ncally logged and stored in structured formats (CSV and JSON) for subsequent analysis. The\\nframework generates standardized visualizations of price evolution, wealth distribution, and\\ndividend payments to facilitate comparative analysis across different experimental configu-\\nrations.\\n3.1 Fundamental Value Calibration\\nThe framework implements a consistent approach to fundamental value calculation that pro-\\nvides a reliable benchmark for price discovery. For infinite horizon markets, the fundamental\\nvalue follows the standard dividend discount model:\\nVt = E[D]\\nr = Expected Dividend\\nInterest Rate (1)\\nFor the default parameters where the expected dividend is $1.40 and the interest rate is\\n5%, this yields a fundamental value of $28.00.\\nIn finite horizon markets with T periods remaining, the fundamental value incorporates\\n30\\nboth future dividends and terminal redemption value K:\\nFVt =\\nTX\\n\\u03c4=t\\nE[D]\\n(1 + r)\\u03c4\\u2212t+1 + K\\n(1 + r)T\\u2212t+1 (2)\\nTo ensure consistency between finite and infinite horizon markets, the redemption value\\nK is set equal to E[D]\\nr , which makes the fundamental value constant atE[D]\\nr across all periods,\\nregardless of the time horizon. This calibration approach ensures a clean experimental design\\nby providing a stable benchmark for price discovery.\\n3.2 Experimental Scenarios\\nTo evaluate market dynamics with LLM-based agents, we implemented several experimental\\nscenarios that systematically explore different initial conditions and agent compositions.\\nEach scenario maintains the fundamental value of $28.00 while varying starting prices, time\\nhorizons, and agent populations. These scenarios address our core research questions (Section\\n1) by testing LLM capabilities under varying market conditions, focusing on price discovery\\ndynamics, the impact of heterogeneous beliefs, and market stability under stress; GPT-4o\\nwas used consistently as the decision-making engine for all LLM agents across these scenarios.\\nWe present the setup for several key scenarios below, followed by a discussion of the observed\\nresults for the 2 experiments involving an infinite horizon market with a starting price either\\nabove or below the fundamental value.\\n3.2.1 Price Discovery (Above Fundamental)\\nThis scenario tests downward price convergence by starting with an initial price 25% above\\nthe fundamental value ( $35.00). It runs for 20 trading rounds and features a diverse\\nagent population, including two Default investors (baseline agents), two Optimistic traders\\n(who believe prices should be higher), two Market makers (providing liquidity by posting\\nbids/asks), and two Speculator agents (opportunistic traders seeking inefficiencies). Market\\n31\\nmakers are given enhanced liquidity with 20x the baseline cash and shares to ensure suffi-\\ncient liquidity provision and facilitate price discovery. The scenario tests whether prices can\\ncorrect downward through trading activity when starting from an overvalued state.\\n3.2.2 Price Discovery (Below Fundamental)\\nThis complementary scenario tests upward price convergence by starting with an initial price\", \"there that the revised index accurately captures the jumps and diffusions in the markets previously unaccounted\\nfor and therefore crucial in estimating the uncertainty as a macro-volatility in financial markets. There are two\\nkey facts to note about the revised VIX index. First, we see a jump in March 2020 which captures the large crash\\nin the S&P500 daily returns post the heightened uncertainty about economic conditions following the impact\\nof the news of a global pandemic. Considering the impact generated by persistent volatility, the NDIG model\\npreserves the volatility measure implied by the intrinsic time subordinator.\\nFigure 10: Normalized Volatility to Match NDIG Estimates: Revised VIX {Volatility of VIX\\n(VVIX) }\\nSecond, following the path of persistent volatility post-pandemic, we see another jump in the volatility following\\nthe events that characterized the plummets in early 2022 following consistent hikes in the federal funds rate, the\\nfear of the start and continued geopolitical conflict between Russia and the Ukraine, along with the tech stock\\nselloff due to an unexpected fall in tech firms\\u2019 earnings indicated by the reports of their earnings.\\n6 Risk\\u2013Reward Ratios over Fractional Time Series\\nR/R ratios offer a balanced approach to exploring the potential gains and losses in the financial market due to\\nviolent market movements. These measures help address the asymmetry in risk perceptions and the potential\\nfor large losses, and are thereby helpful in extracting meaningful signals from the volatility noise that are not\\naccounted for when using measures of dispersion over symmetric distributions. Using an axiomatic approach,\\nevery performance measure or R/R ratio should satisfy the properties of, first monotonicity, which means that\\nmore is better than less. Second, quasi-concavity leads to preferences that value averages higher than extremes,\\nencouraging diversification. Third, scale invariance and last, being distribution-based.\\nLetXbe a convex set of random variables on a probability space (\\u2126 ,F,P). Each element X\\u2208 X denotes a\\nfinancial return over time length T\\u2208R+. Given these conditions, consider an R/R ratio of the following form:\\n10\\n\\u03b1(X) =\\u03b8(X)+\\n\\u03c1(X)+(13)\\nfor a reward measure \\u03b8:X\\u2192R\\u222a {\\u00b1\\u221e} and a risk measure \\u03c1:X\\u2192R\\u222a {\\u00b1\\u221e} . In addition, x+denotes\\nmax{x,0}andx\\u2212denotes \\u2212min{x,0}. The ratio \\u03b1(X) should satisfy the following two conditions:\\n1.(M) Monotonicity: \\u03b1(X)\\u2265\\u03b1(Y)\\u2200X, Y\\u2208 Xsuch that X\\u2265Y\\n2.(Q)Quasi-Concavity: \\u03b1(\\u03bbX+ (1\\u2212\\u03bb)Y)> min (\\u03b1(X), \\u03b1(Y))\\u2200X, Y\\u2208 Xand \\u03bb \\u2208Rsuch that 0 \\u2264\\u03bb\\u22641.\\nCheridito and Kromer (2013) explain that monotonicity is a minimal requirement that every performance\\nindicator should satisfy. It simply implies that more of a financial return is better than less and preferred by\\nall agents. Moreover, quasi-concavity has can explain the aversion to uncertainty. If \\u03b1is monotonic and quasi-\\nconcave, averages are preferred to extremes and diversification is encouraged. In cases when \\u03b1does not satisfy the\\nrequired properties, there are X, Y\\u2208 Xand a scalar \\u03bb\\u2208(0,1) such that \\u03b1(\\u03bbX+ (1\\u2212\\u03bb)Y)< min (\\u03b1(X), \\u03b1(Y)).\\nIn such a case, research on Value-at-Risk (VaR) Artzner et al. (1999) shows that there will be a concentration of\\nrisk.\\nMoreover, there is a large family of R/R ratios that also satisfy the following conditional properties:\\n1.(S) Scale-Invariance: \\u03b1(\\u03bbX) =\\u03b1(X)\\u2200X\\u2208 Xand \\u03bb \\u2208R+\\\\{0}such that\\n\\u03bbX\\u2208 X\\n2.(D) Distribution-based: \\u03b1(X) only depends on the distribution of Xunder P.\\nGiven that performance ratios should satisfy the first two mandatory properties and the two conditional\\nproperties, we can prove the functional properties of \\u03b1to make the ratios micro-founded so as to explain the\\nmeaning of the signals contained in \\u03b1(X).\\nProposition 1: Let\\u03b1follow the form as described in Eq. (7):\\n1.If\\u03b8(X)\\u2265\\u03b8(Y)and\\u03c1(X)< \\u03c1(Y)\\u2200X, Y\\u2208 Xsuch that X\\u2265Y,then \\u03b1satisfies the monotonicity property\\n(M).\\n2.If\\u03b8is concave and \\u03c1convex, then \\u03b1satisfies the quasi-concavity property (Q).\", \"value, the system:\\n1. Sets market price P = \\u03c1V where \\u03c1 is the target ratio\\n2. Generates a consistent order book structure around this price\\n3. Executes multiple decision trials with the same agent type\\n4. Records decision outcomes (buy/sell/hold), order types, quantities, and reasoning\\nThis process maps how LLM agents respond to different price environments, as illustrated\\nin Figures 2, 3, 4, and 5. The analysis reveals clear patterns in decision boundaries, with\\ndistinct transitions between buying, selling, and holding regions that vary by agent type. For\\nexample, value investors show strong buying tendencies when prices are below fundamental\\nvalue (\\u03c1 <1) and selling preferences when prices exceed fundamentals ( \\u03c1 >1). In contrast,\\nmomentum traders show less sensitivity to the fundamental ratio and more responsiveness\\nto recent price trends.\\nThe systematic variation approach also reveals patterns in order sizing and limit price\\nselection, with agents typically placing larger orders when prices deviate significantly from\\ntheir valuation models (Figure 4). This methodology provides unprecedented transparency\\ninto LLM decision processes and enables quantitative comparison of different agent types\\nand LLM architectures.\\n22\\nFigure 2: Price Analysis under Systematic Variation. Shows how agent valuation estimates\\nand price targets respond to varying Price/Fundamental ratios.\\nThe decision analysis can be customized for different experimental designs. For example,\\nresearchers can use the framework to study the impact of various market conditions on agent\\nbehavior by varying other market parameters or the effect of different agent types on market\\ndynamics by changing the agent population.\\n2.3 Data Collection and Analysis\\nEvaluating LLM trading agents requires robust methodologies for capturing, processing,\\nand analyzing their behavior in market environments. The framework implements a com-\\nprehensive analytics module that tracks all market activity, agent decisions, and performance\\nmetrics throughout experimental runs. This multi-layered approach not only records what\\nhappens in each simulation but also provides insights into why agents make specific deci-\\nsions, enabling researchers to validate agent behavior against their defined strategies and\\nassess overall market dynamics. The following sections detail the key components of this\\nanalytics infrastructure.\\n23\\nFigure 3: Trading Decision Distribution under Systematic Variation. Illustrates the proba-\\nbility of Buy, Sell, or Hold decisions across different agent types as the Price/Fundamental\\nratio changes.\\n24\\nFigure 4: Order Size Distribution under Systematic Variation. Shows the average quan-\\ntity traded (as a percentage of initial shares) for Buy and Sell orders across different\\nPrice/Fundamental ratios.\\n2.3.1 Data Collection Architecture\\nThe framework implements a comprehensive data collection system that captures multiple\\ndimensions of market behavior and agent decision-making. This structured approach ensures\\nreproducibility and enables detailed analysis of market dynamics.\\n2.3.2 Core Data Streams\\nThe system captures five primary data streams that work together to provide a complete\\npicture of market activity. Market Data forms the foundation, tracking essential metrics\\nincluding price evolution, fundamental values, trading volumes, order book depth, market\\nliquidity, best bid/ask prices, spreads, and price-fundamental ratios. This is complemented\\nby detailed Trade Data, which records individual transaction details such as prices, quan-\\ntities, buyer and seller identifiers, timestamps, round information, and specific execution\\ndetails.\\nAgent Data provides insights into participant behavior by monitoring cash and share\\n25\\nFigure 5: Order Type Analysis under Systematic Variation. Displays the proportion of\\nMarket vs. Limit orders used by different agent types across varying Price/Fundamental\\nratios.\\n26\"]}": {"cached_metrics_data": [{"metric_data": {"name": "Contextual Precision (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Faithfulness (ragas)", "threshold": 0.8, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.8, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Contextual Recall (ragas)", "threshold": 0.6, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.6, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Answer Relevancy (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}]}, "{\"actual_output\": \"In a continuous double auction, buyers and sellers continuously submit both buy and sell orders (bids and asks) at any time. Trades occur whenever a buy order's price matches or exceeds a sell order's price. This creates a dynamic market where prices fluctuate based on real-time supply and demand. The system maintains an order book (a real-time list of all outstanding buy and sell orders), and orders are matched based on price-time priority (highest bids and lowest asks are given priority, and among same-priced orders, those submitted earlier take precedence).\\nThis differs from the single-price clearing mechanism used in some earlier LLM market simulations. In a single-price clearing system, all orders are collected during a specific period. At the end of that period, a single clearing price is determined that best matches the overall supply and demand. All trades then execute at that single price. Essentially, it's like taking a snapshot of the market at one point in time, rather than allowing continuous trading and price adjustments as in a continuous double auction. The authors critique single-price clearing because it lacks the dynamic price discovery and realistic order book behavior of a continuous double auction, which are crucial aspects of real-world financial markets.\\n\", \"context\": [\"Our framework implements a continuous double\\u2011auction market\\u2026\\u201d + \\u201cWithin the computer\\u2011science literature, early works \\u2026 employ single\\u2011price clearing mechanisms without a persistent order book\\u2026\"], \"expected_output\": \"It allows buyers and sellers to post bids/asks continuously with price\\u2011time priority, unlike prior LLM papers that used single\\u2011price batch clearing without an order book.\", \"hyperparameters\": null, \"input\": \"What is a \\u2018continuous double auction\\u2019, and how does it differ from the single\\u2011price clearing used in earlier LLM\\u2011market papers the authors critique?\", \"retrieval_context\": [\"(2023)). This work, however, focuses on financial markets and how LLM agents can operate\\nas full-fledged trading participants.\\nRecent research examines specific applications of LLMs for trading. FinMem and Trad-\\ningGPT introduce frameworks with layered memory systems and customizable agent traits\\n5\\nto improve financial decision-making (Yu, Li, et al. 2024; Li, Zhang, and Sun 2023). Hierar-\\nchical multi-agent architectures have been explored in FinCon, which uses a manager-analyst\\nsetup for collaborative portfolio decisions (Yu, Yao, et al. 2024). QuantAgent implements\\na self-improving signal-mining approach (Wang et al. 2024), while other work underscores\\nthe importance of long-term memory in LLM agents via vector databases (Hatalis et al.\\n2024). This line of research builds on successful reinforcement learning applications such as\\nAlphaPortfolio (Cong et al. 2021) and AlphaManager (Campello, Cong, and Zhou 2023),\\nwhich leverage deep RL and robust control for portfolio management.\\nAnalyzing LLM agent behavior by changing only some parameters draws on methods\\nfrom the interpretable machine learning literature. In particular, the systematic variation\\nof market parameters to reveal decision patterns mirrors partial dependence plots and in-\\ndividual conditional expectation curves used to interpret complex machine learning models\\n(Molnar 2022). These techniques help reveal how LLM agents respond to changes in specific\\nvariables while holding others constant, providing insight into their internal decision-making\\nprocesses that would otherwise remain opaque.\\nBeyond finance, studies of LLM capabilities in interactive or multi-agent settings offer\\nvaluable insights. Benchmarks like AgentBench evaluate LLMs\\u2019 performance in interac-\\ntive tasks (Liu et al. 2023), while InvestorBench focuses on financial decision-making tasks\\nspecifically (H. Li et al. 2024). NegotiationArena demonstrates LLMs\\u2019 capacity for strategic\\ninteraction in bargaining contexts (Bianchi et al. 2024). Similarly, Guo et al. (2024) provide\\nan economics \\u201darena\\u201d where LLMs compete in strategic games, revealing that advanced\\nmodels like GPT-4 can exhibit rational, adaptive behavior\\u2014albeit not always reaching Nash\\nEquilibrium. Existing frameworks typically assess individual agents or hierarchical collab-\\norations, whereas this work studies emergent market behaviors that arise from multiple\\nindependent LLM traders interacting in a marketplace.\\nThe approach also connects to the tradition of experimental asset markets. For instance,\\nWeitzel et al. (2020) show that even finance professionals are susceptible to speculative\\n6\\nbubbles, especially amid high capital inflows. Kop\\u00b4 anyi-Peuker and Weber (2021) find that\\ntrading experience alone does not eliminate bubbles, challenging assumptions about rational\\nmarket learning. Kirchler, Huber, and St\\u00a8 ockl (2012) identify confusion about fundamental\\nvalues as a key driver of bubble formation. This framework offers a new way to study these\\nphenomena with LLM traders, which can be rigorously parameterized for sophistication,\\nstrategy, and information processing. Hence, this paper provides a method to investigate\\nhow automated or \\u201dartificial\\u201d agents might affect market stability or volatility.\\nOther recent work highlights the versatility of LLM agents in complex, interactive sce-\\nnarios beyond finance. One stream focuses on simulating social behaviors\\u2014such as opinion\\ndynamics (Chuang et al. 2023), trust (Xie et al. 2024), and resource-sharing (Piatti et al.\\n2024). Another examines LLMs\\u2019 strategic capabilities through task-based simulations and\\ncollaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\\nWithin the computer science literature, early works apply LLMs to financial markets but\\nabstract away many fundamental stock market characteristics. Often, they employ single-\\nprice clearing mechanisms without a persistent order book, ignore partial fills and bid-ask\", \"2024). Another examines LLMs\\u2019 strategic capabilities through task-based simulations and\\ncollaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\\nWithin the computer science literature, early works apply LLMs to financial markets but\\nabstract away many fundamental stock market characteristics. Often, they employ single-\\nprice clearing mechanisms without a persistent order book, ignore partial fills and bid-ask\\nspreads, and omit dividends. Consequently, these simplified environments can primarily\\naddress exogenous macro shocks (e.g., changes in interest rates or inflation; Gao et al. 2024),\\nexogenous policy changes (Zhang et al. 2024), or rely on advanced methods such as repetitive\\nnext-token predictions to generate better answers (Koa et al. 2024). This work extends\\nthese efforts by incorporating these crucial market features, enabling the study of complex\\nendogenous events such as flash crashes, liquidity shocks, and large-trader impacts.\\nThis work also connects to emerging research on algorithmic and AI-powered trading\\nsystems. Dou, Goldstein, and Ji (2024) demonstrate how reinforcement learning-based AI\\nspeculators can autonomously learn to sustain collusive behavior without explicit coordi-\\nnation, achieving supra-competitive profits through either price-trigger strategies or self-\\nconfirming bias in learning. This finding is particularly informative for this framework as\\nit highlights potential emergent behaviors that may arise when intelligent agents interact in\\n7\\nmarkets\\u2014behaviors that could manifest differently with LLM agents due to their natural\\nlanguage reasoning capabilities. Similarly, Colliard, Foucault, and Lovo (2022) examine al-\\ngorithmic market makers using Q-learning and find they charge markups that increase when\\nadverse selection costs decrease\\u2014contrary to Nash equilibrium predictions. Their work pro-\\nvides methodological insights on how to test strategic pricing behaviors against theoretical\\nbenchmarks incorporated into this LLM-based framework.\\nFinally, this approach is informed by complexity economics, which views markets as dy-\\nnamic, non-equilibrium systems where agents adaptively learn and evolve strategies (Arthur\\n2013; Wolfram 2017). According to this view, markets exhibit emergent phenomena and\\nself-organization, especially when trading agents (human or artificial) update their behav-\\nior in response to outcomes. This paradigm is particularly relevant in an era of increasing\\nautomation and algorithmic trading (Balland et al. 2022; Ping 2019). Like adaptive agents\\nin complexity economics, these LLM traders incorporate new information and adjust their\\nstrategies, generating emergent market patterns\\u2014a key motivation behind this framework.\\nUnlike previous frameworks that abstract away crucial market features or focus on narrow\\nstrategies, this system incorporates realistic market microstructure while accommodating\\nheterogeneous agents interacting simultaneously. While earlier work demonstrates LLMs\\u2019\\npromise for macroeconomic modeling and simple trading simulations, this work introduces a\\ncomplex, open-source financial market platform that supports multiple agent architectures,\\nthorough market microstructure (limit orders, partial fills, dividends), and rigorous testing\\nprotocols\\u2014fulfilling a critical need in complexity economics research and market microstruc-\\nture analysis.\\n2 Methodology\\nThe methodology section contains three parts. The first part describes the market design,\\nthe second agents\\u2019 design, and the third the analysis module.\\n8\\n2.1 Market Design\\nOur methodological framework integrates three components that create a controlled envi-\\nronment for LLM-based trading agents. The framework implements a flexible continuous\\ndouble-auction market mechanism that couples standard market microstructure principles\\nwith market clearing and matching algorithms to accommodate asynchronous LLM decisions.\", \"33\\nants, allowing researchers to study how different belief structures influence price formation\\nand trading patterns under different initial mispricings. In these scenarios, the fundamental\\nprice is hidden from agents, forcing them to rely on their own valuation models.\\n3.2.5 Market Stress\\nThis scenario tests market resilience under challenging conditions by creating a more volatile\\nenvironment. The scenario includes two consistently bullish Optimistic traders, two consis-\\ntently bearish Pessimistic traders, two Market makers (liquidity providers), and two Value\\ninvestors (rational benchmark traders). The scenario runs for 100 rounds to study long-term\\nmarket behavior and includes unequal initial endowments, with optimistic traders having\\nmore cash (1.5x baseline) but fewer shares (0.5x baseline) and pessimistic traders having less\\ncash (0.5x baseline) but more shares (1.5x baseline). This resource imbalance tests whether\\nparticular agent types can dominate market outcomes through resource advantages.\\nThe scenarios presented here demonstrate the framework\\u2019s capabilities for exploring di-\\nverse market conditions. Its modular structure facilitates the straightforward definition and\\nimplementation of alternative experimental designs, enabling researchers to tailor simulations\\nto specific research questions.\\nIn all scenarios, we maintain consistent baseline parameters with a fundamental value\\nof $28.00, calculated from the expected dividend of $1.40 and interest rate of 5%. Agent\\nendowments start at 1,000,000 monetary units and 10,000 shares unless specifically modified.\\nTransaction costs are set to zero to isolate the effects of agent behavior and market structure\\non price formation.\\n4 Conclusion\\nThis paper demonstrates that Large Language Models can effectively function as diverse\\ntrading agents\\u2014from value investors to market makers\\u2014maintaining strategic consistency\\n34\\nwhile adapting to market conditions. Our experimental framework reveals that their in-\\nteractions generate realistic market dynamics, including phenomena like price bubbles and\\ncorrections, highlighting both the capabilities and potential risks of deploying LLM agents\\nin financial markets.\\nThese findings carry significant implications for market structure and regulation. While\\nLLM agents can enhance price discovery and liquidity, their adherence to programmed strate-\\ngies, even potentially flawed ones derived from prompts, could amplify market volatility or\\nintroduce novel systemic risks, as observed in our simulated bubble scenarios. A key concern\\nis the potential for widespread correlated behavior: similar underlying LLM architectures\\nresponding uniformly to comparable prompts or market signals could inadvertently create\\ndestabilizing trading patterns without explicit coordination. This underscores the critical\\nneed for rigorous testing and validation of LLM-based trading systems prior to live deploy-\\nment.\\nA central contribution of this work is the open-source simulation framework itself, de-\\nsigned to catalyze research into LLM trading agents. We invite the research community to\\nutilize and extend this platform to investigate pressing questions in this rapidly evolving\\narea. The framework enables systematic exploration of complex scenarios\\u2014such as hybrid\\nhuman-LLM markets, stress tests, varying market structures, regulatory impacts, and the\\nnuances of LLM prompting\\u2014often difficult or costly to study otherwise. Specific avenues\\nripe for investigation using this tool include the emergence of novel trading strategies, the\\nprecise effects of agent heterogeneity on market stability, and the development of robust\\nvalidation protocols for AI traders. As artificial intelligence becomes more integrated into\\nfinance, collaborative research leveraging adaptable simulation environments like this one\\nwill be crucial for understanding and responsibly shaping the future of trading.\\n35\\nReferences\", \"Can Large Language Models Trade? Testing Financial\\nTheories with LLM Agents in Market Simulations\\nAlejandro Lopez-Lira\\u2217\\nFirst Version: November 29, 2024; Current Version: April 16, 2025\\nAbstract\\nThis paper presents a realistic simulated stock market where large language models\\n(LLMs) act as heterogeneous competing trading agents. The open-source framework\\nincorporates a persistent order book with market and limit orders, partial fills, div-\\nidends, and equilibrium clearing alongside agents with varied strategies, information\\nsets, and endowments. Agents submit standardized decisions using structured outputs\\nand function calls while expressing their reasoning in natural language. Three findings\\nemerge: First, LLMs demonstrate consistent strategy adherence and can function as\\nvalue investors, momentum traders, or market makers per their instructions. Second,\\nmarket dynamics exhibit features of real financial markets, including price discovery,\\nbubbles, underreaction, and strategic liquidity provision. Third, the framework enables\\nanalysis of LLMs\\u2019 responses to varying market conditions, similar to partial dependence\\nplots in machine-learning interpretability. The framework allows simulating financial\\ntheories without closed-form solutions, creating experimental designs that would be\\ncostly with human participants, and establishing how prompts can generate correlated\\nbehaviors affecting market stability.\\nKeywords: LLM Agents; Agent-Based Markets; Experimental Finance; AI Trading;\\nMulti-Agent Systems\\n\\u2217University of Florida. Email: alejandro.lopez-lira@warrington.ufl.edu. I am grateful to seminar par-\\nticipants at the London Business School, Oxford University, Stockholm School of Economics, University of\\nVirginia, and the City University of Hong Kong for helpful suggestions and feedback.\\n1\\narXiv:2504.10789v1  [q-fin.CP]  15 Apr 2025\\n1 Introduction\\nLarge language models (LLMs) can increasingly function as autonomous agents\\u2014systems\\nthat observe, reason, and act independently. LLMs have shown promising results in finan-\\ncial forecasting, but their potential as trading agents introduces a fundamental shift from\\nalgorithms with explicit objectives to systems guided by natural language instructions. This\\nchange raises critical questions: Can LLMs execute trading strategies? Do LLMs optimize\\nfor profit maximization? What are the implications for market stability and efficiency?\\nIf LLMs trade similarly to humans, they could enable experimental market simulations\\nwithout human participants. Conversely, if their trading behavior differs, understanding\\nthese differences becomes critical for systemic risk management. These questions extend be-\\nyond theory; LLM-based strategies are already being deployed.1 To address these questions,\\nI develop an open-source simulation that tests LLM trading agents in a realistic market envi-\\nronment with a persistent order book, supporting various order types, stochastic dividends,\\nand heterogeneous information.\\nThe framework allows heterogeneous LLMs\\u2014defined in natural language, using different\\nsystem prompts\\u2014to act as diverse types of traders, such as value investors, momentum\\ntraders, market makers, and contrarians. Agents submit standardized trading decisions in a\\nhuman-readable format while expressing their reasoning transparently. Figure 1 illustrates\\nthis approach, showing how a speculator agent combines explicit valuation reasoning with\\nstructured trading parameters, enabling systematic analysis and insight into the agent\\u2019s\\ndecision-making process.\\nThe analysis reveals three key findings about LLMs\\u2019 capabilities as trading agents. First,\\nLLMs can effectively execute trading strategies. They consistently understand market me-\\nchanics, process market information, form price expectations, and execute trades according\\nto specific instructions. Their trading behavior is highly sensitive to the prompts they\\nreceive\\u2014they faithfully follow directions regardless of profit implications. This observance\", \"ceedings of the 62nd Annual Meeting of the Association for Computational Linguistics\\n(Volume 1: Long Papers),edited by Lun-Wei Ku, Andre Martins, and Vivek Srikumar,\\n15523\\u201315536. ACL 2024. Bangkok, Thailand: Association for Computational Linguis-\\ntics, August.\\n39\\nLi, Yuan, Yixuan Zhang, and Lichao Sun. 2023. \\u201cMetaAgents: Simulating Interactions of\\nHuman Behaviors for LLM-based T Ask-Oriented Coordination via Collaborative Gen-\\nerative Agents.\\u201d arXiv.org.\\nLiu, Xiao, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, et al. 2023.\\n\\u201cAgentBench: Evaluating LLMs as Agents.\\u201dInternational Conference on Learning Rep-\\nresentations.\\nLopez-Lira, Alejandro, and Yuehua Tang. 2023. \\u201cCan ChatGPT Forecast Stock Price Move-\\nments? Return Predictability and Large Language Models.\\u201d SSRN Electronic Journal\\n(April 6, 2023).\\nManning, Benjamin S., Kehang Zhu, and John J. Horton. 2024. \\u201cAutomated Social Science:\\nLanguage Models as Scientist and Subjects.\\u201d (Cambridge, MA) (April 29, 2024).\\nMolnar, Christoph. 2022. Interpretable Machine Learning.\\nPelster, Matthias, and Joel Val. 2023. \\u201cCan Chatgpt Assist in Picking Stocks?\\u201dSocial Science\\nResearch Network.\\nPiatti, Giorgio, Zhijing Jin, Max Kleiman-Weiner, Bernhard Sch\\u00a8 olkopf, Mrinmaya Sachan,\\nand Rada Mihalcea. 2024. \\u201cCooperate or Collapse: Emergence of Sustainable Coopera-\\ntion in a Socie Ty of LLM Agents.\\u201d arXiv.org.\\nPing, Chen. 2019. \\u201cFrom Complexity Science to Complexity Economics.\\u201d In Alternative\\nApproaches to Economic Theory,19\\u201355. Routledge, June 11, 2019.\\nWang, Saizhuo, Hang Yuan, Lionel M. Ni, and Jian Guo. 2024. \\u201cQuantAgent: Seeking Holy\\nGrail in Trading by Self-Improving Large Lang Uage Model.\\u201d arXiv.org.\\nWeitzel, Utz, Christoph Huber, J\\u00a8 urgen Huber, Michael Kirchler, Florian Lindner, and Julia\\nRose. 2020. \\u201cBubbles and Financial Professionals.\\u201d The Review of Financial Studies33,\\nno. 6 (June 1, 2020): 2659\\u20132696.\\n40\\nWolfram, Elsner. 2017. \\u201cComplexity Economics as Heterodoxy: Theory and Policy.\\u201dJournal\\nof Economic Issues51, no. 4 (October 2, 2017): 939\\u2013978.\\nWoodhouse, Drew, and Alex Charlesworth. 2023. \\u201cCan ChatGPT Predict Future Interest\\nRate Decisions?\\u201d Social Science Research Network.\\nXie, Chengxing, Canyu Chen, Feiran Jia, Ziyu Ye, Shiyang Lai, Kai Shu, Jindong Gu, et al.\\n2024. \\u201cCan Large Language Model Agents Simulate Human Trust Behavior?\\u201darXiv.org.\\nYang, Stephen. 2023. \\u201cPredictive Patentomics: Forecasting Innovation Success and Valuation\\nw Ith ChatGPT.\\u201d Social Science Research Network.\\nYu, Yangyang, Haohang Li, Zhi Chen, Yuechen Jiang, Yang Li, Denghui Zhang, Rong\\nLiu, Jordan W. Suchow, and Khaldoun Khashanah. 2024. \\u201cFinMem: A Performance-\\nEnhanced LLM Trading Agent with Layered Memory a Nd Character Design.\\u201dProceed-\\nings of the AAAI Symposium Series3, no. 1 (May 20, 2024): 595\\u2013597.\\nYu, Yangyang, Zhiyuan Yao, Haohang Li, Zhiyang Deng, Yupeng Cao, Zhi Chen, Jordan W.\\nSuchow, et al. 2024. \\u201cFinCon: A Synthesized LLM Multi-Agent System with Conceptual\\nVerbal Reinforcement for Enhanced Financial Decision Making.\\u201d Pre-published, Novem-\\nber 7, 2024. Accessed January 8, 2025. https://doi.org/10.48550/arXiv.2407.06567.\\narXiv: 2407.06567 [cs]. http://arxiv.org/abs/2407.06567.\\nZhang, Chong, Xinyi Liu, Zhongmou Zhang, Mingyu Jin, Lingyao Li, Zhenting Wang,\\nWenyue Hua, et al. 2024. \\u201cWhen AI Meets Finance (StockAgent): Large Language\\nModel-based Stock Trading in Simulated Real-world Environments.\\u201d Pre-published,\\nSeptember 21, 2024. Accessed January 26, 2025. https://doi.org /10.48550/arXiv .\\n2407.18957. arXiv: 2407.18957 [q-fin]. http://arxiv.org/abs/2407.18957.\\n41\\nA Technical Implementation Details\\nA.1 Agent Type Specifications\\nThis section details the base system prompts for each agent type in our simulation. These\\nprompts define the core behavioral characteristics and trading strategies for each agent. Each\\nprompt consists of:\\n\\u2022 A role definition that establishes the agent\\u2019s trading philosophy\\n\\u2022 A structured trading strategy that guides decision-making\", \"decision-making process.\\nThe analysis reveals three key findings about LLMs\\u2019 capabilities as trading agents. First,\\nLLMs can effectively execute trading strategies. They consistently understand market me-\\nchanics, process market information, form price expectations, and execute trades according\\nto specific instructions. Their trading behavior is highly sensitive to the prompts they\\nreceive\\u2014they faithfully follow directions regardless of profit implications. This observance\\n1. For example, Autopilot has a ChatGPT-based portfolio https://x.com/thegptinvestor.\\n2\\n{\\\"valuation_reasoning\\\":\\n\\\"The fundamental value is based on the expected dividend,\\nand the interest rate.\\nThe expected dividend is $1.40, and the interest rate is 5%.\\nUsing a perpetuity formula, the value is $1.40 / 0.05 = $28.\\\",\\n\\\"valuation\\\":28.0,\\n\\\"price_target_reasoning\\\":\\\"The current price is $29.00, which is\\nslightly above the fundamental value of $28.00. I expect the price\\nto remain around $29.00 in the next round due to market stability.\\\",\\n\\\"price_target\\\":29.0,\\n\\\"orders\\\":[{\\\"decision\\\":\\\"Sell\\\",\\\"quantity\\\":1000,\\\"order_type\\\":\\\"limit\\\",\\n\\\"price_limit\\\":29.50}],\\n\\\"replace_decision\\\":\\\"Add\\\",\\n\\\"reasoning\\\":\\\"The current price is slightly above the fundamental value.\\nI will place a limit sell order at $29.50 to capitalize on potential price\\nincreases.\\\"}\\nFigure 1: Example of a structured trading decision from a Speculator agent defined by its\\nsystem prompt: \\u201cYou are a speculator who tries to profit from market inefficiencies.\\u201d. The\\nLLM provides explicit reasoning for its valuation, price target, and trading decision in a\\nmachine-readable JSON format that can be directly processed by the trading system.\\nhighlights a fundamental difference from human traders: LLMs do not inherently optimize\\nfor profit maximization but rather for following instructions accurately.\\nSecond, LLMs react meaningfully to market dynamics. They consider current and his-\\ntorical prices, dividends, and other market information when making decisions. However,\\nthey maintain their strategic direction even when market conditions change, following their\\ninstructions even if doing so results in financial losses. This combination of responsiveness\\nto market conditions while maintaining strategic consistency creates a unique trading profile\\ndistinct from rule-based algorithms and human traders.\\nThird, market dynamics with LLM agents can resemble actual markets and mirror classic\\nresults from the theoretical finance literature. When these agents interact, they produce\\nrealistic price discovery and liquidity provision with emergent behaviors, including price\\nconvergence toward fundamental values. Depending on the distribution of agent types,\\nthe system can generate various market phenomena, such as bubbles or underreactions to\\ninformation. This complex behavior suggests potential applications for studying market\\n3\\ndynamics using LLM agents instead of experiments with human participants.\\nHence, these findings raise important questions about algorithmic consistency in LLM-\\nbased systems. Since trading agents are implemented through prompts, their behavior in-\\nherits characteristics of the underlying language models. The standardization of LLM ar-\\nchitectures across implementations could create unexpected behavioral patterns\\u2014if many\\nagents are based on similar foundation models, they might exhibit correlated responses to\\nspecific market conditions, potentially amplifying market instabilities.\\nTo enable this analysis and accelerate development in this emerging field, we provide\\nan open-source framework with three key components: (1) a structured protocol for im-\\nplementing and validating LLM trading agents, supporting both LLM-based and traditional\\nrule-based agents; (2) a controlled market environment with realistic microstructure for test-\\ning agent interactions; and (3) a comprehensive data collection system for analyzing trading\\nbehavior. This framework serves multiple stakeholders in preparation for the evolution of\", \"the second agents\\u2019 design, and the third the analysis module.\\n8\\n2.1 Market Design\\nOur methodological framework integrates three components that create a controlled envi-\\nronment for LLM-based trading agents. The framework implements a flexible continuous\\ndouble-auction market mechanism that couples standard market microstructure principles\\nwith market clearing and matching algorithms to accommodate asynchronous LLM decisions.\\nThe market clearing process employs a dual-stage matching algorithm. In the first stage,\\nlimit orders are posted. In the second stage, market orders are netted using a market-\\nto-market matching engine that processes buy and sell orders, reconciling orders based on\\navailable agent cash and share commitments. In the third stage, any remaining market\\norders are matched against the existing order book, with unfilled quantities converted to\\naggressive limit orders. This three-tiered approach optimizes immediate execution and price\\ndiscovery while maintaining market liquidity.\\nThe system\\u2019s OrderMatchingService orchestrates this process by coordinating trade ex-\\necutions through the TradeExecutionService and managing order state transitions via the\\nOrderStateManager. Each trade is logged in detail, with the overall market state\\u2014including\\norder books, market depth, and price evolution\\u2014recalculated at the end of each trading\\nround.\\nThis modular design in the matching and clearing engine provides several advantages.\\nFirst, it enables rigorous trade validation where each market order is validated against agent\\ncash commitments and position constraints before matching, with the system dynamically\\nadjusting order quantities based on available cash when an agent\\u2019s commitment is insuf-\\nficient, thus minimizing execution errors. Second, it offers flexible liquidity handling by\\nsupporting market-to-market and market-to-book matching, ensuring orders have multiple\\nexecution pathways, with unexecuted market orders converted to aggressive limit orders to\\ncapture remaining liquidity. Third, it maintains detailed trade audit capabilities by recording\\ncomprehensive traceability data including timestamps, trade volumes, executed prices, and\\nagent identifiers, thereby enabling post-trade analysis and performance benchmarking that\\n9\\nserves as the foundation for subsequent market efficiency and agent performance validations.\\n2.1.1 Market Mechanism Design\\nOur framework implements a continuous double-auction market mechanism that processes\\norders in discrete trading rounds. We use discrete trading rounds because LLMs have latency\\nconstraints, making it infeasible to process orders in real time. Within each round, the order\\nof agent submissions is randomized to avoid giving systematic priority to specific agents,\\nthus simulating concurrent order arrival while maintaining fairness. Once randomized, or-\\nders are then processed according to standard price-time priority rules. The system supports\\nfinite and infinite horizon markets, with differences in terminal conditions and wealth cal-\\nculation. In finite-horizon markets, agents are informed of the total number of rounds, and\\ntheir terminal wealth is calculated by redeeming all shares at the fundamental value of the\\nfinal round. In infinite-horizon markets, no terminal information is provided to agents, and\\nfinal wealth is determined using the last market price for share valuation. This design choice\\nenables researchers to study how time horizons influence trading strategies and price for-\\nmation, particularly how agents balance short-term trading opportunities against long-term\\nvalue considerations.\\nIn a double auction, buyers and sellers actively submit orders, with trades occurring when\\ncompatible buy and sell orders match the price. The matching engine processes these orders\\nthrough three sequential phases:\\nFirst, incoming limit orders that do not immediately cross the market are added to\\nthe order book, maintaining strict price-time priority. Second, market orders are processed\", \"value considerations.\\nIn a double auction, buyers and sellers actively submit orders, with trades occurring when\\ncompatible buy and sell orders match the price. The matching engine processes these orders\\nthrough three sequential phases:\\nFirst, incoming limit orders that do not immediately cross the market are added to\\nthe order book, maintaining strict price-time priority. Second, market orders are processed\\nthrough a two-stage matching algorithm: (a) market-to-market matching, where market\\norders are netted against each other at the current market price, and (b) market-to-book\\nmatching, where remaining market orders are executed against standing limit orders. Finally,\\nany crossing limit orders are matched against the order book.\\n10\\n2.1.2 Implementation Details\\nThe matching engine ( MatchingEngine class) implements three primary components that\\nwork together to facilitate efficient market operation. The order processing component han-\\ndles the core matching functionality, where market orders are executed immediately against\\nthe best available prices in the order book during each trading round. When immediate\\nexecution is impossible, limit orders are stored in the order book according to price-time\\npriority. The system supports partial executions, maintaining careful tracking of remaining\\nquantities to ensure complete order fulfillment across multiple trades when necessary.\\nPosition management forms the second critical component, providing comprehensive\\ntracking of agent positions and cash balances throughout the trading session. Before any\\ntrade execution, the system performs rigorous pre-trade validation to ensure agents have suffi-\\ncient resources to fulfill their orders. This check includes validating buyer cash commitments\\nand shares availability for sellers, with the system maintaining accurate records of commit-\\nted and available resources for each agent. The position management system updates in\\nreal-time as trades are executed, ensuring market integrity and preventing over-commitment\\nof resources.\\nThe price formation mechanism constitutes the third component, implementing a sys-\\ntematic price discovery and market monitoring approach. As trades are executed within each\\nround, the system dynamically updates prices based on executed trades while continuously\\ntracking market depth and bid-ask spreads. This data collection provides detailed insights\\ninto market liquidity and efficiency. Each trade is logged with comprehensive information,\\nincluding price, quantity, and participating agents, creating a complete audit trail of mar-\\nket activity. This comprehensive price formation system ensures transparent price discovery\\nwhile generating rich data for market quality analysis.\\n11\\n2.1.3 Extensibility Features\\nThe framework employs a modular architecture to support diverse experimental configura-\\ntions and research objectives. At its foundation, the system implements configurable market\\nrules and trading constraints that can be adjusted to study different market conditions.\\nThe asset model supports fundamental features like dividend payments and interest accrual,\\nenabling research across different market scenarios. Through its modular service-based ar-\\nchitecture, the trading mechanism layer allows for adaptation to other market structures\\nbeyond the base double-auction system, such as call auctions or dark pools. Furthermore,\\nthe framework provides flexible integration points for different LLM agent types and strate-\\ngies, allowing researchers to experiment with diverse behavioral models and decision-making\\napproaches.\\nThis extensible design creates numerous research opportunities for market microstructure\\nstudies. Researchers can systematically investigate how different market structures influence\\nprice formation and efficiency, evaluate the impact of various trading rules on market qual-\\nity, and analyze the complex interactions between different agent types and strategies. The\"]}": {"cached_metrics_data": [{"metric_data": {"name": "Contextual Precision (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Faithfulness (ragas)", "threshold": 0.8, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.8, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Contextual Recall (ragas)", "threshold": 0.6, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.6, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Answer Relevancy (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}]}, "{\"actual_output\": \"In the formula Vt = E[D]/r,\\n\\nVt represents the fundamental value of the firm at time t. This is the theoretical \\\"true\\\" value of the company based on its expected future earnings.\\nE[D] represents the expected value of the firm's dividends. Dividends are the portion of a company's profits that are paid out to its shareholders. E[...] denotes the expected value of a random variable. Since the excerpts mention \\\"discounted-loan\\\" type debt and no dividend payments on equity being assumed, the formula likely refers to expected cash flow available to all security holders, debt and equity.\\nr represents the risk-free interest rate (the return an investor can expect from a \\\"safe\\\" investment like a government bond).\\nIn the simulations, this perpetuity formula (a formula for valuing a stream of payments that continues forever) is used to establish a baseline value for the simulated firm. The simulations then explore how market prices, driven by the AI agents' trading activity, deviate from this fundamental value, specifically testing the scenarios where the market starts 25% above or below this calculated fundamental value. This setup allows the researchers to observe how effectively the AI agents correct over- or under-valuations back towards the \\\"true\\\" value.\\n\", \"context\": [\"The framework implements a consistent approach\\u2026 For infinite horizon markets, the fundamental value follows the standard dividend discount model: Vt=E[D]rV_t = \\frac{E[D]}{r}. \\u2026 For the default parameters where the expected dividend is $1.40 and the interest rate is 5 %, this yields a fundamental value of $28.00.\"], \"expected_output\": \"Vt=E[D]/rV_t = E[D]/r treats the stock as a perpetuity: E[D]E[D] is expected dividend per round and rr the risk\\u2011free rate; with $1.40 and 5 % the value is $28.\", \"hyperparameters\": null, \"input\": \"The paper gives Vt=E[D]rV_t=\\tfrac{E[D]}{r} as Equation (1). What does each variable represent, and how is this perpetuity formula used in the simulations?\", \"retrieval_context\": [\"Fi(V, \\u03c4) = exp( \\u2212\\u03b7\\u03c4)\\u222b\\u221e\\n0Fi(V Z,0)dQ(Z, \\u03c4) i= 1,. . ., n (11.8)\\nBecause the Fi(V Z,0)are known functions determined by the type of security, and U\\nandP(Z, \\u03c4)are assumed known, (11.8) would be suf\\ufb01cient to determine the current\\nequilibrium value of the Eth security if we knew \\u03b7.\\nFrom examination of (11.7) and noting again that dQis independent of the partic-\\nular capital structure chosen, we \\ufb01nd that exp(\\u03b7\\u03c4)(and hence \\u03b7) is independent of the\\nparticular capital structure. Since (11.7) holds for all capital structures, it must hold\\n3The assumption of strict concavity of Uis suf\\ufb01cient to ensure a unique interior maximum which rules out\\nany need for inequalities in the \\ufb01rst-order conditions.\\n4See Samuelson and Merton (1969; this volume, Section 7.2) for further discussion of the util-prob concept.\\n5Thus, the assumption that the \\ufb01rm\\u2019s value is independent of its capital structure provides the same math-\\nematical simpli\\ufb01cation that the assumption of the \\u201cincipient\\u201d case for warrant pricing did in Samuelson and\\nMerton (1969; this volume, Section 7.7).\\n11.3 Some Examples 281\\nfor the trivial capital structure, namely, when the \\ufb01rm issues just one type of security,\\nequity, and n= 1. In this case, it is obvious that F1(V, \\u03c4) =VandF1(V Z,0) =V Z.\\nSubstituting in (11.7), we have that\\nexp(\\u03b7\\u03c4) =\\u222b\\u221e\\n0ZdQ(Z, \\u03c4) (11.9)\\ni.e.exp(\\u03b7\\u03c4)is the expected return on the \\ufb01rm in util-prob space. Equation (11.7)\\nstates that the expected return on all securities in util-prob space must be equated.\\nIfUwas linear (i.e. the representative man was \\u201crisk neutral\\u201d), then dQ=dPand\\n(11.7) would imply the well-known result for risk neutrality that expected returns (in\\nthe ordinary sense) be equated. Hence, the util-prob distribution is the distribution of\\nreturns adjusted for risk.\\n11.3 Some Examples\\nUsing equation (11.8), we can derive the equilibrium pricing for various capital struc-\\ntures of the \\ufb01rm. In the \\ufb01rst example it is assumed that there are two types of securi-\\nties: debt and equity. Suppose that the amount of debt issued by the \\ufb01rm represents\\na terminal claim of Bdollars on the \\ufb01rm. Let F1(V, \\u03c4)be the current value of the\\ndebt outstanding and F2(V, \\u03c4)be the current value of the (residual) equity. Then,\\nfrom previous discussion and equation (11.3), the terminal value of the debt will be\\nF1(V Z,0) = min( B, V Z ). From equations (11.8) and (11.3), the current value of the\\ndebt will be\\nF1(V, \\u03c4) = exp( \\u2212\\u03b7\\u03c4)[\\u222bB/V\\n0ZV dQ (Z, \\u03c4) +\\u222b\\u221e\\nB/VBdQ(Z, \\u03c4)]\\n(11.10)\\nWe can rewrite (11.10) as\\nF1(V, \\u03c4) = exp( \\u2212\\u03b7\\u03c4)B\\u2212exp(\\u2212\\u03b7\\u03c4)\\u222bB/V\\n0(B\\u2212ZV)dQ(Z, \\u03c4) (11.10a)\\nSuppose that the terminal claim of the debtholders is very small relative to the (cur-\\nrent) total value of the \\ufb01rm (i.e. 0< B\\u226aV) or, alternatively, dQ(Z, \\u03c4) = 0 for\\n0\\u2264Z\\u2264B/V . Then\\nF1(V, \\u03c4)\\u2192exp(\\u2212\\u03b7\\u03c4)BasB/V\\u21920 (11.11)\\nIn the limit, the debt becomes riskless and so, from (11.11), we have that \\u03b7must be\\nthe riskless rate of return per unit time (in both util-prob and ordinary returns space)\\nfor the period of length \\u03c4. Hence, from this point on, \\u03b7will he replaced by r, the usual\\nnotation for the riskless rate. Examining (11.11a), the second term is the discounted\\nexpected loss in util-prob space due to default on the debt,6and as such is a risk\\n6Throughout the chapter, all debt is assumed to be of the \\u201cdiscounted-loan\\u201d type with no payments prior to\\nmaturity. Similarly, it is assumed that no dividends are paid on the equity.\\n282 A Dynamic General Equilibrium Model of the Asset Market\\npremium charged over the-riskless rate. A second useful form of (11.10) is\\nF1(V, \\u03c4) = exp( \\u2212r\\u03c4)[\\u222b\\u221e\\n0ZV dQ (Z, \\u03c4)\\u2212\\u222b\\u221e\\nB/V(ZV\\u2212B)dQ(Z, \\u03c4)]\\n=V\\u2212exp(\\u2212r\\u03c4)\\u222b\\u221e\\nB/V(ZV\\u2212B)dQ(Z, \\u03c4) (11.10b)\\nSince, in equilibrium, V=F1(V, \\u03c4) +F2(V, \\u03c4), the current value of equity, F2(V, \\u03c4),\\nmust satisfy\\nF2(V, \\u03c4) = exp( \\u2212r\\u03c4)\\u222b\\u221e\\nB/V(ZV\\u2212B)dQ(Z, \\u03c4) (11.12)\\nEquation (11.12) is identical to the warrant pricing equation derived in Samuelson\\nand Merton (1969; this volume, Section 7.8) for a warrant with exercise price B.\", \"P(r,0) = 1 , to determine P(r,\\u03c4)and hence the term structure of interest rates. How-\\never, without some independent knowledge of \\u03b1m(and hence \\u03b1\\u03c4), we cannot deter-\\nmine an explicit solution for the term structure.\\nSuppose that one knew that the Expectations Hypothesis held. Then \\u03b1\\u03c4\\u2261rfor all\\n\\u03c4and the term structure is completely determined by\\n0 =1\\n2g2Prr+fPr\\u2212P\\u03c4\\u2212rP (11.83)\\nsubject to P(r,0) = 1 . Further, from (11.80), it must be that in equilibrium, \\u03b1m=r.\\nIn this case, the equilibrium condition (11.77) simpli\\ufb01es to\\n\\u03b1k\\u2212r=\\u03c3k(\\u03c1kM\\u2212\\u03c1Mr\\u03c1kr)\\n\\u03c3M(1\\u2212\\u03c12\\nMr)(\\u03b1M\\u2212r) k= 1,. .. , m \\u22121 (11.84)\\nwhere the \\u03c1s are the instantaneous correlation coef\\ufb01cients de\\ufb01ned by \\u03c1kM\\u2261\\u03c3kM/\\u03c3k\\u03c3M,\\n\\u03c1kr\\u2261\\u03c3kr/g\\u03c3k, and\\u03c1Mr\\u2261\\u03c3Mr/g\\u03c3M. Hence, the individual expected returns are pro-\\nportional to the market expected return as was the case in Model I. However, the\\nproportionality factor is not \\u03c3Mk/\\u03c32\\nM. If the mth security is chosen to be a portfolio\\nof government bonds, then, given speci\\ufb01c knowledge of the term structure, the rest\\nof the equilibrium relations work out in a determined fashion.\\nEquation (11.83) cannot be solved in closed form for arbitrary fandg. However,\\nif it is assumed that fandgare constants (i.e. rfollows a Gaussian random walk with\\na drift), then, under the Expectations Hypothesis, we do have the explicit solution\\nP(r,\\u03c4) = exp(\\n\\u2212r\\u03c4\\u2212f\\n2\\u03c42+g2\\n6\\u03c43)\\n(11.85)\\nNote that in (11.85), as \\u03c4\\u2192 \\u221e ,P\\u2192 \\u221e , which is not at all reasonable. Certainly, the\\ncurrent value of a discounted loan which will never be paid should be zero for any\\n300 A Dynamic General Equilibrium Model of the Asset Market\\nrealistic assumption about interest rates. The reason that (11.85) gives such nonsensi-\\ncal results is that, by the assumption that ris Gaussian, there is a positive probability\\nofrbecoming negative. In fact, as \\u03c4\\u2192 \\u221e ,rwill be negative for an arbitrary period\\nof time with positive probability. This result illustrates how the assumption of the\\nnormal distribution for variables which are constrained to be nonnegative can lead to\\nabsurd implications. However, equation (11.83) with reasonable assumptions about\\nfandgcan be solved numerically and further research is planned in this area.42\\nBy arguments similar to those used in Section 11.5, the Fundamental Equation of\\nSecurity Pricing for the capital structure of the \\ufb01rm in Model III can be derived as\\n0 =1\\n2\\u03c32V2FV V+1\\n2g2Frr+\\u03c1g\\u03c3V F rV+rV F V+fFr\\u2212F\\u03c4\\u2212rF (11.86)\\nsubject to an appropriate boundary condition F(V, r,0), where subscripts denote par-\\ntial derivatives and \\u03c1is the instantaneous correlation coef\\ufb01cient of the return on the\\n\\ufb01rm with interest rate changes. The basic difference between equations (11.86) and\\n(11.65) of Model I is the explicit dependence of Fonrwhich must be taken into\\naccount. Under most conditions, (11.86) will not be solvable in closed form. How-\\never, numerical solution seems quite reasonable which implies many possibilities for\\nempirical testing both by direct statistical methods and by simulation.\\n11.8 Conclusion\\nA general intertemporal equilibrium model of the asset market has been derived for\\narbitrary preferences, time horizon, and wealth distribution. The equilibrium rela-\\ntions among securities were shown to depend only on certain \\u201cobservable\\u201d market\\naggregates, and hence are subject to empirical investigation. Under the additional as-\\nsumption of a constant rate of interest, these equilibrium relations are essentially the\\nsame as those of the static CAPM of Sharpe, Lintner, and Mossin. However, these\\nresults were derived without the assumption of Gaussian distributions for security\\nprices or quadratic utility functions. When interest rates vary, some of the intuition\\nabout \\u201cmarket risk\\u201d and equilibrium expected returns provided by the CAPM was\\nshown to be incorrect.43In addition, the model clearly differentiates between the\\ntrading-period horizon ( dt, an in\\ufb01nitesimal) and the planning or time horizon ( Tk,\\nwhich is arbitrary).\", \"ary condition F(V,0) = min( V, B). A comparison of (11.66) with (11.12) shows that\\nthey are the same for dQ=d\\u039b. Equation (11.66) can be rewritten in general form as\\nF(V, \\u03c4) = exp( \\u2212r\\u03c4)\\u222b\\u221e\\n0F(V Z,0)d\\u039b(Z, \\u03c4) (11.67)\\nwhere F(V Z,0)is the terminal claim of the security on the \\ufb01rm. Note that (11.67) de-\\npends only on the rate of interest r, which is an observable, and \\u03c32which can be esti-\\nmated from past data reasonably accurately; and noton\\u03b1, which would be dif\\ufb01cult to\\nestimate. The actual value of Fcan be computed by using standard error-complement\\nfunction tables. Hence, (11.67) is subject to rigorous empirical investigation.\\nAlthough (11.67) is a kind of discounted expected value formula. one should\\nnot infer that the expected return on Fisr. From (11.59), (11.63) and (11.64), the\\nexpected return on Fcan be written as\\n\\u03b1e=r+FVV\\nF(\\u03b1\\u2212r) (11.68)\\nwhich will vary with changes in Vand\\u03c4. although it too can be computed from the\\nerror-complement function tables, given an estimate of \\u03b1.\\n30See Samuelson (1965a. p. 22) for solution of the \\u03b1=\\u03b2case.\\n11.5 Model I: A Constant Interest Rate Assumption 295\\nEquation (11.65) was previously derived by Black and Scholes (1973) as a method\\nfor pricing option contracts.31Moreover, (11.65) actually holds without the assump-\\ntion of market equilibrium used here. Because of its elegance, I derive the Black-\\nScholes model in an alternative fashion which makes use of It \\u02c6o\\u2019s lemma and the\\nassociated theory of stochastic differential equations. Consider a two-asset portfolio\\nconstructed so as to contain the \\ufb01rm as one security and any one of the securities in\\nthe \\ufb01rm\\u2019s capital structure as the other. Let Pbe the price per unit of this portfolio,\\n\\u03b4the fraction of the total portfolio\\u2019s value invested in the \\ufb01rm and 1\\u2212\\u03b4the fraction\\nin the particular security chosen from the \\ufb01rm\\u2019s capital structure. Then, from (11.57)\\nand (11.58),\\ndP\\nP=\\u03b4dV\\nV+ (1\\u2212\\u03b4)dF\\nF\\n= [\\u03b4(\\u03b1\\u2212\\u03b1e) +\\u03b1e]dt+ [\\u03b4(\\u03c3\\u2212\\u03c3e) +\\u03c3e]dZ(11.69)\\nSuppose \\u03b4is chosen such that \\u03b4(\\u03c3\\u2212\\u03c3e)+\\u03c3e= 0. Then, the portfolio will be \\u201cperfectly\\nhedged\\u201d and the instantaneous return on the portfolio will be \\u03b4(\\u03b1\\u2212\\u03b1e) +\\u03b1ewith\\ncertainty. By arbitrage32conditions, \\u03b4(\\u03b1\\u2212\\u03b1e) +\\u03b1e=r, the instantaneous riskless\\nrate of return. Combining these two conditions, we have that\\n\\u03b1e\\u2212r=\\u03c3e\\n\\u03c3(\\u03b1\\u2212r) (11.70)\\nThen, as was done previously, we use It \\u02c6o\\u2019s lemma to derive (11.62) and (11.63).\\nBy combining (11.62), (11.63), and (11.70), we arrive at (11.65). Nowhere was the\\nmarket-equilibrium assumption needed.\\nTwo further remarks must be made before we examine asset pricing in the more\\ncomplex models in Section 11.6 and Section 11.7. Although the value of the \\ufb01rm\\nfollows a simple dynamic process with constant parameters as described in (11.57),\\nthe individual component securities follow more complex processes with changing\\nexpected returns and variances. Thus, in empirical examinations using a regression\\nsuch as (11.55), if one were to use equity instead of \\ufb01rm values, systematic biases\\nwould be introduced. One can \\ufb01nd cases where the risky debt of one \\ufb01rm is more\\ncomparable with the equity of another \\ufb01rm than the equity of one \\ufb01rm is to that of\\nthe other.\\nOne possibly practical application of the equations of this section is to provide\\na systematic method of measuring the riskiness of debt of various \\ufb01rms. Hence, by\\nusing equation (11.67). one could derive a risk structure of interest rates as a function\\nof the percentage of the total capital structure subordinated to the issue and the overall\\nriskiness of the \\ufb01rm. It would be interesting to see how such a method of rating debt\\nwould compare with the classical methods of Moody\\u2019s and Standard & Poor\\u2019s.\\n31For a brief history of the development of the Black-Scholes option pricing model, see Black (1987, 1989)\\nand Bernstein (1992, Ch. 11).\\n32The meaning of \\u201carbitrage\\u201d here is not as strong as the usual de\\ufb01nition since differences of opinion among\\ninvestors about the value of \\u03c32or the belief that Fis a function of other variables besides the value of the\", \"equity, f, will be\\n0 =1\\n2\\u03c32V2fvv+ (rV\\u2212C)fv\\u2212rf\\u2212f\\u03c4= 0 (12.41)\\nsubject to boundary conditions (12.9a), (12.9b), and (12.11). Again, equation (12.41)\\nhas an isomorphic correspondence with an option pricing problem previously stud-\\nied. Equation (12.41) is identical to equation (12.44) in Merton (1973a; this volume,\\nequation (8.44)) which is the equation for the European option value on a stock which\\npays dividends at a constant rate per unit time of C. While a closed-form solution to\\n(12.41) for \\ufb01nite \\u03c4has not yet been found, one has been found for the limiting case\\nof a perpetuity (\\u03c4=\\u221e), and is presented in Merton (1973a; this volume, equation\\n(8.46)). Using the identity F=V\\u2212f, we can write the solution for the perpetual\\nrisky coupon bond as\\nF(v,\\u221e) =C\\nr\\n1\\u2212(\\n2C\\n\\u03c32v)2r\\n\\u03c32\\n\\u0393(\\n2 +2r\\n\\u03c32)M(2r\\n\\u03c32,2 +2r\\n\\u03c32,\\u22122C\\n\\u03c32v)\\n(12.42)\\nwhere \\u0393(\\u00b7)is the gamma function and M(\\u00b7)is the con\\ufb02uent hypergeometric func-\\ntion. While perpetual, non-callable bonds are non-existent in the United States, there\\nare preferred stocks with no maturity date and (12.42) would be the correct pricing\\nfunction for them.\\nMoreover, even for those cases where closed-form solutions cannot be found,\\npowerful numerical integration techniques have been developed for solving equations\\nlike (12.7) or (12.41). Hence, computation and empirical testing of these pricing the-\\nories is entirely feasible.\\nNote that in deducing (12.40), it was assumed that coupon payments were made\\nuniformly and continuously. In fact, coupon payments are usually only made semi-\\nannually or annually in discrete lumps. However, it is a simple matter to take this into\\n322 On the Pricing of Corporate Debt: The Risk Structure of Interest Rates\\naccount by replacing \\u201c C\\u201d in (12.40) by \\u201c\\u2211\\niCi\\u03b4(\\u03c4\\u2212\\u03c4i)\\u201d where \\u03b4(\\u00b7)is the dirac delta\\nfunction and \\u03c4iis the length of time until maturity when the ith coupon payment of\\nCidollars is made.\\nAs a \\ufb01nal illustration, we consider the case of callable bonds. Again, assume the\\nsame capital structure but modify the indenture to state that \\u201cthe \\ufb01rm can redeem\\nthe bonds at its option for a stated price of K(\\u03c4)dollars\\u201d where Kmay depend on\\nthe length of time until maturity. Formally, equation (12.40) and boundary conditions\\n(12.9a) and (12.9c) are still valid. However, instead of the boundary condition (12.9b)\\nwe have that for each \\u03c4, there will be some value for the \\ufb01rm, call it V(\\u03c4), such that\\nfor all V(\\u03c4)\\u2265V(\\u03c4), it would be advantageous for the \\ufb01rm to redeem the bonds.\\nHence, the new boundary condition will be\\nF[V(\\u03c4),\\u03c4] =K(\\u03c4) (12.43)\\nEquation (12.40), (12.9a), (12.9c), and (12.43) provide a well-posed problem to solve\\nforFprovided that the V(\\u03c4)function were known. But, of course, it is not. Fortu-\\nnately, economic theory is rich enough to provide us with an answer. First, imagine\\nthat we solved the problem as if we knew V(\\u03c4)to get F[V, \\u03c4;V(\\u03c4)]as a function of\\nV(\\u03c4). Second, recognize that it is at management\\u2019s option to redeem the bonds and\\nthat management operates in the best interests of the equity holders. Hence, as a\\nbondholder, one must presume that management will select the V(\\u03c4)function so as\\nto maximize the value of equity, f. But, from the identity F=V\\u2212f, this implies that\\ntheV(\\u03c4)function chosen will be the one which minimizes F[V, \\u03c4;V(\\u03c4)]. Therefore,\\nthe additional condition is that\\nF[V, \\u03c4] = min\\n{V(\\u03c4)}F[V, \\u03c4;V(\\u03c4)] (12.44)\\nTo put this in appropriate boundary condition form for solution, we again rely on\\nthe isomorphic correspondence with options and refer the reader to the discussion in\\nMerton (1973a) where it is shown that condition (12.44) is equivalent to the condition\\nFV[V(\\u03c4),\\u03c4] = 0 (12.45)\\nHence, appending (12.45) to (12.40), (12.9a), (12.9c) and (12.43), we solve the prob-\\nlem for the F[V, \\u03c4]andV(\\u03c4)functions simultaneously.\\n12.7 Conclusion\\nWe have developed a method for pricing corporate liabilities which is grounded in\\nsolid economic analysis, requires inputs which are on the whole observable; can\", \"of the \\ufb01rm and the changes in value of the \\ufb01rm\\u2019s capital stock or earning assets\\nover the period. A crucial assumption is that P(Z, \\u03c4)is independent of the particular\\ncapital structure of the \\ufb01rm, i.e. Pis determined solely by the characteristics of the\\nasset side of the balance sheet and is not affected by the particular instruments used\\nby the \\ufb01rm to \\ufb01nance these assets. This assumption is consistent with the Modigliani-\\nMiller (1958) theorem and, as such, we implicitly assume perfect capital markets and\\ntax effects are not considered.\\nConsider that the \\ufb01rm chooses a particular set of \\ufb01nancial instruments (debt, eq-\\nuity, etc.) de\\ufb01ned by their terminal conditions. We now \\ufb01nd the current equilibrium\\nvalue of each of these future claims on the terminal (random) value of the \\ufb01rm. For\\ni= 1,. . ., n , de\\ufb01ne Fi(V, \\u03c4)as the current value of the ith type of security with ter-\\nminal date \\u03c4from now issued by the \\ufb01rm.2The different types of securities are\\ndistinguishable by their terminal value Fi(V Z,0), contingent on the terminal value of\\nthe \\ufb01rm V(t+\\u03c4) =V Z. For example, if one of the securities is a debt issue ( i= 1),\\nsenior to all other claims on the \\ufb01rm, with a terminal claim of Bdollars on the \\ufb01rm,\\nthen\\nF1(V Z,0) = min( B, V Z ) (11.3)\\ni.e. the debtholders will receive Bdollars at the end of the period if the \\ufb01rm can pay,\\nor, in the event that the \\ufb01rm cannot pay (default), they are entitled to all the assets of\\nthe \\ufb01rm which will have value V Z.\\nTo determine the equilibrium values of each of the securities, note that because\\neach of the securities appears separately in the market place, they must be priced so\\n1Since, in this section, we are using a period model, \\u03c4could be set equal to one. However, it will be useful\\nfor later development to carry the general symbol \\u03c4.\\n2Strictly, Fiwill be a function of the current values of all securities senior to it, the capitalization rate, etc.\\nin addition to V. However, in equilibrium, the Fiare perfectly positively related to changes in the value of the\\n\\ufb01rm, and so these other arguments of the function will enter only as parameters.\\n280 A Dynamic General Equilibrium Model of the Asset Market\\nthat when examined by the representative man he will choose his portfolio so as to\\nhold the amount supplied, i.e.\\nV=n\\u2211\\ni=1Fi(V, \\u03c4) (11.4)\\nand, of course, V Z=\\u2211n\\n1Fi(V Z,0). De\\ufb01ne wi\\u2261Fi(V, \\u03c4)/Vas the fraction of the\\n\\ufb01rm\\u2019s assets \\ufb01nanced by the ith security. Then, because the \\ufb01rm is the only asset\\nin the economy, wiwill also be equal to the fraction of the representative man\\u2019s\\ninitial wealth invested in the ith security. We rewrite (11.1) as a maximization under\\nconstraint problem:\\nmax\\n{wi}{\\nEtU[\\nVn\\u2211\\ni=1wiFi(V Z,0)\\nFi(V, \\u03c4)]\\n+\\u03bb[\\n1\\u2212n\\u2211\\ni=1wi]}\\n(11.5)\\nThe \\ufb01rst-order conditions3derived from (11.5) are\\nEt{\\nFi(V Z,0)\\nFi(V, \\u03c4)U\\u2032[\\nVn\\u2211\\ni=1wiFi(V Z,0)\\nFi(V, \\u03c4)]}\\n=\\u03bb i = 1,. . ., n (11.6)\\nEquation (11.6) can be rewritten in terms of util-prob distributions4Qas\\n\\u222b\\u221e\\n0Fi(V Z,0)\\nFi(V, \\u03c4)dQ=\\u222b\\u221e\\n0Fj(V Z,0)\\nFj(V, \\u03c4)dQ\\u2261exp(\\u03b7\\u03c4)for all i,j= 1,. .. , n (11.7)\\nwhere\\ndQ\\u2261U\\u2032(ZV)dP(Z, \\u03c4)\\u222b\\u221e\\n0U\\u2032(ZV)dP(Z, \\u03c4)\\nandexp(\\u03b7\\u03c4)is a new multiplier related to the original \\u03bbmultiplier. Note the important\\nsubstitution of V ZforV\\u2211n\\n1wiFi(V Z,0)/Fi(V, \\u03c4)in the de\\ufb01nition of dQ. By the\\nassumption that the value of the \\ufb01rm is independent of its capital structure, we have\\nthatdQis independent of the functions Fi,i= 1,. .. , n . Therefore, (11.7) is a set of\\nintegral equations, linear in the Fi.5Hence, we can meaningfully rewrite (11.7) as\\nFi(V, \\u03c4) = exp( \\u2212\\u03b7\\u03c4)\\u222b\\u221e\\n0Fi(V Z,0)dQ(Z, \\u03c4) i= 1,. . ., n (11.8)\\nBecause the Fi(V Z,0)are known functions determined by the type of security, and U\\nandP(Z, \\u03c4)are assumed known, (11.8) would be suf\\ufb01cient to determine the current\\nequilibrium value of the Eth security if we knew \\u03b7.\\nFrom examination of (11.7) and noting again that dQis independent of the partic-\\nular capital structure chosen, we \\ufb01nd that exp(\\u03b7\\u03c4)(and hence \\u03b7) is independent of the\", \"one-period model further, an intertemporal equilibrium model, which includes the\\nmodel of Section 11.2 as a special case, is developed in the following sections.\\n11.4 A General Intertemporal Equilibrium Model of the Asset Market\\nConsider an economy with Kconsumers-investors and n\\ufb01rms with current value Vi,\\ni= 1,. .. , n . Each consumer acts so as to\\nmaxE0{\\u222bTk\\n0Uk[\\nCK(s),s]\\nds+Bk[\\nWk(\\nTk)\\n,Tk]}\\n(11.28)\\nwhere E0is the conditional expectation operator, conditional on the value of current\\nwealth Wk(0) = Wkof the kth consumer and on the current value of the \\ufb01rms,\\nVi(0) = Vi,i= 1,. .. , n .Ck(s)is his instantaneous consumption at time s.Ukis a\\nstrictly concave von Neumann-Morgenstern utility function; Bkis a strictly concave\\n\\u201cbequest\\u201d or utility-of-terminal-wealth function; and Tkis the date of death of the\\nkth consumer. De\\ufb01ne Ni(t)Pi(t)\\u2261Vi(t)where Ni(t)is the number of shares14of\\n\\ufb01rmioutstanding at time tandPi(t)is the price per share at time t. It is assumed that\\nexpectations about the dynamics of the prices per share in the future are same for all\\ninvestors and these dynamics ca be described by the stochastic differential equation15\\ndPi\\nPi=\\u03b1idt+\\u03c3idZii= 1,. .. , n (11.29)\\nwhere the instantaneous expected rate of return, \\u03b1i, and the instantaneous standard\\ndeviation of return, \\u03c3i, may change stochastically over time, but only in a way which\\nis instantaneously uncorrelated with price changes (i.e. d\\u03b1idZj=d\\u03c3idZj= 0 for\\ni,j= 1,. .. , n ). The dZirepresent a simple Gauss-Wiener process with zero mean\\nand unit variance rate (often referred to as Gaussian \\u201cwhite noise\\u201d). Equation (11.29)\\nincludes returns from both capital gains and dividends, and re\\ufb02ects both the uncer-\\ntainties about future cash \\ufb02ows and changes in the \\u201ccapitalized\\u201d value of the \\ufb01rm\\u2019s\\nearning assets. Notice that, if \\u03b1iand\\u03c3iwere constant, then the Pi(t)would be log-\\nnormally distributed. Further assume that one of the nassets (by convention the nth\\none) is an \\u201cinstantaneously\\u201d riskless asset16with instantaneous return r(t)and that\\n14In this section, the particular capital structure of the \\ufb01rm is not discussed, and hence one can think of each\\n\\ufb01rm as having the trivial capital structure, namely, all equity. However, the assumption that the value of the\\n\\ufb01rm is independent of its capital structure is retained throughout the chapter.\\n15For a discussion of and further references to stochastic differential equations of the type in (11.29), see\\nMerton (1971; this volume, Ch. 5).\\n16What is meant by an \\u201cinstantaneously\\u201d riskless asset is that, at each instant of time, each investor knows\\nwith certainty that he can earn return r(t)over the next instant by holding the asset (i.e. \\u03c3n= 0and\\u03b1n=r).\\nHowever, the future values of r(t)are not known with certainty. It is assumed here that one of the \\ufb01rms is\\ncharacterized by this asset. Alternatively, one could postulate a government which issues (very) short bonds,\\nor that r(t)is the instantaneous private sector borrowing (and lending) rate.\\n11.4 A General Intertemporal Equilibrium Model of the Asset Market 287\\nthe dynamics of this rate are described by\\ndr=f(r,t)dt+g(r,t)dq (11.30)\\nwhere (11.30) is the same type of equation as (11.29) and dqis a simple Gauss-Wiener\\nprocess. For computational simplicity, it is further assumed that \\u03b1iand\\u03c3i, in (11.29),\\nare functions only of r(t),17i.e. investors only anticipate revising their expectations\\nabout returns if the interest rate changes.\\nFrom the de\\ufb01nition of NiandPi. we have that the change in the value of the ith\\n\\ufb01rm over time is dV=NidPi+dNi(Pi+dPi). The \\ufb01rst term is that part of the changed\\nvalue of the \\ufb01rm due to cash \\ufb02ow and changes in the value of its assets. The second\\nterm is that part of the changed value of the \\ufb01rm due to the issue (or purchase) of new\\nshares at the new price per share Pi+dPi.18Substituting from (11.29) for dPi/Piand\\nwriting everything in percentage terms, we have that\\ndVi\\nVi=\\u03b1idt+\\u03c3idZi+dNi\\nNi(1 +\\u03b1idt+\\u03c3idZi) i= 1,. .. , n (11.31)\", \"or purchase of securities prior to the redemption date of the debt ( \\u03c4\\u201cyears\\u201d from\\nnow).29Hence, from (11.31), we have that\\ndV\\nV=fcdPP =\\u03b1dt+\\u03c3dZ (11.57)\\nwhere \\u03b1and\\u03c3are constants.\\nLetD(t;\\u03c4)be the current value of the debt with \\u03c4years until maturity and with\\nredemption value at that time of B. Then D(t+\\u03c4; 0) = min[ V(t+\\u03c4),B]. and therefore\\nit is reasonable to assume that D(t;\\u03c4)will depend on the interest rate and the proba-\\nbility of default which will be a function of the current value of the \\ufb01rm. Because the\\ncurrent value of equity is V(t)\\u2212D(t;\\u03c4), equity will only depend on the current value\\nof the \\ufb01rm and the interest rate. Let F(V, \\u03c4)be the current value of equity where the\\nvariable rhas been suppressed because, in this model, it is constant. The dynamics\\nof the return on equity can be written as\\ndF\\nF=\\u03b1edt+\\u03c3edZ (11.58)\\nwhere \\u03b1eis the instantaneous expected rate of return, \\u03c3eis the instantaneous standard\\ndeviation of return, and dZis the same standard Wiener process as in (11.57). \\u03b1eand\\n\\u03c3eare not constants but functions of Vand\\u03c4. Like every security in the economy,\\nthe equity of the \\ufb01rm must satisfy (11.51) in equilibrium, and hence\\n\\u03b1e\\u2212r=\\u03c1\\u03c3e\\u03c3M\\n\\u03c32\\nM(\\u03b1M\\u2212r) (11.59)\\nwhere \\u03c1is the instantaneous correlation coef\\ufb01cient between dZand the market return.\\nFurther, by It \\u02c6o\\u2019s lemma (see Merton, 1971; this volume, Lemma 5.1), we have that\\ndF=FVdV+F\\u03c4d\\u03c4+1\\n2FV V(dV)2(11.60)\\nwhere subscripts denote partial derivatives. Since \\u03c4is the length of time until matu-\\nrity,d\\u03c4=\\u2212dt. Substituting for dVfrom (11.57), we rewrite (11.60) as\\ndF=(1\\n2\\u03c32V2FV V+\\u03b1V F V\\u2212F\\u03c4)\\ndt+\\u03c3V F VdZ (11.61)\\n29This assumption is stronger than necessary. It is suf\\ufb01cient that any new issues have the same terms as the\\ncurrent capital structure and that they be issued in the same proportions of units ( notvalues) as the current\\nstructure. A more general model using the same approach as in the text could be formulated to include the\\nexpectations of future issues.\\nThe assumption that the debt is of the discounted-loan type is not completely innocent because of the pos-\\nsibility of default on interim interest payments. Although the resulting mathematics is more complicated, the\\nbasic approach used here could be modi\\ufb01ed to include the case of interim payments as well. (1990 note: see\\nMerton (1974; this volume, Section 12.6) for a solution of the risky coupon-bond case.)\\n294 A Dynamic General Equilibrium Model of the Asset Market\\nwhere (dV)2\\u2261\\u03c32V2dt. Comparing (11.58) and (11.61), it must be that\\n\\u03b1eF\\u22611\\n2\\u03c32V2FV V+\\u03b1V F V\\u2212F\\u03c4 (11.62)\\nand\\n\\u03b1eF\\u2261\\u03c3V F V (11.63)\\nAs previously shown, the return on holding the \\ufb01rm itself must satisfy equation\\n(11.51) in equilibrium. Hence,\\n\\u03b1\\u2212r=\\u03c1\\u03c3i\\u03c3M\\n\\u03c32\\nM(\\u03b1M\\u2212r) (11.64)\\nSubstituting for \\u03b1and\\u03b1efrom (11.59) and (11.64) into (11.62), we have the Funda-\\nmental Partial Differential Equation of Security Pricing\\n0 =1\\n2\\u03c32V2FV V+\\u03b1V F V\\u2212F\\u03c4\\u2212rF (11.65)\\nsubject to the boundary condition F(V,0) = max(0 ,V\\u2212B). The solution30to (11.65)\\nis\\nF(V, \\u03c4) = exp( \\u2212r\\u03c4)\\u222b\\u221e\\nB/V(V Z\\u2212B)d\\u039b(Z, \\u03c4) (11.66)\\nwhere Zis a log-normally distributed random variable with mean exp(r\\u03c4)and vari-\\nance of log(Z)\\u03c32\\u03c4, and d\\u039bis the log-normal density function. I call (11.65) the\\nFundamental Partial Differential Equation of Asset Pricing because all the securities\\nin the \\ufb01rm\\u2019s capital structure must satisfy it. As was true of the model in Section\\n11.1, securities are distinguished by theirs terminal claims (boundary conditions).\\nFor example, the value of the debt of the \\ufb01rm satis\\ufb01es (11.65) subject to the bound-\\nary condition F(V,0) = min( V, B). A comparison of (11.66) with (11.12) shows that\\nthey are the same for dQ=d\\u039b. Equation (11.66) can be rewritten in general form as\\nF(V, \\u03c4) = exp( \\u2212r\\u03c4)\\u222b\\u221e\\n0F(V Z,0)d\\u039b(Z, \\u03c4) (11.67)\\nwhere F(V Z,0)is the terminal claim of the security on the \\ufb01rm. Note that (11.67) de-\\npends only on the rate of interest r, which is an observable, and \\u03c32which can be esti-\\nmated from past data reasonably accurately; and noton\\u03b1, which would be dif\\ufb01cult to\", \"the \\ufb01rst to show that combinations of options could be used to create pure securities\\nand that these pure securities could be used to price derivative securities.\\nIn this section, we derive the natural analog to Arrow-Debreu pure securities in the\\ncontinuous-time model and demonstrate their application to the pricing of contingent-\\nclaim securities. This done, we go on to show the explicit Connections between\\noption pricing theory and the pricing of these pure securities.\\nIn Section 13.2, we derived the price of a general derivative security with payoffs\\nthat are a function of a traded asset\\u2019s price and time. Under Assumptions 1-6 of that\\nchapter, it was shown that the price of the derivative security, F(V, t), will satisfy\\n0 =1\\n2\\u03c32V2F11+ (rV\\u2212D1)F1\\u2212rF+F2+D2 (14.9)\\n10Information costs together with agency problems that prohibit the direct sale of information to investors\\ncan, of course, justify certain types of \\ufb01nancial intermediation such as mutual funds. Regulation and spe-\\ncial features of the tax laws may also induce the creation of specialized \\ufb01nancial instruments and institutions.\\nHowever, in the absence of transactions costs, it is dif\\ufb01cult to explain the complex structure of \\ufb01nancial inter-\\nmediaries and their wide scope of activities that we observe in the real world.\\n11See the classical works of Arrow (1953, 1964) and Debreu (1959) for the original development of pure\\nstate-contingent securities. There is an enormous literature based on the Arrow\\u0142Debreu model (cf. Radner,\\n1972, and Merton, 1982a. 1990a, Section 5).\\n348 Financial Intermediation in the Continuous-Time Model\\nfor0\\u2264V(t)< V < V(t)andt < T , subject to the boundary conditions\\nF[V(t),t] =f[V(t),t] (14.10a)\\nF[V(t),t] =f[V(t),t] (14.10b)\\nF(V, T) =h(V) (14.10c)\\nSubscripts on Fin (14.9) denote partial derivatives with respect to Vandt.D1(V, t)\\nandD2(V, t)denote the cash-\\ufb02ow rates paid to the holders of the traded asset and its\\nderivative security, respectively. The limited liability of the traded asset implies that\\nV(t) = 0 only if V(t+\\u03c4) = 0 andD1(0,t+\\u03c4) = 0 for all \\u03c4 >0. Without loss of\\ngenerality, we can assume that D2(0,t) = 0 .12As discussed in Chapter 13, D2,f,g,\\nandhspecify the payoff function for the derivative security.\\nIn the analysis to follow, we assume that the stochastic process governing the\\ndynamics of the traded asset is such that Pr{V(\\u03c4) = 0|V(t)>0}= 0fort\\u2264\\u03c4 <\\u221e.13\\nLet\\u03c0[V(t),t;E, T]denote the price at time tof the particular derivative security with\\na payoff structure given by D2= 0. and for V(T) =VandE >0\\n\\u03c0(V, T;E, T) =\\u03b4(E\\u2212V) (14.11)\\nwhere \\u03b4(x)denotes the Dirac delta function with the properties that S(x) = 0 for\\nx\\u0338= 0and\\u03b4(0)is in\\ufb01nite in such a way that\\u222bb\\na\\u03b4(x)dx= 1for any a <0< b.14We\\nnow show that the derivative securities de\\ufb01ned by (14.11) for various values of Eand\\nTare essentially Arrow-Debreu pure securities, extended to an environment with a\\ncontinuum of states de\\ufb01ned by the price of the traded asset and time.15\\nLetdE > 0denote the in\\ufb01nitesimal differential of the parameter E. Consider\\na portfolio strategy that at time tpurchases dEunits of each of the continuum of\\nderivative securities with parameter values E\\u2208[E1,E2]and0< E 1< E 2. If the\\nportfolio is held until time TandV(T) =V. then from (14.11), the value of the\\nportfolio is given by\\n\\u222bE2\\nE1\\u03b4(E\\u2212V)dE=\\n1ifE1< V < E 2\\n0otherwise(14.12)\\n12Because V(t) = 0 implies that V(t+\\u03c4) = 0 for\\u03c4 >0, the capitalized value of any promised payments,\\nD2(0,t+\\u03c4), can be incorporated into the termination function g(0,t). Thereby, we can formally set D2(0,t+\\n\\u03c4) = 0 without toss of generality.\\n13That is, we assume that V(t) = 0 is an inaccessible boundary for \\ufb01nite t. For example, this assumption\\nis satis\\ufb01ed if the underlying asset has a proportional payout policy, D1(V, t) =\\u03c1(t)V,0\\u2264\\u03c1(t)<\\u221efor all\\ntand\\u03c3is a constant. General conditions are given in Karlin and Taylor (1981, pp. 226-50)). See also Mardl\\n(1968, pp. 24-5) and Merton (1975a; this volume, Appendix 17B).\"]}": {"cached_metrics_data": [{"metric_data": {"name": "Contextual Precision (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Faithfulness (ragas)", "threshold": 0.8, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.8, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Contextual Recall (ragas)", "threshold": 0.6, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.6, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Answer Relevancy (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}]}, "{\"actual_output\": \"Short selling is prohibited to simplify the simulation and avoid potentially destabilizing effects that short selling can introduce, especially given the experimental nature of using LLMs (Large Language Models) as trading agents. The authors wanted to focus on the core dynamics of price discovery without the added complexity of short selling.\\n\\nAllowing short selling could significantly change the results in several ways:\\n\\nIncreased Downward Pressure on Prices: If agents could short sell, they could put more downward pressure on prices when they believe the asset is overvalued. This might lead to faster and more efficient corrections of overvaluations, potentially mitigating the persistent overvaluation observed in the simulations.\\nIncreased Market Volatility: Short selling can amplify both upward and downward price movements, making the market more volatile. This is because short sellers can create additional selling pressure, driving prices down further and faster than would be possible with only long positions (owning the asset). Conversely, covering short positions (buying back borrowed shares to close a short position) can lead to rapid price increases.\\nMore Complex Agent Strategies: Allowing short selling would open up a wider range of possible trading strategies for the agents. They could implement strategies like short and distort (betting against overvalued assets), pairs trading (simultaneously buying an undervalued asset and shorting an overvalued one), or other more sophisticated approaches. This increased complexity could make it more difficult to interpret the agents' behavior and understand the underlying market dynamics.\\nPotential for Market Manipulation: While not explicitly mentioned, the possibility of market manipulation through short selling could become a factor, especially given the experimental nature of the agents. This could take the form of aggressively shorting an asset to drive down its price, potentially creating artificial price crashes or exacerbating existing downturns.\\n\", \"context\": [\"When the market starts significantly above the fundamental value \\u2026 the price fails to converge downwards \\u2026 remaining substantially elevated. Agent valuations mirror this persistence, with many agents maintaining estimates well above the fundamental value.\"], \"expected_output\": \"It shows asymmetry: over\\u2011valuation persists, but under\\u2011valuation is corrected\\u2014the right panel converges to $28 while the left stays high.\", \"hyperparameters\": null, \"input\": \"Why is short selling prohibited for these agents, and how might allowing it change the results?\", \"retrieval_context\": [\"(2023)). This work, however, focuses on financial markets and how LLM agents can operate\\nas full-fledged trading participants.\\nRecent research examines specific applications of LLMs for trading. FinMem and Trad-\\ningGPT introduce frameworks with layered memory systems and customizable agent traits\\n5\\nto improve financial decision-making (Yu, Li, et al. 2024; Li, Zhang, and Sun 2023). Hierar-\\nchical multi-agent architectures have been explored in FinCon, which uses a manager-analyst\\nsetup for collaborative portfolio decisions (Yu, Yao, et al. 2024). QuantAgent implements\\na self-improving signal-mining approach (Wang et al. 2024), while other work underscores\\nthe importance of long-term memory in LLM agents via vector databases (Hatalis et al.\\n2024). This line of research builds on successful reinforcement learning applications such as\\nAlphaPortfolio (Cong et al. 2021) and AlphaManager (Campello, Cong, and Zhou 2023),\\nwhich leverage deep RL and robust control for portfolio management.\\nAnalyzing LLM agent behavior by changing only some parameters draws on methods\\nfrom the interpretable machine learning literature. In particular, the systematic variation\\nof market parameters to reveal decision patterns mirrors partial dependence plots and in-\\ndividual conditional expectation curves used to interpret complex machine learning models\\n(Molnar 2022). These techniques help reveal how LLM agents respond to changes in specific\\nvariables while holding others constant, providing insight into their internal decision-making\\nprocesses that would otherwise remain opaque.\\nBeyond finance, studies of LLM capabilities in interactive or multi-agent settings offer\\nvaluable insights. Benchmarks like AgentBench evaluate LLMs\\u2019 performance in interac-\\ntive tasks (Liu et al. 2023), while InvestorBench focuses on financial decision-making tasks\\nspecifically (H. Li et al. 2024). NegotiationArena demonstrates LLMs\\u2019 capacity for strategic\\ninteraction in bargaining contexts (Bianchi et al. 2024). Similarly, Guo et al. (2024) provide\\nan economics \\u201darena\\u201d where LLMs compete in strategic games, revealing that advanced\\nmodels like GPT-4 can exhibit rational, adaptive behavior\\u2014albeit not always reaching Nash\\nEquilibrium. Existing frameworks typically assess individual agents or hierarchical collab-\\norations, whereas this work studies emergent market behaviors that arise from multiple\\nindependent LLM traders interacting in a marketplace.\\nThe approach also connects to the tradition of experimental asset markets. For instance,\\nWeitzel et al. (2020) show that even finance professionals are susceptible to speculative\\n6\\nbubbles, especially amid high capital inflows. Kop\\u00b4 anyi-Peuker and Weber (2021) find that\\ntrading experience alone does not eliminate bubbles, challenging assumptions about rational\\nmarket learning. Kirchler, Huber, and St\\u00a8 ockl (2012) identify confusion about fundamental\\nvalues as a key driver of bubble formation. This framework offers a new way to study these\\nphenomena with LLM traders, which can be rigorously parameterized for sophistication,\\nstrategy, and information processing. Hence, this paper provides a method to investigate\\nhow automated or \\u201dartificial\\u201d agents might affect market stability or volatility.\\nOther recent work highlights the versatility of LLM agents in complex, interactive sce-\\nnarios beyond finance. One stream focuses on simulating social behaviors\\u2014such as opinion\\ndynamics (Chuang et al. 2023), trust (Xie et al. 2024), and resource-sharing (Piatti et al.\\n2024). Another examines LLMs\\u2019 strategic capabilities through task-based simulations and\\ncollaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\\nWithin the computer science literature, early works apply LLMs to financial markets but\\nabstract away many fundamental stock market characteristics. Often, they employ single-\\nprice clearing mechanisms without a persistent order book, ignore partial fills and bid-ask\", \"2407.18957. arXiv: 2407.18957 [q-fin]. http://arxiv.org/abs/2407.18957.\\n41\\nA Technical Implementation Details\\nA.1 Agent Type Specifications\\nThis section details the base system prompts for each agent type in our simulation. These\\nprompts define the core behavioral characteristics and trading strategies for each agent. Each\\nprompt consists of:\\n\\u2022 A role definition that establishes the agent\\u2019s trading philosophy\\n\\u2022 A structured trading strategy that guides decision-making\\n\\u2022 Specific instructions for when to use market orders vs limit orders\\nAt runtime, these base prompts are combined with:\\n\\u2022 Current market state (price, volume, order book depth)\\n\\u2022 Position information (current holdings and available cash)\\n\\u2022 Trading options and required response format\\nThe standard runtime template includes:\\nPosition Information Template\\nYour Position:\\n- Available Shares: {shares} shares (Short selling is not allowed)\\n- Main Cash Account: ${cash:.2f}\\n- Dividend Cash Account (not available for trading): ${dividend_cash:.2f}\\n- Total Available Cash: ${total_available_cash:.2f} (Borrowing is not allowed)\\n- Shares in Orders: {committed_shares} shares\\n- Cash in Orders: ${committed_cash:.2f}\\n42\\nTrading Options Template\\nYour analysis should include:\\n- valuation_reasoning: Your numerical analysis of the asset\\u2019s fundamental value\\n- valuation: Your estimate of the asset\\u2019s current fundamental value\\n- price_target_reasoning: Your numerical analysis of the asset\\u2019s price target\\n- price_target: Your predicted price for the next round\\n- reasoning: Your explanation for the trading decision\\nTrading Options:\\n1. New Orders (replace_decision=\\u2019Add\\u2019):\\n- Single or multiple orders allowed\\n- For each order:\\n- Market order: Set order_type=\\u2019market\\u2019\\n- Limit order: Set order_type=\\u2019limit\\u2019 and specify price_limit\\n- IMPORTANT: Sell orders require sufficient available shares\\n- Short selling is NOT allowed\\n2. Cancel Orders (replace_decision=\\u2019Cancel\\u2019):\\n- Return an empty orders list: orders=[]\\nYour decision must include:\\n- orders: list of orders (empty list for Hold/Cancel)\\n- For Buy/Sell orders, each must contain:\\n- decision: \\\"Buy\\\" or \\\"Sell\\\"\\n- quantity: number of shares\\n- order_type: \\\"market\\\" or \\\"limit\\\"\\n- price_limit: required for limit orders\\n- reasoning: brief explanation\\n- replace_decision: \\\"Add\\\", \\\"Cancel\\\", or \\\"Replace\\\"\\n43\\nBase System Prompts The following are the base system prompts for each LLM-based\\nagent type:\\nA.1.1 Value-Based Agents\\nValue Investor\\nYou are a value investor who focuses on fundamental analysis.\\nYou believe in mean reversion and try to buy undervalued assets and sell overvalued ones.\\nA.1.2 Trend-Following Agents\\nMomentum Trader\\nYou are a momentum trader who focuses on price trends and volume.\\nYou believe that \\u2019the trend is your friend\\u2019 and try to identify and follow market momentum.\\nA.1.3 Liquidity Providers Agents\\nMarket Maker\\nYou are a professional market maker who provides liquidity to the market.\\nYour profit comes from capturing the spread between bid and ask prices, not from directional price movement.\\nIMPORTANT: There is NO SHORT SELLING allowed. You can only sell shares you already own.\\nTrading Guidelines:\\n- Place LIMIT buy orders slightly below the current market price (1-3% lower)\\n- Place LIMIT sell orders slightly above the current market price (1-3% higher)\\n- Your spread should be proportional to volatility but typically 2-6% of price\\n- NEVER place sell orders more than 10% above your buy orders\\n- Adjust your spread width based on recent price volatility\\n44\\nInventory Management (No Short Selling):\\n- Monitor your current inventory in the market data\\n- Only place sell orders for quantities you actually own\\n- If you have no inventory, focus on buy orders first\\n- As you acquire inventory, gradually place sell orders\\n- If inventory grows too large, reduce or pause buy orders\\n- Adjust your buy/sell ratio based on current inventory level\\nExample: If price = $100, you might place buy orders at $97-99 and sell orders at $101-103,\", \"33\\nants, allowing researchers to study how different belief structures influence price formation\\nand trading patterns under different initial mispricings. In these scenarios, the fundamental\\nprice is hidden from agents, forcing them to rely on their own valuation models.\\n3.2.5 Market Stress\\nThis scenario tests market resilience under challenging conditions by creating a more volatile\\nenvironment. The scenario includes two consistently bullish Optimistic traders, two consis-\\ntently bearish Pessimistic traders, two Market makers (liquidity providers), and two Value\\ninvestors (rational benchmark traders). The scenario runs for 100 rounds to study long-term\\nmarket behavior and includes unequal initial endowments, with optimistic traders having\\nmore cash (1.5x baseline) but fewer shares (0.5x baseline) and pessimistic traders having less\\ncash (0.5x baseline) but more shares (1.5x baseline). This resource imbalance tests whether\\nparticular agent types can dominate market outcomes through resource advantages.\\nThe scenarios presented here demonstrate the framework\\u2019s capabilities for exploring di-\\nverse market conditions. Its modular structure facilitates the straightforward definition and\\nimplementation of alternative experimental designs, enabling researchers to tailor simulations\\nto specific research questions.\\nIn all scenarios, we maintain consistent baseline parameters with a fundamental value\\nof $28.00, calculated from the expected dividend of $1.40 and interest rate of 5%. Agent\\nendowments start at 1,000,000 monetary units and 10,000 shares unless specifically modified.\\nTransaction costs are set to zero to isolate the effects of agent behavior and market structure\\non price formation.\\n4 Conclusion\\nThis paper demonstrates that Large Language Models can effectively function as diverse\\ntrading agents\\u2014from value investors to market makers\\u2014maintaining strategic consistency\\n34\\nwhile adapting to market conditions. Our experimental framework reveals that their in-\\nteractions generate realistic market dynamics, including phenomena like price bubbles and\\ncorrections, highlighting both the capabilities and potential risks of deploying LLM agents\\nin financial markets.\\nThese findings carry significant implications for market structure and regulation. While\\nLLM agents can enhance price discovery and liquidity, their adherence to programmed strate-\\ngies, even potentially flawed ones derived from prompts, could amplify market volatility or\\nintroduce novel systemic risks, as observed in our simulated bubble scenarios. A key concern\\nis the potential for widespread correlated behavior: similar underlying LLM architectures\\nresponding uniformly to comparable prompts or market signals could inadvertently create\\ndestabilizing trading patterns without explicit coordination. This underscores the critical\\nneed for rigorous testing and validation of LLM-based trading systems prior to live deploy-\\nment.\\nA central contribution of this work is the open-source simulation framework itself, de-\\nsigned to catalyze research into LLM trading agents. We invite the research community to\\nutilize and extend this platform to investigate pressing questions in this rapidly evolving\\narea. The framework enables systematic exploration of complex scenarios\\u2014such as hybrid\\nhuman-LLM markets, stress tests, varying market structures, regulatory impacts, and the\\nnuances of LLM prompting\\u2014often difficult or costly to study otherwise. Specific avenues\\nripe for investigation using this tool include the emergence of novel trading strategies, the\\nprecise effects of agent heterogeneity on market stability, and the development of robust\\nvalidation protocols for AI traders. As artificial intelligence becomes more integrated into\\nfinance, collaborative research leveraging adaptable simulation environments like this one\\nwill be crucial for understanding and responsibly shaping the future of trading.\\n35\\nReferences\", \"44\\nInventory Management (No Short Selling):\\n- Monitor your current inventory in the market data\\n- Only place sell orders for quantities you actually own\\n- If you have no inventory, focus on buy orders first\\n- As you acquire inventory, gradually place sell orders\\n- If inventory grows too large, reduce or pause buy orders\\n- Adjust your buy/sell ratio based on current inventory level\\nExample: If price = $100, you might place buy orders at $97-99 and sell orders at $101-103,\\nbut limit your sell quantity to what you currently own.\\nRemember that extreme spreads (e.g., buying at $3 and selling at $30) will not execute and will lead to losses.\\nA.1.4 Contrarian Agents\\nContrarian Trader\\nYou are a contrarian trader who looks for excessive market moves to trade against.\\nYou believe markets often overreact and try to profit from reversals.\\nA.1.5 Sentiment-Based Agents\\nOptimistic\\nYou are an optimistic trader who firmly believes assets are significantly undervalued.\\nYour Core Beliefs:\\n- The probability of maximum dividends is much higher than stated (80-90% chance)\\nPessimistic\\nYou are a pessimistic trader who firmly believes assets are significantly overvalued.\\n45\\nYour Core Beliefs:\\n- The probability of minimum dividends is much higher than stated (80-90% chance)\\nA.1.6 Miscellaneous Agents\\nSpeculator\\nYou are a speculator who tries to profit from market inefficiencies.\\nRetail Trader\\nYou are a retail trader.\\nLLM Hold Trader\\nYou are a holding agent that never trades.\\nA.1.7 Deterministic Agents\\nThe framework also includes several deterministic rule-based agents that serve as benchmarks\\nand controls. These agents follow fixed algorithmic rules rather than LLM-based decision-\\nmaking. They include directional traders (always buy, always sell), technical traders (mean\\nreversion, momentum), and algorithmic market makers with pre-defined spread-posting\\nstrategies.\\n46\", \"Main Cash Account: $988500.00\\nDividend Cash Account (not available for trading): $296920.65\\nTotal Available Cash: $988500.00 (Borrowing is not allowed)\\nShares in Orders: 0 shares\\nCash in Orders: $11500.00\\nPosition information establishes resource constraints and current market exposure, enabling\\nthe agent to make contextually appropriate decisions while maintaining awareness of out-\\nstanding commitments.\\n2.2.11 Historical Context\\nPrice History (last 5 rounds):\\nRound 3: $29.00 (Volume: 100)\\nRound 2: $29.00 (Volume: 100)\\n19\\nRound 1: $28.00 (Volume: 100)\\nRound 0: $56.00 (Volume: 0)\\nHistorical price and volume data enables pattern recognition and trend analysis, which is\\nespecially important for agents identifying market inefficiencies and developing trends.\\n2.2.12 Asset Fundamentals\\nDividend Information:\\nLast Paid Dividend: $2.40\\nExpected Dividend: $1.40\\nBase Dividend: $1.40\\nVariation Amount: $1.00\\nMaximum Scenario: $2.40 with 50% probability\\nMinimum Scenario: $0.40 with 50% probability\\nPayment Schedule:\\nNext Payment in: 1 rounds\\nPayment Destination: dividend account (non-tradeable)\\nRedemption Information:\\nThis market has an infinite time horizon. Shares will not be redeemed.\\nInterest Rate Information:\\nBase Rate: 5.0\\\\%\\nCompound Frequency: 1 times per round\\nPayment Destination: dividend account (separate from trading)\\nFundamental value determinants allow the agent to perform intrinsic valuation, assess risk-\\nreward scenarios, and identify mispricing. The probabilistic dividend structure introduces\\nuncertainty agents that must be incorporated into their decision models. In this example,\\nthe fundamental value is unobservable.\\n20\\n2.2.13 Decision Requirements\\nYour analysis should include:\\nvaluation_reasoning: Your numerical analysis of the asset\\u2019s fundamental value\\nvaluation: Your estimate of the asset\\u2019s current fundamental value\\nprice_target_reasoning: Your numerical analysis of the asset\\u2019s price target\\nprice_target: Your predicted price for the next round\\nreasoning: Your explanation for the trading decision\\nThe decision schema enforces consistent output structure and explicit reasoning, enabling\\nsystematic analysis of agent decision processes and reliable parsing of machine-actionable\\ncomponents.\\n2.2.14 Trading Options\\nTrading Options:\\nNew Orders (replace_decision=\\u2019Add\\u2019):\\nSingle or multiple orders allowed\\nFor each order:\\nMarket order: Set order_type=\\u2019market\\u2019\\nLimit order: Set order_type=\\u2019limit\\u2019 and specify price_limit\\nIMPORTANT: Sell orders require sufficient available shares\\nShort selling is NOT allowed\\nCancel Orders (replace_decision=\\u2019Cancel\\u2019):\\nReturn an empty orders list: orders=[]\\nThe trading options subsection establishes the action space and constraints, ensuring agents\\nunderstand available choices and limitations while providing precise formatting requirements\\nfor machine-readable decisions.\\nThe response from the LLM agent is depicted in Figure 1.\\n21\\n2.2.15 Systematic Decision Analysis\\nFinally, the framework enables systematic analysis of LLM decision processes through con-\\ntrolled parameter variation, similar to partial dependence plots in machine learning inter-\\npretability. This approach allows researchers to understand how specific market variables\\ninfluence LLM trading decisions while holding other factors constant.\\nOur example implementation varies the price-to-fundamental ratio ( \\u03c1 = P/V ) across a\\nrange from 0.1 to 3.5 while maintaining all other market parameters constant. For each ratio\\nvalue, the system:\\n1. Sets market price P = \\u03c1V where \\u03c1 is the target ratio\\n2. Generates a consistent order book structure around this price\\n3. Executes multiple decision trials with the same agent type\\n4. Records decision outcomes (buy/sell/hold), order types, quantities, and reasoning\\nThis process maps how LLM agents respond to different price environments, as illustrated\\nin Figures 2, 3, 4, and 5. The analysis reveals clear patterns in decision boundaries, with\", \"bids/asks), and two Speculator agents (opportunistic traders seeking inefficiencies). Market\\n31\\nmakers are given enhanced liquidity with 20x the baseline cash and shares to ensure suffi-\\ncient liquidity provision and facilitate price discovery. The scenario tests whether prices can\\ncorrect downward through trading activity when starting from an overvalued state.\\n3.2.2 Price Discovery (Below Fundamental)\\nThis complementary scenario tests upward price convergence by starting with an initial price\\n25% below the fundamental value ( $21.00). It employs the identical agent composition and\\nparameters as the above-fundamental scenario, allowing for direct comparison of market\\nbehavior under opposite initial mispricing conditions. This design enables researchers to\\nassess potential asymmetries in price discovery processes.\\n3.2.3 Infinite Horizon Price Discovery\\nWe extend both price discovery scenarios to infinite horizon settings, where shares are not\\nredeemed at a terminal date. The initial prices are set at double ($56.00) and half ($14.00) the\\nfundamental value for the above and below fundamental scenarios respectively, creating more\\nextreme mispricing conditions. These scenarios run for 15 trading rounds and test whether\\nagents correctly value assets based on expected dividend streams rather than redemption\\nvalues. Each infinite horizon scenario involves two Default investors, two Optimistic traders,\\ntwo Market makers, and two Speculator agents.\\nThe results from these infinite horizon scenarios reveal interesting asymmetries in price\\ndiscovery, as illustrated in Figure 6 and Figure 7. When the market starts significantly above\\nthe fundamental value (left panels), the price fails to converge downwards towards the$28.00\\nbenchmark within the 15 rounds, remaining substantially elevated. Agent valuations mirror\\nthis persistence, with many agents maintaining estimates well above the fundamental value.\\nHowever, when the market begins significantly below the fundamental value (right panels),\\nthe price exhibits a clear convergence towards the fundamental benchmark. Agent valuations\\nin this scenario also tend to adjust upwards, aligning more closely with the calculated fun-\\n32\\ndamental value over time. This suggests that under these conditions, LLM agents are more\\neffective at correcting undervaluation than overvaluation within the simulated timeframe.\\nFigure 6: Price Evolution: Infinite Horizon Scenarios. Left: Initial price $56.00 (Above\\nFundamental). Right: Initial price $14.00 (Below Fundamental). The dashed line indicates\\nthe fundamental value ($28.00).\\nFigure 7: Agent Valuations: Infinite Horizon Scenarios. Left: Initial price $56.00 (Above\\nFundamental). Right: Initial price $14.00 (Below Fundamental). Shows individual agent\\nestimates of fundamental value over time.\\n3.2.4 Divergent Beliefs\\nThis scenario explores the impact of heterogeneous beliefs about fundamental value by com-\\nbining agents with systematically different valuation models. The agent composition is\\ndesigned to create heterogeneity: two Optimistic traders (believing the fundamental value is\\nsignificantly higher), two Pessimistic traders (believing it is significantly lower), two neutral\\nMarket makers, two Momentum traders (following price trends rather than fundamentals),\\nand two Default investors (baseline agents). We test both above-fundamental (initial price\\n$56.00, 2x fundamental) and below-fundamental (initial price$14.00, 0.5x fundamental) vari-\\n33\\nants, allowing researchers to study how different belief structures influence price formation\\nand trading patterns under different initial mispricings. In these scenarios, the fundamental\\nprice is hidden from agents, forcing them to rely on their own valuation models.\\n3.2.5 Market Stress\\nThis scenario tests market resilience under challenging conditions by creating a more volatile\\nenvironment. The scenario includes two consistently bullish Optimistic traders, two consis-\", \"market efficiency and price discovery processes throughout the simulation.\\nAgent performance metrics include absolute position tracking (shares, cash, and total\\nwealth), wealth composition analysis, position change metrics, and return calculations. The\\nsystem computes both absolute and percentage returns on various portfolio components\\nand compares performance across agent types to identify relative advantages of different\\nstrategies. Trading flow analysis visualizes the volume of shares moving between different\\nagent types and cumulative net trading flows, revealing which agents act as net buyers or\\nsellers in different market conditions.\\nDecision pattern analysis employs heatmaps to visualize the consistency of agent decision-\\nmaking over time, allowing researchers to identify shifts in strategic behavior. This is com-\\nplemented by decision quantities visualization that plots order sizes to highlight variations\\nin trade aggressiveness across agent types. When agent reasoning data is available, the\\nsystem generates wordclouds to extract key terms from agent explanations, providing qual-\\nitative insights into decision drivers for different agent strategies. Additional visualizations\\ntrack price target accuracy and compare agent-specific valuations to realized market prices,\\n28\\noffering insights into the forecasting abilities of different agents.\\nA key advantage of simulation-based analysis is complete observability of all market\\nprocesses and agent states. Unlike real-world markets where data availability is often limited,\\nthe framework captures every interaction, decision, and state change with perfect fidelity.\\nThis comprehensive data collection allows researchers to compute additional metrics beyond\\nstandard market measures, enabling novel analyses such as counterfactual testing (e.g., how\\nwould markets evolve with different agent compositions), causal inference of specific agent\\nbehaviors on market outcomes, and the development of custom efficiency or stability metrics\\ntailored to particular research questions. The system\\u2019s modular design facilitates rapid\\nimplementation of new metrics and visualizations as research questions evolve.\\n3 Experimental Design and Results\\nOur experimental framework implements a dividend-paying asset market with heterogeneous\\nagents. The baseline simulation runs for 15 to 20 rounds with 8 participating agents, although\\nthese parameters are fully configurable. Each agent begins with an initial endowment of\\n1,000,000 monetary units and 10,000 shares of the asset. The fundamental value of the asset\\nis set at $28.00, with a final redemption value matching this fundamental price in finite\\nhorizon scenarios. Transaction costs are set to zero to isolate the effects of agent behavior\\nand market structure.\\nThe dividend structure follows a stochastic process with a base payment of $1.40 and a\\nvariation of \\u00b1$1.00, paid with 50% probability each round. This design creates uncertainty\\nin the asset\\u2019s income stream while maintaining a known expected value. Cash holdings earn\\na risk-free interest rate of 5% per round, providing an opportunity cost for asset investment.\\nAgent composition is controlled through a flexible distribution system that allows for\\nvarious experimental configurations. In our baseline setup, we employ a mixed population\\nof value investors, momentum traders, and market makers. Each agent type implements\\n29\\ndistinct trading strategies through Large Language Model (LLM) prompts, with GPT-4o as\\nthe decision-making engine.\\nThe data collection system captures comprehensive market activity across multiple di-\\nmensions. At the market level, it tracks the evolution of prices, fundamental values, and\\nrealized dividends, providing insights into overall market dynamics. Individual agent data\\nincludes detailed wealth trajectories and portfolio compositions, enabling analysis of strategy\\neffectiveness and wealth distribution patterns. The system maintains complete transaction\", \"standardized, human-readable, machine-readable agent decisions. This technique allows\\nLLMs to generate outputs in a specific format that can be directly validated and processed\\nby the trading system, bridging the gap between natural language reasoning and executable\\ntrading actions.\\nThe system uses Pydantic for validation and parsing of agent outputs, with a schema-\\nbased approach that defines the required structure:\\nclass TradeDecisionSchema(BaseModel):\\nSchema for trade decisions\\nvaluation_reasoning: str = Field(...,\\ndescription=\\\"Brief explanation of valuation analysis\\\")\\nvaluation: float = Field(...,\\ndescription=\\\"Agent\\u2019s estimated fundamental value\\\")\\nprice_target: float = Field(...,\\ndescription=\\\"Agent\\u2019s predicted price in near future\\\")\\norders: List[OrderSchema] = Field(...,\\ndescription=\\\"List of orders to execute\\\")\\n16\\nreplace_decision: str = Field(...,\\ndescription=\\\"Add, Cancel, or Replace\\\")\\nreasoning: str = Field(...,\\ndescription=\\\"Explanation for the trading decisions\\\")\\nEach order within the decision follows a nested schema:\\nclass OrderSchema(BaseModel):\\nSchema for individual orders\\ndecision: Literal[\\\"Buy\\\", \\\"Sell\\\"] = Field(...,\\ndescription=\\\"Buy, Sell\\\")\\nquantity: int = Field(...,\\ndescription=\\\"Number of shares\\\")\\norder_type: str = Field(...,\\ndescription=\\\"market or limit\\\")\\nprice_limit: Optional[float] = Field(None,\\ndescription=\\\"Required for limit orders\\\")\\nThis structured approach enables several critical features: (1) automatic validation of all\\ndecision components, (2) consistent parsing of agent outputs, (3) clear documentation of the\\nexpected response format, and (4) standardized error handling for malformed responses. The\\nfunction calling methodology ensures that LLMs can focus on trading strategy. At the same\\ntime, the system handles the technical validation of their decisions, significantly improving\\nreliability compared to free-form text parsing.\\n2.2.7 Complete Example\\nThe following example illustrates the complete prompt for a speculator agent, with annota-\\ntions explaining the purpose of each information component.\\nYou are a speculator who tries to profit from market inefficiencies.\\n17\\nThe system prompt establishes the agent\\u2019s core identity and strategic objective concisely,\\ncreating a consistent behavioral foundation. Then, the user prompt provides the immediate\\nmarket context necessary for tactical decision-making.\\n2.2.8 Market State Information\\nMarket State:\\nLast Price: $29.00\\nRound Number: 4/Infinite\\nBest Public Estimate of Risk-Neutral Fundamental Value: Unavailable\\nLast Trading Volume: 500.00\\nPrice/Fundamental Ratio: Unavailable\\nThis subsection provides essential market pricing data to establish current conditions. The\\nspeculator intentionally receives no fundamental value estimate to simulate information\\nasymmetry and encourage independent analysis.\\n2.2.9 Market Depth\\nMarket Depth:\\nBest Bid: $28.00\\nBest Ask: $29.00\\nSell Orders:\\n2000 shares @ $57.00\\n3800 shares @ $50.40\\n2000 shares @ $30.00\\n1000 shares @ $29.50\\n4400 shares @ $29.00\\nBuy Orders:\\n1900 shares @ $28.00\\n18\\n1500 shares @ $27.50\\n2500 shares @ $27.00\\nOrder book information lets the agent assess market liquidity, identify potential trading\\nopportunities, and determine optimal order placement strategies. The visible imbalance\\nbetween the bid and ask sides provides critical information about supply and demand dy-\\nnamics.\\n2.2.10 Agent Position\\nYour Outstanding Orders:\\nBuy Orders:\\n400 shares @ $28.00\\nYour Position:\\nAvailable Shares: 10000 shares (Short selling is not allowed)\\nMain Cash Account: $988500.00\\nDividend Cash Account (not available for trading): $296920.65\\nTotal Available Cash: $988500.00 (Borrowing is not allowed)\\nShares in Orders: 0 shares\\nCash in Orders: $11500.00\\nPosition information establishes resource constraints and current market exposure, enabling\\nthe agent to make contextually appropriate decisions while maintaining awareness of out-\\nstanding commitments.\\n2.2.11 Historical Context\\nPrice History (last 5 rounds):\"]}": {"cached_metrics_data": [{"metric_data": {"name": "Contextual Precision (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Faithfulness (ragas)", "threshold": 0.8, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.8, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Contextual Recall (ragas)", "threshold": 0.6, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.6, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Answer Relevancy (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}]}, "{\"actual_output\": \"Figure 7 shows that the AI agents were better at correcting under-valuations than over-valuations. When the simulated market started low, the agents' valuations gradually increased over time, moving closer to the true fundamental value. However, when the market started high, the agents' valuations remained high and didn't adjust downwards towards the true value within the timeframe of the simulation.\\n\", \"context\": [\"When the market starts significantly above the fundamental value \\u2026 the price fails to converge downwards \\u2026 remaining substantially elevated. Agent valuations mirror this persistence, with many agents maintaining estimates well above the fundamental value.\"], \"expected_output\": \"With an initial price 25 % above fundamentals, prices failed to converge downward within 15 rounds and agents kept over\\u2011valuing the asset.\", \"hyperparameters\": null, \"input\": \"In simple terms, what does Figure 7 (agent valuations over time) tell us about over\\u2011 vs under\\u2011valuation corrections?\", \"retrieval_context\": [\"(2023)). This work, however, focuses on financial markets and how LLM agents can operate\\nas full-fledged trading participants.\\nRecent research examines specific applications of LLMs for trading. FinMem and Trad-\\ningGPT introduce frameworks with layered memory systems and customizable agent traits\\n5\\nto improve financial decision-making (Yu, Li, et al. 2024; Li, Zhang, and Sun 2023). Hierar-\\nchical multi-agent architectures have been explored in FinCon, which uses a manager-analyst\\nsetup for collaborative portfolio decisions (Yu, Yao, et al. 2024). QuantAgent implements\\na self-improving signal-mining approach (Wang et al. 2024), while other work underscores\\nthe importance of long-term memory in LLM agents via vector databases (Hatalis et al.\\n2024). This line of research builds on successful reinforcement learning applications such as\\nAlphaPortfolio (Cong et al. 2021) and AlphaManager (Campello, Cong, and Zhou 2023),\\nwhich leverage deep RL and robust control for portfolio management.\\nAnalyzing LLM agent behavior by changing only some parameters draws on methods\\nfrom the interpretable machine learning literature. In particular, the systematic variation\\nof market parameters to reveal decision patterns mirrors partial dependence plots and in-\\ndividual conditional expectation curves used to interpret complex machine learning models\\n(Molnar 2022). These techniques help reveal how LLM agents respond to changes in specific\\nvariables while holding others constant, providing insight into their internal decision-making\\nprocesses that would otherwise remain opaque.\\nBeyond finance, studies of LLM capabilities in interactive or multi-agent settings offer\\nvaluable insights. Benchmarks like AgentBench evaluate LLMs\\u2019 performance in interac-\\ntive tasks (Liu et al. 2023), while InvestorBench focuses on financial decision-making tasks\\nspecifically (H. Li et al. 2024). NegotiationArena demonstrates LLMs\\u2019 capacity for strategic\\ninteraction in bargaining contexts (Bianchi et al. 2024). Similarly, Guo et al. (2024) provide\\nan economics \\u201darena\\u201d where LLMs compete in strategic games, revealing that advanced\\nmodels like GPT-4 can exhibit rational, adaptive behavior\\u2014albeit not always reaching Nash\\nEquilibrium. Existing frameworks typically assess individual agents or hierarchical collab-\\norations, whereas this work studies emergent market behaviors that arise from multiple\\nindependent LLM traders interacting in a marketplace.\\nThe approach also connects to the tradition of experimental asset markets. For instance,\\nWeitzel et al. (2020) show that even finance professionals are susceptible to speculative\\n6\\nbubbles, especially amid high capital inflows. Kop\\u00b4 anyi-Peuker and Weber (2021) find that\\ntrading experience alone does not eliminate bubbles, challenging assumptions about rational\\nmarket learning. Kirchler, Huber, and St\\u00a8 ockl (2012) identify confusion about fundamental\\nvalues as a key driver of bubble formation. This framework offers a new way to study these\\nphenomena with LLM traders, which can be rigorously parameterized for sophistication,\\nstrategy, and information processing. Hence, this paper provides a method to investigate\\nhow automated or \\u201dartificial\\u201d agents might affect market stability or volatility.\\nOther recent work highlights the versatility of LLM agents in complex, interactive sce-\\nnarios beyond finance. One stream focuses on simulating social behaviors\\u2014such as opinion\\ndynamics (Chuang et al. 2023), trust (Xie et al. 2024), and resource-sharing (Piatti et al.\\n2024). Another examines LLMs\\u2019 strategic capabilities through task-based simulations and\\ncollaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\\nWithin the computer science literature, early works apply LLMs to financial markets but\\nabstract away many fundamental stock market characteristics. Often, they employ single-\\nprice clearing mechanisms without a persistent order book, ignore partial fills and bid-ask\", \"33\\nants, allowing researchers to study how different belief structures influence price formation\\nand trading patterns under different initial mispricings. In these scenarios, the fundamental\\nprice is hidden from agents, forcing them to rely on their own valuation models.\\n3.2.5 Market Stress\\nThis scenario tests market resilience under challenging conditions by creating a more volatile\\nenvironment. The scenario includes two consistently bullish Optimistic traders, two consis-\\ntently bearish Pessimistic traders, two Market makers (liquidity providers), and two Value\\ninvestors (rational benchmark traders). The scenario runs for 100 rounds to study long-term\\nmarket behavior and includes unequal initial endowments, with optimistic traders having\\nmore cash (1.5x baseline) but fewer shares (0.5x baseline) and pessimistic traders having less\\ncash (0.5x baseline) but more shares (1.5x baseline). This resource imbalance tests whether\\nparticular agent types can dominate market outcomes through resource advantages.\\nThe scenarios presented here demonstrate the framework\\u2019s capabilities for exploring di-\\nverse market conditions. Its modular structure facilitates the straightforward definition and\\nimplementation of alternative experimental designs, enabling researchers to tailor simulations\\nto specific research questions.\\nIn all scenarios, we maintain consistent baseline parameters with a fundamental value\\nof $28.00, calculated from the expected dividend of $1.40 and interest rate of 5%. Agent\\nendowments start at 1,000,000 monetary units and 10,000 shares unless specifically modified.\\nTransaction costs are set to zero to isolate the effects of agent behavior and market structure\\non price formation.\\n4 Conclusion\\nThis paper demonstrates that Large Language Models can effectively function as diverse\\ntrading agents\\u2014from value investors to market makers\\u2014maintaining strategic consistency\\n34\\nwhile adapting to market conditions. Our experimental framework reveals that their in-\\nteractions generate realistic market dynamics, including phenomena like price bubbles and\\ncorrections, highlighting both the capabilities and potential risks of deploying LLM agents\\nin financial markets.\\nThese findings carry significant implications for market structure and regulation. While\\nLLM agents can enhance price discovery and liquidity, their adherence to programmed strate-\\ngies, even potentially flawed ones derived from prompts, could amplify market volatility or\\nintroduce novel systemic risks, as observed in our simulated bubble scenarios. A key concern\\nis the potential for widespread correlated behavior: similar underlying LLM architectures\\nresponding uniformly to comparable prompts or market signals could inadvertently create\\ndestabilizing trading patterns without explicit coordination. This underscores the critical\\nneed for rigorous testing and validation of LLM-based trading systems prior to live deploy-\\nment.\\nA central contribution of this work is the open-source simulation framework itself, de-\\nsigned to catalyze research into LLM trading agents. We invite the research community to\\nutilize and extend this platform to investigate pressing questions in this rapidly evolving\\narea. The framework enables systematic exploration of complex scenarios\\u2014such as hybrid\\nhuman-LLM markets, stress tests, varying market structures, regulatory impacts, and the\\nnuances of LLM prompting\\u2014often difficult or costly to study otherwise. Specific avenues\\nripe for investigation using this tool include the emergence of novel trading strategies, the\\nprecise effects of agent heterogeneity on market stability, and the development of robust\\nvalidation protocols for AI traders. As artificial intelligence becomes more integrated into\\nfinance, collaborative research leveraging adaptable simulation environments like this one\\nwill be crucial for understanding and responsibly shaping the future of trading.\\n35\\nReferences\", \"bids/asks), and two Speculator agents (opportunistic traders seeking inefficiencies). Market\\n31\\nmakers are given enhanced liquidity with 20x the baseline cash and shares to ensure suffi-\\ncient liquidity provision and facilitate price discovery. The scenario tests whether prices can\\ncorrect downward through trading activity when starting from an overvalued state.\\n3.2.2 Price Discovery (Below Fundamental)\\nThis complementary scenario tests upward price convergence by starting with an initial price\\n25% below the fundamental value ( $21.00). It employs the identical agent composition and\\nparameters as the above-fundamental scenario, allowing for direct comparison of market\\nbehavior under opposite initial mispricing conditions. This design enables researchers to\\nassess potential asymmetries in price discovery processes.\\n3.2.3 Infinite Horizon Price Discovery\\nWe extend both price discovery scenarios to infinite horizon settings, where shares are not\\nredeemed at a terminal date. The initial prices are set at double ($56.00) and half ($14.00) the\\nfundamental value for the above and below fundamental scenarios respectively, creating more\\nextreme mispricing conditions. These scenarios run for 15 trading rounds and test whether\\nagents correctly value assets based on expected dividend streams rather than redemption\\nvalues. Each infinite horizon scenario involves two Default investors, two Optimistic traders,\\ntwo Market makers, and two Speculator agents.\\nThe results from these infinite horizon scenarios reveal interesting asymmetries in price\\ndiscovery, as illustrated in Figure 6 and Figure 7. When the market starts significantly above\\nthe fundamental value (left panels), the price fails to converge downwards towards the$28.00\\nbenchmark within the 15 rounds, remaining substantially elevated. Agent valuations mirror\\nthis persistence, with many agents maintaining estimates well above the fundamental value.\\nHowever, when the market begins significantly below the fundamental value (right panels),\\nthe price exhibits a clear convergence towards the fundamental benchmark. Agent valuations\\nin this scenario also tend to adjust upwards, aligning more closely with the calculated fun-\\n32\\ndamental value over time. This suggests that under these conditions, LLM agents are more\\neffective at correcting undervaluation than overvaluation within the simulated timeframe.\\nFigure 6: Price Evolution: Infinite Horizon Scenarios. Left: Initial price $56.00 (Above\\nFundamental). Right: Initial price $14.00 (Below Fundamental). The dashed line indicates\\nthe fundamental value ($28.00).\\nFigure 7: Agent Valuations: Infinite Horizon Scenarios. Left: Initial price $56.00 (Above\\nFundamental). Right: Initial price $14.00 (Below Fundamental). Shows individual agent\\nestimates of fundamental value over time.\\n3.2.4 Divergent Beliefs\\nThis scenario explores the impact of heterogeneous beliefs about fundamental value by com-\\nbining agents with systematically different valuation models. The agent composition is\\ndesigned to create heterogeneity: two Optimistic traders (believing the fundamental value is\\nsignificantly higher), two Pessimistic traders (believing it is significantly lower), two neutral\\nMarket makers, two Momentum traders (following price trends rather than fundamentals),\\nand two Default investors (baseline agents). We test both above-fundamental (initial price\\n$56.00, 2x fundamental) and below-fundamental (initial price$14.00, 0.5x fundamental) vari-\\n33\\nants, allowing researchers to study how different belief structures influence price formation\\nand trading patterns under different initial mispricings. In these scenarios, the fundamental\\nprice is hidden from agents, forcing them to rely on their own valuation models.\\n3.2.5 Market Stress\\nThis scenario tests market resilience under challenging conditions by creating a more volatile\\nenvironment. The scenario includes two consistently bullish Optimistic traders, two consis-\", \"by detailed Trade Data, which records individual transaction details such as prices, quan-\\ntities, buyer and seller identifiers, timestamps, round information, and specific execution\\ndetails.\\nAgent Data provides insights into participant behavior by monitoring cash and share\\n25\\nFigure 5: Order Type Analysis under Systematic Variation. Displays the proportion of\\nMarket vs. Limit orders used by different agent types across varying Price/Fundamental\\nratios.\\n26\\npositions, portfolio values, wealth evolution, and agent type and strategy identifiers. Or-\\nder Data captures the complete lifecycle of trading decisions, including order specifications\\n(type, size, price), agent reasoning and justification, decision context and timing, and order\\nlifecycle events. Finally, Market State data maintains a comprehensive view of overall mar-\\nket conditions through order book snapshots, market depth information, aggregate statistics,\\nand various market microstructure metrics.\\n2.3.3 Data Validation and Storage\\nThe system implements a comprehensive set of data quality measures to ensure reliability and\\nconsistency. The validation framework performs continuous checks for data completeness,\\nverifies consistency across related data streams, enforces format and type validation, and\\nmaintains proper temporal sequencing of all recorded events. These validation mechanisms\\nwork together to maintain data integrity throughout the experimental process.\\nThe storage architecture employs multiple formats optimized for different data types and\\nuse cases. Structured CSV files store tabular data for efficient analysis, while JSON formats\\naccommodate complex nested structures that preserve the rich relationships between market\\nelements. The system maintains detailed timestamped logs for debugging purposes and\\ngenerates summary statistics to facilitate quick analysis of experimental outcomes.\\nThis comprehensive data collection architecture enables researchers to conduct detailed\\nanalysis of market dynamics, validate agent behavior patterns, ensure experiment repro-\\nducibility, and perform meaningful cross-experiment comparisons. The integrated approach\\nto data management provides the foundation for rigorous empirical investigation of market\\nbehavior and agent interactions.\\nThe framework implements specialized visualization techniques to analyze agent behavior\\nand market dynamics. Decision heatmaps plot agent actions across trading rounds, reveal-\\ning strategic patterns and consistency. Trading flow visualizations track cumulative position\\nchanges, identifying net buyers and sellers throughout market evolution. Reasoning word-\\n27\\nclouds extract key terms from agent explanations, providing insight into decision drivers\\nacross different agent types.\\nThe system also generates specialized market quality visualizations including bid-ask\\nspread evolution, price target accuracy, and agent valuation tracking. These visualizations\\nwork in concert with the numerical metrics to provide both quantitative and qualitative\\ninsights into agent behavior and market dynamics.\\n2.3.4 Validation Metrics and Performance Monitoring\\nThe framework implements a comprehensive set of performance metrics and visualization\\ntools that monitor agent behavior and market dynamics. Market evolution visualizations\\ntrack price movements relative to fundamental values, including time series of transaction\\nprices, midpoint prices, and bid-ask spreads. These visualizations enable researchers to assess\\nmarket efficiency and price discovery processes throughout the simulation.\\nAgent performance metrics include absolute position tracking (shares, cash, and total\\nwealth), wealth composition analysis, position change metrics, and return calculations. The\\nsystem computes both absolute and percentage returns on various portfolio components\\nand compares performance across agent types to identify relative advantages of different\", \"market efficiency and price discovery processes throughout the simulation.\\nAgent performance metrics include absolute position tracking (shares, cash, and total\\nwealth), wealth composition analysis, position change metrics, and return calculations. The\\nsystem computes both absolute and percentage returns on various portfolio components\\nand compares performance across agent types to identify relative advantages of different\\nstrategies. Trading flow analysis visualizes the volume of shares moving between different\\nagent types and cumulative net trading flows, revealing which agents act as net buyers or\\nsellers in different market conditions.\\nDecision pattern analysis employs heatmaps to visualize the consistency of agent decision-\\nmaking over time, allowing researchers to identify shifts in strategic behavior. This is com-\\nplemented by decision quantities visualization that plots order sizes to highlight variations\\nin trade aggressiveness across agent types. When agent reasoning data is available, the\\nsystem generates wordclouds to extract key terms from agent explanations, providing qual-\\nitative insights into decision drivers for different agent strategies. Additional visualizations\\ntrack price target accuracy and compare agent-specific valuations to realized market prices,\\n28\\noffering insights into the forecasting abilities of different agents.\\nA key advantage of simulation-based analysis is complete observability of all market\\nprocesses and agent states. Unlike real-world markets where data availability is often limited,\\nthe framework captures every interaction, decision, and state change with perfect fidelity.\\nThis comprehensive data collection allows researchers to compute additional metrics beyond\\nstandard market measures, enabling novel analyses such as counterfactual testing (e.g., how\\nwould markets evolve with different agent compositions), causal inference of specific agent\\nbehaviors on market outcomes, and the development of custom efficiency or stability metrics\\ntailored to particular research questions. The system\\u2019s modular design facilitates rapid\\nimplementation of new metrics and visualizations as research questions evolve.\\n3 Experimental Design and Results\\nOur experimental framework implements a dividend-paying asset market with heterogeneous\\nagents. The baseline simulation runs for 15 to 20 rounds with 8 participating agents, although\\nthese parameters are fully configurable. Each agent begins with an initial endowment of\\n1,000,000 monetary units and 10,000 shares of the asset. The fundamental value of the asset\\nis set at $28.00, with a final redemption value matching this fundamental price in finite\\nhorizon scenarios. Transaction costs are set to zero to isolate the effects of agent behavior\\nand market structure.\\nThe dividend structure follows a stochastic process with a base payment of $1.40 and a\\nvariation of \\u00b1$1.00, paid with 50% probability each round. This design creates uncertainty\\nin the asset\\u2019s income stream while maintaining a known expected value. Cash holdings earn\\na risk-free interest rate of 5% per round, providing an opportunity cost for asset investment.\\nAgent composition is controlled through a flexible distribution system that allows for\\nvarious experimental configurations. In our baseline setup, we employ a mixed population\\nof value investors, momentum traders, and market makers. Each agent type implements\\n29\\ndistinct trading strategies through Large Language Model (LLM) prompts, with GPT-4o as\\nthe decision-making engine.\\nThe data collection system captures comprehensive market activity across multiple di-\\nmensions. At the market level, it tracks the evolution of prices, fundamental values, and\\nrealized dividends, providing insights into overall market dynamics. Individual agent data\\nincludes detailed wealth trajectories and portfolio compositions, enabling analysis of strategy\\neffectiveness and wealth distribution patterns. The system maintains complete transaction\", \"the decision-making engine.\\nThe data collection system captures comprehensive market activity across multiple di-\\nmensions. At the market level, it tracks the evolution of prices, fundamental values, and\\nrealized dividends, providing insights into overall market dynamics. Individual agent data\\nincludes detailed wealth trajectories and portfolio compositions, enabling analysis of strategy\\neffectiveness and wealth distribution patterns. The system maintains complete transaction\\nrecords with prices, quantities, and counterparty information, facilitating the study of trad-\\ning patterns and market microstructure. Additionally, it captures agent decision rationales\\nand strategy adherence metrics, allowing researchers to evaluate the consistency and effec-\\ntiveness of different trading approaches.\\nAll experimental parameters, market outcomes, and agent interactions are systemati-\\ncally logged and stored in structured formats (CSV and JSON) for subsequent analysis. The\\nframework generates standardized visualizations of price evolution, wealth distribution, and\\ndividend payments to facilitate comparative analysis across different experimental configu-\\nrations.\\n3.1 Fundamental Value Calibration\\nThe framework implements a consistent approach to fundamental value calculation that pro-\\nvides a reliable benchmark for price discovery. For infinite horizon markets, the fundamental\\nvalue follows the standard dividend discount model:\\nVt = E[D]\\nr = Expected Dividend\\nInterest Rate (1)\\nFor the default parameters where the expected dividend is $1.40 and the interest rate is\\n5%, this yields a fundamental value of $28.00.\\nIn finite horizon markets with T periods remaining, the fundamental value incorporates\\n30\\nboth future dividends and terminal redemption value K:\\nFVt =\\nTX\\n\\u03c4=t\\nE[D]\\n(1 + r)\\u03c4\\u2212t+1 + K\\n(1 + r)T\\u2212t+1 (2)\\nTo ensure consistency between finite and infinite horizon markets, the redemption value\\nK is set equal to E[D]\\nr , which makes the fundamental value constant atE[D]\\nr across all periods,\\nregardless of the time horizon. This calibration approach ensures a clean experimental design\\nby providing a stable benchmark for price discovery.\\n3.2 Experimental Scenarios\\nTo evaluate market dynamics with LLM-based agents, we implemented several experimental\\nscenarios that systematically explore different initial conditions and agent compositions.\\nEach scenario maintains the fundamental value of $28.00 while varying starting prices, time\\nhorizons, and agent populations. These scenarios address our core research questions (Section\\n1) by testing LLM capabilities under varying market conditions, focusing on price discovery\\ndynamics, the impact of heterogeneous beliefs, and market stability under stress; GPT-4o\\nwas used consistently as the decision-making engine for all LLM agents across these scenarios.\\nWe present the setup for several key scenarios below, followed by a discussion of the observed\\nresults for the 2 experiments involving an infinite horizon market with a starting price either\\nabove or below the fundamental value.\\n3.2.1 Price Discovery (Above Fundamental)\\nThis scenario tests downward price convergence by starting with an initial price 25% above\\nthe fundamental value ( $35.00). It runs for 20 trading rounds and features a diverse\\nagent population, including two Default investors (baseline agents), two Optimistic traders\\n(who believe prices should be higher), two Market makers (providing liquidity by posting\\nbids/asks), and two Speculator agents (opportunistic traders seeking inefficiencies). Market\\n31\\nmakers are given enhanced liquidity with 20x the baseline cash and shares to ensure suffi-\\ncient liquidity provision and facilitate price discovery. The scenario tests whether prices can\\ncorrect downward through trading activity when starting from an overvalued state.\\n3.2.2 Price Discovery (Below Fundamental)\\nThis complementary scenario tests upward price convergence by starting with an initial price\", \"the second agents\\u2019 design, and the third the analysis module.\\n8\\n2.1 Market Design\\nOur methodological framework integrates three components that create a controlled envi-\\nronment for LLM-based trading agents. The framework implements a flexible continuous\\ndouble-auction market mechanism that couples standard market microstructure principles\\nwith market clearing and matching algorithms to accommodate asynchronous LLM decisions.\\nThe market clearing process employs a dual-stage matching algorithm. In the first stage,\\nlimit orders are posted. In the second stage, market orders are netted using a market-\\nto-market matching engine that processes buy and sell orders, reconciling orders based on\\navailable agent cash and share commitments. In the third stage, any remaining market\\norders are matched against the existing order book, with unfilled quantities converted to\\naggressive limit orders. This three-tiered approach optimizes immediate execution and price\\ndiscovery while maintaining market liquidity.\\nThe system\\u2019s OrderMatchingService orchestrates this process by coordinating trade ex-\\necutions through the TradeExecutionService and managing order state transitions via the\\nOrderStateManager. Each trade is logged in detail, with the overall market state\\u2014including\\norder books, market depth, and price evolution\\u2014recalculated at the end of each trading\\nround.\\nThis modular design in the matching and clearing engine provides several advantages.\\nFirst, it enables rigorous trade validation where each market order is validated against agent\\ncash commitments and position constraints before matching, with the system dynamically\\nadjusting order quantities based on available cash when an agent\\u2019s commitment is insuf-\\nficient, thus minimizing execution errors. Second, it offers flexible liquidity handling by\\nsupporting market-to-market and market-to-book matching, ensuring orders have multiple\\nexecution pathways, with unexecuted market orders converted to aggressive limit orders to\\ncapture remaining liquidity. Third, it maintains detailed trade audit capabilities by recording\\ncomprehensive traceability data including timestamps, trade volumes, executed prices, and\\nagent identifiers, thereby enabling post-trade analysis and performance benchmarking that\\n9\\nserves as the foundation for subsequent market efficiency and agent performance validations.\\n2.1.1 Market Mechanism Design\\nOur framework implements a continuous double-auction market mechanism that processes\\norders in discrete trading rounds. We use discrete trading rounds because LLMs have latency\\nconstraints, making it infeasible to process orders in real time. Within each round, the order\\nof agent submissions is randomized to avoid giving systematic priority to specific agents,\\nthus simulating concurrent order arrival while maintaining fairness. Once randomized, or-\\nders are then processed according to standard price-time priority rules. The system supports\\nfinite and infinite horizon markets, with differences in terminal conditions and wealth cal-\\nculation. In finite-horizon markets, agents are informed of the total number of rounds, and\\ntheir terminal wealth is calculated by redeeming all shares at the fundamental value of the\\nfinal round. In infinite-horizon markets, no terminal information is provided to agents, and\\nfinal wealth is determined using the last market price for share valuation. This design choice\\nenables researchers to study how time horizons influence trading strategies and price for-\\nmation, particularly how agents balance short-term trading opportunities against long-term\\nvalue considerations.\\nIn a double auction, buyers and sellers actively submit orders, with trades occurring when\\ncompatible buy and sell orders match the price. The matching engine processes these orders\\nthrough three sequential phases:\\nFirst, incoming limit orders that do not immediately cross the market are added to\\nthe order book, maintaining strict price-time priority. Second, market orders are processed\", \"value, the system:\\n1. Sets market price P = \\u03c1V where \\u03c1 is the target ratio\\n2. Generates a consistent order book structure around this price\\n3. Executes multiple decision trials with the same agent type\\n4. Records decision outcomes (buy/sell/hold), order types, quantities, and reasoning\\nThis process maps how LLM agents respond to different price environments, as illustrated\\nin Figures 2, 3, 4, and 5. The analysis reveals clear patterns in decision boundaries, with\\ndistinct transitions between buying, selling, and holding regions that vary by agent type. For\\nexample, value investors show strong buying tendencies when prices are below fundamental\\nvalue (\\u03c1 <1) and selling preferences when prices exceed fundamentals ( \\u03c1 >1). In contrast,\\nmomentum traders show less sensitivity to the fundamental ratio and more responsiveness\\nto recent price trends.\\nThe systematic variation approach also reveals patterns in order sizing and limit price\\nselection, with agents typically placing larger orders when prices deviate significantly from\\ntheir valuation models (Figure 4). This methodology provides unprecedented transparency\\ninto LLM decision processes and enables quantitative comparison of different agent types\\nand LLM architectures.\\n22\\nFigure 2: Price Analysis under Systematic Variation. Shows how agent valuation estimates\\nand price targets respond to varying Price/Fundamental ratios.\\nThe decision analysis can be customized for different experimental designs. For example,\\nresearchers can use the framework to study the impact of various market conditions on agent\\nbehavior by varying other market parameters or the effect of different agent types on market\\ndynamics by changing the agent population.\\n2.3 Data Collection and Analysis\\nEvaluating LLM trading agents requires robust methodologies for capturing, processing,\\nand analyzing their behavior in market environments. The framework implements a com-\\nprehensive analytics module that tracks all market activity, agent decisions, and performance\\nmetrics throughout experimental runs. This multi-layered approach not only records what\\nhappens in each simulation but also provides insights into why agents make specific deci-\\nsions, enabling researchers to validate agent behavior against their defined strategies and\\nassess overall market dynamics. The following sections detail the key components of this\\nanalytics infrastructure.\\n23\\nFigure 3: Trading Decision Distribution under Systematic Variation. Illustrates the proba-\\nbility of Buy, Sell, or Hold decisions across different agent types as the Price/Fundamental\\nratio changes.\\n24\\nFigure 4: Order Size Distribution under Systematic Variation. Shows the average quan-\\ntity traded (as a percentage of initial shares) for Buy and Sell orders across different\\nPrice/Fundamental ratios.\\n2.3.1 Data Collection Architecture\\nThe framework implements a comprehensive data collection system that captures multiple\\ndimensions of market behavior and agent decision-making. This structured approach ensures\\nreproducibility and enables detailed analysis of market dynamics.\\n2.3.2 Core Data Streams\\nThe system captures five primary data streams that work together to provide a complete\\npicture of market activity. Market Data forms the foundation, tracking essential metrics\\nincluding price evolution, fundamental values, trading volumes, order book depth, market\\nliquidity, best bid/ask prices, spreads, and price-fundamental ratios. This is complemented\\nby detailed Trade Data, which records individual transaction details such as prices, quan-\\ntities, buyer and seller identifiers, timestamps, round information, and specific execution\\ndetails.\\nAgent Data provides insights into participant behavior by monitoring cash and share\\n25\\nFigure 5: Order Type Analysis under Systematic Variation. Displays the proportion of\\nMarket vs. Limit orders used by different agent types across varying Price/Fundamental\\nratios.\\n26\"]}": {"cached_metrics_data": [{"metric_data": {"name": "Contextual Precision (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Faithfulness (ragas)", "threshold": 0.8, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.8, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Contextual Recall (ragas)", "threshold": 0.6, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.6, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Answer Relevancy (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}]}, "{\"actual_output\": \"In the infinite horizon scenario where the simulated market began 25% above the fundamental value (overvalued at $56.00 compared to the true value of $28.00), the price failed to converge downwards towards the fundamental value within the 15 trading rounds. The LLM (Large Language Model)-driven agents' valuations also remained significantly elevated above the fundamental value, mirroring the overall market's persistent overvaluation. This suggests that, under these specific conditions, the AI agents were less effective at correcting overvaluation compared to undervaluation within the given timeframe.\", \"context\": [\"When the market starts significantly above the fundamental value \\u2026 the price fails to converge downwards \\u2026 remaining substantially elevated. Agent valuations mirror this persistence, with many agents maintaining estimates well above the fundamental value.\"], \"expected_output\": \"With an initial price 25 % above fundamentals, prices failed to converge downward within 15 rounds and agents kept over\\u2011valuing the asset.\", \"hyperparameters\": null, \"input\": \"What is the main experimental finding when the simulated market starts 25 % above the fundamental value?\", \"retrieval_context\": [\"33\\nants, allowing researchers to study how different belief structures influence price formation\\nand trading patterns under different initial mispricings. In these scenarios, the fundamental\\nprice is hidden from agents, forcing them to rely on their own valuation models.\\n3.2.5 Market Stress\\nThis scenario tests market resilience under challenging conditions by creating a more volatile\\nenvironment. The scenario includes two consistently bullish Optimistic traders, two consis-\\ntently bearish Pessimistic traders, two Market makers (liquidity providers), and two Value\\ninvestors (rational benchmark traders). The scenario runs for 100 rounds to study long-term\\nmarket behavior and includes unequal initial endowments, with optimistic traders having\\nmore cash (1.5x baseline) but fewer shares (0.5x baseline) and pessimistic traders having less\\ncash (0.5x baseline) but more shares (1.5x baseline). This resource imbalance tests whether\\nparticular agent types can dominate market outcomes through resource advantages.\\nThe scenarios presented here demonstrate the framework\\u2019s capabilities for exploring di-\\nverse market conditions. Its modular structure facilitates the straightforward definition and\\nimplementation of alternative experimental designs, enabling researchers to tailor simulations\\nto specific research questions.\\nIn all scenarios, we maintain consistent baseline parameters with a fundamental value\\nof $28.00, calculated from the expected dividend of $1.40 and interest rate of 5%. Agent\\nendowments start at 1,000,000 monetary units and 10,000 shares unless specifically modified.\\nTransaction costs are set to zero to isolate the effects of agent behavior and market structure\\non price formation.\\n4 Conclusion\\nThis paper demonstrates that Large Language Models can effectively function as diverse\\ntrading agents\\u2014from value investors to market makers\\u2014maintaining strategic consistency\\n34\\nwhile adapting to market conditions. Our experimental framework reveals that their in-\\nteractions generate realistic market dynamics, including phenomena like price bubbles and\\ncorrections, highlighting both the capabilities and potential risks of deploying LLM agents\\nin financial markets.\\nThese findings carry significant implications for market structure and regulation. While\\nLLM agents can enhance price discovery and liquidity, their adherence to programmed strate-\\ngies, even potentially flawed ones derived from prompts, could amplify market volatility or\\nintroduce novel systemic risks, as observed in our simulated bubble scenarios. A key concern\\nis the potential for widespread correlated behavior: similar underlying LLM architectures\\nresponding uniformly to comparable prompts or market signals could inadvertently create\\ndestabilizing trading patterns without explicit coordination. This underscores the critical\\nneed for rigorous testing and validation of LLM-based trading systems prior to live deploy-\\nment.\\nA central contribution of this work is the open-source simulation framework itself, de-\\nsigned to catalyze research into LLM trading agents. We invite the research community to\\nutilize and extend this platform to investigate pressing questions in this rapidly evolving\\narea. The framework enables systematic exploration of complex scenarios\\u2014such as hybrid\\nhuman-LLM markets, stress tests, varying market structures, regulatory impacts, and the\\nnuances of LLM prompting\\u2014often difficult or costly to study otherwise. Specific avenues\\nripe for investigation using this tool include the emergence of novel trading strategies, the\\nprecise effects of agent heterogeneity on market stability, and the development of robust\\nvalidation protocols for AI traders. As artificial intelligence becomes more integrated into\\nfinance, collaborative research leveraging adaptable simulation environments like this one\\nwill be crucial for understanding and responsibly shaping the future of trading.\\n35\\nReferences\", \"allocations are brie\\ufb02y addressed in Chapter 15 and analyzed more fully in Chapter 16. If a set of existing\\nsecurities and markets leads to an equilibrium that is an unconstrained Pareto optimum, then any additional\\nsecurities or markets will be redundant.\\n50The term \\u201ctransactions costs\\u201d can, of course, mean more than just the bid-ask spread or commissions\\npaid for buying and selling assets. For example, if an investor literally traded his portfolio continuously, he\\nwould have no time to do anything else! Because investment management and \\ufb01nancial intermediation involve\\nprimarily information processing and security trading, there arc signi\\ufb01cant economies of scale. One would thus\\nexpect substantially lower costs for the individual investor to use intermediaries instead of transacting directly\\nin the asset markets.\\n368 Financial Intermediation in the Continuous-Time Model\\nIt would seem therefore that the same dichotomy derived in the frictionless-market\\ncase applies also to our model with transactions costs. In a formal computational\\nsense it does. We can still solve for the equilibrium asset-price dynamics in the model\\nof Chapter 15 and then compute the prices of derivative securities, mutual funds, and\\ncorporate liabilities using CCA. There is one signi\\ufb01cant difference, however: the\\n\\ufb01rst-part calculation of equilibrium real-sector allocations is valid if and only if there\\nexists a suf\\ufb01ciently rich set of securities and intermediaries in the \\ufb01nancial sector to\\nmake these allocations feasible for agents who cannot trade without cost. Because\\nof this conditioning. perhaps a more appropriate term for this separation is \\u201cquasi-\\ndichotomy.\\u201d\\nWith the assumption that not all agents can trade continuously without cost, a\\nsigni\\ufb01cant economic role is established for derivative-security markets and \\ufb01nancial\\nintermediaries in the model. Somewhat paradoxically, we \\ufb01nd that, if intermediation\\nis ef\\ufb01cient, then derivative securities and the \\ufb01nancial products of the intermediaries\\nwill be priced as if they are redundant.51Under these conditions, quasi-dichotomy\\nobtains, and we can derive equilibrium real-sector allocations and asset prices from\\nthe frictionless-market version of the model.\\n14.6 Afterword: Policy and Strategy in Financial Intermediation\\nIn this chapter, as throughout the book, the focus has been on theory. Allusions to\\npractice were concentrated on the micro quantitative applications of the continuous-\\ntime model to product technologies and risk management. Still, I cannot wholly\\nresist the temptation to call attention to the model\\u2019s potential for addressing broader\\nissues in the practice of intermediation. And so this afterword shall ever so brie\\ufb02y\\ntouch upon implications of the model for intermediation policy and strategy in the\\nhope that it will lead others, better quali\\ufb01ed, to explore this matter elsewhere.\\nDerivative securities have long been an integral part of the \\ufb01nancial markets,52\\nbut most would mark the creation of the Chicago Board Options Exchange in April\\n1973 as the start of the current wave of \\ufb01nancial innovations involving derivative\\nsecurities. The succeeding years have witnessed an unprecedented proliferation of\\norganized trading markets in both equity and \\ufb01xed-income derivative instruments.\\nIn turn, these markets made possible the creation of a wide range of \\ufb01nancial prod-\\n51Thus, our model provides a resolution to Hakansson\\u2019s (1979, p. 722) \\u201cThe Catch 22 of Option Pricing.\\u201d\\nAlthough the equilibrium prices of options and other derivative securities satisfy the redundancy condition of\\nCCA, they are nevertheless needed to support the equilibrium allocations, and hence their elimination would\\nreduce social welfare.\\n52Bernstein (1992) reports that Aristotle\\u2019s anecdote about Thales in Book I of Politics is the \\ufb01rst recorded\\nmention of a \\ufb01nancial option. Schaede (1988) makes the case that the Dojima rice market in Osaka was a\", \"bids/asks), and two Speculator agents (opportunistic traders seeking inefficiencies). Market\\n31\\nmakers are given enhanced liquidity with 20x the baseline cash and shares to ensure suffi-\\ncient liquidity provision and facilitate price discovery. The scenario tests whether prices can\\ncorrect downward through trading activity when starting from an overvalued state.\\n3.2.2 Price Discovery (Below Fundamental)\\nThis complementary scenario tests upward price convergence by starting with an initial price\\n25% below the fundamental value ( $21.00). It employs the identical agent composition and\\nparameters as the above-fundamental scenario, allowing for direct comparison of market\\nbehavior under opposite initial mispricing conditions. This design enables researchers to\\nassess potential asymmetries in price discovery processes.\\n3.2.3 Infinite Horizon Price Discovery\\nWe extend both price discovery scenarios to infinite horizon settings, where shares are not\\nredeemed at a terminal date. The initial prices are set at double ($56.00) and half ($14.00) the\\nfundamental value for the above and below fundamental scenarios respectively, creating more\\nextreme mispricing conditions. These scenarios run for 15 trading rounds and test whether\\nagents correctly value assets based on expected dividend streams rather than redemption\\nvalues. Each infinite horizon scenario involves two Default investors, two Optimistic traders,\\ntwo Market makers, and two Speculator agents.\\nThe results from these infinite horizon scenarios reveal interesting asymmetries in price\\ndiscovery, as illustrated in Figure 6 and Figure 7. When the market starts significantly above\\nthe fundamental value (left panels), the price fails to converge downwards towards the$28.00\\nbenchmark within the 15 rounds, remaining substantially elevated. Agent valuations mirror\\nthis persistence, with many agents maintaining estimates well above the fundamental value.\\nHowever, when the market begins significantly below the fundamental value (right panels),\\nthe price exhibits a clear convergence towards the fundamental benchmark. Agent valuations\\nin this scenario also tend to adjust upwards, aligning more closely with the calculated fun-\\n32\\ndamental value over time. This suggests that under these conditions, LLM agents are more\\neffective at correcting undervaluation than overvaluation within the simulated timeframe.\\nFigure 6: Price Evolution: Infinite Horizon Scenarios. Left: Initial price $56.00 (Above\\nFundamental). Right: Initial price $14.00 (Below Fundamental). The dashed line indicates\\nthe fundamental value ($28.00).\\nFigure 7: Agent Valuations: Infinite Horizon Scenarios. Left: Initial price $56.00 (Above\\nFundamental). Right: Initial price $14.00 (Below Fundamental). Shows individual agent\\nestimates of fundamental value over time.\\n3.2.4 Divergent Beliefs\\nThis scenario explores the impact of heterogeneous beliefs about fundamental value by com-\\nbining agents with systematically different valuation models. The agent composition is\\ndesigned to create heterogeneity: two Optimistic traders (believing the fundamental value is\\nsignificantly higher), two Pessimistic traders (believing it is significantly lower), two neutral\\nMarket makers, two Momentum traders (following price trends rather than fundamentals),\\nand two Default investors (baseline agents). We test both above-fundamental (initial price\\n$56.00, 2x fundamental) and below-fundamental (initial price$14.00, 0.5x fundamental) vari-\\n33\\nants, allowing researchers to study how different belief structures influence price formation\\nand trading patterns under different initial mispricings. In these scenarios, the fundamental\\nprice is hidden from agents, forcing them to rely on their own valuation models.\\n3.2.5 Market Stress\\nThis scenario tests market resilience under challenging conditions by creating a more volatile\\nenvironment. The scenario includes two consistently bullish Optimistic traders, two consis-\", \"investors\\u2019 optimal demand functions will depend upon how frequently they can revise\\ntheir portfolios. Therefore, it should be pointed out that nowhere in the analysis\\npresented here is it assumed that the distribution of X(T)\\u2212X(0)is invariant to h.\\nDe\\ufb01ne the conditional expectation operator Etto be the expectation operator con-\\nditional on knowing all relevant information revealed as of time tor before. De\\ufb01ne\\nthe random variables \\u01eb(k)by\\n\\u01eb(k)\\u2261X(k)\\u2212X(k\\u22121)\\u2212Ek\\u22121{\\nX(k)\\u2212X(k\\u22121)}\\nk= 1,. .. , n (3.2)\\nwhere \\u201ctime k\\u201d is used as shorthand for \\u201ctime kh.\\u201d By construction, Ek\\u22121{\\u01eb(k)}= 0,\\nand\\u01eb(k)is the unanticipated price change in the security between k\\u22121andk, condi-\\n5See Merton (1975b).\\n3.1 Introduction 49\\ntional on being at time k\\u22121. Moreover, by the properties of conditional expectation,\\nit follows that Ek\\u2212j{\\u01eb(k)}= 0forj= 1,. . ., k . Hence the partial sums Sn\\u2261\\u2211n\\n1\\u01eb(k)\\nform a martingale .6As will be seen, the mathematical analysis to follow depends\\nheavily on the properties of martingales. The theory of martingales is usually associ-\\nated in the \\ufb01nancial economics literature with the \\u201cEf\\ufb01cient-Market Hypothesis\\u201d of\\nFama and Samuelson.7Therefore, the reader may be tempted to connect the martin-\\ngale property of the unanticipated returns derived here with an implicit assumption\\nthat \\u201csecurities are priced correctly.\\u201d However, the martingale property of the unan-\\nticipated returns here is purely a result of construction, and therefore imposes no such\\neconomics assumption. However, two economics assumptions that will be imposed\\nare as follows.\\nAssumption 5.\\nFor each \\ufb01nite time interval [0,T]there exists a number A1>0, independent of the\\nnumber of trading intervals n, such that Var(Sn)\\u2265A1where Var(Sn)\\u2261E0{[\\u2211n\\n1\\u01eb(k)]2}\\n.\\nAssumption 6.\\nFor each \\ufb01nite time interval [0,T], there exists a number A2<\\u221e, independent of n,\\nsuch that Var(Sn)\\u2264A2.\\nAssumption 1 ensures that the uncertainty associated with the unanticipated price\\nchanges is not \\u201cwashed out\\u201d or eliminated even in the limit of continuous trading.\\nThat is, even as h\\u2192dt, the \\u201cend-of-period\\u201d price at time kwill be uncertain relative\\nto time k\\u22121. This assumption is essential for the continuous-trading model to capture\\nthis fundamental property of stock-price behavior.\\nAssumption 2 ensures that the uncertainty associated with the unanticipated price\\nchanges over a \\ufb01nite period of time is not so great that the variance becomes un-\\nbounded. It rules out the possibility that the very act of allowing more frequent trad-\\ning will induce suf\\ufb01cient price instability to cause the limiting variance of X(T)\\u2212\\nX(0)to become unbounded, and it also rules out the Pareto-Levy stable distributions\\nwith in\\ufb01nite variances.\\nDe\\ufb01ne V(k)\\u2261E0{\\u01eb2(k)},k= 1,2,. . ., n , to be the variance of the dollar return on\\nthe security between time k\\u22121andkbased upon information available as of time\\nzero, and de\\ufb01ne V\\u2261maxkV(k).\\nAssumption 7.\\nThere exists a number A3,1\\u2265A3>0, independent of n, such that for k= 1,. .. , n ,\\nV(k)/V\\u2265A3.\\n6For a formal de\\ufb01nition of the martingale and discussions of its properties, see Feller (1966, pp. 210-15\\nand 234-8). Important mathematical analyzes of martingales in continuous-time processes are by Dellacherie\\nand Meyer (1982) and Kunita and Watanabe (1967).\\n7See Fama (1965a, 1970a, 1991), Samuelson (1965b, 1973), and also Cootner (1964). The theory of\\nmartingales provides a powerful technique for the analysis of equilibrium security prices in continuous-time\\nmodels. See Harrison and Kreps (1979), Kreps (1981), Harrison and Pliska (1981, 1983), Duf\\ufb01e and Huang\\n(1985, 1986), Duf\\ufb01e (1986, 1988), Huang (1985a, b, 1987), Pliska (1986), and Cox and Huang (1989a, b.\\n1991).\\n50 On the Mathematics and Economics Assumptions of Continuous-Time Models\\nAssumption 3 is closely related to Assumption 1 and in effect rules out the possi-\\nbility that all the uncertainty in the unanticipated price changes over [0,T]is concen-\\ntrated in a few of the many trading periods. In other words, there is signi\\ufb01cant price\", \"market efficiency and price discovery processes throughout the simulation.\\nAgent performance metrics include absolute position tracking (shares, cash, and total\\nwealth), wealth composition analysis, position change metrics, and return calculations. The\\nsystem computes both absolute and percentage returns on various portfolio components\\nand compares performance across agent types to identify relative advantages of different\\nstrategies. Trading flow analysis visualizes the volume of shares moving between different\\nagent types and cumulative net trading flows, revealing which agents act as net buyers or\\nsellers in different market conditions.\\nDecision pattern analysis employs heatmaps to visualize the consistency of agent decision-\\nmaking over time, allowing researchers to identify shifts in strategic behavior. This is com-\\nplemented by decision quantities visualization that plots order sizes to highlight variations\\nin trade aggressiveness across agent types. When agent reasoning data is available, the\\nsystem generates wordclouds to extract key terms from agent explanations, providing qual-\\nitative insights into decision drivers for different agent strategies. Additional visualizations\\ntrack price target accuracy and compare agent-specific valuations to realized market prices,\\n28\\noffering insights into the forecasting abilities of different agents.\\nA key advantage of simulation-based analysis is complete observability of all market\\nprocesses and agent states. Unlike real-world markets where data availability is often limited,\\nthe framework captures every interaction, decision, and state change with perfect fidelity.\\nThis comprehensive data collection allows researchers to compute additional metrics beyond\\nstandard market measures, enabling novel analyses such as counterfactual testing (e.g., how\\nwould markets evolve with different agent compositions), causal inference of specific agent\\nbehaviors on market outcomes, and the development of custom efficiency or stability metrics\\ntailored to particular research questions. The system\\u2019s modular design facilitates rapid\\nimplementation of new metrics and visualizations as research questions evolve.\\n3 Experimental Design and Results\\nOur experimental framework implements a dividend-paying asset market with heterogeneous\\nagents. The baseline simulation runs for 15 to 20 rounds with 8 participating agents, although\\nthese parameters are fully configurable. Each agent begins with an initial endowment of\\n1,000,000 monetary units and 10,000 shares of the asset. The fundamental value of the asset\\nis set at $28.00, with a final redemption value matching this fundamental price in finite\\nhorizon scenarios. Transaction costs are set to zero to isolate the effects of agent behavior\\nand market structure.\\nThe dividend structure follows a stochastic process with a base payment of $1.40 and a\\nvariation of \\u00b1$1.00, paid with 50% probability each round. This design creates uncertainty\\nin the asset\\u2019s income stream while maintaining a known expected value. Cash holdings earn\\na risk-free interest rate of 5% per round, providing an opportunity cost for asset investment.\\nAgent composition is controlled through a flexible distribution system that allows for\\nvarious experimental configurations. In our baseline setup, we employ a mixed population\\nof value investors, momentum traders, and market makers. Each agent type implements\\n29\\ndistinct trading strategies through Large Language Model (LLM) prompts, with GPT-4o as\\nthe decision-making engine.\\nThe data collection system captures comprehensive market activity across multiple di-\\nmensions. At the market level, it tracks the evolution of prices, fundamental values, and\\nrealized dividends, providing insights into overall market dynamics. Individual agent data\\nincludes detailed wealth trajectories and portfolio compositions, enabling analysis of strategy\\neffectiveness and wealth distribution patterns. The system maintains complete transaction\", \"the decision-making engine.\\nThe data collection system captures comprehensive market activity across multiple di-\\nmensions. At the market level, it tracks the evolution of prices, fundamental values, and\\nrealized dividends, providing insights into overall market dynamics. Individual agent data\\nincludes detailed wealth trajectories and portfolio compositions, enabling analysis of strategy\\neffectiveness and wealth distribution patterns. The system maintains complete transaction\\nrecords with prices, quantities, and counterparty information, facilitating the study of trad-\\ning patterns and market microstructure. Additionally, it captures agent decision rationales\\nand strategy adherence metrics, allowing researchers to evaluate the consistency and effec-\\ntiveness of different trading approaches.\\nAll experimental parameters, market outcomes, and agent interactions are systemati-\\ncally logged and stored in structured formats (CSV and JSON) for subsequent analysis. The\\nframework generates standardized visualizations of price evolution, wealth distribution, and\\ndividend payments to facilitate comparative analysis across different experimental configu-\\nrations.\\n3.1 Fundamental Value Calibration\\nThe framework implements a consistent approach to fundamental value calculation that pro-\\nvides a reliable benchmark for price discovery. For infinite horizon markets, the fundamental\\nvalue follows the standard dividend discount model:\\nVt = E[D]\\nr = Expected Dividend\\nInterest Rate (1)\\nFor the default parameters where the expected dividend is $1.40 and the interest rate is\\n5%, this yields a fundamental value of $28.00.\\nIn finite horizon markets with T periods remaining, the fundamental value incorporates\\n30\\nboth future dividends and terminal redemption value K:\\nFVt =\\nTX\\n\\u03c4=t\\nE[D]\\n(1 + r)\\u03c4\\u2212t+1 + K\\n(1 + r)T\\u2212t+1 (2)\\nTo ensure consistency between finite and infinite horizon markets, the redemption value\\nK is set equal to E[D]\\nr , which makes the fundamental value constant atE[D]\\nr across all periods,\\nregardless of the time horizon. This calibration approach ensures a clean experimental design\\nby providing a stable benchmark for price discovery.\\n3.2 Experimental Scenarios\\nTo evaluate market dynamics with LLM-based agents, we implemented several experimental\\nscenarios that systematically explore different initial conditions and agent compositions.\\nEach scenario maintains the fundamental value of $28.00 while varying starting prices, time\\nhorizons, and agent populations. These scenarios address our core research questions (Section\\n1) by testing LLM capabilities under varying market conditions, focusing on price discovery\\ndynamics, the impact of heterogeneous beliefs, and market stability under stress; GPT-4o\\nwas used consistently as the decision-making engine for all LLM agents across these scenarios.\\nWe present the setup for several key scenarios below, followed by a discussion of the observed\\nresults for the 2 experiments involving an infinite horizon market with a starting price either\\nabove or below the fundamental value.\\n3.2.1 Price Discovery (Above Fundamental)\\nThis scenario tests downward price convergence by starting with an initial price 25% above\\nthe fundamental value ( $35.00). It runs for 20 trading rounds and features a diverse\\nagent population, including two Default investors (baseline agents), two Optimistic traders\\n(who believe prices should be higher), two Market makers (providing liquidity by posting\\nbids/asks), and two Speculator agents (opportunistic traders seeking inefficiencies). Market\\n31\\nmakers are given enhanced liquidity with 20x the baseline cash and shares to ensure suffi-\\ncient liquidity provision and facilitate price discovery. The scenario tests whether prices can\\ncorrect downward through trading activity when starting from an overvalued state.\\n3.2.2 Price Discovery (Below Fundamental)\\nThis complementary scenario tests upward price convergence by starting with an initial price\", \"tory equilibrium theory of allocations and prices in the presence of transactions costs\\npromises still more complexity, because it requires a simultaneous endogenous de-\\ntermination of prices, allocations, and the least-cost form of market structure and\\n\\ufb01nancial intermediation.\\nTo circumvent all this complexity and also preserve a role for intermediation, I in-\\ntroduce a continuous-time model in which many investors cannot trade costlessly, but\\nthe lowest-cost transactors (by de\\ufb01nition, \\ufb01nancial intermediaries) can. In this model,\\nstandard CCA can be used to determine the production costs for \\ufb01nancial products is-\\nsued by intermediaries. However, unlike in the standard zero-cost model, these prod-\\nucts can signi\\ufb01cantly improve economic ef\\ufb01ciency. If, moreover, the traded-security\\nmarkets and \\ufb01nancial-services industry are competitive, then equilibrium prices of\\n\\ufb01nancial products will equal the production costs of the lowest-cost transactors. In\\nSection 14.5, we analyze this model and show that, through intermediation, all in-\\nvestors can achieve optimal consumption-bequest allocations as if they could trade\\ncontinuously without cost. Hence, in this model with transactions costs, both the\\ncontingent-claims analyzes of Chapters 11-13 and the equilibrium analyzes of Chap-\\nter 15 can be used to determine equilibrium allocations and prices.4Thus, this model\\nprovides a resolution of the Hakansson paradox by showing that mutual funds and\\nderivative-security markets can provide important economic bene\\ufb01ts to investors and\\ncorporate issuers, even though these securities are priced in equilibrium as if they\\nwere redundant.\\n3With diffusion processes and proportional transactions costs, investors cannot trade continuously, and\\ntherefore cannot perfectly hedge derivative-security positions. The reason is that, with continuous trading,\\ntransactions costs at each trade will be proportional to |dz|, where dzis a Brownian motion. However, for any\\nnonin\\ufb01nitesimal time interval T,\\u222bT\\n0|dz|=\\u221ealmost certainly, and hence with continuous trading the total\\ntransactions cost is unbounded with probability one.\\n4More generally, standard CCA will provide a close approximation if the \\u201cmark-up\\u201d per unit required\\nto cover the intermediary\\u2019s transactions costs and pro\\ufb01t is suf\\ufb01ciently small that, from the perspective of its\\ncustomers\\u2019 behavior, the additional cost is negligible. Of course, a tiny margin applied to large volume can\\nproduce substantial total pro\\ufb01ts for the \\ufb01nancial intermediation industry.\\n14.2 Derivative-Security Pricing with Transactions Costs 341\\n14.2 Derivative-Security Pricing with Transactions Costs\\nIn this section, we examine the effects of transactions costs on derivative security\\npricing by using the two-period version of the Cox-Ross-Rubinstein binomial option\\npricing model as analyzed in Section 10.2. In that model, the initial stock price S(0)\\nis given by S0. At time 1, the stock price will equal either S11orS12. IfS(1) = S11,\\nthen at time 2, S(2)will equal either S21orS22. IfS(1) = S12, then at time 2, S(2)\\nwill equal either S23orS24.Rdenotes the return per dollar invested in the riskless\\nsecurity and is constant over both periods. To capture the effect of transactions costs,\\nwe assume that a commission must be paid on each purchase or sale of the stock\\nand that the commission rate is a \\ufb01xed proportion \\u03c4of the dollar amount of the\\ntransaction. Equivalently, we could assume a bid-ask spread, in which investors pay\\ntheask price for the stock, Sa(t)\\u2261(1 +\\u03c4)S(t), when they buy and receive the bid\\nprice ,Sb(t)\\u2261(1\\u2212\\u03c4)S(t)when they sell. There are no costs for transacting in the\\nriskless security.\\nAs shown in (10.3), the array of possible stock prices must satisfy certain condi-\\ntions to rule out the possibility of arbitrage or dominance opportunities between the\\nstock and the riskless security. The corresponding set of restrictions, in the presence\\nof transactions costs can be written as\\nS11< S0R <(1\\u2212\\u03c4)S12\\n1 +\\u03c4(14.1a)\\nS21< S11R <(1\\u2212\\u03c4)S22\", \"value, the system:\\n1. Sets market price P = \\u03c1V where \\u03c1 is the target ratio\\n2. Generates a consistent order book structure around this price\\n3. Executes multiple decision trials with the same agent type\\n4. Records decision outcomes (buy/sell/hold), order types, quantities, and reasoning\\nThis process maps how LLM agents respond to different price environments, as illustrated\\nin Figures 2, 3, 4, and 5. The analysis reveals clear patterns in decision boundaries, with\\ndistinct transitions between buying, selling, and holding regions that vary by agent type. For\\nexample, value investors show strong buying tendencies when prices are below fundamental\\nvalue (\\u03c1 <1) and selling preferences when prices exceed fundamentals ( \\u03c1 >1). In contrast,\\nmomentum traders show less sensitivity to the fundamental ratio and more responsiveness\\nto recent price trends.\\nThe systematic variation approach also reveals patterns in order sizing and limit price\\nselection, with agents typically placing larger orders when prices deviate significantly from\\ntheir valuation models (Figure 4). This methodology provides unprecedented transparency\\ninto LLM decision processes and enables quantitative comparison of different agent types\\nand LLM architectures.\\n22\\nFigure 2: Price Analysis under Systematic Variation. Shows how agent valuation estimates\\nand price targets respond to varying Price/Fundamental ratios.\\nThe decision analysis can be customized for different experimental designs. For example,\\nresearchers can use the framework to study the impact of various market conditions on agent\\nbehavior by varying other market parameters or the effect of different agent types on market\\ndynamics by changing the agent population.\\n2.3 Data Collection and Analysis\\nEvaluating LLM trading agents requires robust methodologies for capturing, processing,\\nand analyzing their behavior in market environments. The framework implements a com-\\nprehensive analytics module that tracks all market activity, agent decisions, and performance\\nmetrics throughout experimental runs. This multi-layered approach not only records what\\nhappens in each simulation but also provides insights into why agents make specific deci-\\nsions, enabling researchers to validate agent behavior against their defined strategies and\\nassess overall market dynamics. The following sections detail the key components of this\\nanalytics infrastructure.\\n23\\nFigure 3: Trading Decision Distribution under Systematic Variation. Illustrates the proba-\\nbility of Buy, Sell, or Hold decisions across different agent types as the Price/Fundamental\\nratio changes.\\n24\\nFigure 4: Order Size Distribution under Systematic Variation. Shows the average quan-\\ntity traded (as a percentage of initial shares) for Buy and Sell orders across different\\nPrice/Fundamental ratios.\\n2.3.1 Data Collection Architecture\\nThe framework implements a comprehensive data collection system that captures multiple\\ndimensions of market behavior and agent decision-making. This structured approach ensures\\nreproducibility and enables detailed analysis of market dynamics.\\n2.3.2 Core Data Streams\\nThe system captures five primary data streams that work together to provide a complete\\npicture of market activity. Market Data forms the foundation, tracking essential metrics\\nincluding price evolution, fundamental values, trading volumes, order book depth, market\\nliquidity, best bid/ask prices, spreads, and price-fundamental ratios. This is complemented\\nby detailed Trade Data, which records individual transaction details such as prices, quan-\\ntities, buyer and seller identifiers, timestamps, round information, and specific execution\\ndetails.\\nAgent Data provides insights into participant behavior by monitoring cash and share\\n25\\nFigure 5: Order Type Analysis under Systematic Variation. Displays the proportion of\\nMarket vs. Limit orders used by different agent types across varying Price/Fundamental\\nratios.\\n26\"]}": {"cached_metrics_data": [{"metric_data": {"name": "Contextual Precision (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Faithfulness (ragas)", "threshold": 0.8, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.8, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Contextual Recall (ragas)", "threshold": 0.6, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.6, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Answer Relevancy (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}]}, "{\"actual_output\": \"LLMs (Large Language Models, AI models that can understand and generate human-like text) have latency constraints (delays in processing information). This makes real-time order processing infeasible, so the authors use discrete trading rounds instead.\", \"context\": [\"When the market starts significantly above\\nthe fundamental value (left panels), the price fails to converge downwards towards the $28.00\\nbenchmark within the 15 rounds, remaining substantially elevated. Agent valuations mirror\\nthis persistence, with many agents maintaining estimates well above the fundamental value.\\nHowever, when the market begins significantly below the fundamental value\"], \"expected_output\": \"LLMs have latency; discrete rounds let agents think while still approximating concurrency via randomised order of submission.\", \"hyperparameters\": null, \"input\": \"Why do the authors choose discrete trading rounds instead of real\\u2011time order processing for the LLM agents?\", \"retrieval_context\": [\"(2023)). This work, however, focuses on financial markets and how LLM agents can operate\\nas full-fledged trading participants.\\nRecent research examines specific applications of LLMs for trading. FinMem and Trad-\\ningGPT introduce frameworks with layered memory systems and customizable agent traits\\n5\\nto improve financial decision-making (Yu, Li, et al. 2024; Li, Zhang, and Sun 2023). Hierar-\\nchical multi-agent architectures have been explored in FinCon, which uses a manager-analyst\\nsetup for collaborative portfolio decisions (Yu, Yao, et al. 2024). QuantAgent implements\\na self-improving signal-mining approach (Wang et al. 2024), while other work underscores\\nthe importance of long-term memory in LLM agents via vector databases (Hatalis et al.\\n2024). This line of research builds on successful reinforcement learning applications such as\\nAlphaPortfolio (Cong et al. 2021) and AlphaManager (Campello, Cong, and Zhou 2023),\\nwhich leverage deep RL and robust control for portfolio management.\\nAnalyzing LLM agent behavior by changing only some parameters draws on methods\\nfrom the interpretable machine learning literature. In particular, the systematic variation\\nof market parameters to reveal decision patterns mirrors partial dependence plots and in-\\ndividual conditional expectation curves used to interpret complex machine learning models\\n(Molnar 2022). These techniques help reveal how LLM agents respond to changes in specific\\nvariables while holding others constant, providing insight into their internal decision-making\\nprocesses that would otherwise remain opaque.\\nBeyond finance, studies of LLM capabilities in interactive or multi-agent settings offer\\nvaluable insights. Benchmarks like AgentBench evaluate LLMs\\u2019 performance in interac-\\ntive tasks (Liu et al. 2023), while InvestorBench focuses on financial decision-making tasks\\nspecifically (H. Li et al. 2024). NegotiationArena demonstrates LLMs\\u2019 capacity for strategic\\ninteraction in bargaining contexts (Bianchi et al. 2024). Similarly, Guo et al. (2024) provide\\nan economics \\u201darena\\u201d where LLMs compete in strategic games, revealing that advanced\\nmodels like GPT-4 can exhibit rational, adaptive behavior\\u2014albeit not always reaching Nash\\nEquilibrium. Existing frameworks typically assess individual agents or hierarchical collab-\\norations, whereas this work studies emergent market behaviors that arise from multiple\\nindependent LLM traders interacting in a marketplace.\\nThe approach also connects to the tradition of experimental asset markets. For instance,\\nWeitzel et al. (2020) show that even finance professionals are susceptible to speculative\\n6\\nbubbles, especially amid high capital inflows. Kop\\u00b4 anyi-Peuker and Weber (2021) find that\\ntrading experience alone does not eliminate bubbles, challenging assumptions about rational\\nmarket learning. Kirchler, Huber, and St\\u00a8 ockl (2012) identify confusion about fundamental\\nvalues as a key driver of bubble formation. This framework offers a new way to study these\\nphenomena with LLM traders, which can be rigorously parameterized for sophistication,\\nstrategy, and information processing. Hence, this paper provides a method to investigate\\nhow automated or \\u201dartificial\\u201d agents might affect market stability or volatility.\\nOther recent work highlights the versatility of LLM agents in complex, interactive sce-\\nnarios beyond finance. One stream focuses on simulating social behaviors\\u2014such as opinion\\ndynamics (Chuang et al. 2023), trust (Xie et al. 2024), and resource-sharing (Piatti et al.\\n2024). Another examines LLMs\\u2019 strategic capabilities through task-based simulations and\\ncollaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\\nWithin the computer science literature, early works apply LLMs to financial markets but\\nabstract away many fundamental stock market characteristics. Often, they employ single-\\nprice clearing mechanisms without a persistent order book, ignore partial fills and bid-ask\", \"2024). Another examines LLMs\\u2019 strategic capabilities through task-based simulations and\\ncollaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\\nWithin the computer science literature, early works apply LLMs to financial markets but\\nabstract away many fundamental stock market characteristics. Often, they employ single-\\nprice clearing mechanisms without a persistent order book, ignore partial fills and bid-ask\\nspreads, and omit dividends. Consequently, these simplified environments can primarily\\naddress exogenous macro shocks (e.g., changes in interest rates or inflation; Gao et al. 2024),\\nexogenous policy changes (Zhang et al. 2024), or rely on advanced methods such as repetitive\\nnext-token predictions to generate better answers (Koa et al. 2024). This work extends\\nthese efforts by incorporating these crucial market features, enabling the study of complex\\nendogenous events such as flash crashes, liquidity shocks, and large-trader impacts.\\nThis work also connects to emerging research on algorithmic and AI-powered trading\\nsystems. Dou, Goldstein, and Ji (2024) demonstrate how reinforcement learning-based AI\\nspeculators can autonomously learn to sustain collusive behavior without explicit coordi-\\nnation, achieving supra-competitive profits through either price-trigger strategies or self-\\nconfirming bias in learning. This finding is particularly informative for this framework as\\nit highlights potential emergent behaviors that may arise when intelligent agents interact in\\n7\\nmarkets\\u2014behaviors that could manifest differently with LLM agents due to their natural\\nlanguage reasoning capabilities. Similarly, Colliard, Foucault, and Lovo (2022) examine al-\\ngorithmic market makers using Q-learning and find they charge markups that increase when\\nadverse selection costs decrease\\u2014contrary to Nash equilibrium predictions. Their work pro-\\nvides methodological insights on how to test strategic pricing behaviors against theoretical\\nbenchmarks incorporated into this LLM-based framework.\\nFinally, this approach is informed by complexity economics, which views markets as dy-\\nnamic, non-equilibrium systems where agents adaptively learn and evolve strategies (Arthur\\n2013; Wolfram 2017). According to this view, markets exhibit emergent phenomena and\\nself-organization, especially when trading agents (human or artificial) update their behav-\\nior in response to outcomes. This paradigm is particularly relevant in an era of increasing\\nautomation and algorithmic trading (Balland et al. 2022; Ping 2019). Like adaptive agents\\nin complexity economics, these LLM traders incorporate new information and adjust their\\nstrategies, generating emergent market patterns\\u2014a key motivation behind this framework.\\nUnlike previous frameworks that abstract away crucial market features or focus on narrow\\nstrategies, this system incorporates realistic market microstructure while accommodating\\nheterogeneous agents interacting simultaneously. While earlier work demonstrates LLMs\\u2019\\npromise for macroeconomic modeling and simple trading simulations, this work introduces a\\ncomplex, open-source financial market platform that supports multiple agent architectures,\\nthorough market microstructure (limit orders, partial fills, dividends), and rigorous testing\\nprotocols\\u2014fulfilling a critical need in complexity economics research and market microstruc-\\nture analysis.\\n2 Methodology\\nThe methodology section contains three parts. The first part describes the market design,\\nthe second agents\\u2019 design, and the third the analysis module.\\n8\\n2.1 Market Design\\nOur methodological framework integrates three components that create a controlled envi-\\nronment for LLM-based trading agents. The framework implements a flexible continuous\\ndouble-auction market mechanism that couples standard market microstructure principles\\nwith market clearing and matching algorithms to accommodate asynchronous LLM decisions.\", \"2407.18957. arXiv: 2407.18957 [q-fin]. http://arxiv.org/abs/2407.18957.\\n41\\nA Technical Implementation Details\\nA.1 Agent Type Specifications\\nThis section details the base system prompts for each agent type in our simulation. These\\nprompts define the core behavioral characteristics and trading strategies for each agent. Each\\nprompt consists of:\\n\\u2022 A role definition that establishes the agent\\u2019s trading philosophy\\n\\u2022 A structured trading strategy that guides decision-making\\n\\u2022 Specific instructions for when to use market orders vs limit orders\\nAt runtime, these base prompts are combined with:\\n\\u2022 Current market state (price, volume, order book depth)\\n\\u2022 Position information (current holdings and available cash)\\n\\u2022 Trading options and required response format\\nThe standard runtime template includes:\\nPosition Information Template\\nYour Position:\\n- Available Shares: {shares} shares (Short selling is not allowed)\\n- Main Cash Account: ${cash:.2f}\\n- Dividend Cash Account (not available for trading): ${dividend_cash:.2f}\\n- Total Available Cash: ${total_available_cash:.2f} (Borrowing is not allowed)\\n- Shares in Orders: {committed_shares} shares\\n- Cash in Orders: ${committed_cash:.2f}\\n42\\nTrading Options Template\\nYour analysis should include:\\n- valuation_reasoning: Your numerical analysis of the asset\\u2019s fundamental value\\n- valuation: Your estimate of the asset\\u2019s current fundamental value\\n- price_target_reasoning: Your numerical analysis of the asset\\u2019s price target\\n- price_target: Your predicted price for the next round\\n- reasoning: Your explanation for the trading decision\\nTrading Options:\\n1. New Orders (replace_decision=\\u2019Add\\u2019):\\n- Single or multiple orders allowed\\n- For each order:\\n- Market order: Set order_type=\\u2019market\\u2019\\n- Limit order: Set order_type=\\u2019limit\\u2019 and specify price_limit\\n- IMPORTANT: Sell orders require sufficient available shares\\n- Short selling is NOT allowed\\n2. Cancel Orders (replace_decision=\\u2019Cancel\\u2019):\\n- Return an empty orders list: orders=[]\\nYour decision must include:\\n- orders: list of orders (empty list for Hold/Cancel)\\n- For Buy/Sell orders, each must contain:\\n- decision: \\\"Buy\\\" or \\\"Sell\\\"\\n- quantity: number of shares\\n- order_type: \\\"market\\\" or \\\"limit\\\"\\n- price_limit: required for limit orders\\n- reasoning: brief explanation\\n- replace_decision: \\\"Add\\\", \\\"Cancel\\\", or \\\"Replace\\\"\\n43\\nBase System Prompts The following are the base system prompts for each LLM-based\\nagent type:\\nA.1.1 Value-Based Agents\\nValue Investor\\nYou are a value investor who focuses on fundamental analysis.\\nYou believe in mean reversion and try to buy undervalued assets and sell overvalued ones.\\nA.1.2 Trend-Following Agents\\nMomentum Trader\\nYou are a momentum trader who focuses on price trends and volume.\\nYou believe that \\u2019the trend is your friend\\u2019 and try to identify and follow market momentum.\\nA.1.3 Liquidity Providers Agents\\nMarket Maker\\nYou are a professional market maker who provides liquidity to the market.\\nYour profit comes from capturing the spread between bid and ask prices, not from directional price movement.\\nIMPORTANT: There is NO SHORT SELLING allowed. You can only sell shares you already own.\\nTrading Guidelines:\\n- Place LIMIT buy orders slightly below the current market price (1-3% lower)\\n- Place LIMIT sell orders slightly above the current market price (1-3% higher)\\n- Your spread should be proportional to volatility but typically 2-6% of price\\n- NEVER place sell orders more than 10% above your buy orders\\n- Adjust your spread width based on recent price volatility\\n44\\nInventory Management (No Short Selling):\\n- Monitor your current inventory in the market data\\n- Only place sell orders for quantities you actually own\\n- If you have no inventory, focus on buy orders first\\n- As you acquire inventory, gradually place sell orders\\n- If inventory grows too large, reduce or pause buy orders\\n- Adjust your buy/sell ratio based on current inventory level\\nExample: If price = $100, you might place buy orders at $97-99 and sell orders at $101-103,\", \"Can Large Language Models Trade? Testing Financial\\nTheories with LLM Agents in Market Simulations\\nAlejandro Lopez-Lira\\u2217\\nFirst Version: November 29, 2024; Current Version: April 16, 2025\\nAbstract\\nThis paper presents a realistic simulated stock market where large language models\\n(LLMs) act as heterogeneous competing trading agents. The open-source framework\\nincorporates a persistent order book with market and limit orders, partial fills, div-\\nidends, and equilibrium clearing alongside agents with varied strategies, information\\nsets, and endowments. Agents submit standardized decisions using structured outputs\\nand function calls while expressing their reasoning in natural language. Three findings\\nemerge: First, LLMs demonstrate consistent strategy adherence and can function as\\nvalue investors, momentum traders, or market makers per their instructions. Second,\\nmarket dynamics exhibit features of real financial markets, including price discovery,\\nbubbles, underreaction, and strategic liquidity provision. Third, the framework enables\\nanalysis of LLMs\\u2019 responses to varying market conditions, similar to partial dependence\\nplots in machine-learning interpretability. The framework allows simulating financial\\ntheories without closed-form solutions, creating experimental designs that would be\\ncostly with human participants, and establishing how prompts can generate correlated\\nbehaviors affecting market stability.\\nKeywords: LLM Agents; Agent-Based Markets; Experimental Finance; AI Trading;\\nMulti-Agent Systems\\n\\u2217University of Florida. Email: alejandro.lopez-lira@warrington.ufl.edu. I am grateful to seminar par-\\nticipants at the London Business School, Oxford University, Stockholm School of Economics, University of\\nVirginia, and the City University of Hong Kong for helpful suggestions and feedback.\\n1\\narXiv:2504.10789v1  [q-fin.CP]  15 Apr 2025\\n1 Introduction\\nLarge language models (LLMs) can increasingly function as autonomous agents\\u2014systems\\nthat observe, reason, and act independently. LLMs have shown promising results in finan-\\ncial forecasting, but their potential as trading agents introduces a fundamental shift from\\nalgorithms with explicit objectives to systems guided by natural language instructions. This\\nchange raises critical questions: Can LLMs execute trading strategies? Do LLMs optimize\\nfor profit maximization? What are the implications for market stability and efficiency?\\nIf LLMs trade similarly to humans, they could enable experimental market simulations\\nwithout human participants. Conversely, if their trading behavior differs, understanding\\nthese differences becomes critical for systemic risk management. These questions extend be-\\nyond theory; LLM-based strategies are already being deployed.1 To address these questions,\\nI develop an open-source simulation that tests LLM trading agents in a realistic market envi-\\nronment with a persistent order book, supporting various order types, stochastic dividends,\\nand heterogeneous information.\\nThe framework allows heterogeneous LLMs\\u2014defined in natural language, using different\\nsystem prompts\\u2014to act as diverse types of traders, such as value investors, momentum\\ntraders, market makers, and contrarians. Agents submit standardized trading decisions in a\\nhuman-readable format while expressing their reasoning transparently. Figure 1 illustrates\\nthis approach, showing how a speculator agent combines explicit valuation reasoning with\\nstructured trading parameters, enabling systematic analysis and insight into the agent\\u2019s\\ndecision-making process.\\nThe analysis reveals three key findings about LLMs\\u2019 capabilities as trading agents. First,\\nLLMs can effectively execute trading strategies. They consistently understand market me-\\nchanics, process market information, form price expectations, and execute trades according\\nto specific instructions. Their trading behavior is highly sensitive to the prompts they\\nreceive\\u2014they faithfully follow directions regardless of profit implications. This observance\", \"\\u2022 Market Makers: Provide liquidity through symmetric bid-ask spreads\\n\\u2022 Contrarian Traders: Trade against market extremes and overreactions\\n\\u2022 Speculators: Seek to profit from market inefficiencies\\n\\u2022 Sentiment-Based Agents: Include optimistic and pessimistic variants with biased\\nexpectations\\n\\u2022 Retail Traders: Simulate typical individual investor behavior\\nThe software also includes a set of deterministic rule-based agents that serve as bench-\\nmarks and control conditions:\\n\\u2022 Directional Traders: Always-buy, always-sell, and always-hold agents\\n\\u2022 Technical Agents: Gap traders, mean reversion traders, and momentum traders\\n\\u2022 Algorithmic Market Makers: Implement fixed spread-posting strategies\\n14\\nEach agent type is defined by its system prompt (for LLM agents) or algorithmic rules (for\\ndeterministic agents), with standardized interfaces enabling direct comparison across diverse\\nstrategies. The agent composition system supports flexible specifications\\u2014including uni-\\nform distributions, type-specific concentrations (e.g., \\u201dvalue heavy\\u201d), and precise numerical\\nallocations\\u2014enabling systematic exploration of how market dynamics emerge from different\\nagent populations.\\nThe framework\\u2019s extensible design makes it remarkably simple to add new agent types\\u2014\\nLLM-based agents require only defining a new system prompt that specifies the trading\\nstrategy. In contrast, deterministic agents can be implemented through the standard agent\\ninterface. This flexibility allows researchers to rapidly prototype and deploy novel trading\\nstrategies without modifying the underlying system architecture.\\nThe complete list of agent types included in the framework and their detailed specifi-\\ncations is provided in the Appendix. The framework\\u2019s flexible prompt-based architecture\\nallows researchers to rapidly prototype and deploy new agent types by developing appropri-\\nate strategic and tactical prompts without modifying the underlying system architecture.\\n2.2.4 User Prompt\\nThe user prompt provides the immediate market context necessary for tactical decision-\\nmaking. This dynamic component delivers current market state information, including\\nprices, volumes, and emerging trends, alongside the agent\\u2019s current position information\\nand available trading options. Additionally, the user prompt specifies immediate decision\\nrequirements and operational constraints, ensuring that agent responses remain within fea-\\nsible bounds while aligning with their strategic objectives. This separation of strategic and\\ntactical prompting enables precise control over agent behavior while maintaining flexibility\\nfor market interactions. All the information in the user prompt is optional at the agent level\\nand can be customized for different experimental designs.\\n15\\n2.2.5 Decision Structure\\nEach agent decision follows a standardized output format comprising several key components.\\nThe decision field specifies the basic action as either Buy, Sell, or Hold. For active trades,\\nthe quantity field determines the number of shares to trade, while the order type indicates\\nwhether it is a Market or Limit order. When placing limit orders, the price limit field\\nspecifies the maximum (for buys) or minimum (for sells) acceptable execution price. Finally,\\neach decision includes a reasoning field that provides an explicit rationale for the trading\\ndecision, ensuring transparency and facilitating analysis of agent behavior.\\n2.2.6 Structured Outputs and Function Calling\\nOur framework implements a structured output approach using function calling to ensure\\nstandardized, human-readable, machine-readable agent decisions. This technique allows\\nLLMs to generate outputs in a specific format that can be directly validated and processed\\nby the trading system, bridging the gap between natural language reasoning and executable\\ntrading actions.\\nThe system uses Pydantic for validation and parsing of agent outputs, with a schema-\\nbased approach that defines the required structure:\\nclass TradeDecisionSchema(BaseModel):\", \"ceedings of the 62nd Annual Meeting of the Association for Computational Linguistics\\n(Volume 1: Long Papers),edited by Lun-Wei Ku, Andre Martins, and Vivek Srikumar,\\n15523\\u201315536. ACL 2024. Bangkok, Thailand: Association for Computational Linguis-\\ntics, August.\\n39\\nLi, Yuan, Yixuan Zhang, and Lichao Sun. 2023. \\u201cMetaAgents: Simulating Interactions of\\nHuman Behaviors for LLM-based T Ask-Oriented Coordination via Collaborative Gen-\\nerative Agents.\\u201d arXiv.org.\\nLiu, Xiao, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, et al. 2023.\\n\\u201cAgentBench: Evaluating LLMs as Agents.\\u201dInternational Conference on Learning Rep-\\nresentations.\\nLopez-Lira, Alejandro, and Yuehua Tang. 2023. \\u201cCan ChatGPT Forecast Stock Price Move-\\nments? Return Predictability and Large Language Models.\\u201d SSRN Electronic Journal\\n(April 6, 2023).\\nManning, Benjamin S., Kehang Zhu, and John J. Horton. 2024. \\u201cAutomated Social Science:\\nLanguage Models as Scientist and Subjects.\\u201d (Cambridge, MA) (April 29, 2024).\\nMolnar, Christoph. 2022. Interpretable Machine Learning.\\nPelster, Matthias, and Joel Val. 2023. \\u201cCan Chatgpt Assist in Picking Stocks?\\u201dSocial Science\\nResearch Network.\\nPiatti, Giorgio, Zhijing Jin, Max Kleiman-Weiner, Bernhard Sch\\u00a8 olkopf, Mrinmaya Sachan,\\nand Rada Mihalcea. 2024. \\u201cCooperate or Collapse: Emergence of Sustainable Coopera-\\ntion in a Socie Ty of LLM Agents.\\u201d arXiv.org.\\nPing, Chen. 2019. \\u201cFrom Complexity Science to Complexity Economics.\\u201d In Alternative\\nApproaches to Economic Theory,19\\u201355. Routledge, June 11, 2019.\\nWang, Saizhuo, Hang Yuan, Lionel M. Ni, and Jian Guo. 2024. \\u201cQuantAgent: Seeking Holy\\nGrail in Trading by Self-Improving Large Lang Uage Model.\\u201d arXiv.org.\\nWeitzel, Utz, Christoph Huber, J\\u00a8 urgen Huber, Michael Kirchler, Florian Lindner, and Julia\\nRose. 2020. \\u201cBubbles and Financial Professionals.\\u201d The Review of Financial Studies33,\\nno. 6 (June 1, 2020): 2659\\u20132696.\\n40\\nWolfram, Elsner. 2017. \\u201cComplexity Economics as Heterodoxy: Theory and Policy.\\u201dJournal\\nof Economic Issues51, no. 4 (October 2, 2017): 939\\u2013978.\\nWoodhouse, Drew, and Alex Charlesworth. 2023. \\u201cCan ChatGPT Predict Future Interest\\nRate Decisions?\\u201d Social Science Research Network.\\nXie, Chengxing, Canyu Chen, Feiran Jia, Ziyu Ye, Shiyang Lai, Kai Shu, Jindong Gu, et al.\\n2024. \\u201cCan Large Language Model Agents Simulate Human Trust Behavior?\\u201darXiv.org.\\nYang, Stephen. 2023. \\u201cPredictive Patentomics: Forecasting Innovation Success and Valuation\\nw Ith ChatGPT.\\u201d Social Science Research Network.\\nYu, Yangyang, Haohang Li, Zhi Chen, Yuechen Jiang, Yang Li, Denghui Zhang, Rong\\nLiu, Jordan W. Suchow, and Khaldoun Khashanah. 2024. \\u201cFinMem: A Performance-\\nEnhanced LLM Trading Agent with Layered Memory a Nd Character Design.\\u201dProceed-\\nings of the AAAI Symposium Series3, no. 1 (May 20, 2024): 595\\u2013597.\\nYu, Yangyang, Zhiyuan Yao, Haohang Li, Zhiyang Deng, Yupeng Cao, Zhi Chen, Jordan W.\\nSuchow, et al. 2024. \\u201cFinCon: A Synthesized LLM Multi-Agent System with Conceptual\\nVerbal Reinforcement for Enhanced Financial Decision Making.\\u201d Pre-published, Novem-\\nber 7, 2024. Accessed January 8, 2025. https://doi.org/10.48550/arXiv.2407.06567.\\narXiv: 2407.06567 [cs]. http://arxiv.org/abs/2407.06567.\\nZhang, Chong, Xinyi Liu, Zhongmou Zhang, Mingyu Jin, Lingyao Li, Zhenting Wang,\\nWenyue Hua, et al. 2024. \\u201cWhen AI Meets Finance (StockAgent): Large Language\\nModel-based Stock Trading in Simulated Real-world Environments.\\u201d Pre-published,\\nSeptember 21, 2024. Accessed January 26, 2025. https://doi.org /10.48550/arXiv .\\n2407.18957. arXiv: 2407.18957 [q-fin]. http://arxiv.org/abs/2407.18957.\\n41\\nA Technical Implementation Details\\nA.1 Agent Type Specifications\\nThis section details the base system prompts for each agent type in our simulation. These\\nprompts define the core behavioral characteristics and trading strategies for each agent. Each\\nprompt consists of:\\n\\u2022 A role definition that establishes the agent\\u2019s trading philosophy\\n\\u2022 A structured trading strategy that guides decision-making\", \"decision-making process.\\nThe analysis reveals three key findings about LLMs\\u2019 capabilities as trading agents. First,\\nLLMs can effectively execute trading strategies. They consistently understand market me-\\nchanics, process market information, form price expectations, and execute trades according\\nto specific instructions. Their trading behavior is highly sensitive to the prompts they\\nreceive\\u2014they faithfully follow directions regardless of profit implications. This observance\\n1. For example, Autopilot has a ChatGPT-based portfolio https://x.com/thegptinvestor.\\n2\\n{\\\"valuation_reasoning\\\":\\n\\\"The fundamental value is based on the expected dividend,\\nand the interest rate.\\nThe expected dividend is $1.40, and the interest rate is 5%.\\nUsing a perpetuity formula, the value is $1.40 / 0.05 = $28.\\\",\\n\\\"valuation\\\":28.0,\\n\\\"price_target_reasoning\\\":\\\"The current price is $29.00, which is\\nslightly above the fundamental value of $28.00. I expect the price\\nto remain around $29.00 in the next round due to market stability.\\\",\\n\\\"price_target\\\":29.0,\\n\\\"orders\\\":[{\\\"decision\\\":\\\"Sell\\\",\\\"quantity\\\":1000,\\\"order_type\\\":\\\"limit\\\",\\n\\\"price_limit\\\":29.50}],\\n\\\"replace_decision\\\":\\\"Add\\\",\\n\\\"reasoning\\\":\\\"The current price is slightly above the fundamental value.\\nI will place a limit sell order at $29.50 to capitalize on potential price\\nincreases.\\\"}\\nFigure 1: Example of a structured trading decision from a Speculator agent defined by its\\nsystem prompt: \\u201cYou are a speculator who tries to profit from market inefficiencies.\\u201d. The\\nLLM provides explicit reasoning for its valuation, price target, and trading decision in a\\nmachine-readable JSON format that can be directly processed by the trading system.\\nhighlights a fundamental difference from human traders: LLMs do not inherently optimize\\nfor profit maximization but rather for following instructions accurately.\\nSecond, LLMs react meaningfully to market dynamics. They consider current and his-\\ntorical prices, dividends, and other market information when making decisions. However,\\nthey maintain their strategic direction even when market conditions change, following their\\ninstructions even if doing so results in financial losses. This combination of responsiveness\\nto market conditions while maintaining strategic consistency creates a unique trading profile\\ndistinct from rule-based algorithms and human traders.\\nThird, market dynamics with LLM agents can resemble actual markets and mirror classic\\nresults from the theoretical finance literature. When these agents interact, they produce\\nrealistic price discovery and liquidity provision with emergent behaviors, including price\\nconvergence toward fundamental values. Depending on the distribution of agent types,\\nthe system can generate various market phenomena, such as bubbles or underreactions to\\ninformation. This complex behavior suggests potential applications for studying market\\n3\\ndynamics using LLM agents instead of experiments with human participants.\\nHence, these findings raise important questions about algorithmic consistency in LLM-\\nbased systems. Since trading agents are implemented through prompts, their behavior in-\\nherits characteristics of the underlying language models. The standardization of LLM ar-\\nchitectures across implementations could create unexpected behavioral patterns\\u2014if many\\nagents are based on similar foundation models, they might exhibit correlated responses to\\nspecific market conditions, potentially amplifying market instabilities.\\nTo enable this analysis and accelerate development in this emerging field, we provide\\nan open-source framework with three key components: (1) a structured protocol for im-\\nplementing and validating LLM trading agents, supporting both LLM-based and traditional\\nrule-based agents; (2) a controlled market environment with realistic microstructure for test-\\ning agent interactions; and (3) a comprehensive data collection system for analyzing trading\\nbehavior. This framework serves multiple stakeholders in preparation for the evolution of\", \"the second agents\\u2019 design, and the third the analysis module.\\n8\\n2.1 Market Design\\nOur methodological framework integrates three components that create a controlled envi-\\nronment for LLM-based trading agents. The framework implements a flexible continuous\\ndouble-auction market mechanism that couples standard market microstructure principles\\nwith market clearing and matching algorithms to accommodate asynchronous LLM decisions.\\nThe market clearing process employs a dual-stage matching algorithm. In the first stage,\\nlimit orders are posted. In the second stage, market orders are netted using a market-\\nto-market matching engine that processes buy and sell orders, reconciling orders based on\\navailable agent cash and share commitments. In the third stage, any remaining market\\norders are matched against the existing order book, with unfilled quantities converted to\\naggressive limit orders. This three-tiered approach optimizes immediate execution and price\\ndiscovery while maintaining market liquidity.\\nThe system\\u2019s OrderMatchingService orchestrates this process by coordinating trade ex-\\necutions through the TradeExecutionService and managing order state transitions via the\\nOrderStateManager. Each trade is logged in detail, with the overall market state\\u2014including\\norder books, market depth, and price evolution\\u2014recalculated at the end of each trading\\nround.\\nThis modular design in the matching and clearing engine provides several advantages.\\nFirst, it enables rigorous trade validation where each market order is validated against agent\\ncash commitments and position constraints before matching, with the system dynamically\\nadjusting order quantities based on available cash when an agent\\u2019s commitment is insuf-\\nficient, thus minimizing execution errors. Second, it offers flexible liquidity handling by\\nsupporting market-to-market and market-to-book matching, ensuring orders have multiple\\nexecution pathways, with unexecuted market orders converted to aggressive limit orders to\\ncapture remaining liquidity. Third, it maintains detailed trade audit capabilities by recording\\ncomprehensive traceability data including timestamps, trade volumes, executed prices, and\\nagent identifiers, thereby enabling post-trade analysis and performance benchmarking that\\n9\\nserves as the foundation for subsequent market efficiency and agent performance validations.\\n2.1.1 Market Mechanism Design\\nOur framework implements a continuous double-auction market mechanism that processes\\norders in discrete trading rounds. We use discrete trading rounds because LLMs have latency\\nconstraints, making it infeasible to process orders in real time. Within each round, the order\\nof agent submissions is randomized to avoid giving systematic priority to specific agents,\\nthus simulating concurrent order arrival while maintaining fairness. Once randomized, or-\\nders are then processed according to standard price-time priority rules. The system supports\\nfinite and infinite horizon markets, with differences in terminal conditions and wealth cal-\\nculation. In finite-horizon markets, agents are informed of the total number of rounds, and\\ntheir terminal wealth is calculated by redeeming all shares at the fundamental value of the\\nfinal round. In infinite-horizon markets, no terminal information is provided to agents, and\\nfinal wealth is determined using the last market price for share valuation. This design choice\\nenables researchers to study how time horizons influence trading strategies and price for-\\nmation, particularly how agents balance short-term trading opportunities against long-term\\nvalue considerations.\\nIn a double auction, buyers and sellers actively submit orders, with trades occurring when\\ncompatible buy and sell orders match the price. The matching engine processes these orders\\nthrough three sequential phases:\\nFirst, incoming limit orders that do not immediately cross the market are added to\\nthe order book, maintaining strict price-time priority. Second, market orders are processed\"]}": {"cached_metrics_data": [{"metric_data": {"name": "Contextual Precision (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Faithfulness (ragas)", "threshold": 0.8, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.8, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Contextual Recall (ragas)", "threshold": 0.6, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.6, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Answer Relevancy (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}]}, "{\"actual_output\": \"The matching engine in the continuous double-auction market uses a three-stage algorithm:\\nStage 1: Order Book Population: Incoming limit orders (orders to buy or sell at a specific price or better) that don't immediately find a match are added to the order book. The order book is organized using price-time priority, meaning the best prices are matched first, and if multiple orders exist at the same price, the oldest order is prioritized.\\nStage 2: Market Order Processing: Market orders (orders to buy or sell at the best available price) are processed in two steps:\\n(a) Market-to-Market Matching: Market buy orders are matched with market sell orders at the current market price. These orders are essentially netted against each other.\\n(b) Market-to-Book Matching: Any remaining market orders are then matched against existing limit orders in the order book.\\nStage 3: Crossing Limit Order Matching: Any limit orders that cross the market (a buy order with a price higher than the best ask price or a sell order with a price lower than the best bid price) are matched against existing orders in the order book. This ensures that trades occur whenever possible.\", \"context\": [\"The matching engine processes these orders\\nthrough three sequential phases:\\nFirst, incoming limit orders that do not immediately cross the market are added to\\nthe order book, maintaining strict price-time priority. Second, market orders are processed\\nthrough a two-stage matching algorithm: (a) market-to-market matching, where market\\norders are netted against each other at the current market price, and (b) market-to-book\\nmatching, where remaining market orders are executed against standing limit orders. Finally,\\nany crossing limit orders are matched against the order book.\"], \"expected_output\": \"Orders are handled in three sequential phases: (1) non\\u2011crossing limit orders join the book; (2a) market\\u2011to\\u2011market netting; (2b) market\\u2011to\\u2011book execution; (3) any still\\u2011crossing limit orders are matched.\", \"hyperparameters\": null, \"input\": \"Could you walk me through the three\\u2011stage matching algorithm the authors implement in their continuous double\\u2011auction market?\", \"retrieval_context\": [\"2024). Another examines LLMs\\u2019 strategic capabilities through task-based simulations and\\ncollaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\\nWithin the computer science literature, early works apply LLMs to financial markets but\\nabstract away many fundamental stock market characteristics. Often, they employ single-\\nprice clearing mechanisms without a persistent order book, ignore partial fills and bid-ask\\nspreads, and omit dividends. Consequently, these simplified environments can primarily\\naddress exogenous macro shocks (e.g., changes in interest rates or inflation; Gao et al. 2024),\\nexogenous policy changes (Zhang et al. 2024), or rely on advanced methods such as repetitive\\nnext-token predictions to generate better answers (Koa et al. 2024). This work extends\\nthese efforts by incorporating these crucial market features, enabling the study of complex\\nendogenous events such as flash crashes, liquidity shocks, and large-trader impacts.\\nThis work also connects to emerging research on algorithmic and AI-powered trading\\nsystems. Dou, Goldstein, and Ji (2024) demonstrate how reinforcement learning-based AI\\nspeculators can autonomously learn to sustain collusive behavior without explicit coordi-\\nnation, achieving supra-competitive profits through either price-trigger strategies or self-\\nconfirming bias in learning. This finding is particularly informative for this framework as\\nit highlights potential emergent behaviors that may arise when intelligent agents interact in\\n7\\nmarkets\\u2014behaviors that could manifest differently with LLM agents due to their natural\\nlanguage reasoning capabilities. Similarly, Colliard, Foucault, and Lovo (2022) examine al-\\ngorithmic market makers using Q-learning and find they charge markups that increase when\\nadverse selection costs decrease\\u2014contrary to Nash equilibrium predictions. Their work pro-\\nvides methodological insights on how to test strategic pricing behaviors against theoretical\\nbenchmarks incorporated into this LLM-based framework.\\nFinally, this approach is informed by complexity economics, which views markets as dy-\\nnamic, non-equilibrium systems where agents adaptively learn and evolve strategies (Arthur\\n2013; Wolfram 2017). According to this view, markets exhibit emergent phenomena and\\nself-organization, especially when trading agents (human or artificial) update their behav-\\nior in response to outcomes. This paradigm is particularly relevant in an era of increasing\\nautomation and algorithmic trading (Balland et al. 2022; Ping 2019). Like adaptive agents\\nin complexity economics, these LLM traders incorporate new information and adjust their\\nstrategies, generating emergent market patterns\\u2014a key motivation behind this framework.\\nUnlike previous frameworks that abstract away crucial market features or focus on narrow\\nstrategies, this system incorporates realistic market microstructure while accommodating\\nheterogeneous agents interacting simultaneously. While earlier work demonstrates LLMs\\u2019\\npromise for macroeconomic modeling and simple trading simulations, this work introduces a\\ncomplex, open-source financial market platform that supports multiple agent architectures,\\nthorough market microstructure (limit orders, partial fills, dividends), and rigorous testing\\nprotocols\\u2014fulfilling a critical need in complexity economics research and market microstruc-\\nture analysis.\\n2 Methodology\\nThe methodology section contains three parts. The first part describes the market design,\\nthe second agents\\u2019 design, and the third the analysis module.\\n8\\n2.1 Market Design\\nOur methodological framework integrates three components that create a controlled envi-\\nronment for LLM-based trading agents. The framework implements a flexible continuous\\ndouble-auction market mechanism that couples standard market microstructure principles\\nwith market clearing and matching algorithms to accommodate asynchronous LLM decisions.\", \"The theory of intermediation developed in Chapter 14 focuses on the risk-pooling and\\nrisk-sharing products created by \\ufb01nancial-services institutions. Products examined\\nrange from standardized instruments such as a group of mutual funds with charac-\\nteristics described in Theorem 15.5 to custom products tailored to meet the speci\\ufb01c\\nrequirements of each investor. Contingent-claims analysis (CCA) is the tool used\\nto derive the production technologies and costs for intermediaries to create these\\ncustom derivative securities. As discussed, such \\ufb01nancial products and the associ-\\nated activities of their producers are redundant in a frictionless environment with no\\ninformation-gathering or transactions costs. Thus, to provide a nontrivial role for\\nintermediaries in our equilibrium analysis here, we assume that some investors and\\nbusiness \\ufb01rms face transactions costs for trading and issuing securities directly in\\nthe capital markets. However, to preserve the CCA production theory for intermedi-\\naries, we follow the model in Chapter 14 and posit that \\ufb01nancial intermediaries, as\\nthe lowest-cost transactors, can trade continuously in the capital market at no cost.\\n2In this chapter, the returns on he growth-optimum portfolio are perfectly correlated with a combination of\\nthemtraded securities used to hedge against state-variable changes. Hence, them m+ 2spanning funds of\\nTheorem 15.5 reduce to in m+ 1funds.\\n16.2 Financial Intermediation with Dynamically-Complete Markets 417\\nIn applying this model to derive equilibrium prices and allocations, we shall further\\nassume that the \\ufb01nancial-services industry is competitive so that \\ufb01nancial-product\\nprices equal their marginal production costs.\\nIn the production theory of Chapter 14, a manufacturing technology is developed\\nto create Arrow-Debreu securities that are contingent on traded asset prices. In this\\nsection, we generalize that analysis to derive the production technology and cost\\nfor intermediaries to create a complete set of Arrow-Debreu securities with payoffs\\ncontingent on the state of the economy S(t)at each time t.\\nFrom (16.2), we can express \\u03c1ijdt\\u2261dqidqj,i,j= 1,. .. , n as functions of \\u03c1kiand\\n\\u03b4ij,k, i= 1,. . ., m andj=m+ 1,. .. , n . De\\ufb01ne hjby\\nhj\\u2261\\nfj\\u2212r\\u2212gj\\u03b1j\\u2212r\\n\\u03c3jj= 1,. . ., m\\nfj\\u2212r\\u2212gjm\\u2211\\ni=1\\u03b4ij\\u03b1i\\u2212r\\n\\u03c3ij=m+ 1,. .. , n(16.6)\\nLet\\u03a0(S, t;S,\\u03c4)denote the solution to the linear partial differential equation\\n0 =1\\n2n\\u2211\\ni=1n\\u2211\\nj=1gigj\\u03c1ijSiSj\\u03a0ij+n\\u2211\\nj=1(r+hj)Sj\\u03a0j+ \\u03a0t\\u2212r\\u03a0 (16.7)\\nsubject to the boundary conditions that \\u03a0(S, t;S,\\u03c4)\\u22650and\\u222b\\u221e\\n0\\u00b7\\u00b7\\u00b7\\u222b\\u221e\\n0\\u03a0(S, t;S,\\u03c4)dS1\\u00b7\\u00b7\\u00b7dSn\\nexists for all Sandt < \\u03c4 < \\u221e;\\u03a0(S, t;S,\\u03c4) =\\u03b4(S1\\u2212S1)\\u03b4(S2\\u2212S2)\\u00b7\\u00b7\\u00b7\\u03b4(Sn\\u2212Sn)\\nwhere \\u03b4(\\u00b7)is the Dirac delta function and S\\u2261[S1,. . .,Sn]is a vector of speci\\ufb01ed pos-\\nitive numbers. Subscripts on \\u03a0denote partial derivatives with respect to S1,. .. , S n,\\nandt.{hj,gj,r,\\u03c1ij}are functions of Sandt, and under mild regularity conditions on\\nthese functions, a solution to (16.7) exists and is unique.\\nConsider the continuous-trading portfolio strategy that allocates fraction\\nxj(t) =\\u03a0jgjSj+\\u2211n\\nk=m+1\\u03a0kgkSk\\u03b4jk\\n\\u03c3jV(t)(16.8)\\nto traded asset j,j= 1,. .. , m and fraction 1\\u2212\\u2211m\\n1xj(t)to the riskless security at\\ntimet, where V(t)denotes the current value of the portfolio. It follows from (16.3),\\n(16.6), and (16.8) that the dynamics of the portfolio value can be written as\\ndV=V\\nm\\u2211\\nj=1xj(\\u03b1j\\u2212r) +r\\ndt+m\\u2211\\nj=1xj\\u03c3jdzj\\n=\\nrV+n\\u2211\\nj=1\\u03a0jSj(fj\\u2212hj\\u2212r)\\ndt+m\\u2211\\nj=1(\\n\\u03a0jgjSj+n\\u2211\\nk=m+1\\u03a0kgkSk\\u03b4jk)\\ndzj\\n=\\nrV+n\\u2211\\nj=1\\u03a0jSj(fj\\u2212hj\\u2212r)\\ndt+n\\u2211\\nj=1\\u03a0jgjSjdqj\\n(16.9)\\nbecause, from (16.2), dqk=\\u2211m\\n1\\u03b4jkdqj,k=m+1,. . ., n , and, from (16.4), dzj=dqj,\\nj= 1,. .. , m .\\n418 A Complete-Markets General Equilibrium Theory of Finance in Continuous Time\\n\\u03a0is a solution to (16.7) and is therefore twice-continuously differentiable. Thus,\\nIt\\u02c6o\\u2019s lemma can be used to describe the stochastic process for Y(t)\\u2261\\u03a0[S(t),t;S,\\u03c4]\\nas\\ndY=\\n1\\n2n\\u2211\\ni=1n\\u2211\\nj=1gigj\\u03c1ijSiSj\\u03a0ij+n\\u2211\\nj=1\\u03a0jfjSj+ \\u03a0t\\ndt+n\\u2211\\nj=1\\u03a0jgjSjdqj(16.10)\\nwhere \\u03a0and its derivatives are evaluated at S=S(t)at each time t. Because \\u03a0\", \"allocations are brie\\ufb02y addressed in Chapter 15 and analyzed more fully in Chapter 16. If a set of existing\\nsecurities and markets leads to an equilibrium that is an unconstrained Pareto optimum, then any additional\\nsecurities or markets will be redundant.\\n50The term \\u201ctransactions costs\\u201d can, of course, mean more than just the bid-ask spread or commissions\\npaid for buying and selling assets. For example, if an investor literally traded his portfolio continuously, he\\nwould have no time to do anything else! Because investment management and \\ufb01nancial intermediation involve\\nprimarily information processing and security trading, there arc signi\\ufb01cant economies of scale. One would thus\\nexpect substantially lower costs for the individual investor to use intermediaries instead of transacting directly\\nin the asset markets.\\n368 Financial Intermediation in the Continuous-Time Model\\nIt would seem therefore that the same dichotomy derived in the frictionless-market\\ncase applies also to our model with transactions costs. In a formal computational\\nsense it does. We can still solve for the equilibrium asset-price dynamics in the model\\nof Chapter 15 and then compute the prices of derivative securities, mutual funds, and\\ncorporate liabilities using CCA. There is one signi\\ufb01cant difference, however: the\\n\\ufb01rst-part calculation of equilibrium real-sector allocations is valid if and only if there\\nexists a suf\\ufb01ciently rich set of securities and intermediaries in the \\ufb01nancial sector to\\nmake these allocations feasible for agents who cannot trade without cost. Because\\nof this conditioning. perhaps a more appropriate term for this separation is \\u201cquasi-\\ndichotomy.\\u201d\\nWith the assumption that not all agents can trade continuously without cost, a\\nsigni\\ufb01cant economic role is established for derivative-security markets and \\ufb01nancial\\nintermediaries in the model. Somewhat paradoxically, we \\ufb01nd that, if intermediation\\nis ef\\ufb01cient, then derivative securities and the \\ufb01nancial products of the intermediaries\\nwill be priced as if they are redundant.51Under these conditions, quasi-dichotomy\\nobtains, and we can derive equilibrium real-sector allocations and asset prices from\\nthe frictionless-market version of the model.\\n14.6 Afterword: Policy and Strategy in Financial Intermediation\\nIn this chapter, as throughout the book, the focus has been on theory. Allusions to\\npractice were concentrated on the micro quantitative applications of the continuous-\\ntime model to product technologies and risk management. Still, I cannot wholly\\nresist the temptation to call attention to the model\\u2019s potential for addressing broader\\nissues in the practice of intermediation. And so this afterword shall ever so brie\\ufb02y\\ntouch upon implications of the model for intermediation policy and strategy in the\\nhope that it will lead others, better quali\\ufb01ed, to explore this matter elsewhere.\\nDerivative securities have long been an integral part of the \\ufb01nancial markets,52\\nbut most would mark the creation of the Chicago Board Options Exchange in April\\n1973 as the start of the current wave of \\ufb01nancial innovations involving derivative\\nsecurities. The succeeding years have witnessed an unprecedented proliferation of\\norganized trading markets in both equity and \\ufb01xed-income derivative instruments.\\nIn turn, these markets made possible the creation of a wide range of \\ufb01nancial prod-\\n51Thus, our model provides a resolution to Hakansson\\u2019s (1979, p. 722) \\u201cThe Catch 22 of Option Pricing.\\u201d\\nAlthough the equilibrium prices of options and other derivative securities satisfy the redundancy condition of\\nCCA, they are nevertheless needed to support the equilibrium allocations, and hence their elimination would\\nreduce social welfare.\\n52Bernstein (1992) reports that Aristotle\\u2019s anecdote about Thales in Book I of Politics is the \\ufb01rst recorded\\nmention of a \\ufb01nancial option. Schaede (1988) makes the case that the Dojima rice market in Osaka was a\", \"by detailed Trade Data, which records individual transaction details such as prices, quan-\\ntities, buyer and seller identifiers, timestamps, round information, and specific execution\\ndetails.\\nAgent Data provides insights into participant behavior by monitoring cash and share\\n25\\nFigure 5: Order Type Analysis under Systematic Variation. Displays the proportion of\\nMarket vs. Limit orders used by different agent types across varying Price/Fundamental\\nratios.\\n26\\npositions, portfolio values, wealth evolution, and agent type and strategy identifiers. Or-\\nder Data captures the complete lifecycle of trading decisions, including order specifications\\n(type, size, price), agent reasoning and justification, decision context and timing, and order\\nlifecycle events. Finally, Market State data maintains a comprehensive view of overall mar-\\nket conditions through order book snapshots, market depth information, aggregate statistics,\\nand various market microstructure metrics.\\n2.3.3 Data Validation and Storage\\nThe system implements a comprehensive set of data quality measures to ensure reliability and\\nconsistency. The validation framework performs continuous checks for data completeness,\\nverifies consistency across related data streams, enforces format and type validation, and\\nmaintains proper temporal sequencing of all recorded events. These validation mechanisms\\nwork together to maintain data integrity throughout the experimental process.\\nThe storage architecture employs multiple formats optimized for different data types and\\nuse cases. Structured CSV files store tabular data for efficient analysis, while JSON formats\\naccommodate complex nested structures that preserve the rich relationships between market\\nelements. The system maintains detailed timestamped logs for debugging purposes and\\ngenerates summary statistics to facilitate quick analysis of experimental outcomes.\\nThis comprehensive data collection architecture enables researchers to conduct detailed\\nanalysis of market dynamics, validate agent behavior patterns, ensure experiment repro-\\nducibility, and perform meaningful cross-experiment comparisons. The integrated approach\\nto data management provides the foundation for rigorous empirical investigation of market\\nbehavior and agent interactions.\\nThe framework implements specialized visualization techniques to analyze agent behavior\\nand market dynamics. Decision heatmaps plot agent actions across trading rounds, reveal-\\ning strategic patterns and consistency. Trading flow visualizations track cumulative position\\nchanges, identifying net buyers and sellers throughout market evolution. Reasoning word-\\n27\\nclouds extract key terms from agent explanations, providing insight into decision drivers\\nacross different agent types.\\nThe system also generates specialized market quality visualizations including bid-ask\\nspread evolution, price target accuracy, and agent valuation tracking. These visualizations\\nwork in concert with the numerical metrics to provide both quantitative and qualitative\\ninsights into agent behavior and market dynamics.\\n2.3.4 Validation Metrics and Performance Monitoring\\nThe framework implements a comprehensive set of performance metrics and visualization\\ntools that monitor agent behavior and market dynamics. Market evolution visualizations\\ntrack price movements relative to fundamental values, including time series of transaction\\nprices, midpoint prices, and bid-ask spreads. These visualizations enable researchers to assess\\nmarket efficiency and price discovery processes throughout the simulation.\\nAgent performance metrics include absolute position tracking (shares, cash, and total\\nwealth), wealth composition analysis, position change metrics, and return calculations. The\\nsystem computes both absolute and percentage returns on various portfolio components\\nand compares performance across agent types to identify relative advantages of different\", \"market efficiency and price discovery processes throughout the simulation.\\nAgent performance metrics include absolute position tracking (shares, cash, and total\\nwealth), wealth composition analysis, position change metrics, and return calculations. The\\nsystem computes both absolute and percentage returns on various portfolio components\\nand compares performance across agent types to identify relative advantages of different\\nstrategies. Trading flow analysis visualizes the volume of shares moving between different\\nagent types and cumulative net trading flows, revealing which agents act as net buyers or\\nsellers in different market conditions.\\nDecision pattern analysis employs heatmaps to visualize the consistency of agent decision-\\nmaking over time, allowing researchers to identify shifts in strategic behavior. This is com-\\nplemented by decision quantities visualization that plots order sizes to highlight variations\\nin trade aggressiveness across agent types. When agent reasoning data is available, the\\nsystem generates wordclouds to extract key terms from agent explanations, providing qual-\\nitative insights into decision drivers for different agent strategies. Additional visualizations\\ntrack price target accuracy and compare agent-specific valuations to realized market prices,\\n28\\noffering insights into the forecasting abilities of different agents.\\nA key advantage of simulation-based analysis is complete observability of all market\\nprocesses and agent states. Unlike real-world markets where data availability is often limited,\\nthe framework captures every interaction, decision, and state change with perfect fidelity.\\nThis comprehensive data collection allows researchers to compute additional metrics beyond\\nstandard market measures, enabling novel analyses such as counterfactual testing (e.g., how\\nwould markets evolve with different agent compositions), causal inference of specific agent\\nbehaviors on market outcomes, and the development of custom efficiency or stability metrics\\ntailored to particular research questions. The system\\u2019s modular design facilitates rapid\\nimplementation of new metrics and visualizations as research questions evolve.\\n3 Experimental Design and Results\\nOur experimental framework implements a dividend-paying asset market with heterogeneous\\nagents. The baseline simulation runs for 15 to 20 rounds with 8 participating agents, although\\nthese parameters are fully configurable. Each agent begins with an initial endowment of\\n1,000,000 monetary units and 10,000 shares of the asset. The fundamental value of the asset\\nis set at $28.00, with a final redemption value matching this fundamental price in finite\\nhorizon scenarios. Transaction costs are set to zero to isolate the effects of agent behavior\\nand market structure.\\nThe dividend structure follows a stochastic process with a base payment of $1.40 and a\\nvariation of \\u00b1$1.00, paid with 50% probability each round. This design creates uncertainty\\nin the asset\\u2019s income stream while maintaining a known expected value. Cash holdings earn\\na risk-free interest rate of 5% per round, providing an opportunity cost for asset investment.\\nAgent composition is controlled through a flexible distribution system that allows for\\nvarious experimental configurations. In our baseline setup, we employ a mixed population\\nof value investors, momentum traders, and market makers. Each agent type implements\\n29\\ndistinct trading strategies through Large Language Model (LLM) prompts, with GPT-4o as\\nthe decision-making engine.\\nThe data collection system captures comprehensive market activity across multiple di-\\nmensions. At the market level, it tracks the evolution of prices, fundamental values, and\\nrealized dividends, providing insights into overall market dynamics. Individual agent data\\nincludes detailed wealth trajectories and portfolio compositions, enabling analysis of strategy\\neffectiveness and wealth distribution patterns. The system maintains complete transaction\", \"the second agents\\u2019 design, and the third the analysis module.\\n8\\n2.1 Market Design\\nOur methodological framework integrates three components that create a controlled envi-\\nronment for LLM-based trading agents. The framework implements a flexible continuous\\ndouble-auction market mechanism that couples standard market microstructure principles\\nwith market clearing and matching algorithms to accommodate asynchronous LLM decisions.\\nThe market clearing process employs a dual-stage matching algorithm. In the first stage,\\nlimit orders are posted. In the second stage, market orders are netted using a market-\\nto-market matching engine that processes buy and sell orders, reconciling orders based on\\navailable agent cash and share commitments. In the third stage, any remaining market\\norders are matched against the existing order book, with unfilled quantities converted to\\naggressive limit orders. This three-tiered approach optimizes immediate execution and price\\ndiscovery while maintaining market liquidity.\\nThe system\\u2019s OrderMatchingService orchestrates this process by coordinating trade ex-\\necutions through the TradeExecutionService and managing order state transitions via the\\nOrderStateManager. Each trade is logged in detail, with the overall market state\\u2014including\\norder books, market depth, and price evolution\\u2014recalculated at the end of each trading\\nround.\\nThis modular design in the matching and clearing engine provides several advantages.\\nFirst, it enables rigorous trade validation where each market order is validated against agent\\ncash commitments and position constraints before matching, with the system dynamically\\nadjusting order quantities based on available cash when an agent\\u2019s commitment is insuf-\\nficient, thus minimizing execution errors. Second, it offers flexible liquidity handling by\\nsupporting market-to-market and market-to-book matching, ensuring orders have multiple\\nexecution pathways, with unexecuted market orders converted to aggressive limit orders to\\ncapture remaining liquidity. Third, it maintains detailed trade audit capabilities by recording\\ncomprehensive traceability data including timestamps, trade volumes, executed prices, and\\nagent identifiers, thereby enabling post-trade analysis and performance benchmarking that\\n9\\nserves as the foundation for subsequent market efficiency and agent performance validations.\\n2.1.1 Market Mechanism Design\\nOur framework implements a continuous double-auction market mechanism that processes\\norders in discrete trading rounds. We use discrete trading rounds because LLMs have latency\\nconstraints, making it infeasible to process orders in real time. Within each round, the order\\nof agent submissions is randomized to avoid giving systematic priority to specific agents,\\nthus simulating concurrent order arrival while maintaining fairness. Once randomized, or-\\nders are then processed according to standard price-time priority rules. The system supports\\nfinite and infinite horizon markets, with differences in terminal conditions and wealth cal-\\nculation. In finite-horizon markets, agents are informed of the total number of rounds, and\\ntheir terminal wealth is calculated by redeeming all shares at the fundamental value of the\\nfinal round. In infinite-horizon markets, no terminal information is provided to agents, and\\nfinal wealth is determined using the last market price for share valuation. This design choice\\nenables researchers to study how time horizons influence trading strategies and price for-\\nmation, particularly how agents balance short-term trading opportunities against long-term\\nvalue considerations.\\nIn a double auction, buyers and sellers actively submit orders, with trades occurring when\\ncompatible buy and sell orders match the price. The matching engine processes these orders\\nthrough three sequential phases:\\nFirst, incoming limit orders that do not immediately cross the market are added to\\nthe order book, maintaining strict price-time priority. Second, market orders are processed\", \"value considerations.\\nIn a double auction, buyers and sellers actively submit orders, with trades occurring when\\ncompatible buy and sell orders match the price. The matching engine processes these orders\\nthrough three sequential phases:\\nFirst, incoming limit orders that do not immediately cross the market are added to\\nthe order book, maintaining strict price-time priority. Second, market orders are processed\\nthrough a two-stage matching algorithm: (a) market-to-market matching, where market\\norders are netted against each other at the current market price, and (b) market-to-book\\nmatching, where remaining market orders are executed against standing limit orders. Finally,\\nany crossing limit orders are matched against the order book.\\n10\\n2.1.2 Implementation Details\\nThe matching engine ( MatchingEngine class) implements three primary components that\\nwork together to facilitate efficient market operation. The order processing component han-\\ndles the core matching functionality, where market orders are executed immediately against\\nthe best available prices in the order book during each trading round. When immediate\\nexecution is impossible, limit orders are stored in the order book according to price-time\\npriority. The system supports partial executions, maintaining careful tracking of remaining\\nquantities to ensure complete order fulfillment across multiple trades when necessary.\\nPosition management forms the second critical component, providing comprehensive\\ntracking of agent positions and cash balances throughout the trading session. Before any\\ntrade execution, the system performs rigorous pre-trade validation to ensure agents have suffi-\\ncient resources to fulfill their orders. This check includes validating buyer cash commitments\\nand shares availability for sellers, with the system maintaining accurate records of commit-\\nted and available resources for each agent. The position management system updates in\\nreal-time as trades are executed, ensuring market integrity and preventing over-commitment\\nof resources.\\nThe price formation mechanism constitutes the third component, implementing a sys-\\ntematic price discovery and market monitoring approach. As trades are executed within each\\nround, the system dynamically updates prices based on executed trades while continuously\\ntracking market depth and bid-ask spreads. This data collection provides detailed insights\\ninto market liquidity and efficiency. Each trade is logged with comprehensive information,\\nincluding price, quantity, and participating agents, creating a complete audit trail of mar-\\nket activity. This comprehensive price formation system ensures transparent price discovery\\nwhile generating rich data for market quality analysis.\\n11\\n2.1.3 Extensibility Features\\nThe framework employs a modular architecture to support diverse experimental configura-\\ntions and research objectives. At its foundation, the system implements configurable market\\nrules and trading constraints that can be adjusted to study different market conditions.\\nThe asset model supports fundamental features like dividend payments and interest accrual,\\nenabling research across different market scenarios. Through its modular service-based ar-\\nchitecture, the trading mechanism layer allows for adaptation to other market structures\\nbeyond the base double-auction system, such as call auctions or dark pools. Furthermore,\\nthe framework provides flexible integration points for different LLM agent types and strate-\\ngies, allowing researchers to experiment with diverse behavioral models and decision-making\\napproaches.\\nThis extensible design creates numerous research opportunities for market microstructure\\nstudies. Researchers can systematically investigate how different market structures influence\\nprice formation and efficiency, evaluate the impact of various trading rules on market qual-\\nity, and analyze the complex interactions between different agent types and strategies. The\", \"value, the system:\\n1. Sets market price P = \\u03c1V where \\u03c1 is the target ratio\\n2. Generates a consistent order book structure around this price\\n3. Executes multiple decision trials with the same agent type\\n4. Records decision outcomes (buy/sell/hold), order types, quantities, and reasoning\\nThis process maps how LLM agents respond to different price environments, as illustrated\\nin Figures 2, 3, 4, and 5. The analysis reveals clear patterns in decision boundaries, with\\ndistinct transitions between buying, selling, and holding regions that vary by agent type. For\\nexample, value investors show strong buying tendencies when prices are below fundamental\\nvalue (\\u03c1 <1) and selling preferences when prices exceed fundamentals ( \\u03c1 >1). In contrast,\\nmomentum traders show less sensitivity to the fundamental ratio and more responsiveness\\nto recent price trends.\\nThe systematic variation approach also reveals patterns in order sizing and limit price\\nselection, with agents typically placing larger orders when prices deviate significantly from\\ntheir valuation models (Figure 4). This methodology provides unprecedented transparency\\ninto LLM decision processes and enables quantitative comparison of different agent types\\nand LLM architectures.\\n22\\nFigure 2: Price Analysis under Systematic Variation. Shows how agent valuation estimates\\nand price targets respond to varying Price/Fundamental ratios.\\nThe decision analysis can be customized for different experimental designs. For example,\\nresearchers can use the framework to study the impact of various market conditions on agent\\nbehavior by varying other market parameters or the effect of different agent types on market\\ndynamics by changing the agent population.\\n2.3 Data Collection and Analysis\\nEvaluating LLM trading agents requires robust methodologies for capturing, processing,\\nand analyzing their behavior in market environments. The framework implements a com-\\nprehensive analytics module that tracks all market activity, agent decisions, and performance\\nmetrics throughout experimental runs. This multi-layered approach not only records what\\nhappens in each simulation but also provides insights into why agents make specific deci-\\nsions, enabling researchers to validate agent behavior against their defined strategies and\\nassess overall market dynamics. The following sections detail the key components of this\\nanalytics infrastructure.\\n23\\nFigure 3: Trading Decision Distribution under Systematic Variation. Illustrates the proba-\\nbility of Buy, Sell, or Hold decisions across different agent types as the Price/Fundamental\\nratio changes.\\n24\\nFigure 4: Order Size Distribution under Systematic Variation. Shows the average quan-\\ntity traded (as a percentage of initial shares) for Buy and Sell orders across different\\nPrice/Fundamental ratios.\\n2.3.1 Data Collection Architecture\\nThe framework implements a comprehensive data collection system that captures multiple\\ndimensions of market behavior and agent decision-making. This structured approach ensures\\nreproducibility and enables detailed analysis of market dynamics.\\n2.3.2 Core Data Streams\\nThe system captures five primary data streams that work together to provide a complete\\npicture of market activity. Market Data forms the foundation, tracking essential metrics\\nincluding price evolution, fundamental values, trading volumes, order book depth, market\\nliquidity, best bid/ask prices, spreads, and price-fundamental ratios. This is complemented\\nby detailed Trade Data, which records individual transaction details such as prices, quan-\\ntities, buyer and seller identifiers, timestamps, round information, and specific execution\\ndetails.\\nAgent Data provides insights into participant behavior by monitoring cash and share\\n25\\nFigure 5: Order Type Analysis under Systematic Variation. Displays the proportion of\\nMarket vs. Limit orders used by different agent types across varying Price/Fundamental\\nratios.\\n26\"]}": {"cached_metrics_data": [{"metric_data": {"name": "Contextual Precision (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Faithfulness (ragas)", "threshold": 0.8, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.8, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Contextual Recall (ragas)", "threshold": 0.6, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.6, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}, {"metric_data": {"name": "Answer Relevancy (ragas)", "threshold": 0.7, "success": false, "score": NaN, "strictMode": false, "evaluationModel": "gpt-3.5-turbo", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-3.5-turbo", "strict_mode": false, "include_reason": false}}]}}}