{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepeval in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (2.3.7)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (4.67.1)\n",
      "Requirement already satisfied: pytest in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (8.3.4)\n",
      "Requirement already satisfied: tabulate in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (0.9.0)\n",
      "Requirement already satisfied: typer in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (0.9.4)\n",
      "Requirement already satisfied: rich in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (13.9.4)\n",
      "Requirement already satisfied: protobuf in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (4.25.6)\n",
      "Requirement already satisfied: pydantic in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (2.10.6)\n",
      "Requirement already satisfied: sentry-sdk in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (2.21.0)\n",
      "Requirement already satisfied: pytest-repeat in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (0.9.3)\n",
      "Requirement already satisfied: pytest-xdist in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (3.6.1)\n",
      "Requirement already satisfied: portalocker in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (3.1.1)\n",
      "Requirement already satisfied: langchain in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (0.3.18)\n",
      "Requirement already satisfied: llama-index in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (0.12.17)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (0.3.35)\n",
      "Requirement already satisfied: langchain_openai in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (0.3.6)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (0.3.17)\n",
      "Requirement already satisfied: docx2txt~=0.8 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (0.8)\n",
      "Requirement already satisfied: importlib-metadata>=6.0.2 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (8.4.0)\n",
      "Requirement already satisfied: tenacity<=9.0.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (9.0.0)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.24.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.24.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (1.27.0)\n",
      "Requirement already satisfied: grpcio==1.67.1 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (1.67.1)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (1.6.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (3.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from importlib-metadata>=6.0.2->deepeval) (3.21.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from opentelemetry-api<2.0.0,>=1.24.0->deepeval) (1.2.18)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.62.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.27.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.27.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from opentelemetry-sdk<2.0.0,>=1.24.0->deepeval) (0.48b0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from opentelemetry-sdk<2.0.0,>=1.24.0->deepeval) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from datasets->deepeval) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from datasets->deepeval) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from datasets->deepeval) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from datasets->deepeval) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from datasets->deepeval) (2.2.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from datasets->deepeval) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from datasets->deepeval) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets->deepeval) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from datasets->deepeval) (3.11.12)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from datasets->deepeval) (0.28.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from datasets->deepeval) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from datasets->deepeval) (6.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from requests->deepeval) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from requests->deepeval) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from requests->deepeval) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from requests->deepeval) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from tqdm->deepeval) (0.4.6)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from langchain->deepeval) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from langchain->deepeval) (0.3.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from langchain->deepeval) (2.0.38)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from langchain-core->deepeval) (1.33)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from pydantic->deepeval) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from pydantic->deepeval) (2.27.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from langchain-community->deepeval) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from langchain-community->deepeval) (2.7.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from langchain-community->deepeval) (0.4.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from langchain_openai->deepeval) (1.63.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from langchain_openai->deepeval) (0.9.0)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index->deepeval) (0.4.5)\n",
      "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index->deepeval) (0.4.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.17 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index->deepeval) (0.12.17)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index->deepeval) (0.3.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index->deepeval) (0.6.4)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index->deepeval) (0.3.19)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index->deepeval) (0.4.3)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index->deepeval) (0.3.1)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index->deepeval) (0.3.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index->deepeval) (0.4.5)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index->deepeval) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index->deepeval) (3.9.1)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from portalocker->deepeval) (308)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from pytest->deepeval) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from pytest->deepeval) (1.5.0)\n",
      "Requirement already satisfied: execnet>=2.1 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from pytest-xdist->deepeval) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from rich->deepeval) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from rich->deepeval) (2.19.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from typer->deepeval) (8.1.8)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from aiohttp->datasets->deepeval) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from aiohttp->datasets->deepeval) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from aiohttp->datasets->deepeval) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from aiohttp->datasets->deepeval) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from aiohttp->datasets->deepeval) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from aiohttp->datasets->deepeval) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from aiohttp->datasets->deepeval) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->deepeval) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->deepeval) (0.9.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.24.0->deepeval) (1.17.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core->deepeval) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain->deepeval) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain->deepeval) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain->deepeval) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain->deepeval) (0.23.0)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index->deepeval) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index->deepeval) (1.2.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index->deepeval) (3.4.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index->deepeval) (11.1.0)\n",
      "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.8 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index->deepeval) (0.1.12)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->deepeval) (4.12.3)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->deepeval) (5.3.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->deepeval) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index->deepeval) (0.6.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->deepeval) (0.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from nltk>3.8.1->llama-index->deepeval) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from nltk>3.8.1->llama-index->deepeval) (2023.12.25)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai->deepeval) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai->deepeval) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai->deepeval) (0.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai->deepeval) (1.3.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->deepeval) (1.0.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain->deepeval) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from pandas->datasets->deepeval) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from pandas->datasets->deepeval) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from pandas->datasets->deepeval) (2025.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->deepeval) (2.6)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain->deepeval) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain->deepeval) (0.14.0)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.1 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->deepeval) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets->deepeval) (1.17.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->deepeval) (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (1.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting absl-py (from rouge-score)\n",
      "  Downloading absl_py-2.2.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: nltk in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from rouge-score) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from rouge-score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from rouge-score) (1.17.0)\n",
      "Requirement already satisfied: click in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from nltk->rouge-score) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from nltk->rouge-score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from nltk->rouge-score) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from nltk->rouge-score) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from click->nltk->rouge-score) (0.4.6)\n",
      "Downloading absl_py-2.2.1-py3-none-any.whl (277 kB)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py): started\n",
      "  Building wheel for rouge-score (setup.py): finished with status 'done'\n",
      "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24972 sha256=15b68232745607f03bff984a973ab32f607c8ba5855846a04fa6495a7c0a00ef\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\85\\9d\\af\\01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: absl-py, rouge-score\n",
      "Successfully installed absl-py-2.2.1 rouge-score-0.1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install deepeval\n",
    "# !pip install python-dotenv\n",
    "# !pip install rouge-score\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Importing metrics from deepeval\n",
    "from deepeval.metrics.ragas import (\n",
    "    RAGASContextualPrecisionMetric,\n",
    "    RAGASFaithfulnessMetric,\n",
    "    RAGASContextualRecallMetric,\n",
    "    RAGASAnswerRelevancyMetric\n",
    ")\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.evaluate import evaluate\n",
    "\n",
    "# Download necessary NLTK data files\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Import NLTK translation metrics\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "# Import ROUGE scorer\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics Overview\n",
    "\n",
    "This evaluation framework assesses our RAG system using both quantitative and qualitative metrics. The quantitative metrics provide objective, automated scores that reflect the similarity, consistency, and factuality of the generated answers. The qualitative metrics capture aspects such as context relevance, diversity, and clarity, which are essential for understanding the overall performance in real-world applications.\n",
    "\n",
    "---\n",
    "\n",
    "### Quantitative Metrics\n",
    "\n",
    "- **BLEUMetric**  \n",
    "  **What it measures:** Similarity between the generated answer and the expected output based on n-gram overlap.  \n",
    "  **Explanation:** Uses NLTK's `sentence_bleu` to compute a BLEU score. A higher score indicates a better overlap with the reference answer.\n",
    "\n",
    "- **ROUGEMetric**  \n",
    "  **What it measures:** Recall-oriented overlap between the generated answer and the expected output.  \n",
    "  **Explanation:** Computes ROUGE-1, ROUGE-2, and ROUGE-L F-measures and averages them. This reflects the degree to which key phrases and overall content are captured.\n",
    "\n",
    "- **METEORMetric**  \n",
    "  **What it measures:** Similarity between the generated answer and the expected output, addressing certain limitations of BLEU.  \n",
    "  **Explanation:** Uses NLTK’s `meteor_score` to compute the METEOR score, providing an alternative perspective on answer quality.\n",
    "\n",
    "- **FactualConsistencyMetric**  \n",
    "  **What it measures:** The factual consistency between the generated answer and the retrieved context.  \n",
    "  **Explanation:** Computes the cosine similarity between the TF-IDF vector representations of the generated answer and the combined retrieval context. A higher score indicates better alignment of the answer with the supporting context.\n",
    "\n",
    "---\n",
    "\n",
    "### Qualitative Metrics\n",
    "\n",
    "- **RAGASContextualPrecisionMetric**  \n",
    "  **What it measures:** Relevance of the retrieved context to the query.  \n",
    "  **Threshold:** >0.7.\n",
    "\n",
    "- **RAGASFaithfulnessMetric**  \n",
    "  **What it measures:** Factual consistency between the generated answer and the retrieved context.  \n",
    "  **Threshold:** >0.8.\n",
    "\n",
    "- **RAGASContextualRecallMetric**  \n",
    "  **What it measures:** Completeness of the retrieved context with respect to the query.  \n",
    "  **Threshold:** >0.6.\n",
    "\n",
    "- **RAGASAnswerRelevancyMetric**  \n",
    "  **What it measures:** Relevance of the generated answer to the query.  \n",
    "  **Threshold:** >0.7.\n",
    "\n",
    "- **ContextualRelevancyMetric (Custom)**  \n",
    "  **What it measures:** Combined relevance of the context and the generated answer to the query, computed via cosine similarity using TF-IDF vectors.  \n",
    "  **Threshold:** >0.65.\n",
    "\n",
    "- **ContextualDiversityMetric (Custom)**  \n",
    "  **What it measures:** Diversity of the retrieved context.  \n",
    "  **Threshold:** >0.5.\n",
    "\n",
    "- **ContextualConsistencyMetric (Custom)**  \n",
    "  **What it measures:** Consistency of the generated answer across multiple queries or context sources.  \n",
    "  **Threshold:** >0.7.\n",
    "\n",
    "- **TechnicalTermClarityMetric (Custom)**  \n",
    "  **What it measures:** Clarity of technical term explanations in the generated answer.  \n",
    "  **Threshold:** At least 1 explanation per technical term.\n",
    "\n",
    "- **QuerySpecificityMetric (Custom)**  \n",
    "  **What it measures:** Specificity of the generated answer relative to the query.  \n",
    "  **Threshold:** >0.7.\n",
    "\n",
    "- **CrossDocumentConsistencyMetric (Custom)**  \n",
    "  **What it measures:** Consistency of the generated answer across multiple documents or context sources.  \n",
    "  **Threshold:** >0.8.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    LLMTestCase(\n",
    "        input=\"What is the role of attention mechanisms in Transformers?\",\n",
    "        actual_output=\"Attention mechanisms (components that weigh the importance of different input tokens) enable Transformers to process sequential data efficiently.\",\n",
    "        expected_output=\"Attention mechanisms allow Transformers to focus on relevant parts of the input.\",\n",
    "        context=[\n",
    "            \"\"\"The matching engine processes these orders\n",
    "through three sequential phases:\n",
    "First, incoming limit orders that do not immediately cross the market are added to\n",
    "the order book, maintaining strict price-time priority. Second, market orders are processed\n",
    "through a two-stage matching algorithm: (a) market-to-market matching, where market\n",
    "orders are netted against each other at the current market price, and (b) market-to-book\n",
    "matching, where remaining market orders are executed against standing limit orders. Finally,\n",
    "any crossing limit orders are matched against the order book.\"\"\"\n",
    "        ],\n",
    "        retrieval_context=[\n",
    "            \"oAttentin mechanisms in Transformers...\",\n",
    "            \"The 2017 paper introduced self-attention...\"\n",
    "        ]\n",
    "    ),\n",
    "    # Add more test cases\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    LLMTestCase(\n",
    "        input=\"Could you walk me through the three‑stage matching algorithm the authors implement in their continuous double‑auction market?\",\n",
    "        actual_output = \"\"\"The matching engine in the continuous double-auction market uses a three-stage algorithm:\n",
    "Stage 1: Order Book Population: Incoming limit orders (orders to buy or sell at a specific price or better) that don't immediately find a match are added to the order book. The order book is organized using price-time priority, meaning the best prices are matched first, and if multiple orders exist at the same price, the oldest order is prioritized.\n",
    "Stage 2: Market Order Processing: Market orders (orders to buy or sell at the best available price) are processed in two steps:\n",
    "(a) Market-to-Market Matching: Market buy orders are matched with market sell orders at the current market price. These orders are essentially netted against each other.\n",
    "(b) Market-to-Book Matching: Any remaining market orders are then matched against existing limit orders in the order book.\n",
    "Stage 3: Crossing Limit Order Matching: Any limit orders that cross the market (a buy order with a price higher than the best ask price or a sell order with a price lower than the best bid price) are matched against existing orders in the order book. This ensures that trades occur whenever possible.\"\"\",\n",
    "\n",
    "        expected_output=\"\"\"Orders are handled in three sequential phases: (1) non‑crossing limit orders join the book; (2a) market‑to‑market netting; (2b) market‑to‑book execution; (3) any still‑crossing limit orders are matched.\"\"\",\n",
    "        context=[\n",
    "            \"\"\"The matching engine processes these orders\n",
    "through three sequential phases:\n",
    "First, incoming limit orders that do not immediately cross the market are added to\n",
    "the order book, maintaining strict price-time priority. Second, market orders are processed\n",
    "through a two-stage matching algorithm: (a) market-to-market matching, where market\n",
    "orders are netted against each other at the current market price, and (b) market-to-book\n",
    "matching, where remaining market orders are executed against standing limit orders. Finally,\n",
    "any crossing limit orders are matched against the order book.\"\"\"\n",
    "            \n",
    "        ],\n",
    "        retrieval_context = [\n",
    "    \"value considerations.\\nIn a double auction, buyers and sellers actively submit orders, with trades occurring when\\ncompatible buy and sell orders match the price. The matching engine processes these orders\\nthrough three sequential phases:\\nFirst, incoming limit orders that do not immediately cross the market are added to\\nthe order book, maintaining strict price-time priority. Second, market orders are processed\\nthrough a two-stage matching algorithm: (a) market-to-market matching, where market\\norders are netted against each other at the current market price, and (b) market-to-book\\nmatching, where remaining market orders are executed against standing limit orders. Finally,\\nany crossing limit orders are matched against the order book.\\n10\\n2.1.2 Implementation Details\\nThe matching engine ( MatchingEngine class) implements three primary components that\\nwork together to facilitate efficient market operation. The order processing component han-\\ndles the core matching functionality, where market orders are executed immediately against\\nthe best available prices in the order book during each trading round. When immediate\\nexecution is impossible, limit orders are stored in the order book according to price-time\\npriority. The system supports partial executions, maintaining careful tracking of remaining\\nquantities to ensure complete order fulfillment across multiple trades when necessary.\\nPosition management forms the second critical component, providing comprehensive\\ntracking of agent positions and cash balances throughout the trading session. Before any\\ntrade execution, the system performs rigorous pre-trade validation to ensure agents have suffi-\\ncient resources to fulfill their orders. This check includes validating buyer cash commitments\\nand shares availability for sellers, with the system maintaining accurate records of commit-\\nted and available resources for each agent. The position management system updates in\\nreal-time as trades are executed, ensuring market integrity and preventing over-commitment\\nof resources.\\nThe price formation mechanism constitutes the third component, implementing a sys-\\ntematic price discovery and market monitoring approach. As trades are executed within each\\nround, the system dynamically updates prices based on executed trades while continuously\\ntracking market depth and bid-ask spreads. This data collection provides detailed insights\\ninto market liquidity and efficiency. Each trade is logged with comprehensive information,\\nincluding price, quantity, and participating agents, creating a complete audit trail of mar-\\nket activity. This comprehensive price formation system ensures transparent price discovery\\nwhile generating rich data for market quality analysis.\\n11\",\n",
    "    \"the second agents’ design, and the third the analysis module.\\n8\\n2.1 Market Design\\nOur methodological framework integrates three components that create a controlled envi-\\nronment for LLM-based trading agents. The framework implements a flexible continuous\\ndouble-auction market mechanism that couples standard market microstructure principles\\nwith market clearing and matching algorithms to accommodate asynchronous LLM decisions.\\nThe market clearing process employs a dual-stage matching algorithm. In the first stage,\\nlimit orders are posted. In the second stage, market orders are netted using a market-\\nto-market matching engine that processes buy and sell orders, reconciling orders based on\\navailable agent cash and share commitments. In the third stage, any remaining market\\norders are matched against the existing order book, with unfilled quantities converted to\\naggressive limit orders. This three-tiered approach optimizes immediate execution and price\\ndiscovery while maintaining market liquidity.\\nThe system’s OrderMatchingService orchestrates this process by coordinating trade ex-\\necutions through the TradeExecutionService and managing order state transitions via the\\nOrderStateManager. Each trade is logged in detail, with the overall market state—including\\norder books, market depth, and price evolution—recalculated at the end of each trading\\nround.\\nThis modular design in the matching and clearing engine provides several advantages.\\nFirst, it enables rigorous trade validation where each market order is validated against agent\\ncash commitments and position constraints before matching, with the system dynamically\\nadjusting order quantities based on available cash when an agent’s commitment is insuf-\\nficiary, thus minimizing execution errors. Second, it offers flexible liquidity handling by\\nsupporting market-to-market and market-to-book matching, ensuring orders have multiple\\nexecution pathways, with unexecuted market orders converted to aggressive limit orders to\\ncapture remaining liquidity. Third, it maintains detailed trade audit capabilities by recording\\ncomprehensive traceability data including timestamps, trade volumes, executed prices, and\\nagent identifiers, thereby enabling post-trade analysis and performance benchmarking that\\n9\",\n",
    "    \"2024). Another examines LLMs’ strategic capabilities through task-based simulations and\\ncollaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\\nWithin the computer science literature, early works apply LLMs to financial markets but\\nabstract away many fundamental stock market characteristics. Often, they employ single-\\nprice clearing mechanisms without a persistent order book, ignore partial fills and bid-ask\\nspreads, and omit dividends. Consequently, these simplified environments can primarily\\naddress exogenous macro shocks (e.g., changes in interest rates or inflation; Gao et al. 2024),\\nexogenous policy changes (Zhang et al. 2024), or rely on advanced methods such as repetitive\\nnext-token predictions to generate better answers (Koa et al. 2024). This work extends\\nthese efforts by incorporating these crucial market features, enabling the study of complex\\nendogenous events such as flash crashes, liquidity shocks, and large-trader impacts.\\nThis work also connects to emerging research on algorithmic and AI-powered trading\\nsystems. Dou, Goldstein, and Ji (2024) demonstrate how reinforcement learning-based AI\\nspeculators can autonomously learn to sustain collusive behavior without explicit coordi-\\nnation, achieving supra-competitive profits through either price-trigger strategies or self-\\nconfirming bias in learning. This finding is particularly informative for this framework as\\nit highlights potential emergent behaviors that may arise when intelligent agents interact in\\n7\",\n",
    "    \"by detailed Trade Data, which records individual transaction details such as prices, quan-\\ntities, buyer and seller identifiers, timestamps, round information, and specific execution\\ndetails.\\nAgent Data provides insights into participant behavior by monitoring cash and share\\npositions, portfolio values, wealth evolution, and agent type and strategy identifiers. Order\\nData captures the complete lifecycle of trading decisions, including order specifications\\n(type, size, price), agent reasoning and justification, decision context and timing, and order\\nlifecycle events. Finally, Market State data maintains a comprehensive view of overall mar-\\nket conditions through order book snapshots, market depth information, aggregate statistics,\\nand various market microstructure metrics.\\n25\\nFigure 5: Order Type Analysis under Systematic Variation. Displays the proportion of\\nMarket vs. Limit orders used by different agent types across varying Price/Fundamental\\nratios.\\n26\",\n",
    "    \"The theory of intermediation developed in Chapter 14 focuses on the risk-pooling and\\nrisk-sharing products created by financial-services institutions. Products examined\\nrange from standardized instruments such as a group of mutual funds with charac-\\nteristics described in Theorem 15.5 to custom products tailored to meet the specific\\nrequirements of each investor. Contingent-claims analysis (CCA) is the tool used\\nto derive the production technologies and costs for intermediaries to create these\\ncustom derivative securities. As discussed, such financial products and the associ-\\nated activities of their producers are redundant in a frictionless environment with no\\ninformation-gathering or transactions costs. Thus, to provide a nontrivial role for\\nintermediaries in our equilibrium analysis here, we assume that some investors and\\nbusiness firms face transactions costs for trading and issuing securities directly in\\nthe capital markets. However, to preserve the CCA production theory for intermedi-\\naries, we follow the model in Chapter 14 and posit that financial intermediaries, as\\nthe lowest-cost transactors, can trade continuously in the capital market at no cost.\\n16.2 Financial Intermediation with Dynamically-Complete Markets 417\",\n",
    "    \"market efficiency and price discovery processes throughout the simulation.\\nAgent performance metrics include absolute position tracking (shares, cash, and total\\nwealth), wealth composition analysis, position change metrics, and return calculations. The\\nsystem computes both absolute and percentage returns on various portfolio components\\nand compares performance across agent types to identify relative advantages of different\",\n",
    "    \"value, the system:\\n1. Sets market price P = ρV where ρ is the target ratio\\n2. Generates a consistent order book structure around this price\\n3. Executes multiple decision trials with the same agent type\\n4. Records decision outcomes (buy/sell/hold), order types, quantities, and reasoning\",\n",
    "    \"allocations are briefly addressed in Chapter 15 and analyzed more fully in Chapter 16. If a set of existing\\nsecurities and markets leads to an equilibrium that is an unconstrained Pareto optimum, then any additional\\nsecurities or markets will be redundant.\\n50The term “transactions costs” can, of course, mean more than just the bid-ask spread or commissions\\npaid for buying and selling assets. For example, if an investor literally traded his portfolio continuously, he\\nwould have no time to do anything else! Because investment management and financial intermediation involve\\nprimarily information processing and security trading, there are significant economies of scale. One would thus\\nexpect substantially lower costs for the individual investor to use intermediaries instead of transacting directly\\nin the asset markets.\"\n",
    "]\n",
    "    ),\n",
    "    LLMTestCase(\n",
    "        input=\"Why do the authors choose discrete trading rounds instead of real‑time order processing for the LLM agents?\",\n",
    "        actual_output = \"\"\"The authors use discrete trading rounds because LLMs (Large Language Models) have latency (delay) constraints, making real-time order processing infeasible. Essentially, LLMs take time to process information and make decisions, so a continuous real-time system wouldn't work efficiently. Discrete rounds provide structured intervals for the LLMs to receive information, decide on their actions, and submit their orders.\"\"\",\n",
    "\n",
    "        expected_output=\"\"\"LLMs have latency; discrete rounds let agents think while still approximating concurrency via randomised order of submission.\"\"\",\n",
    "        context=[\n",
    "            \"\"\"When the market starts significantly above\n",
    "the fundamental value (left panels), the price fails to converge downwards towards the $28.00\n",
    "benchmark within the 15 rounds, remaining substantially elevated. Agent valuations mirror\n",
    "this persistence, with many agents maintaining estimates well above the fundamental value.\n",
    "However, when the market begins significantly below the fundamental value\"\"\"\n",
    "            \n",
    "        ],\n",
    "        retrieval_context = [\n",
    "    \"value considerations.\\nIn a double auction, buyers and sellers actively submit orders, with trades occurring when\\ncompatible buy and sell orders match the price. The matching engine processes these orders\\nthrough three sequential phases:\\nFirst, incoming limit orders that do not immediately cross the market are added to\\nthe order book, maintaining strict price-time priority. Second, market orders are processed\\nthrough a two-stage matching algorithm: (a) market-to-market matching, where market\\norders are netted against each other at the current market price, and (b) market-to-book\\nmatching, where remaining market orders are executed against standing limit orders. Finally,\\nany crossing limit orders are matched against the order book.\\n10\\n2.1.2 Implementation Details\\nThe matching engine ( MatchingEngine class) implements three primary components that\\nwork together to facilitate efficient market operation. The order processing component han-\\ndles the core matching functionality, where market orders are executed immediately against\\nthe best available prices in the order book during each trading round. When immediate\\nexecution is impossible, limit orders are stored in the order book according to price-time\\npriority. The system supports partial executions, maintaining careful tracking of remaining\\nquantities to ensure complete order fulfillment across multiple trades when necessary.\\nPosition management forms the second critical component, providing comprehensive\\ntracking of agent positions and cash balances throughout the trading session. Before any\\ntrade execution, the system performs rigorous pre-trade validation to ensure agents have suffi-\\ncient resources to fulfill their orders. This check includes validating buyer cash commitments\\nand shares availability for sellers, with the system maintaining accurate records of commit-\\nted and available resources for each agent. The position management system updates in\\nreal-time as trades are executed, ensuring market integrity and preventing over-commitment\\nof resources.\\nThe price formation mechanism constitutes the third component, implementing a sys-\\ntematic price discovery and market monitoring approach. As trades are executed within each\\nround, the system dynamically updates prices based on executed trades while continuously\\ntracking market depth and bid-ask spreads. This data collection provides detailed insights\\ninto market liquidity and efficiency. Each trade is logged with comprehensive information,\\nincluding price, quantity, and participating agents, creating a complete audit trail of mar-\\nket activity. This comprehensive price formation system ensures transparent price discovery\\nwhile generating rich data for market quality analysis.\\n11\",\n",
    "    \"the second agents’ design, and the third the analysis module.\\n8\\n2.1 Market Design\\nOur methodological framework integrates three components that create a controlled envi-\\nronment for LLM-based trading agents. The framework implements a flexible continuous\\ndouble-auction market mechanism that couples standard market microstructure principles\\nwith market clearing and matching algorithms to accommodate asynchronous LLM decisions.\\nThe market clearing process employs a dual-stage matching algorithm. In the first stage,\\nlimit orders are posted. In the second stage, market orders are netted using a market-\\nto-market matching engine that processes buy and sell orders, reconciling orders based on\\navailable agent cash and share commitments. In the third stage, any remaining market\\norders are matched against the existing order book, with unfilled quantities converted to\\naggressive limit orders. This three-tiered approach optimizes immediate execution and price\\ndiscovery while maintaining market liquidity.\\nThe system’s OrderMatchingService orchestrates this process by coordinating trade ex-\\necutions through the TradeExecutionService and managing order state transitions via the\\nOrderStateManager. Each trade is logged in detail, with the overall market state—including\\norder books, market depth, and price evolution—recalculated at the end of each trading\\nround.\\nThis modular design in the matching and clearing engine provides several advantages.\\nFirst, it enables rigorous trade validation where each market order is validated against agent\\ncash commitments and position constraints before matching, with the system dynamically\\nadjusting order quantities based on available cash when an agent’s commitment is insuf-\\nficiary, thus minimizing execution errors. Second, it offers flexible liquidity handling by\\nsupporting market-to-market and market-to-book matching, ensuring orders have multiple\\nexecution pathways, with unexecuted market orders converted to aggressive limit orders to\\ncapture remaining liquidity. Third, it maintains detailed trade audit capabilities by recording\\ncomprehensive traceability data including timestamps, trade volumes, executed prices, and\\nagent identifiers, thereby enabling post-trade analysis and performance benchmarking that\\n9\",\n",
    "    \"2024). Another examines LLMs’ strategic capabilities through task-based simulations and\\ncollaborative decision-making (Li, Zhang, and Sun 2023; Piatti et al. 2024).\\nWithin the computer science literature, early works apply LLMs to financial markets but\\nabstract away many fundamental stock market characteristics. Often, they employ single-\\nprice clearing mechanisms without a persistent order book, ignore partial fills and bid-ask\\nspreads, and omit dividends. Consequently, these simplified environments can primarily\\naddress exogenous macro shocks (e.g., changes in interest rates or inflation; Gao et al. 2024),\\nexogenous policy changes (Zhang et al. 2024), or rely on advanced methods such as repetitive\\nnext-token predictions to generate better answers (Koa et al. 2024). This work extends\\nthese efforts by incorporating these crucial market features, enabling the study of complex\\nendogenous events such as flash crashes, liquidity shocks, and large-trader impacts.\\nThis work also connects to emerging research on algorithmic and AI-powered trading\\nsystems. Dou, Goldstein, and Ji (2024) demonstrate how reinforcement learning-based AI\\nspeculators can autonomously learn to sustain collusive behavior without explicit coordi-\\nnation, achieving supra-competitive profits through either price-trigger strategies or self-\\nconfirming bias in learning. This finding is particularly informative for this framework as\\nit highlights potential emergent behaviors that may arise when intelligent agents interact in\\n7\",\n",
    "    \"by detailed Trade Data, which records individual transaction details such as prices, quan-\\ntities, buyer and seller identifiers, timestamps, round information, and specific execution\\ndetails.\\nAgent Data provides insights into participant behavior by monitoring cash and share\\npositions, portfolio values, wealth evolution, and agent type and strategy identifiers. Order\\nData captures the complete lifecycle of trading decisions, including order specifications\\n(type, size, price), agent reasoning and justification, decision context and timing, and order\\nlifecycle events. Finally, Market State data maintains a comprehensive view of overall mar-\\nket conditions through order book snapshots, market depth information, aggregate statistics,\\nand various market microstructure metrics.\\n25\\nFigure 5: Order Type Analysis under Systematic Variation. Displays the proportion of\\nMarket vs. Limit orders used by different agent types across varying Price/Fundamental\\nratios.\\n26\",\n",
    "    \"The theory of intermediation developed in Chapter 14 focuses on the risk-pooling and\\nrisk-sharing products created by financial-services institutions. Products examined\\nrange from standardized instruments such as a group of mutual funds with charac-\\nteristics described in Theorem 15.5 to custom products tailored to meet the specific\\nrequirements of each investor. Contingent-claims analysis (CCA) is the tool used\\nto derive the production technologies and costs for intermediaries to create these\\ncustom derivative securities. As discussed, such financial products and the associ-\\nated activities of their producers are redundant in a frictionless environment with no\\ninformation-gathering or transactions costs. Thus, to provide a nontrivial role for\\nintermediaries in our equilibrium analysis here, we assume that some investors and\\nbusiness firms face transactions costs for trading and issuing securities directly in\\nthe capital markets. However, to preserve the CCA production theory for intermedi-\\naries, we follow the model in Chapter 14 and posit that financial intermediaries, as\\nthe lowest-cost transactors, can trade continuously in the capital market at no cost.\\n16.2 Financial Intermediation with Dynamically-Complete Markets 417\",\n",
    "    \"market efficiency and price discovery processes throughout the simulation.\\nAgent performance metrics include absolute position tracking (shares, cash, and total\\nwealth), wealth composition analysis, position change metrics, and return calculations. The\\nsystem computes both absolute and percentage returns on various portfolio components\\nand compares performance across agent types to identify relative advantages of different\",\n",
    "    \"value, the system:\\n1. Sets market price P = ρV where ρ is the target ratio\\n2. Generates a consistent order book structure around this price\\n3. Executes multiple decision trials with the same agent type\\n4. Records decision outcomes (buy/sell/hold), order types, quantities, and reasoning\",\n",
    "    \"allocations are briefly addressed in Chapter 15 and analyzed more fully in Chapter 16. If a set of existing\\nsecurities and markets leads to an equilibrium that is an unconstrained Pareto optimum, then any additional\\nsecurities or markets will be redundant.\\n50The term “transactions costs” can, of course, mean more than just the bid-ask spread or commissions\\npaid for buying and selling assets. For example, if an investor literally traded his portfolio continuously, he\\nwould have no time to do anything else! Because investment management and financial intermediation involve\\nprimarily information processing and security trading, there are significant economies of scale. One would thus\\nexpect substantially lower costs for the individual investor to use intermediaries instead of transacting directly\\nin the asset markets.\"\n",
    "]\n",
    "    ),\n",
    "    LLMTestCase(\n",
    "        input=\"What is the main experimental finding when the simulated market starts 25 % above the fundamental value?\",\n",
    "        actual_output=\"\"\"In the infinite horizon scenario where the simulated market began 25% above the fundamental value (overvalued at $56.00 compared to the true value of $28.00), the price failed to converge downwards toward the fundamental value within the 15 trading rounds. The LLM (Large Language Model - a type of artificial intelligence model that can generate human-like text) agents' valuations also remained significantly elevated above the fundamental value, mirroring the persistent overvaluation in the market. This suggests that, under these specific conditions, the AI agents were less effective at correcting overvaluation compared to undervaluation within the given timeframe.\"\"\",\n",
    "        expected_output=\"\"\"With an initial price 25 % above fundamentals, prices failed to converge downward within 15 rounds and agents kept over‑valuing the asset.\"\"\",\n",
    "        context=[\n",
    "            \"\"\"When the market starts significantly above the fundamental value … the price fails to converge downwards … remaining substantially elevated. Agent valuations mirror this persistence, with many agents maintaining estimates well above the fundamental value.\"\"\"\n",
    "        ],\n",
    "        retrieval_context=[\n",
    "            \"oAttentin mechanisms in Transformers...\",\n",
    "            \"The 2017 paper introduced self-attention...\"\n",
    "        ]\n",
    "    ),\n",
    "    \n",
    "    LLMTestCase(\n",
    "        input=\"What is the main experimental finding when the simulated market starts 25 % above the fundamental value?\",\n",
    "        actual_output=\"Attention mechanisms (components that weigh the importance of different input tokens) enable Transformers to process sequential data efficiently.\",\n",
    "        expected_output=\"\"\"With an initial price 25 % above fundamentals, prices failed to converge downward within 15 rounds and agents kept over‑valuing the asset.\"\"\",\n",
    "        context=[\n",
    "            \"\"\"When the market starts significantly above the fundamental value … the price fails to converge downwards … remaining substantially elevated. Agent valuations mirror this persistence, with many agents maintaining estimates well above the fundamental value.\"\"\"\n",
    "        ],\n",
    "        retrieval_context=[\n",
    "            \"oAttentin mechanisms in Transformers...\",\n",
    "            \"The 2017 paper introduced self-attention...\"\n",
    "        ]\n",
    "    ),\n",
    "    LLMTestCase(\n",
    "        input=\"In simple terms, what does Figure 7 (agent valuations over time) tell us about over‑ vs under‑valuation corrections?\",\n",
    "        actual_output=\"Attention mechanisms (components that weigh the importance of different input tokens) enable Transformers to process sequential data efficiently.\",\n",
    "        expected_output=\"\"\"It shows asymmetry: over‑valuation persists, but under‑valuation is corrected—the right panel converges to $28 while the left stays high.\"\"\",\n",
    "        context=[\n",
    "            \"\"\"When the market starts significantly above the fundamental value … the price fails to converge downwards … remaining substantially elevated. Agent valuations mirror this persistence, with many agents maintaining estimates well above the fundamental value.\"\"\"\n",
    "        ],\n",
    "        retrieval_context=[\n",
    "            \"oAttentin mechanisms in Transformers...\",\n",
    "            \"The 2017 paper introduced self-attention...\"\n",
    "        ]\n",
    "    ),\n",
    "    LLMTestCase(\n",
    "        input=\"The paper gives Vt=E[D]rV_t=\\tfrac{E[D]}{r} as Equation (1). What does each variable represent, and how is this perpetuity formula used in the simulations?\",\n",
    "        actual_output=\"Attention mechanisms (components that weigh the importance of different input tokens) enable Transformers to process sequential data efficiently.\",\n",
    "        expected_output=\"\"\"Vt=E[D]/rV_t = E[D]/r treats the stock as a perpetuity: E[D]E[D] is expected dividend per round and rr the risk‑free rate; with $1.40 and 5 % the value is $28.\"\"\",\n",
    "        context=[\n",
    "            \"\"\"The framework implements a consistent approach… For infinite horizon markets, the fundamental value follows the standard dividend discount model: Vt=E[D]rV_t = \\frac{E[D]}{r}. … For the default parameters where the expected dividend is $1.40 and the interest rate is 5 %, this yields a fundamental value of $28.00.\"\"\"\n",
    "        ],\n",
    "        retrieval_context=[\n",
    "            \"oAttentin mechanisms in Transformers...\",\n",
    "            \"The 2017 paper introduced self-attention...\"\n",
    "        ]\n",
    "    ),\n",
    "    LLMTestCase(\n",
    "        input=\"What is a ‘continuous double auction’, and how does it differ from the single‑price clearing used in earlier LLM‑market papers the authors critique?\",\n",
    "        actual_output=\"Attention mechanisms (components that weigh the importance of different input tokens) enable Transformers to process sequential data efficiently.\",\n",
    "        expected_output=\"\"\"It allows buyers and sellers to post bids/asks continuously with price‑time priority, unlike prior LLM papers that used single‑price batch clearing without an order book.\"\"\",\n",
    "        context=[\n",
    "            \"\"\"Our framework implements a continuous double‑auction market…” + “Within the computer‑science literature, early works … employ single‑price clearing mechanisms without a persistent order book…\"\"\"\n",
    "        ],\n",
    "        retrieval_context=[\n",
    "            \"oAttentin mechanisms in Transformers...\",\n",
    "            \"The 2017 paper introduced self-attention...\"\n",
    "        ]\n",
    "    ),\n",
    "    LLMTestCase(\n",
    "        input=\"How do the authors define the price‑to‑fundamental ratio and why is it central to their systematic variation experiments?\",\n",
    "        actual_output=\"Attention mechanisms (components that weigh the importance of different input tokens) enable Transformers to process sequential data efficiently.\",\n",
    "        expected_output=\"\"\"ρ = P ⁄ V. By sweeping ρ from 0.1–3.5 and holding other factors fixed, the authors trace decision boundaries of each agent type.\"\"\",\n",
    "        context=[\n",
    "            \"\"\"Our example implementation varies the price‑to‑fundamental ratio (ρ = P/V) across a range from 0.1 to 3.5 while maintaining all other market parameters constant…\"\"\"\n",
    "        ],\n",
    "        retrieval_context=[\n",
    "            \"oAttentin mechanisms in Transformers...\",\n",
    "            \"The 2017 paper introduced self-attention...\"\n",
    "        ]\n",
    "    ),\n",
    "    LLMTestCase(\n",
    "        input=\"HWhat are the roles of system prompts vs user prompts in shaping an LLM trading agent’s behaviour?\",\n",
    "        actual_output=\"Attention mechanisms (components that weigh the importance of different input tokens) enable Transformers to process sequential data efficiently.\",\n",
    "        expected_output=\"\"\"System prompt fixes the agent’s identity and objectives across rounds; user prompt feeds current market state & constraints for the immediate decision.\"\"\",\n",
    "        context=[\n",
    "            \"\"\"The system prompt establishes the agent’s fundamental trading characteristics…” / “The user prompt provides the immediate market context necessary for tactical decision‑making.\"\"\"\n",
    "        ],\n",
    "        retrieval_context=[\n",
    "            \"oAttentin mechanisms in Transformers...\",\n",
    "            \"The 2017 paper introduced self-attention...\"\n",
    "        ]\n",
    "    ),\n",
    "    LLMTestCase(\n",
    "        input=\"The authors note that LLMs ‘follow instructions even if doing so results in financial losses.’ How might this limit their realism as profit‑seeking traders?\",\n",
    "        actual_output=\"Attention mechanisms (components that weigh the importance of different input tokens) enable Transformers to process sequential data efficiently.\",\n",
    "        expected_output=\"\"\"LLMs optimise for prompt fidelity; they keep executing the instructed strategy even when it loses money, unlike humans who adapt for profit.\"\"\",\n",
    "        context=[\n",
    "            \"\"\"They maintain their strategic direction even if doing so results in financial losses. This… creates a unique trading profile distinct from rule‑based algorithms and human traders.\"\"\"\n",
    "        ],\n",
    "        retrieval_context=[\n",
    "            \"oAttentin mechanisms in Transformers...\",\n",
    "            \"The 2017 paper introduced self-attention...\"\n",
    "        ]\n",
    "    ),\n",
    "    LLMTestCase(\n",
    "        input=\"What systemic risks do the authors foresee if many firms deploy similarly prompted LLM traders in real markets?\",\n",
    "        actual_output=\"Attention mechanisms (components that weigh the importance of different input tokens) enable Transformers to process sequential data efficiently.\",\n",
    "        expected_output=\"\"\"If many firms deploy similarly prompted LLMs built on the same foundation model, their synchronised reactions could amplify volatility and create new instabilities.\"\"\",\n",
    "        context=[\n",
    "            \"\"\"A key concern is the potential for widespread correlated behavior… similar underlying LLM architectures responding uniformly… could destabilize trading patterns without explicit coordination.\"\"\"\n",
    "        ],\n",
    "        retrieval_context=[\n",
    "            \"oAttentin mechanisms in Transformers...\",\n",
    "            \"The 2017 paper introduced self-attention...\"\n",
    "        ]\n",
    "    ),\n",
    "    LLMTestCase(\n",
    "        input=\"In SRCNN, what practical role does the non‑linear mapping layer with 1 × 1 filters play in the overall SR pipeline?\",\n",
    "        actual_output=\"Attention mechanisms (components that weigh the importance of different input tokens) enable Transformers to process sequential data efficiently.\",\n",
    "        expected_output=\"\"\"It transforms every patch‑level feature vector (extracted by the first conv layer) into a new, lower‑dimensional representation that will later be linearly combined into HR pixels. Because the spatial kernel is 1 × 1, the mapping is applied channel‑wise without mixing spatial positions, mimicking the sparse‑coding step but in a single feed‑forward pass.\"\"\",\n",
    "        context=[\n",
    "            \"\"\"The first layer extracts an n₁‑dimensional feature for each patch. In the second operation, we **map each of these n₁‑dimensional vectors into an n₂‑dimensional one. This is equivalent to applying n₂ filters which have a trivial spatial support 1 × 1 … This operation non‑linearly maps each high‑dimensional vector onto another high‑dimensional vector.\"\"\"\n",
    "        ],\n",
    "        retrieval_context=[\n",
    "            \"oAttentin mechanisms in Transformers...\",\n",
    "            \"The 2017 paper introduced self-attention...\"\n",
    "        ]\n",
    "    ),\n",
    "    LLMTestCase(\n",
    "        input=\"Why do the authors of SRCNN first upscale the LR image with bicubic interpolation instead of learning that step end‑to‑end?\",\n",
    "        actual_output=\"Attention mechanisms (components that weigh the importance of different input tokens) enable Transformers to process sequential data efficiently.\",\n",
    "        expected_output=\"\"\"Because popular GPU conv‑net toolkits (cuda‑convnet at the time) did not yet support fractional‑stride convolutions. Upscaling once with bicubic ensures the network can stay fully convolutional with integer strides while still learning the rest of the SR mapping end‑to‑end.\"\"\",\n",
    "        context=[\n",
    "            \"\"\"…we first upscale it to the desired size using bicubic interpolation, which is the only pre‑processing we perform. … There is a fractional stride. To take advantage of the popular well‑optimized implementations such as cuda‑convnet, we exclude this “layer” from learning.\"\"\"\n",
    "        ],\n",
    "        retrieval_context=[\n",
    "            \"oAttentin mechanisms in Transformers...\",\n",
    "            \"The 2017 paper introduced self-attention...\"\n",
    "        ]\n",
    "    ),\n",
    "    LLMTestCase(\n",
    "        input=\"What exactly is meant by “perceptual loss” in SRGAN, and how is it computed from VGG feature maps?\",\n",
    "        actual_output=\"Attention mechanisms (components that weigh the importance of different input tokens) enable Transformers to process sequential data efficiently.\",\n",
    "        expected_output=\"\"\"It is a weighted sum of a content loss (Euclidean distance between VGG‑feature maps of SR vs. HR images) and an adversarial loss (−log D(G(I))). The VGG layers (e.g., φ5,4) provide semantics; the adversarial term pushes outputs onto the natural‑image manifold.\"\"\",\n",
    "        context=[\n",
    "            \"\"\"We formulate the perceptual loss as the weighted sum of a content loss and an adversarial loss component … Content loss l_{VGG/i.j} = 1/(W_{i,j}H_{i,j}) Σ(φ_{i,j}(I_{HR}) − φ_{i,j}(G(I_{LR})))² … l_{Gen} = −log D(G(I_{LR}))\"\"\"\n",
    "        ],\n",
    "        retrieval_context=[\n",
    "            \"oAttentin mechanisms in Transformers...\",\n",
    "            \"The 2017 paper introduced self-attention...\"\n",
    "        ]\n",
    "    ),\n",
    "    LLMTestCase(\n",
    "        input=\"SRCNN reports 8 032 trainable parameters; can you explain how this relatively small count is achieved?\",\n",
    "        actual_output=\"Attention mechanisms (components that weigh the importance of different input tokens) enable Transformers to process sequential data efficiently.\",\n",
    "        expected_output=\"\"\"Because it uses just three convolutional layers with relatively few filters (64, 32, c) and small kernels (9×9, 1×1, 5×5). Param count = (c·9²·64)+(64·1²·32)+(32·5²·c)+biases ≈ 8 k\"\"\",\n",
    "        context=[\n",
    "            \"\"\"A typical and basic setting is f₁ = 9, f₂ = 1, f₃ = 5, n₁ = 64, n₂ = 32 … the number of parameters of 9‑1‑5 … is 8 032.\"\"\"\n",
    "        ],\n",
    "        retrieval_context=[\n",
    "            \"oAttentin mechanisms in Transformers...\",\n",
    "            \"The 2017 paper introduced self-attention...\"\n",
    "        ]\n",
    "    ),\n",
    "    LLMTestCase(\n",
    "        input=\"SRGAN introduces two networks called SRResNet and SRGAN. What is the structural difference between them?\",\n",
    "        actual_output=\"Attention mechanisms (components that weigh the importance of different input tokens) enable Transformers to process sequential data efficiently.\",\n",
    "        expected_output=\"\"\"Both share the same 16‑block residual generator; SRResNet is trained only with a pixel/feature content loss, whereas SRGAN adds a discriminator and the adversarial term during training, yielding sharper textures.\"\"\",\n",
    "        context=[\n",
    "            \"\"\"We employ a deep residual network (SRResNet) … We then train SRGAN, which uses the same generator but adds a discriminator network and optimizes the adversarial loss in addition to the content loss.\"\"\"\n",
    "        ],\n",
    "        retrieval_context=[\n",
    "            \"oAttentin mechanisms in Transformers...\",\n",
    "            \"The 2017 paper introduced self-attention...\"\n",
    "        ]\n",
    "    ),\n",
    "    # Add more test cases\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BLEUMetric:\n",
    "    \"\"\"\n",
    "    BLEU Metric calculates the BLEU score between the generated answer (actual_output)\n",
    "    and the expected output as a measure of similarity.\n",
    "    \n",
    "    A higher BLEU score indicates better overlap between the generated answer and the reference.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.score = 0\n",
    "\n",
    "    def measure(self, test_case: LLMTestCase) -> float:\n",
    "        reference = [test_case.expected_output.split()]\n",
    "        hypothesis = test_case.actual_output.split()\n",
    "        smoothing = SmoothingFunction().method1\n",
    "        self.score = sentence_bleu(reference, hypothesis, smoothing_function=smoothing)\n",
    "        return self.score\n",
    "\n",
    "class ROUGEMetric:\n",
    "    \"\"\"\n",
    "    ROUGE Metric calculates ROUGE scores (e.g., ROUGE-1, ROUGE-2, ROUGE-L) between the\n",
    "    generated answer (actual_output) and the expected output.\n",
    "    \n",
    "    These scores reflect the recall-oriented overlap between the generated and reference texts.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.score = 0\n",
    "        self.details = {}\n",
    "\n",
    "    def measure(self, test_case: LLMTestCase) -> float:\n",
    "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "        scores = scorer.score(test_case.expected_output, test_case.actual_output)\n",
    "        # For simplicity, we can average the three ROUGE scores (using F-measure)\n",
    "        self.details = scores\n",
    "        self.score = np.mean([score.fmeasure for score in scores.values()])\n",
    "        return self.score\n",
    "\n",
    "class METEORMetric:\n",
    "    \"\"\"\n",
    "    METEOR Metric calculates the METEOR score between the generated answer (actual_output)\n",
    "    and the expected output. METEOR is designed to address some weaknesses of BLEU.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.score = 0\n",
    "\n",
    "    def measure(self, test_case: LLMTestCase) -> float:\n",
    "        self.score = meteor_score([test_case.expected_output], test_case.actual_output)\n",
    "        return self.score\n",
    "\n",
    "class FactualConsistencyMetric:\n",
    "    \"\"\"\n",
    "    FactualConsistencyMetric measures the factual consistency between the generated answer \n",
    "    and the retrieved context by computing the cosine similarity (using TF-IDF vectors)\n",
    "    between the answer and the combined retrieval context.\n",
    "    \n",
    "    A higher score indicates a better alignment of the generated answer with the context.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.score = 0\n",
    "\n",
    "    def measure(self, test_case: LLMTestCase) -> float:\n",
    "        answer = test_case.actual_output\n",
    "        context = \" \".join(test_case.retrieval_context)\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vectors = vectorizer.fit_transform([answer, context])\n",
    "        similarity = cosine_similarity(vectors[0:1], vectors[1:2])[0][0]\n",
    "        self.score = similarity\n",
    "        return self.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextualRelevancyMetric:\n",
    "    def __init__(self):\n",
    "        self.score = 0\n",
    "\n",
    "    def measure(self, test_case: LLMTestCase) -> float:\n",
    "        query = test_case.input\n",
    "        answer = test_case.actual_output\n",
    "        context = \" \".join(test_case.retrieval_context)\n",
    "        \n",
    "        # Compute similarity between query, answer, and context\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vectors = vectorizer.fit_transform([query, answer, context])\n",
    "        query_answer_sim = cosine_similarity(vectors[0:1], vectors[1:2])[0][0]\n",
    "        query_context_sim = cosine_similarity(vectors[0:1], vectors[2:3])[0][0]\n",
    "        \n",
    "        self.score = (query_answer_sim + query_context_sim) / 2\n",
    "        return self.score\n",
    "    \n",
    "\n",
    "\n",
    "class ContextualDiversityMetric:\n",
    "    def __init__(self):\n",
    "        self.score = 0\n",
    "\n",
    "    def measure(self, test_case: LLMTestCase) -> float:\n",
    "        contexts = test_case.retrieval_context\n",
    "        \n",
    "        # Compute pairwise similarity between contexts\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vectors = vectorizer.fit_transform(contexts)\n",
    "        similarity_matrix = cosine_similarity(vectors)\n",
    "        \n",
    "        # Average similarity (lower = more diverse)\n",
    "        avg_similarity = np.mean(similarity_matrix[np.triu_indices(len(contexts), 1)])\n",
    "        self.score = 1 - avg_similarity\n",
    "        return self.score\n",
    "    \n",
    "\n",
    "class ContextualConsistencyMetric:\n",
    "    def __init__(self):\n",
    "        self.score = 0\n",
    "\n",
    "    def measure(self, test_case: LLMTestCase) -> float:\n",
    "        contexts = test_case.retrieval_context\n",
    "        answer = test_case.actual_output\n",
    "        \n",
    "        # Check if answer appears in all contexts\n",
    "        consistent = all([answer in ctx for ctx in contexts])\n",
    "        self.score = 1.0 if consistent else 0.0\n",
    "        return self.score\n",
    "    \n",
    "\n",
    "class TechnicalTermClarityMetric:\n",
    "    def __init__(self):\n",
    "        self.score = 0\n",
    "        self.explanations = []\n",
    "\n",
    "    def measure(self, test_case: LLMTestCase) -> float:\n",
    "        answer = test_case.actual_output\n",
    "        # Regex to detect terms with explanations in parentheses\n",
    "        pattern = r\"([A-Z][a-zA-Z\\s]+) \\((.+?)\\)\"\n",
    "        matches = re.findall(pattern, answer)\n",
    "        \n",
    "        self.explanations = [term[0] for term in matches]\n",
    "        self.score = len(matches) / len(self._detect_technical_terms(answer))\n",
    "        return self.score\n",
    "\n",
    "    def _detect_technical_terms(self, text: str) -> List[str]:\n",
    "        # Replace with your domain-specific term list\n",
    "        technical_terms = [\"attention mechanisms\", \"Transformers\", \"self-attention\"]\n",
    "        return [term for term in technical_terms if term in text]\n",
    "    \n",
    "\n",
    "class QuerySpecificityMetric:\n",
    "    def __init__(self):\n",
    "        self.score = 0\n",
    "\n",
    "    def measure(self, test_case: LLMTestCase) -> float:\n",
    "        query = test_case.input\n",
    "        answer = test_case.actual_output\n",
    "        \n",
    "        # Simple heuristic: Longer answers for specific queries\n",
    "        query_words = len(query.split())\n",
    "        answer_words = len(answer.split())\n",
    "        self.score = min(answer_words / (query_words * 3), 1.0)\n",
    "        return self.score\n",
    "    \n",
    "\n",
    "class CrossDocumentConsistencyMetric:\n",
    "    def __init__(self):\n",
    "        self.score = 0\n",
    "\n",
    "    def measure(self, test_case: LLMTestCase) -> float:\n",
    "        contexts = test_case.retrieval_context\n",
    "        answer = test_case.actual_output\n",
    "        \n",
    "        # Check if answer appears in all contexts\n",
    "        consistent = all([answer in ctx for ctx in contexts])\n",
    "        self.score = 1.0 if consistent else 0.0\n",
    "        return self.score\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rag_system(test_cases):\n",
    "    metrics = [\n",
    "        RAGASContextualPrecisionMetric(threshold=0.7),\n",
    "        RAGASFaithfulnessMetric(threshold=0.8),\n",
    "        RAGASContextualRecallMetric(threshold=0.6),\n",
    "        RAGASAnswerRelevancyMetric(threshold=0.7),\n",
    "        ContextualRelevancyMetric(),\n",
    "        ContextualDiversityMetric(),\n",
    "        ContextualConsistencyMetric(),\n",
    "        TechnicalTermClarityMetric(),\n",
    "        QuerySpecificityMetric(),\n",
    "        CrossDocumentConsistencyMetric(),\n",
    "        # New quantitative metrics:\n",
    "        BLEUMetric(),\n",
    "        ROUGEMetric(),\n",
    "        METEORMetric(),\n",
    "        FactualConsistencyMetric()\n",
    "    ]\n",
    "    \n",
    "    return evaluate(test_cases, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate_rag_system(test_cases)\n",
    "for metric in results:\n",
    "    metric_name = metric.__class__.__name__\n",
    "    # For ROUGEMetric, include additional details if available.\n",
    "    if metric_name == \"ROUGEMetric\":\n",
    "        print(f\"{metric_name}: {metric.score:.3f} (Details: {metric.details}) (Passed: {metric.score >= 0.0})\")\n",
    "    else:\n",
    "        print(f\"{metric_name}: {metric.score:.3f} (Passed: {metric.score >= getattr(metric, 'threshold', 0)})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
