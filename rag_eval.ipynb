{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepeval in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (2.3.7)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (4.67.1)\n",
      "Requirement already satisfied: pytest in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (8.3.4)\n",
      "Requirement already satisfied: tabulate in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (0.9.0)\n",
      "Requirement already satisfied: typer in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (0.9.4)\n",
      "Requirement already satisfied: rich in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (13.9.4)\n",
      "Requirement already satisfied: protobuf in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (4.25.6)\n",
      "Requirement already satisfied: pydantic in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (2.10.6)\n",
      "Requirement already satisfied: sentry-sdk in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (2.21.0)\n",
      "Requirement already satisfied: pytest-repeat in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (0.9.3)\n",
      "Requirement already satisfied: pytest-xdist in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (3.6.1)\n",
      "Requirement already satisfied: portalocker in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (3.1.1)\n",
      "Requirement already satisfied: langchain in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (0.3.18)\n",
      "Requirement already satisfied: llama-index in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (0.12.17)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (0.3.35)\n",
      "Requirement already satisfied: langchain_openai in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (0.3.6)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (0.3.17)\n",
      "Requirement already satisfied: docx2txt~=0.8 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (0.8)\n",
      "Requirement already satisfied: importlib-metadata>=6.0.2 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (8.4.0)\n",
      "Requirement already satisfied: tenacity<=9.0.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (9.0.0)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.24.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.24.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (1.27.0)\n",
      "Requirement already satisfied: grpcio==1.67.1 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (1.67.1)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (1.6.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deepeval) (3.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from importlib-metadata>=6.0.2->deepeval) (3.21.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from opentelemetry-api<2.0.0,>=1.24.0->deepeval) (1.2.18)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.62.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.27.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.27.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from opentelemetry-sdk<2.0.0,>=1.24.0->deepeval) (0.48b0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from opentelemetry-sdk<2.0.0,>=1.24.0->deepeval) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from datasets->deepeval) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from datasets->deepeval) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from datasets->deepeval) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from datasets->deepeval) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from datasets->deepeval) (2.2.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from datasets->deepeval) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from datasets->deepeval) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets->deepeval) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from datasets->deepeval) (3.11.12)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from datasets->deepeval) (0.28.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from datasets->deepeval) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from datasets->deepeval) (6.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from requests->deepeval) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from requests->deepeval) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from requests->deepeval) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from requests->deepeval) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from tqdm->deepeval) (0.4.6)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from langchain->deepeval) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from langchain->deepeval) (0.3.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from langchain->deepeval) (2.0.38)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from langchain-core->deepeval) (1.33)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from pydantic->deepeval) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from pydantic->deepeval) (2.27.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from langchain-community->deepeval) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from langchain-community->deepeval) (2.7.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from langchain-community->deepeval) (0.4.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from langchain_openai->deepeval) (1.63.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from langchain_openai->deepeval) (0.9.0)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index->deepeval) (0.4.5)\n",
      "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index->deepeval) (0.4.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.17 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index->deepeval) (0.12.17)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index->deepeval) (0.3.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index->deepeval) (0.6.4)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index->deepeval) (0.3.19)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index->deepeval) (0.4.3)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index->deepeval) (0.3.1)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index->deepeval) (0.3.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index->deepeval) (0.4.5)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index->deepeval) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index->deepeval) (3.9.1)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from portalocker->deepeval) (308)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from pytest->deepeval) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from pytest->deepeval) (1.5.0)\n",
      "Requirement already satisfied: execnet>=2.1 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from pytest-xdist->deepeval) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from rich->deepeval) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from rich->deepeval) (2.19.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from typer->deepeval) (8.1.8)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from aiohttp->datasets->deepeval) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from aiohttp->datasets->deepeval) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from aiohttp->datasets->deepeval) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from aiohttp->datasets->deepeval) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from aiohttp->datasets->deepeval) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from aiohttp->datasets->deepeval) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from aiohttp->datasets->deepeval) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->deepeval) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->deepeval) (0.9.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.24.0->deepeval) (1.17.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core->deepeval) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain->deepeval) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain->deepeval) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain->deepeval) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain->deepeval) (0.23.0)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index->deepeval) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index->deepeval) (1.2.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index->deepeval) (3.4.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index->deepeval) (11.1.0)\n",
      "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.8 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index->deepeval) (0.1.12)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->deepeval) (4.12.3)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->deepeval) (5.3.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->deepeval) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index->deepeval) (0.6.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->deepeval) (0.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from nltk>3.8.1->llama-index->deepeval) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from nltk>3.8.1->llama-index->deepeval) (2023.12.25)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai->deepeval) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai->deepeval) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai->deepeval) (0.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain_openai->deepeval) (1.3.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->deepeval) (1.0.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain->deepeval) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from pandas->datasets->deepeval) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from pandas->datasets->deepeval) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from pandas->datasets->deepeval) (2025.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->deepeval) (2.6)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain->deepeval) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain->deepeval) (0.14.0)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.1 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->deepeval) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets->deepeval) (1.17.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->deepeval) (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (1.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting absl-py (from rouge-score)\n",
      "  Downloading absl_py-2.2.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: nltk in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from rouge-score) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from rouge-score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from rouge-score) (1.17.0)\n",
      "Requirement already satisfied: click in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from nltk->rouge-score) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from nltk->rouge-score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from nltk->rouge-score) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from nltk->rouge-score) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from click->nltk->rouge-score) (0.4.6)\n",
      "Downloading absl_py-2.2.1-py3-none-any.whl (277 kB)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py): started\n",
      "  Building wheel for rouge-score (setup.py): finished with status 'done'\n",
      "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24972 sha256=15b68232745607f03bff984a973ab32f607c8ba5855846a04fa6495a7c0a00ef\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\85\\9d\\af\\01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: absl-py, rouge-score\n",
      "Successfully installed absl-py-2.2.1 rouge-score-0.1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\desktop\\final_year_proj\\intellipaper\\venv\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install deepeval\n",
    "# !pip install python-dotenv\n",
    "# !pip install rouge-score\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Importing metrics from deepeval\n",
    "from deepeval.metrics.ragas import (\n",
    "    RAGASContextualPrecisionMetric,\n",
    "    RAGASFaithfulnessMetric,\n",
    "    RAGASContextualRecallMetric,\n",
    "    RAGASAnswerRelevancyMetric\n",
    ")\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.evaluate import evaluate\n",
    "\n",
    "# Download necessary NLTK data files\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Import NLTK translation metrics\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "# Import ROUGE scorer\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics Overview\n",
    "\n",
    "This evaluation framework assesses our RAG system using both quantitative and qualitative metrics. The quantitative metrics provide objective, automated scores that reflect the similarity, consistency, and factuality of the generated answers. The qualitative metrics capture aspects such as context relevance, diversity, and clarity, which are essential for understanding the overall performance in real-world applications.\n",
    "\n",
    "---\n",
    "\n",
    "### Quantitative Metrics\n",
    "\n",
    "- **BLEUMetric**  \n",
    "  **What it measures:** Similarity between the generated answer and the expected output based on n-gram overlap.  \n",
    "  **Explanation:** Uses NLTK's `sentence_bleu` to compute a BLEU score. A higher score indicates a better overlap with the reference answer.\n",
    "\n",
    "- **ROUGEMetric**  \n",
    "  **What it measures:** Recall-oriented overlap between the generated answer and the expected output.  \n",
    "  **Explanation:** Computes ROUGE-1, ROUGE-2, and ROUGE-L F-measures and averages them. This reflects the degree to which key phrases and overall content are captured.\n",
    "\n",
    "- **METEORMetric**  \n",
    "  **What it measures:** Similarity between the generated answer and the expected output, addressing certain limitations of BLEU.  \n",
    "  **Explanation:** Uses NLTK’s `meteor_score` to compute the METEOR score, providing an alternative perspective on answer quality.\n",
    "\n",
    "- **FactualConsistencyMetric**  \n",
    "  **What it measures:** The factual consistency between the generated answer and the retrieved context.  \n",
    "  **Explanation:** Computes the cosine similarity between the TF-IDF vector representations of the generated answer and the combined retrieval context. A higher score indicates better alignment of the answer with the supporting context.\n",
    "\n",
    "---\n",
    "\n",
    "### Qualitative Metrics\n",
    "\n",
    "- **RAGASContextualPrecisionMetric**  \n",
    "  **What it measures:** Relevance of the retrieved context to the query.  \n",
    "  **Threshold:** >0.7.\n",
    "\n",
    "- **RAGASFaithfulnessMetric**  \n",
    "  **What it measures:** Factual consistency between the generated answer and the retrieved context.  \n",
    "  **Threshold:** >0.8.\n",
    "\n",
    "- **RAGASContextualRecallMetric**  \n",
    "  **What it measures:** Completeness of the retrieved context with respect to the query.  \n",
    "  **Threshold:** >0.6.\n",
    "\n",
    "- **RAGASAnswerRelevancyMetric**  \n",
    "  **What it measures:** Relevance of the generated answer to the query.  \n",
    "  **Threshold:** >0.7.\n",
    "\n",
    "- **ContextualRelevancyMetric (Custom)**  \n",
    "  **What it measures:** Combined relevance of the context and the generated answer to the query, computed via cosine similarity using TF-IDF vectors.  \n",
    "  **Threshold:** >0.65.\n",
    "\n",
    "- **ContextualDiversityMetric (Custom)**  \n",
    "  **What it measures:** Diversity of the retrieved context.  \n",
    "  **Threshold:** >0.5.\n",
    "\n",
    "- **ContextualConsistencyMetric (Custom)**  \n",
    "  **What it measures:** Consistency of the generated answer across multiple queries or context sources.  \n",
    "  **Threshold:** >0.7.\n",
    "\n",
    "- **TechnicalTermClarityMetric (Custom)**  \n",
    "  **What it measures:** Clarity of technical term explanations in the generated answer.  \n",
    "  **Threshold:** At least 1 explanation per technical term.\n",
    "\n",
    "- **QuerySpecificityMetric (Custom)**  \n",
    "  **What it measures:** Specificity of the generated answer relative to the query.  \n",
    "  **Threshold:** >0.7.\n",
    "\n",
    "- **CrossDocumentConsistencyMetric (Custom)**  \n",
    "  **What it measures:** Consistency of the generated answer across multiple documents or context sources.  \n",
    "  **Threshold:** >0.8.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    LLMTestCase(\n",
    "        input=\"What is the role of attention mechanisms in Transformers?\",\n",
    "        actual_output=\"Attention mechanisms (components that weigh the importance of different input tokens) enable Transformers to process sequential data efficiently.\",\n",
    "        expected_output=\"Attention mechanisms allow Transformers to focus on relevant parts of the input.\",\n",
    "        context=[\n",
    "            \"Transformers use attention mechanisms to process sequential data. (Attention mechanisms are components that weigh the importance of different input tokens.)\",\n",
    "            \"Attention was introduced in the 2017 'Attention Is All You Need' paper.\"\n",
    "        ],\n",
    "        retrieval_context=[\n",
    "            \"oAttentin mechanisms in Transformers...\",\n",
    "            \"The 2017 paper introduced self-attention...\"\n",
    "        ]\n",
    "    ),\n",
    "    # Add more test cases\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BLEUMetric:\n",
    "    \"\"\"\n",
    "    BLEU Metric calculates the BLEU score between the generated answer (actual_output)\n",
    "    and the expected output as a measure of similarity.\n",
    "    \n",
    "    A higher BLEU score indicates better overlap between the generated answer and the reference.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.score = 0\n",
    "\n",
    "    def measure(self, test_case: LLMTestCase) -> float:\n",
    "        reference = [test_case.expected_output.split()]\n",
    "        hypothesis = test_case.actual_output.split()\n",
    "        smoothing = SmoothingFunction().method1\n",
    "        self.score = sentence_bleu(reference, hypothesis, smoothing_function=smoothing)\n",
    "        return self.score\n",
    "\n",
    "class ROUGEMetric:\n",
    "    \"\"\"\n",
    "    ROUGE Metric calculates ROUGE scores (e.g., ROUGE-1, ROUGE-2, ROUGE-L) between the\n",
    "    generated answer (actual_output) and the expected output.\n",
    "    \n",
    "    These scores reflect the recall-oriented overlap between the generated and reference texts.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.score = 0\n",
    "        self.details = {}\n",
    "\n",
    "    def measure(self, test_case: LLMTestCase) -> float:\n",
    "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "        scores = scorer.score(test_case.expected_output, test_case.actual_output)\n",
    "        # For simplicity, we can average the three ROUGE scores (using F-measure)\n",
    "        self.details = scores\n",
    "        self.score = np.mean([score.fmeasure for score in scores.values()])\n",
    "        return self.score\n",
    "\n",
    "class METEORMetric:\n",
    "    \"\"\"\n",
    "    METEOR Metric calculates the METEOR score between the generated answer (actual_output)\n",
    "    and the expected output. METEOR is designed to address some weaknesses of BLEU.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.score = 0\n",
    "\n",
    "    def measure(self, test_case: LLMTestCase) -> float:\n",
    "        self.score = meteor_score([test_case.expected_output], test_case.actual_output)\n",
    "        return self.score\n",
    "\n",
    "class FactualConsistencyMetric:\n",
    "    \"\"\"\n",
    "    FactualConsistencyMetric measures the factual consistency between the generated answer \n",
    "    and the retrieved context by computing the cosine similarity (using TF-IDF vectors)\n",
    "    between the answer and the combined retrieval context.\n",
    "    \n",
    "    A higher score indicates a better alignment of the generated answer with the context.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.score = 0\n",
    "\n",
    "    def measure(self, test_case: LLMTestCase) -> float:\n",
    "        answer = test_case.actual_output\n",
    "        context = \" \".join(test_case.retrieval_context)\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vectors = vectorizer.fit_transform([answer, context])\n",
    "        similarity = cosine_similarity(vectors[0:1], vectors[1:2])[0][0]\n",
    "        self.score = similarity\n",
    "        return self.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextualRelevancyMetric:\n",
    "    def __init__(self):\n",
    "        self.score = 0\n",
    "\n",
    "    def measure(self, test_case: LLMTestCase) -> float:\n",
    "        query = test_case.input\n",
    "        answer = test_case.actual_output\n",
    "        context = \" \".join(test_case.retrieval_context)\n",
    "        \n",
    "        # Compute similarity between query, answer, and context\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vectors = vectorizer.fit_transform([query, answer, context])\n",
    "        query_answer_sim = cosine_similarity(vectors[0:1], vectors[1:2])[0][0]\n",
    "        query_context_sim = cosine_similarity(vectors[0:1], vectors[2:3])[0][0]\n",
    "        \n",
    "        self.score = (query_answer_sim + query_context_sim) / 2\n",
    "        return self.score\n",
    "    \n",
    "\n",
    "\n",
    "class ContextualDiversityMetric:\n",
    "    def __init__(self):\n",
    "        self.score = 0\n",
    "\n",
    "    def measure(self, test_case: LLMTestCase) -> float:\n",
    "        contexts = test_case.retrieval_context\n",
    "        \n",
    "        # Compute pairwise similarity between contexts\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vectors = vectorizer.fit_transform(contexts)\n",
    "        similarity_matrix = cosine_similarity(vectors)\n",
    "        \n",
    "        # Average similarity (lower = more diverse)\n",
    "        avg_similarity = np.mean(similarity_matrix[np.triu_indices(len(contexts), 1)])\n",
    "        self.score = 1 - avg_similarity\n",
    "        return self.score\n",
    "    \n",
    "\n",
    "class ContextualConsistencyMetric:\n",
    "    def __init__(self):\n",
    "        self.score = 0\n",
    "\n",
    "    def measure(self, test_case: LLMTestCase) -> float:\n",
    "        contexts = test_case.retrieval_context\n",
    "        answer = test_case.actual_output\n",
    "        \n",
    "        # Check if answer appears in all contexts\n",
    "        consistent = all([answer in ctx for ctx in contexts])\n",
    "        self.score = 1.0 if consistent else 0.0\n",
    "        return self.score\n",
    "    \n",
    "\n",
    "class TechnicalTermClarityMetric:\n",
    "    def __init__(self):\n",
    "        self.score = 0\n",
    "        self.explanations = []\n",
    "\n",
    "    def measure(self, test_case: LLMTestCase) -> float:\n",
    "        answer = test_case.actual_output\n",
    "        # Regex to detect terms with explanations in parentheses\n",
    "        pattern = r\"([A-Z][a-zA-Z\\s]+) \\((.+?)\\)\"\n",
    "        matches = re.findall(pattern, answer)\n",
    "        \n",
    "        self.explanations = [term[0] for term in matches]\n",
    "        self.score = len(matches) / len(self._detect_technical_terms(answer))\n",
    "        return self.score\n",
    "\n",
    "    def _detect_technical_terms(self, text: str) -> List[str]:\n",
    "        # Replace with your domain-specific term list\n",
    "        technical_terms = [\"attention mechanisms\", \"Transformers\", \"self-attention\"]\n",
    "        return [term for term in technical_terms if term in text]\n",
    "    \n",
    "\n",
    "class QuerySpecificityMetric:\n",
    "    def __init__(self):\n",
    "        self.score = 0\n",
    "\n",
    "    def measure(self, test_case: LLMTestCase) -> float:\n",
    "        query = test_case.input\n",
    "        answer = test_case.actual_output\n",
    "        \n",
    "        # Simple heuristic: Longer answers for specific queries\n",
    "        query_words = len(query.split())\n",
    "        answer_words = len(answer.split())\n",
    "        self.score = min(answer_words / (query_words * 3), 1.0)\n",
    "        return self.score\n",
    "    \n",
    "\n",
    "class CrossDocumentConsistencyMetric:\n",
    "    def __init__(self):\n",
    "        self.score = 0\n",
    "\n",
    "    def measure(self, test_case: LLMTestCase) -> float:\n",
    "        contexts = test_case.retrieval_context\n",
    "        answer = test_case.actual_output\n",
    "        \n",
    "        # Check if answer appears in all contexts\n",
    "        consistent = all([answer in ctx for ctx in contexts])\n",
    "        self.score = 1.0 if consistent else 0.0\n",
    "        return self.score\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rag_system(test_cases):\n",
    "    metrics = [\n",
    "        RAGASContextualPrecisionMetric(threshold=0.7),\n",
    "        RAGASFaithfulnessMetric(threshold=0.8),\n",
    "        RAGASContextualRecallMetric(threshold=0.6),\n",
    "        RAGASAnswerRelevancyMetric(threshold=0.7),\n",
    "        ContextualRelevancyMetric(),\n",
    "        ContextualDiversityMetric(),\n",
    "        ContextualConsistencyMetric(),\n",
    "        TechnicalTermClarityMetric(),\n",
    "        QuerySpecificityMetric(),\n",
    "        CrossDocumentConsistencyMetric(),\n",
    "        # New quantitative metrics:\n",
    "        BLEUMetric(),\n",
    "        ROUGEMetric(),\n",
    "        METEORMetric(),\n",
    "        FactualConsistencyMetric()\n",
    "    ]\n",
    "    \n",
    "    return evaluate(test_cases, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate_rag_system(test_cases)\n",
    "for metric in results:\n",
    "    metric_name = metric.__class__.__name__\n",
    "    # For ROUGEMetric, include additional details if available.\n",
    "    if metric_name == \"ROUGEMetric\":\n",
    "        print(f\"{metric_name}: {metric.score:.3f} (Details: {metric.details}) (Passed: {metric.score >= 0.0})\")\n",
    "    else:\n",
    "        print(f\"{metric_name}: {metric.score:.3f} (Passed: {metric.score >= getattr(metric, 'threshold', 0)})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
